#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
api_health_probe.py ‚Äî ÈÅ∏ÂÆö„Éó„É≠„Ç∞„É©„É†‰æùÂ≠òAPIÔºàYahoo Finance / SEC / FinnhubÔºâ„ÅÆÁ∑èÂêà„Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ
Usage:
  export SLACK_WEBHOOK_URL=...
  export FINNHUB_API_KEY=...            # ‰ªªÊÑèÔºàÁÑ°„Åë„Çå„Å∞ Finnhub„ÅØSKIPPEDÔºâ
  export SEC_EMAIL=you@example.com      # Êé®Â•®ÔºàSEC User-Agent „Å´‰ΩøÁî®Ôºâ
  python tools/api_health_probe.py
Env (optional):
  CSV_CURRENT=./current.csv
  CSV_CANDIDATE=./candidate.csv
  YF_PERIOD=1y
  YF_MIN_LEN=120
  TIMEOUT_MS_WARN=5000
  MAX_WORKERS=8
  SOFT_FAIL=0   # 1„Å™„ÇâÂ∏∏„Å´exit 0
Exit codes:
  HEALTHY=0, DEGRADED=10, DOWN=20 ÔºàSOFT_FAIL=1„Å™„ÇâÂ∏∏„Å´0Ôºâ
"""
import os, sys, time, json, math, csv, re, concurrent.futures as cf
from typing import List, Dict, Tuple
import pandas as pd
import numpy as np
import requests
import yfinance as yf

# ---- Settings
CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
YF_PERIOD   = os.getenv("YF_PERIOD","1y")
YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
FINN_KEY    = os.getenv("FINNHUB_API_KEY")
SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
SEC_EMAIL   = os.getenv("SEC_EMAIL","")
MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
# ‚Äú‰ªªÊÑèAPI‚Äù„ÅÆÊâ±„ÅÑÔºö„Åì„Åì„Å´ÂàóÊåô„Åï„Çå„ÅüAPI„ÅåDOWN„Åß„ÇÇÂÖ®‰Ωì„ÅØÊúÄÂ§ßDEGRADEDÊ≠¢„Åæ„Çä
OPTIONAL_APIS = set([x.strip().upper() for x in os.getenv("OPTIONAL_APIS","FINNHUB").split(",") if x.strip()])
# ÈÄÄÂá∫Êù°‰ª∂ÔºàÊó¢ÂÆö: DEGRADEDÔºâ„ÄÇDOWN„Å´„Åô„Çå„Å∞„ÄåDOWN„ÅÆÊôÇ„Å†„ÅëÂ§±Êïó„Äç
EXIT_ON_LEVEL = os.getenv("EXIT_ON_LEVEL","DEGRADED").upper()

# ---- Utils
def _now_ms() -> int: return int(time.time()*1000)

def _post_slack(text: str):
    if not SLACK_WEBHOOK:
        print("[SLACK] webhook missing; print only\n"+text); return
    try:
        r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=5)
        print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
    except Exception as e: print(f"[SLACK] send error: {e}")

def _read_tickers(path: str) -> List[str]:
    if not os.path.exists(path): return []
    # 'ticker','symbol','Symbol','Ticker' „ÅÆÂàó„Å´ÂØæÂøú„ÄÇÁÑ°„Åë„Çå„Å∞1ÂàóCSV„ÇÇË®±ÂÆπ„ÄÇ
    try:
        df = pd.read_csv(path)
        for c in ["ticker","symbol","Symbol","Ticker"]:
            if c in df.columns:
                col = df[c].astype(str).str.strip()
                return [t for t in col if t and t.lower()!="nan"]
        with open(path, newline="") as f:
            rd = csv.reader(f)
            vals = [row[0].strip() for row in rd if row]
            if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
            return [v for v in vals if v]
    except Exception:
        return []

def _autodiscover_csv() -> tuple[str|None, str|None]:
    """
    „É™„Éù„Ç∏„Éà„É™ÂÜÖ„Åã„Çâ current*.csv / candidate*.csv „ÇíÂÜçÂ∏∞Êé¢Á¥¢„Åó„ÄÅÊúÄÂàù„Å´Ë¶ã„Å§„Åë„Åü„ÇÇ„ÅÆ„ÇíËøî„Åô„ÄÇ
    ÊòéÁ§∫ÊåáÂÆöÔºàENVÔºâ„Åå„ÅÇ„Çå„Å∞„Åù„Çå„ÇíÂÑ™ÂÖà„ÄÇË¶ã„Å§„Åã„Çâ„Å™„Åë„Çå„Å∞ None„ÄÇ
    """
    cur = CSV_CURRENT if os.path.exists(CSV_CURRENT) else None
    cand = CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None
    if cur and cand:
        return cur, cand

    for root, _, files in os.walk(".", topdown=True):
        for fn in files:
            if not fn.lower().endswith(".csv"):
                continue
            path = os.path.join(root, fn)
            name = fn.lower()
            if not cur and "current" in name:
                cur = path
            if not cand and "candidate" in name:
                cand = path
        if cur and cand:
            break
    return cur, cand

def _fmt_ms(ms: int) -> str:
    return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"

# ---- Ticker Ê≠£Ë¶èÂåñÔºàYFÁî®Ôºâ
def _yf_variants(sym: str):
    s = (sym or "").upper()
    cands = []
    def add(x):
        if x and x not in cands: cands.append(x)
    add(s)
    add(s.replace(".","-"))   # BRK.B -> BRK-B, PBR.A -> PBR-A
    add(re.sub(r"[.\-^]", "", s))  # Ë®òÂè∑Èô§Âéª
    return cands

# ================================================================
# Yahoo Finance: price series „Éò„É´„Çπ
# ================================================================
def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
    t0 = _now_ms()
    data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
    close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
    per_ticker_missing = {}
    nf=[]          # ‰∏ÄÊã¨„Åß„ÇÇÂà•ÂêçÂÜçË©¶Ë°å„Åß„ÇÇÂèñÂæó„Åß„Åç„Åö
    missing=[]     # Âàó„ÅØ„ÅÇ„Çã„ÅåNaN/‰∏çË∂≥
    ok=[]          # ÂïèÈ°å„Å™„Åó
    alias_fixed=[] # (orig, alias) Âà•Âêç„ÅßÂõûÂæ©
    for t in tickers:
        if t not in close.columns:
            # Á∞°Êòì„Éé„Éº„Éû„É©„Ç§„Ç∫Âæå„ÄÅÂÄãÂà•„Åß5d„Å†„ÅëÂÜçÂèñÂæó„Åó„Å¶ÊúÄ‰ΩéÈôê„ÅÆÁîüÂ≠òÁ¢∫Ë™ç
            recovered = False
            for alias in _yf_variants(t):
                try:
                    s = yf.Ticker(alias).history(period="5d", auto_adjust=True)["Close"]
                    if isinstance(s, pd.Series) and s.notna().sum() > 0:
                        recovered = True
                        alias_fixed.append((t, alias))
                        break
                except Exception:
                    pass
            if not recovered:
                nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
            # ÂÜçÂèñÂæó„ÅßÂõûÂæ©„Åó„ÅüÂ†¥Âêà„ÅØOKÊâ±„ÅÑÔºàdates/max_gap„ÅØÁ©∫„ÅÆ„Åæ„ÅæÔºâ
            ok.append(t); per_ticker_missing.setdefault(t, {"dates":set(),"max_gap":0}); continue
        s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
        isna = s.isna().values; idx = s.index
        total_nan = int(isna.sum()); cur=max_gap=0
        dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
        for v in isna:
            if v: cur+=1
            else:
                if cur>0: max_gap=max(max_gap,cur); cur=0
        if cur>0: max_gap=max(max_gap,cur)
        per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
        if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
        else: ok.append(t)
    ms = _now_ms()-t0
    level = "HEALTHY" if len(ok)==len(tickers) else ("DEGRADED" if len(ok)>=len(tickers)//2 else "DOWN")
    slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
    return f"YF_PRICE:{level} ok={len(ok)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
        "level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
        "per_ticker_missing":per_ticker_missing,
        "alias_fixed": alias_fixed
    }

# ================================================================
# Yahoo Finance: fast_info.lastPrice „Éò„É´„Çπ
# ================================================================
def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
    t0 = _now_ms(); tk = yf.Tickers(" ".join(tickers)); bad=[]
    for t in tickers:
        try:
            v = tk.tickers[t].fast_info.get("lastPrice", None)
            if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
        except Exception: bad.append(t)
    ms=_now_ms()-t0
    level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
    slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
    return f"YF_INFO:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
        "level":level,"latency_ms":ms,"bad":bad
    }

# ================================================================
# Yahoo Finance: financialsÔºàCFO/Capex/FCFÔºâ„Éò„É´„Çπ
# ================================================================
_CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
               "capex":["Capital Expenditure","Capital Expenditures"]}
def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
    if df is None or df.empty: return None
    idx_lower = {str(i).lower():i for i in df.index}
    for n in names:
        k = n.lower()
        if k in idx_lower: return df.loc[idx_lower[k]]
    return None
def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
    if s is None or s.empty: return None
    v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
def _latest(s: pd.Series|None) -> float|None:
    if s is None or s.empty: return None
    v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None

def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
    t0=_now_ms(); bad=[]
    def one(t):
        try:
            tk = yf.Ticker(t)
            qcf = tk.quarterly_cashflow
            cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
            cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
            fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
            cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
            if any(v is None for v in (cfo,cap,fcf)):
                acf = tk.cashflow
                if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
                if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
                if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
            return None if all(v is not None for v in (cfo,cap,fcf)) else t
        except Exception: return t
    with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        for r in ex.map(one, tickers):
            if r: bad.append(r)
    ms=_now_ms()-t0
    level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
    slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
    return f"YF_FIN:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
        "level":level,"latency_ms":ms,"bad":bad
    }

# ================================================================
# Finnhub: cash-flowÔºàCFO/CapexÔºâ„Éò„É´„ÇπÔºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºâ
# ================================================================
_FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
_FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]

def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
    for i in range(retries):
        r = session.get(url, params=params, timeout=15)
        if r.status_code==429:
            time.sleep(min(2**i*sleep_s, 4.0)); continue
        r.raise_for_status(); return r.json()
    r.raise_for_status()

def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
    if not FINN_KEY:
        return "FINNHUB:SKIPPED (no key)", dict(level="SKIPPED",bad=[])
    t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
    for sym in tickers:
        try:
            j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
            arr=j.get("cashFlow") or []
            def pick(item,keys):
                for k in keys:
                    if k in item and item[k] is not None: return item[k]
            cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
            cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
            cfo_ttm = np.nansum([np.nan if v is None else float(v) for v in cfo_vals]) if any(v is not None for v in cfo_vals) else None
            cap_ttm = np.nansum([np.nan if v is None else float(v) for v in cap_vals]) if any(v is not None for v in cap_vals) else None
            if cfo_ttm is None or cap_ttm is None:
                j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"annual","limit":1,"token":FINN_KEY})
                arr=j.get("cashFlow") or []
                if arr:
                    item0=arr[0]
                    if cfo_ttm is None:
                        v=pick(item0,_FINN_CFO_KEYS); 
                        if v is not None: cfo_ttm=float(v)
                    if cap_ttm is None:
                        v=pick(item0,_FINN_CAPEX_KEYS); 
                        if v is not None: cap_ttm=float(v)
            if cfo_ttm is None or cap_ttm is None: bad.append(sym)
        except Exception: bad.append(sym)
    ms=_now_ms()-t0
    level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
    slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
    return f"FINNHUB:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
        "level":level,"latency_ms":ms,"bad":bad
    }

# ================================================================
# SEC: companyfactsÔºàRevenue/EPSÔºâ„Éò„É´„Çπ
# ================================================================
def _sec_headers():
    """
    SEC„ÅØÈÄ£Áµ°ÂÖà‰ªò„ÅçUser-Agent/From„ÇíÂº∑„ÅèÊé®Â•®„Éª‰∏ÄÈÉ®„ÅßÂøÖÈ†à„ÄÇ
    SEC_EMAIL„ÅåÁ©∫„Å™„ÇâÊúÄ‰ΩéÈôê„ÅÆUA„Å´„Åó„Å§„Å§„ÄÅ403Áô∫ÁîüÊôÇ„ÅØ‰∏ä‰Ωç„ÅßSKIPÊâ±„ÅÑ„Å´„Åô„Çã„ÄÇ
    """
    ua = (f"api-health-probe/1 (+mailto:{SEC_EMAIL})" if SEC_EMAIL else "api-health-probe/1")
    hdr = {
        "User-Agent": ua[:200],
        "Accept": "application/json",
    }
    if SEC_EMAIL:
        hdr["From"] = SEC_EMAIL[:200]
    return hdr

def _sec_get(url: str, params=None, retries=3, sleep_s: float=0.5):
    """
    403„ÇÑ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Ç®„É©„Éº„ÅØ‰∏ä‰Ωç„ÅßSKIPÂà§ÂÆö„Åß„Åç„Çã„Çà„ÅÜ None „ÇíËøî„Åô„ÄÇ
    """
    for i in range(retries):
        try:
            r = requests.get(url, params=params or {}, headers=_sec_headers(), timeout=15)
            if r.status_code==429:
                time.sleep(min(2**i*sleep_s, 4.0)); continue
            if r.status_code==403:
                # UA/FromÊú™Ë®≠ÂÆö„ÇÑ„Ç¢„ÇØ„Çª„ÇπÂà∂Èôê„ÄÇ‰∏ä‰Ωç„ÅßSKIP„ÄÇ
                return None
            r.raise_for_status(); return r.json()
        except Exception:
            time.sleep(min(2**i*sleep_s, 2.0))
    return None

def _sec_ticker_map() -> Dict[str,str]:
    j = _sec_get("https://www.sec.gov/files/company_tickers.json")
    if j is None:
        return {}
    out={}
    it=(j.values() if isinstance(j,dict) else j)
    for item in it:
        try:
            t=(item.get("ticker") or item.get("TICKER") or "").upper()
            cik=str(item.get("cik_str") or item.get("CIK") or "").zfill(10)
            if t and cik: out[t]=cik
        except Exception: continue
    return out

SEC_REV_TAGS=["Revenues","RevenueFromContractWithCustomerExcludingAssessedTax","SalesRevenueNet","SalesRevenueGoodsNet","SalesRevenueServicesNet","Revenue"]
SEC_EPS_TAGS=["EarningsPerShareDiluted","EarningsPerShareBasicAndDiluted","EarningsPerShare","EarningsPerShareBasic"]

def _normalize_for_sec(sym: str) -> List[str]:
    s=(sym or "").upper(); outs=[]; add=lambda x: outs.append(x) if x and x not in outs else None
    add(s); add(s.replace(".","-")); add(s.replace("-","")); add(s.replace(".","")); return outs

def _units_for_tags(facts: dict, spaces: List[str], tags: List[str]) -> list:
    got=[]
    for sp in spaces:
        d=(facts.get("facts") or {}).get(sp) or {}
        for tg in tags:
            arr=(d.get(tg) or {}).get("units") or {}
            for unit, vals in (arr.items() if isinstance(arr,dict) else []):
                if isinstance(vals,list) and vals: got.append(vals)
    return got

def _series_q_and_a(arrs: list) -> Tuple[list, list]:
    q_pairs,a_pairs=[],[]
    for vals in arrs:
        for v in vals:
            try:
                dt=v.get("end") or v.get("fy"); val=float(v.get("val")); form=(v.get("form") or "").upper()
                if "10-Q" in form or "6-K" in form or form=="Q": q_pairs.append((dt,val))
                elif "10-K" in form or "20-F" in form or form=="K": a_pairs.append((dt,val))
            except Exception: pass
    q_pairs=sorted(q_pairs,key=lambda x: str(x[0]),reverse=True)
    a_pairs=sorted(a_pairs,key=lambda x: str(x[0]),reverse=True)
    return q_pairs,a_pairs

def sec_health(tickers: List[str]) -> Tuple[str, Dict]:
    t0=_now_ms(); t2cik=_sec_ticker_map(); bad=[]
    # CIK„Éû„ÉÉ„Éó„ÅåÂèñ„Çå„Å™„ÅÑÔºà403/„Éç„ÉÉ„ÉàÊñ≠/UAÊú™Ë®≠ÂÆö„Å™„Å©Ôºâ„ÅØSKIPPED
    if not t2cik:
        ms=_now_ms()-t0
        note="no SEC_EMAIL/403" if not SEC_EMAIL else "SEC endpoint blocked"
        det=f"SEC:SKIPPED ({note}) latency={_fmt_ms(ms)}"
        return det,{"level":"SKIPPED","latency_ms":ms,"bad":[]}
    for t in tickers:
        cands=_normalize_for_sec(t); cik=next((t2cik.get(x) for x in cands if t2cik.get(x)), None)
        if not cik: bad.append(t); continue
        try:
            j=_sec_get(f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json")
            if j is None:
                bad.append(t); continue
            rev_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_REV_TAGS)
            eps_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_EPS_TAGS)
            rev_q,rev_a=_series_q_and_a(rev_arr); eps_q,eps_a=_series_q_and_a(eps_arr)
            if not (rev_q or rev_a) or not (eps_q or eps_a): bad.append(t)
        except Exception: bad.append(t)
        time.sleep(0.30)  # SECË≤†Ëç∑ÈÖçÊÖÆ
    ms=_now_ms()-t0
    level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
    slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
    return f"SEC:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
        "level":level,"latency_ms":ms,"bad":bad
    }

# ================================================================
# Orchestration
# ================================================================
def main():
    cur_path, cand_path = _autodiscover_csv()
    if not cur_path or not cand_path:
        msg = f"‚ö†Ô∏è CSV not found. cur={cur_path} cand={cand_path} (set CSV_CURRENT/CSV_CANDIDATE or place files)"
        print(msg); _post_slack(msg)
        if SOFT_FAIL:
            sys.exit(0)
        sys.exit(78)

    tickers=sorted(set(_read_tickers(cur_path)+_read_tickers(cand_path)))
    if not tickers:
        msg = f"‚ö†Ô∏è No tickers from CSV. cur={cur_path} cand={cand_path}"
        print(msg); _post_slack(msg)
        if SOFT_FAIL:
            sys.exit(0)
        sys.exit(78)

    # YF
    det_price,meta_price=yf_price_health(tickers)
    det_info ,meta_info =yf_fastinfo_health(tickers)
    det_fin  ,meta_fin  =yf_financials_health(tickers)

    # SEC
    det_sec  ,meta_sec  =sec_health(tickers)

    # FinnhubÔºàÂøÖË¶ÅÊôÇ„ÅÆ„Åø„ÄÇYFË≤°ÂãôNGÈäòÊüÑ„Å∏„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ§úË®ºÔºâ
    need_finn=meta_fin["bad"]
    det_finn,meta_finn  =finnhub_health(need_finn if need_finn else tickers[:0])

    # APIÂà•„É¨„Éô„É´
    levels_map = {
        "YF_PRICE": meta_price["level"],
        "YF_INFO" : meta_info ["level"],
        "YF_FIN"  : meta_fin  ["level"],
        "SEC"     : meta_sec  ["level"],
        "FINNHUB" : meta_finn.get("level","SKIPPED"),
    }
    pri={"DOWN":3,"DEGRADED":2,"HEALTHY":1,"SKIPPED":0}
    # „Ç≥„Ç¢APIÔºàOPTIONAL_APIS ‰ª•Â§ñÔºâ„ÅÆ„ÉØ„Éº„Çπ„Éà
    core_levels = [lvl for api,lvl in levels_map.items() if api not in OPTIONAL_APIS]
    core_worst = max(core_levels, key=lambda x: pri.get(x,0)) if core_levels else "HEALTHY"
    # ÂÖ®‰Ωì„ÉØ„Éº„Çπ„ÉàÔºàË°®Á§∫Áî®Ôºâ
    all_worst  = max(levels_map.values(), key=lambda x: pri.get(x,0))
    # „Åü„Å†„Åó„ÄÅDOWN „Åå OPTIONAL_APIS „ÅÆ„Åø„Åã„ÇâÊù•„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØÂÖ®‰Ωì„Çí DEGRADED „Åæ„Åß„Å´ÊäëÂà∂
    if all_worst=="DOWN" and core_worst!="DOWN":
        worst = "DEGRADED"
    else:
        worst = all_worst
    emoji={"HEALTHY":"‚úÖ","DEGRADED":"‚ö†Ô∏è","DOWN":"üõë"}.get(worst,"‚ÑπÔ∏è")

    # ÂÖ±ÈÄöÈöúÂÆ≥ÔºàÂêå‰∏ÄÊó•„Å†„Åë„ÅÆÊ¨†Êêç„ÅåÈÅéÂçäÔºâ„ÇíÁ∞°ÊòìÊ§úÁü•Ôºà‰æ°Ê†ºÁ≥ªÂàó„Éô„Éº„ÇπÔºâ
    outage_note=""
    try:
        from collections import Counter
        missing_dates=meta_price.get("per_ticker_missing",{})
        date_counter=Counter(); one_day_missing=0
        for _,info in missing_dates.items():
            dates=info.get("dates",set()); max_gap=info.get("max_gap",0)
            if len(dates)==1 and max_gap==1:
                one_day_missing+=1; date_counter.update(dates)
        threshold=max(1,len(tickers)//2)
        if one_day_missing>=threshold:
            (missing_day,hits),=date_counter.most_common(1)
            outage_note=f" | OUTAGE: common_missing_day={missing_day} hits={hits}"
            if worst=="HEALTHY":
                worst="DEGRADED"; emoji="üü†"
    except Exception:
        pass

    summary=f"{emoji} API_HEALTH {worst}{outage_note} (exit_on={EXIT_ON_LEVEL})\n{det_price} | {det_info} | {det_fin} | {det_sec} | {det_finn}"
    has_problem=("DEGRADED" in worst) or ("DOWN" in worst)

    if has_problem:
        def head_problem(xs): return ", ".join(xs[:10]) + (f" ‚Ä¶(+{len(xs)-10})" if len(xs)>10 else "")
        lines=[]
        if meta_price["missing"] or meta_price["nf"]:
            xs=[*meta_price["nf"],*meta_price["missing"]]; lines.append(f"YF_PRICE NG: {head_problem(xs)}")
        if meta_info["bad"]:  lines.append(f"YF_INFO NG: {head_problem(meta_info['bad'])}")
        if meta_fin["bad"]:   lines.append(f"YF_FIN NG: {head_problem(meta_fin['bad'])}")
        if meta_sec["bad"]:   lines.append(f"SEC NG: {head_problem(meta_sec['bad'])}")
        if meta_finn.get("bad"): lines.append(f"FINNHUB NG: {head_problem(meta_finn['bad'])}")
        text=summary + ("\n" + "\n".join(lines) if lines else "")
    else:
        text=summary

    # ‚ÄúÂ§â„Å™„ÉÜ„Ç£„ÉÉ„Ç´„Éº‚Äù„ÅØÊØéÂõûÈÄöÂ†±
    def head_pair(pairs):
        xs=[f"{a}->{b}" for (a,b) in pairs[:10]]
        return ", ".join(xs) + (f" ‚Ä¶(+{len(pairs)-10})" if len(pairs)>10 else "")
    def head(xs):
        return ", ".join(xs[:10]) + (f" ‚Ä¶(+{len(xs)-10})" if len(xs)>10 else "")
    alias_fixed = meta_price.get("alias_fixed", [])
    still_missing = meta_price.get("nf", [])
    weird_lines = []
    if alias_fixed:
        weird_lines.append(f"Weird tickers (alias fixed): {head_pair(alias_fixed)}")
    if still_missing:
        weird_lines.append(f"Weird tickers (not found): {head(still_missing)}")
    if weird_lines:
        text = text + "\n" + "\n".join(weird_lines)

    print(text); _post_slack(text)
    if SOFT_FAIL: sys.exit(0)
    # ÈÄÄÂá∫Âà§ÂÆöÔºöÂü∫Ê∫ñ„ÅØ‚Äú„Ç≥„Ç¢API„ÅÆÁä∂ÊÖã‚Äù„ÄÇOPTIONAL„ÅåDOWN„Åß„ÇÇ core„ÅåHEALTHY/DEGRADED„Å™„ÇâÁ∑©Âíå„ÄÇ
    exit_by = core_worst if core_worst!="HEALTHY" else worst
    def _rank(x): return {"HEALTHY":1,"DEGRADED":2,"DOWN":3}.get(x,0)
    # EXIT_ON_LEVEL Êú™Ê∫Ä„Å™„ÇâÊàêÂäüÁµÇ‰∫Ü
    if _rank(exit_by) < _rank(EXIT_ON_LEVEL):
        sys.exit(0)
    sys.exit(20 if exit_by=="DOWN" else 10)

if __name__=="__main__":
    main()
