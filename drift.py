import pandas as pd, yfinance as yf
import numpy as np
import requests
import os
import json
import time
from pathlib import Path
import csv
import config

# --- Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã—ãã„å€¤ï¼ˆGrowthã®å¹³å‡DDåŸºæº–ï¼‰---
CD_CAUTION = 0.10   # -10% ã§è­¦æˆ’
CD_EMERG = 0.15   # -15% ã§ç·Šæ€¥

MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
# Slacké€šçŸ¥ç”¨ã®ãƒ¢ãƒ¼ãƒ‰ã‚¢ã‚¤ã‚³ãƒ³
MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸ”´"}
MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}

# --- breadth utilities (factor parity) ---
BENCH = "^GSPC"
CAND_PRICE_MAX = 450.0
RESULTS_DIR = "results"
os.makedirs(RESULTS_DIR, exist_ok=True)

def _state_file():
    return str(Path(RESULTS_DIR) / "breadth_state.json")


def _load_state_dict() -> dict:
    try:
        with open(_state_file()) as fh:
            data = json.load(fh)
        return data if isinstance(data, dict) else {}
    except Exception:
        return {}


def _save_state_dict(state: dict):
    try:
        with open(_state_file(), "w") as fh:
            json.dump(state, fh)
    except Exception:
        pass


def load_breadth_mode(default: str = "NORMAL") -> str:
    state = _load_state_dict()
    mode = state.get("breadth_mode", state.get("mode", default))
    return mode if mode in MODE_RANK else default


def save_breadth_mode(mode: str):
    state = _load_state_dict()
    state["breadth_mode"] = mode
    _save_state_dict(state)


def load_final_mode(default: str = "NORMAL") -> str:
    state = _load_state_dict()
    mode = state.get("final_mode", state.get("mode", default))
    return mode if mode in MODE_RANK else default


def save_final_mode(mode: str):
    state = _load_state_dict()
    state["final_mode"] = mode
    state.setdefault("breadth_mode", state.get("breadth_mode", mode))
    state["mode"] = mode
    _save_state_dict(state)


def _read_csv_list(fname):
    p = Path(__file__).with_name(fname)
    if not p.exists(): return []
    return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()


# leaders.csv èª­ã¿è¾¼ã¿ï¼ˆresults/leaders.csv, 1åˆ—æƒ³å®šï¼‰
def _read_leaders_symbols() -> list[str]:
    p = Path(__file__).with_name("results").joinpath("leaders.csv")
    df = pd.read_csv(p, header=None)
    return sorted(set(df.iloc[:,0].astype(str).str.strip().str.upper().tolist()))

def _load_universe():
    # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
    exist = _read_csv_list("current_tickers.csv")
    cand  = _read_csv_list("candidate_tickers.csv")
    cand_info = yf.Tickers(" ".join(cand)) if cand else None
    cand_keep = []
    for t in cand:
        try:
            px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
        except Exception:
            px = float("inf")
        if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
            cand_keep.append(t)
    tickers = sorted(set(exist + cand_keep))
    return exist, cand_keep, tickers


def _fetch_prices_600d(tickers):
    data = yf.download(
        tickers + [BENCH],
        period="600d",
        auto_adjust=True,
        progress=False,
        threads=False,
    )
    close = data["Close"]
    px = close.dropna(how="all", axis=1).ffill(limit=2)
    spx = close[BENCH].reindex(px.index).ffill()
    return px, spx


def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
    # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
    import numpy as np, pandas as pd
    if px is None or px.empty:
        return pd.Series(dtype=int)
    px = px.dropna(how="all", axis=1)
    if win_days and win_days > 0:
        px = px.tail(win_days)
    if px.empty:
        return pd.Series(dtype=int)
    # æ¬ æå¸å
    px = px.ffill(limit=2)
    spx = spx.reindex(px.index).ffill()

    ma50  = px.rolling(50,  min_periods=50).mean()
    ma150 = px.rolling(150, min_periods=150).mean()
    ma200 = px.rolling(200, min_periods=200).mean()

    tt = (px > ma150)
    tt &= (px > ma200)
    tt &= (ma150 > ma200)
    tt &= (ma200 - ma200.shift(21) > 0)
    tt &= (ma50  > ma150)
    tt &= (ma50  > ma200)
    tt &= (px    > ma50)

    lo252 = px.rolling(252, min_periods=252).min()
    hi252 = px.rolling(252, min_periods=252).max()
    tt &= (px.divide(lo252).sub(1.0) >= 0.30)
    tt &= (px >= (0.75 * hi252))

    r12  = px.divide(px.shift(252)).sub(1.0)
    br12 = spx.divide(spx.shift(252)).sub(1.0)
    r1   = px.divide(px.shift(22)).sub(1.0)
    br1  = spx.divide(spx.shift(22)).sub(1.0)
    rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
    tt &= (rs >= 0.10)

    return tt.fillna(False).sum(axis=1).astype(int)


def build_breadth_header():
    # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
    exist, cand, tickers = _load_universe()
    if not tickers:
        return "", "NORMAL", 0
    px, spx = _fetch_prices_600d(tickers)
    win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
    C_ts = trend_template_breadth_series(px, spx, win_days=win)
    if C_ts.empty:
        return "", "NORMAL", 0
    warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
    base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
    C_full = int(C_ts.iloc[-1])

    q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
    q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
    q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))

    # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
    N_G = config.N_G
    th_in_rec   = max(N_G, q05)
    th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
    th_norm_rec = max(3*N_G, q60)

    use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
    if use_calib:
        th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
    else:
        th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
        th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
        th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
        th_src = "æ‰‹å‹•"

    prev = load_breadth_mode("NORMAL")
    if   prev == "EMERG":
        mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
    elif prev == "CAUTION":
        mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
    else:
        mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
    save_breadth_mode(mode)

    mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
    eff_days = len(base)

    lead_lines = [
        f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
        f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
        "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
        f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
        f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
        f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
        f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
        f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
        f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
        f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
    ]
    return "```" + "\n".join(lead_lines) + "```", mode, C_full


def _format_mode(mode: str) -> str:
    upper = (mode or "NORMAL").upper()
    return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"


def _gcd_mode_today(g_syms: list[str]) -> tuple[str, float]:
    """
    ç¾åœ¨ã®Growthç¾¤ã«ã¤ã„ã¦ã€Low_today / Peak60(High) ã®ç­‰åŠ é‡å¹³å‡ã‹ã‚‰ G-CD(%) ã‚’ç®—å‡ºã—ã€ãƒ¢ãƒ¼ãƒ‰ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (gcd_mode, gcd_pct)  â€»gcd_pctã¯æ­£ã®%ï¼ˆä¾‹ 11.3 ã¯ -11.3%ã®ä¸‹è½ï¼‰
    """

    if not g_syms:
        print("ğŸ“ audit[G-CD details]: GéŠ˜æŸ„ãŒç©ºã®ãŸã‚ç®—å‡ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    try:
        df = yf.download(
            g_syms,
            period="100d",
            interval="1d",
            auto_adjust=False,
            progress=False,
        )
    except Exception as e:
        print(f"âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    if not isinstance(df, pd.DataFrame) or df.empty:
        print("âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    hi_all = df.get("High") if isinstance(df, pd.DataFrame) else None
    lo_all = df.get("Low") if isinstance(df, pd.DataFrame) else None
    if hi_all is None or lo_all is None:
        print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã¾ã™")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    if isinstance(hi_all, pd.Series):
        hi_all = hi_all.to_frame(name=g_syms[0])
    if isinstance(lo_all, pd.Series):
        lo_all = lo_all.to_frame(name=g_syms[0])

    if hi_all.empty or lo_all.empty:
        print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    peak60 = hi_all.rolling(60, min_periods=20).max().tail(1).iloc[0]
    low_today = lo_all.tail(1).iloc[0]

    details: list[tuple[str, float, float, float, float]] = []
    for sym in g_syms:
        p = float(peak60.get(sym, float("nan"))) if hasattr(peak60, "get") else float("nan")
        lt = float(low_today.get(sym, float("nan"))) if hasattr(low_today, "get") else float("nan")
        if pd.notna(p) and p > 0 and pd.notna(lt) and lt > 0:
            ratio = lt / p
            ddpct = (1.0 - ratio) * 100.0
            details.append((sym, p, lt, ratio, ddpct))

    if not details:
        print("âš ï¸ audit[G-CD details]: æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
        return "NORMAL", 0.0

    details.sort(key=lambda x: x[4], reverse=True)
    today = pd.Timestamp.today(tz="America/New_York").date().isoformat()
    print(f"ğŸ“ audit[G-CD details] {today}  G={len(g_syms)}")
    print("  SYMBOL        Peak60(H)     Low(T)     ratio    DD%")
    for sym, peak, low, ratio, ddpct in details:
        print(f"  {sym:<8}  {peak:>12.6g}  {low:>10.6g}   {ratio:>6.3f}  {ddpct:>6.2f}")

    avg_ratio = float(np.mean([r for _, _, _, r, _ in details]))
    gcd_pct = max(0.0, (1.0 - avg_ratio) * 100.0)
    mode = "EMERG" if gcd_pct >= CD_EMERG * 100 else "CAUTION" if gcd_pct >= CD_CAUTION * 100 else "NORMAL"
    print(
        f"ğŸ“ audit[G-CD summary]: avg_low/peak60={avg_ratio:.4f}  drawdown={gcd_pct:.2f}%  => {mode}"
    )
    return mode, gcd_pct
# Debug flag
debug_mode = False  # set to True for detailed output

# --- Finnhub settings & helper ---
FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
if not FINNHUB_API_KEY:
    raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")

RATE_LIMIT = 55  # requests per minute (free tier is 60)
call_times = []


def finnhub_get(endpoint, params):
    """Call Finnhub API with basic rate limiting."""
    now = time.time()
    cutoff = now - 60
    while call_times and call_times[0] < cutoff:
        call_times.pop(0)
    if len(call_times) >= RATE_LIMIT:
        sleep_time = 60 - (now - call_times[0])
        time.sleep(sleep_time)
    params = {**params, "token": FINNHUB_API_KEY}
    try:
        resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
        resp.raise_for_status()
        data = resp.json()
    except requests.exceptions.JSONDecodeError as e:
        print(f"âš ï¸ Finnhub API JSON decode error: {e}")
        return {}
    except Exception as e:
        print(f"âš ï¸ Finnhub API error: {e}")
        return {}
    call_times.append(time.time())
    return data


def fetch_price(symbol):
    try:
        data = finnhub_get("quote", {"symbol": symbol})
        price = data.get("c")
        return float(price) if price not in (None, 0) else float("nan")
    except Exception:
        return float("nan")


def fetch_vix_ma5():
    """Retrieve VIX 5-day moving average via yfinance."""
    try:
        vix = (
            yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
            .dropna()
            .tail(5)
        )
        if len(vix) < 5:
            return float("nan")
        return vix.mean().item()
    except Exception:
        return float("nan")



# === Minervini-like sell signals ===
def _yf_df(sym, period="6mo"):
    """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
    try:
        df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
        if df is None or df.empty:
            return None
        return df.dropna().assign(
            ma20=lambda d: d["Close"].rolling(20).mean(),
            ma50=lambda d: d["Close"].rolling(50).mean(),
            vol50=lambda d: d["Volume"].rolling(50).mean(),
        )
    except Exception:
        return None


def _scalar(row, col):
    """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
    try:
        v = row[col]
        if hasattr(v, "item"):
            try:
                v = v.item()
            except Exception:
                pass
        return v
    except Exception:
        return float("nan")


def _is_strict_down(seq):
    """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
    try:
        xs = [float(x) for x in seq]
        if any(pd.isna(x) for x in xs) or len(xs) < 4:
            return False
        return all(b < a for a, b in zip(xs[:-1], xs[1:]))
    except Exception:
        return False


def _signals_for_day(df, idx):
    """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
    try:
        sig = []
        d = df.loc[idx]
        close = _scalar(d, "Close")
        ma20 = _scalar(d, "ma20")
        ma50 = _scalar(d, "ma50")
        vol = _scalar(d, "Volume")
        vol50 = _scalar(d, "vol50")

        if pd.notna(close) and pd.notna(ma20) and close < ma20:
            sig.append("20DMAâ†“")

        if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
            sig.append("50DMAâ†“(å¤§å•†ã„)")

        last4 = df.loc[:idx].tail(4)
        last10 = df.loc[:idx].tail(10)

        lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
        reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
        if lows_desc or reds > 5:
            sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")

        ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
        if ups >= 7:
            sig.append("ä¸Šã’åé‡(>70%)")

        last15 = df.loc[:idx].tail(15)
        base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
        if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
            sig.append("+25%/15æ—¥å†…")

        if len(df.loc[:idx]) >= 2:
            t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
            t1_high = _scalar(t1, "High")
            t0_open = _scalar(t0, "Open")
            t0_close = _scalar(t0, "Close")
            if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
                if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
                    sig.append("GUâ†’é™°ç·š")
        return sig
    except Exception:
        return []


def scan_sell_signals(symbols, lookback_days=5):
    """
    ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
    æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
    """
    out = {}
    for s in symbols:
        df = _yf_df(s)
        if df is None or len(df) < 60:
            continue
        alerts = []
        for idx in df.tail(lookback_days).index:
            tags = _signals_for_day(df, idx)
            if tags:
                alerts.append((idx.strftime("%Y-%m-%d"), tags))
        if alerts:
            out[s] = alerts
    return out


def load_portfolio():
    tickers_path = Path(__file__).with_name("current_tickers.csv")
    with tickers_path.open() as f:
        rows = [row for row in csv.reader(f) if row and row[0].strip()]
    n = len(rows)
    portfolio = []
    for row in rows:
        sym = row[0].strip().upper()
        qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
        bucket = row[2].strip().upper() if len(row) > 2 else ""
        entry = {
            "symbol": sym,
            "shares": qty,
            "target_ratio": 1 / n if n else 0.0,
            "bucket": bucket,
        }
        portfolio.append(entry)
    return portfolio


def compute_threshold():
    vix_ma5 = fetch_vix_ma5()
    drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
    return vix_ma5, drift_threshold


def compute_threshold_by_mode(mode: str):
    """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
    m = (mode or "NORMAL").upper()
    cash_ratio = config.CASH_RATIO_BY_MODE.get(
        m, config.CASH_RATIO_BY_MODE.get("NORMAL", 0.10)
    )
    drift_threshold = config.DRIFT_THRESHOLD_BY_MODE.get(
        m, config.DRIFT_THRESHOLD_BY_MODE.get("NORMAL", 12)
    )
    return cash_ratio, drift_threshold


def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
    """
    ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
    cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
    NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
    """
    m = (mode or "NORMAL").upper()
    base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
    now  = config.COUNTS_BY_MODE.get(m, base)
    cash_slots = max(0, base["G"] - now["G"])
    return now["G"], now["D"], cash_slots


def _mode_tail_line(final_mode: str) -> str:
    """â‘ ãƒ–ãƒ­ãƒƒã‚¯è¡¨ç¤ºï¼šæ”¹è¡Œï¼‹ã‚¢ã‚¤ã‚³ãƒ³ã§æ•´å½¢"""
    fm = (final_mode or "NORMAL").upper()
    base_ts = config.TS_BASE_BY_MODE.get(fm, config.TS_BASE_BY_MODE.get("NORMAL", 0.15))
    ts_base_pct = int(round(base_ts * 100))
    d1, d2, d3 = config.TS_STEP_DELTAS_PT
    step30 = max(ts_base_pct - d1, 0)
    step60 = max(ts_base_pct - d2, 0)
    step100 = max(ts_base_pct - d3, 0)
    g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(fm)
    cash_pct = config.CASH_RATIO_BY_MODE.get(fm, config.CASH_RATIO_BY_MODE.get("NORMAL", 0.10)) * 100
    drift_th = config.DRIFT_THRESHOLD_BY_MODE.get(fm, config.DRIFT_THRESHOLD_BY_MODE.get("NORMAL", 12))
    drift_str = "ğŸ”´(åœæ­¢)" if drift_th == float("inf") else f"{int(drift_th)}%"
    return "\n".join([
        "ã€”ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šã€•",
        f"ğŸ¯ TSåŸºæœ¬: -{ts_base_pct}ï¼…ï¼ˆ+30%â†’-{step30}ï¼…ï¼+60%â†’-{step60}ï¼…ï¼+100%â†’-{step100}ï¼…ï¼‰",
        f"ğŸ§© æ¨å¥¨ä¿æœ‰: G{g_cnt}ãƒ»D{d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}ï¼‰",
        f"ğŸ’¼ æ¨å¥¨ç¾é‡‘æ¯”ç‡: {cash_pct:.0f}ï¼…",
        f"ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤: {drift_str}",
    ])


def build_dataframe(portfolio):
    for stock in portfolio:
        price = fetch_price(stock["symbol"])
        stock["price"] = price
        stock["value"] = price * stock["shares"]

    df = pd.DataFrame(portfolio)
    total_value = df["value"].sum()
    df["current_ratio"] = df["value"] / total_value
    df["drift"] = df["current_ratio"] - df["target_ratio"]
    df["drift_abs"] = df["drift"].abs()
    total_drift_abs = df["drift_abs"].sum()
    df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
    df["adjustable"] = (
        (df["adjusted_ratio"] * total_value) >= df["price"]
    ) & df["price"].notna() & df["price"].gt(0)
    return df, total_value, total_drift_abs


def simulate(df, total_value, total_drift_abs, drift_threshold):
    alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
    if alert:
        df["trade_shares"] = df.apply(
            lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
            if r["adjustable"] and r["price"] > 0 else 0,
            axis=1,
        )
        df["new_shares"] = df["shares"] + df["trade_shares"]
        df["new_value"] = df["new_shares"] * df["price"]
        new_total_value = df["new_value"].sum()
        df["simulated_ratio"] = df["new_value"] / new_total_value
        df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
        simulated_total_drift_abs = df["simulated_drift_abs"].sum()
    else:
        df["trade_shares"] = np.nan
        df["new_shares"] = np.nan
        df["new_value"] = np.nan
        new_total_value = np.nan
        df["simulated_ratio"] = np.nan
        df["simulated_drift_abs"] = np.nan
        simulated_total_drift_abs = np.nan
    return df, alert, new_total_value, simulated_total_drift_abs


def prepare_summary(df, total_drift_abs, alert):
    summary = {
        "symbol": "åˆè¨ˆ",
        "shares": df["shares"].sum(),
        "value": df["value"].sum(),
        "current_ratio": np.nan,
        "drift_abs": total_drift_abs,
    }
    if alert:
        summary["trade_shares"] = np.nan
    # Sort details by evaluation value descending before appending summary
    df = df.sort_values(by="value", ascending=False)
    df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
    if alert:
        cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
        df_small = df[cols].copy()
        df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
    else:
        cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
        df_small = df[cols].copy()
        df_small.columns = ["sym", "qty", "val", "now", "|d|"]
    return df_small


def currency(x):
    return f"${x:,.0f}" if pd.notnull(x) else ""


def formatters_for(alert):
    formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
    if alert:
        formatters["Î”qty"] = "{:.0f}".format
    return formatters


def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
    # ğŸ’¼ã¯â‘ ã«é›†ç´„ã—éè¡¨ç¤ºã€‚ğŸ“Šã¯ç¶­æŒã€‚
    header  = f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(int(drift_threshold)) + '%'}\n"
    header += f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
    if alert:
        header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
        header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
    else:
        header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
    return header


def send_slack(text):
    SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
    if not SLACK_WEBHOOK_URL:
        raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
    payload = {"text": text}
    try:
        resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
        resp.raise_for_status()
        print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")


def send_debug(debug_text):
    SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
    if not SLACK_WEBHOOK_URL:
        raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
    debug_payload = {"text": "```" + debug_text + "```"}
    try:
        resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
        resp.raise_for_status()
        print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    portfolio = load_portfolio()
    symbols = [r["symbol"] for r in portfolio]
    # Gé›†åˆã¯ leaders.csv ã‚’ä½¿ç”¨ï¼ˆå­˜åœ¨å‰æï¼‰
    g_syms = _read_leaders_symbols()
    sell_alerts = scan_sell_signals(symbols, lookback_days=5)

    breadth_block, breadth_mode, breadth_score = build_breadth_header()
    gcd_mode, gcd_pct = _gcd_mode_today(g_syms)

    # ãƒ¢ãƒ¼ãƒ‰ã¯ Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDD ã®ã¿ã§æ±ºå®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    final_mode = gcd_mode
    save_final_mode(final_mode)

    cash_ratio, drift_threshold = compute_threshold_by_mode(final_mode)

    df, total_value, total_drift_abs = build_dataframe(portfolio)
    df, alert, new_total_value, simulated_total_drift_abs = simulate(
        df, total_value, total_drift_abs, drift_threshold
    )
    df_small = prepare_summary(df, total_drift_abs, alert)
    if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
        col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
        if col_sym:
            alert_keys = {str(k) for k in sell_alerts.keys()}
            df_small[col_sym] = df_small[col_sym].astype(str)
            df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
            latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
            df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
    formatters = formatters_for(alert)
    header_core = build_header(
        final_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
    )

    # --- Slack é€ä¿¡ï¼šâ‘ ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆåˆ¤å®šï¼‹ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šã€œæ¨å¥¨ç¾é‡‘æ¯”ç‡ï¼‰ã‚’ç‹¬ç«‹ã€â‘¡ä»¥é™ã¯åˆ¥ãƒ–ãƒ­ãƒƒã‚¯ ---
    me_g = MODE_EMOJIS.get(gcd_mode, "")
    me_b = MODE_EMOJIS.get(breadth_mode, "")
    block_gcd = (
        f"â‘  Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDD: -{gcd_pct:.1f}%"
        f"ï¼ˆåŸºæº–: C={CD_CAUTION*100:.0f}% / E={CD_EMERG*100:.0f}%ï¼‰ åˆ¤å®š: {me_g} {gcd_mode}"
    )
    # â‘ ãƒ–ãƒ­ãƒƒã‚¯ï¼šã“ã“ã¾ã§ï¼‹ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šã€œæ¨å¥¨ç¾é‡‘æ¯”ç‡ã¾ã§
    first_block = "```\n" + block_gcd + "\n" + _mode_tail_line(final_mode) + "\n```"

    # â‘¡ä»¥é™ãƒ–ãƒ­ãƒƒã‚¯ï¼šBreadthã®ã¿ï¼ˆâ€œç·åˆï¼ˆå‚è€ƒè¡¨ç¤ºï¼‰â€ã¯å‰Šé™¤ï¼‰
    block_breadth = f"â‘¡ Breadth: {me_b} {breadth_mode}ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}ï¼‰"
    # breadth_block ã®ä¸­èº«ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹é™¤å»ï¼‹é‡è¤‡è¡Œã¯é™¤å»ï¼‰
    breadth_details = ""
    if breadth_block:
        inner = breadth_block
        if inner.startswith("```"):
            inner = inner[len("```"):]
            if inner.startswith("\n"):
                inner = inner[1:]
            if inner.endswith("```"):
                inner = inner[:-3]
        inner_lines = [ln for ln in inner.splitlines() if ("ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in ln and "ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°" not in ln)]
        breadth_details = "\n".join(inner_lines).strip()
    second_body = block_breadth + ("\n" + breadth_details if breadth_details else "")
    second_block = "```\n" + second_body.strip() + "\n```"

    header = first_block + "\n" + second_block + "\n" + header_core
    if sell_alerts:
        def fmt_pair(date_tags):
            date, tags = date_tags
            return f"{date}:" + "ãƒ»".join(tags)
        listed = []
        for t, arr in sell_alerts.items():
            listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
        hits = ", ".join(listed)
        if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
            header = header.replace(
                "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
                f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
            )
        else:
            header += f"\nğŸŸ¥ {hits}"
    table_text = df_small.to_string(formatters=formatters, index=False)
    send_slack(header + "\n```" + table_text + "```")

    if debug_mode:
        debug_cols = [
            "symbol",
            "shares",
            "price",
            "value",
            "current_ratio",
            "drift",
            "drift_abs",
            "adjusted_ratio",
            "adjustable",
            "trade_shares",
            "new_shares",
            "new_value",
            "simulated_ratio",
            "simulated_drift_abs",
        ]
        debug_text = (
            "=== DEBUG: full dataframe ===\n"
            + df[debug_cols].to_string()
            + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
            + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
        )
        print("\n" + debug_text)
        send_debug(debug_text)


if __name__ == "__main__":
    main()

