```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: tools/api_health_probe.py, .github/workflows/api-health.yml
# 作成日時: 2025-09-24 16:45:47 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <tools/api_health_probe.py>
```text
L1 #!/usr/bin/env python3
L2 # -*- coding: utf-8 -*-
L3 """
L4 api_health_probe.py — 選定プログラム依存API（Yahoo Finance / SEC / Finnhub）の総合ヘルスチェック
L5 Usage:
L6   export SLACK_WEBHOOK_URL=...
L7   export FINNHUB_API_KEY=...            # 任意（無ければ FinnhubはSKIPPED）
L8   export SEC_EMAIL=you@example.com      # 推奨（SEC User-Agent に使用）
L9   python tools/api_health_probe.py
L10 Env (optional):
L11   CSV_CURRENT=./current.csv
L12   CSV_CANDIDATE=./candidate.csv
L13   YF_PERIOD=1y
L14   YF_MIN_LEN=120
L15   TIMEOUT_MS_WARN=5000
L16   MAX_WORKERS=8
L17   SOFT_FAIL=0   # 1なら常にexit 0
L18 Exit codes:
L19   HEALTHY=0, DEGRADED=10, DOWN=20 （SOFT_FAIL=1なら常に0）
L20 """
L21 import os, sys, time, json, math, csv, re, concurrent.futures as cf
L22 from typing import List, Dict, Tuple
L23 import pandas as pd
L24 import numpy as np
L25 import requests
L26 import yfinance as yf
L27
L28 # ---- Settings
L29 CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
L30 CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
L31 YF_PERIOD   = os.getenv("YF_PERIOD","1y")
L32 YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
L33 TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
L34 SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
L35 FINN_KEY    = os.getenv("FINNHUB_API_KEY")
L36 SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
L37 SEC_EMAIL   = os.getenv("SEC_EMAIL","")
L38 MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
L39 # “任意API”の扱い：ここに列挙されたAPIがDOWNでも全体は最大DEGRADED止まり
L40 OPTIONAL_APIS = set([x.strip().upper() for x in os.getenv("OPTIONAL_APIS","FINNHUB").split(",") if x.strip()])
L41
L42 # ---- Utils
L43 def _now_ms() -> int: return int(time.time()*1000)
L44
L45 def _post_slack(text: str):
L46     if not SLACK_WEBHOOK:
L47         print("[SLACK] webhook missing; print only\n"+text); return
L48     try:
L49         r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=5)
L50         print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
L51     except Exception as e: print(f"[SLACK] send error: {e}")
L52
L53 def _read_tickers(path: str) -> List[str]:
L54     if not os.path.exists(path): return []
L55     # 'ticker','symbol','Symbol','Ticker' の列に対応。無ければ1列CSVも許容。
L56     try:
L57         df = pd.read_csv(path)
L58         for c in ["ticker","symbol","Symbol","Ticker"]:
L59             if c in df.columns:
L60                 col = df[c].astype(str).str.strip()
L61                 return [t for t in col if t and t.lower()!="nan"]
L62         with open(path, newline="") as f:
L63             rd = csv.reader(f)
L64             vals = [row[0].strip() for row in rd if row]
L65             if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
L66             return [v for v in vals if v]
L67     except Exception:
L68         return []
L69
L70 def _autodiscover_csv() -> tuple[str|None, str|None]:
L71     """
L72     リポジトリ内から current*.csv / candidate*.csv を再帰探索し、最初に見つけたものを返す。
L73     明示指定（ENV）があればそれを優先。見つからなければ None。
L74     """
L75     cur = CSV_CURRENT if os.path.exists(CSV_CURRENT) else None
L76     cand = CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None
L77     if cur and cand:
L78         return cur, cand
L79
L80     for root, _, files in os.walk(".", topdown=True):
L81         for fn in files:
L82             if not fn.lower().endswith(".csv"):
L83                 continue
L84             path = os.path.join(root, fn)
L85             name = fn.lower()
L86             if not cur and "current" in name:
L87                 cur = path
L88             if not cand and "candidate" in name:
L89                 cand = path
L90         if cur and cand:
L91             break
L92     return cur, cand
L93
L94 def _fmt_ms(ms: int) -> str:
L95     return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"
L96
L97 # ---- Ticker 正規化（YF用）
L98 def _yf_variants(sym: str):
L99     s = (sym or "").upper()
L100     cands = []
L101     def add(x):
L102         if x and x not in cands: cands.append(x)
L103     add(s)
L104     add(s.replace(".","-"))   # BRK.B -> BRK-B, PBR.A -> PBR-A
L105     add(re.sub(r"[.\-^]", "", s))  # 記号除去
L106     return cands
L107
L108 # ================================================================
L109 # Yahoo Finance: price series ヘルス
L110 # ================================================================
L111 def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
L112     t0 = _now_ms()
L113     data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
L114     close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
L115     per_ticker_missing = {}; nf=[]; missing=[]; ok=[]
L116     for t in tickers:
L117         if t not in close.columns:
L118             # 簡易ノーマライズ後、個別で5dだけ再取得して最低限の生存確認
L119             recovered = False
L120             for alias in _yf_variants(t):
L121                 try:
L122                     s = yf.Ticker(alias).history(period="5d", auto_adjust=True)["Close"]
L123                     if isinstance(s, pd.Series) and s.notna().sum() > 0:
L124                         recovered = True
L125                         break
L126                 except Exception:
L127                     pass
L128             if not recovered:
L129                 nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
L130             # 再取得で回復した場合はOK扱い（dates/max_gapは空のまま）
L131             ok.append(t); per_ticker_missing.setdefault(t, {"dates":set(),"max_gap":0}); continue
L132         s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
L133         isna = s.isna().values; idx = s.index
L134         total_nan = int(isna.sum()); cur=max_gap=0
L135         dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
L136         for v in isna:
L137             if v: cur+=1
L138             else:
L139                 if cur>0: max_gap=max(max_gap,cur); cur=0
L140         if cur>0: max_gap=max(max_gap,cur)
L141         per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
L142         if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
L143         else: ok.append(t)
L144     ms = _now_ms()-t0
L145     level = "HEALTHY" if len(ok)==len(tickers) else ("DEGRADED" if len(ok)>=len(tickers)//2 else "DOWN")
L146     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L147     return f"YF_PRICE:{level} ok={len(ok)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L148         "level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
L149         "per_ticker_missing":per_ticker_missing
L150     }
L151
L152 # ================================================================
L153 # Yahoo Finance: fast_info.lastPrice ヘルス
L154 # ================================================================
L155 def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
L156     t0 = _now_ms(); tk = yf.Tickers(" ".join(tickers)); bad=[]
L157     for t in tickers:
L158         try:
L159             v = tk.tickers[t].fast_info.get("lastPrice", None)
L160             if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
L161         except Exception: bad.append(t)
L162     ms=_now_ms()-t0
L163     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L164     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L165     return f"YF_INFO:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L166         "level":level,"latency_ms":ms,"bad":bad
L167     }
L168
L169 # ================================================================
L170 # Yahoo Finance: financials（CFO/Capex/FCF）ヘルス
L171 # ================================================================
L172 _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
L173                "capex":["Capital Expenditure","Capital Expenditures"]}
L174 def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
L175     if df is None or df.empty: return None
L176     idx_lower = {str(i).lower():i for i in df.index}
L177     for n in names:
L178         k = n.lower()
L179         if k in idx_lower: return df.loc[idx_lower[k]]
L180     return None
L181 def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
L182     if s is None or s.empty: return None
L183     v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L184 def _latest(s: pd.Series|None) -> float|None:
L185     if s is None or s.empty: return None
L186     v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L187
L188 def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
L189     t0=_now_ms(); bad=[]
L190     def one(t):
L191         try:
L192             tk = yf.Ticker(t)
L193             qcf = tk.quarterly_cashflow
L194             cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
L195             cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
L196             fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L197             cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
L198             if any(v is None for v in (cfo,cap,fcf)):
L199                 acf = tk.cashflow
L200                 if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
L201                 if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
L202                 if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L203             return None if all(v is not None for v in (cfo,cap,fcf)) else t
L204         except Exception: return t
L205     with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
L206         for r in ex.map(one, tickers):
L207             if r: bad.append(r)
L208     ms=_now_ms()-t0
L209     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L210     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L211     return f"YF_FIN:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L212         "level":level,"latency_ms":ms,"bad":bad
L213     }
L214
L215 # ================================================================
L216 # Finnhub: cash-flow（CFO/Capex）ヘルス（フォールバック）
L217 # ================================================================
L218 _FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L219 _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L220
L221 def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L222     for i in range(retries):
L223         r = session.get(url, params=params, timeout=15)
L224         if r.status_code==429:
L225             time.sleep(min(2**i*sleep_s, 4.0)); continue
L226         r.raise_for_status(); return r.json()
L227     r.raise_for_status()
L228
L229 def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
L230     if not FINN_KEY:
L231         return "FINNHUB:SKIPPED (no key)", dict(level="SKIPPED",bad=[])
L232     t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
L233     for sym in tickers:
L234         try:
L235             j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
L236             arr=j.get("cashFlow") or []
L237             def pick(item,keys):
L238                 for k in keys:
L239                     if k in item and item[k] is not None: return item[k]
L240             cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
L241             cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
L242             cfo_ttm = np.nansum([np.nan if v is None 
```