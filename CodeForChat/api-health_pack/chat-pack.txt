# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: tools/api_health_probe.py, .github/workflows/api-health.yml
# ä½œæˆæ—¥æ™‚: 2025-09-24 22:56:44 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <tools/api_health_probe.py>
```text
L1 #!/usr/bin/env python3
L2 # -*- coding: utf-8 -*-
L3 """
L4 api_health_probe.py â€” é¸å®šãƒ—ãƒ­ã‚°ãƒ©ãƒ ä¾å­˜APIï¼ˆYahoo Finance / SEC / Finnhubï¼‰ã®ç·åˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
L5
L6 æ©Ÿèƒ½:
L7 - CSVè‡ªå‹•æ¤œå‡ºï¼ˆcurrent*/candidate*ï¼‰
L8 - å„APIã®ãƒ˜ãƒ«ã‚¹: YFä¾¡æ ¼/YF fast_info/YFè²¡å‹™/SEC companyfacts/Finnhub cash-flow
L9 - é…å»¶æ¸¬å®šãƒ»ã—ãã„å€¤SLOWè¡¨ç¤º
L10 - å…±é€šæ¬ ææ—¥ã®ç°¡æ˜“OUTAGEæ¤œçŸ¥ï¼ˆä¾¡æ ¼ç³»åˆ—ãƒ™ãƒ¼ã‚¹ï¼‰
L11 - â€œå¤‰ãªãƒ†ã‚£ãƒƒã‚«ãƒ¼â€ã®å¸¸æ™‚é€šå ±ï¼ˆaliasã§å›å¾© / not foundï¼‰
L12 - Slacké€šçŸ¥ã¯ã‚¢ã‚¤ã‚³ãƒ³ä»˜ãã€NGéŠ˜æŸ„ã¯æ”¹è¡Œã—ã¦å…¨ä»¶åˆ—æŒ™
L13 - EXIT_ON_LEVEL ã§CIã®å¤±æ•—åŸºæº–ã‚’åˆ¶å¾¡ï¼ˆæ—¢å®šDEGRADEDã€workflowã§DOWNã«è¨­å®šæ¨å¥¨ï¼‰
L14 - Finnhubã¯ä»»æ„APIï¼ˆOPTIONAL_APIS=FINNHUBï¼‰ï¼å˜ç‹¬DOWNã§ã‚‚å…¨ä½“ã¯æœ€å¤§DEGRADED
L15
L16 Env:
L17   SLACK_WEBHOOK_URL=[å¿…é ˆ] Slack Incoming Webhook
L18   FINNHUB_API_KEY   [ä»»æ„]
L19   SEC_CONTACT_EMAIL [æ¨å¥¨]  # ç„¡ã„å ´åˆã¯SECã‚’SKIPPEDï¼ˆ403å›é¿ï¼‰
L20   # å¾Œæ–¹äº’æ›: SEC_EMAIL ãŒã‚ã‚Œã° SEC_CONTACT_EMAIL ã®ä»£æ›¿ã¨ã—ã¦ä½¿ç”¨
L21   CSV_CURRENT=./current.csv
L22   CSV_CANDIDATE=./candidate.csv
L23   YF_PERIOD=1y
L24   YF_MIN_LEN=120
L25   TIMEOUT_MS_WARN=5000
L26   MAX_WORKERS=8
L27   OPTIONAL_APIS=FINNHUB
L28   EXIT_ON_LEVEL=DEGRADED  # workflowå´ã§ DOWN ã‚’æŒ‡å®šã™ã‚‹ã¨â€œDOWNã®æ™‚ã ã‘â€å¤±æ•—
L29   SOFT_FAIL=0             # 1ãªã‚‰å¸¸ã«exit 0
L30 """
L31 import os, sys, time, json, math, csv, re, concurrent.futures as cf
L32 from typing import List, Dict, Tuple
L33 import pandas as pd
L34 import numpy as np
L35 import requests
L36 import yfinance as yf
L37
L38 # ==== Settings
L39 CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
L40 CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
L41 YF_PERIOD   = os.getenv("YF_PERIOD","1y")
L42 YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
L43 TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
L44 SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
L45 FINN_KEY      = os.getenv("FINNHUB_API_KEY")
L46 SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
L47 # SECãƒ¡ãƒ¼ãƒ«ã¯ SEC_CONTACT_EMAIL ã‚’å„ªå…ˆï¼ˆå¾Œæ–¹äº’æ›ã§ SEC_EMAILï¼‰
L48 SEC_CONTACT_EMAIL = (os.getenv("SEC_CONTACT_EMAIL") or os.getenv("SEC_EMAIL") or "").strip()
L49 MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
L50 OPTIONAL_APIS = set([x.strip().upper() for x in os.getenv("OPTIONAL_APIS","FINNHUB").split(",") if x.strip()])
L51 EXIT_ON_LEVEL = os.getenv("EXIT_ON_LEVEL","DEGRADED").upper()
L52
L53 # ==== Utils
L54 def _now_ms() -> int: return int(time.time()*1000)
L55
L56 def _post_slack(text: str):
L57     if not SLACK_WEBHOOK:
L58         print("[SLACK] webhook missing; print only\n"+text); return
L59     try:
L60         r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=8)
L61         print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
L62     except Exception as e: print(f"[SLACK] send error: {e}")
L63
L64 def _read_tickers(path: str) -> List[str]:
L65     if not os.path.exists(path): return []
L66     try:
L67         df = pd.read_csv(path)
L68         for c in ["ticker","symbol","Symbol","Ticker"]:
L69             if c in df.columns:
L70                 col = df[c].astype(str).str.strip()
L71                 return [t for t in col if t and t.lower()!="nan"]
L72         with open(path, newline="") as f:
L73             rd = csv.reader(f)
L74             vals = [row[0].strip() for row in rd if row]
L75             if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
L76             return [v for v in vals if v]
L77     except Exception:
L78         return []
L79
L80 def _autodiscover_csv() -> tuple[str|None, str|None]:
L81     cur, cand = (CSV_CURRENT if os.path.exists(CSV_CURRENT) else None,
L82                  CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None)
L83     if cur and cand: return cur, cand
L84     for root, _, files in os.walk(".", topdown=True):
L85         for fn in files:
L86             if not fn.lower().endswith(".csv"): continue
L87             p = os.path.join(root, fn); fl = fn.lower()
L88             if "current" in fl and not cur: cur = p
L89             if "candidate" in fl and not cand: cand = p
L90         if cur and cand: break
L91     return cur, cand
L92
L93 def _fmt_ms(ms: int) -> str:
L94     return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"
L95
L96 def _latency_icon(ms: int) -> str:
L97     return "ğŸ¢" if ms >= TIMEOUT_MS_WARN else "âœ…"
L98
L99 # ==== SEC helpers
L100 def _sec_headers():
L101     """
L102     SECã¯é€£çµ¡å…ˆä»˜ãUser-Agent/FromãŒæ¨å¥¨ï¼ˆSEC_CONTACT_EMAILï¼‰ã€‚
L103     é€£çµ¡å…ˆãŒç©ºã§ã‚‚å‹•ã‹ã™ãŒã€403æ™‚ã¯ä¸Šä½ã§SKIPã€‚
L104     """
L105     mail = SEC_CONTACT_EMAIL
L106     ua   = f"api-health-probe/1 ({mail})" if mail else "api-health-probe/1"
L107     h    = {"User-Agent": ua[:200], "Accept": "application/json"}
L108     if mail:
L109         h["From"] = mail[:200]
L110     return h
L111
L112 def _sec_get(url: str, params=None, retries=3, sleep_s: float=0.5):
L113     last_err = None
L114     for i in range(retries):
L115         try:
L116             r = requests.get(url, params=params or {}, headers=_sec_headers(), timeout=15)
L117             if r.status_code == 429:
L118                 time.sleep(min(2**i*sleep_s, 4.0)); continue
L119             if r.status_code == 403:
L120                 return None
L121             r.raise_for_status()
L122             return r.json()
L123         except Exception as e:
L124             last_err = e
L125             time.sleep(min(2**i*sleep_s, 2.0))
L126     return None
L127
L128 def _sec_ticker_map() -> Dict[str,str]:
L129     j = _sec_get("https://www.sec.gov/files/company_tickers.json")
L130     if j is None: return {}
L131     out={}
L132     it=(j.values() if isinstance(j,dict) else j)
L133     for item in it:
L134         try:
L135             t=(item.get("ticker") or item.get("TICKER") or "").upper()
L136             cik=str(item.get("cik_str") or item.get("CIK") or "").zfill(10)
L137             if t and cik: out[t]=cik
L138         except Exception: continue
L139     return out
L140
L141 # ==== Yahoo Finance: ticker variants (for recovery)
L142 def _yf_variants(sym: str):
L143     s = (sym or "").upper()
L144     cands = []
L145     def add(x):
L146         if x and x not in cands: cands.append(x)
L147     add(s)
L148     add(s.replace(".","-"))            # BRK.B -> BRK-B, PBR.A -> PBR-A
L149     add(re.sub(r"[.\-^]", "", s))      # è¨˜å·é™¤å»
L150     return cands
L151
L152 # ==== YF: price series health
L153 def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
L154     t0 = _now_ms()
L155     data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
L156     close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
L157
L158     per_ticker_missing = {}
L159     nf=[]          # ä¸€æ‹¬ã§ã‚‚åˆ¥åå†è©¦è¡Œã§ã‚‚å–å¾—ã§ããš
L160     missing=[]     # åˆ—ã¯ã‚ã‚‹ãŒNaN/ä¸è¶³
L161     ok=[]          # å•é¡Œãªã—
L162     alias_fixed=[] # (orig, alias) åˆ¥åã§å›å¾©
L163
L164     for t in tickers:
L165         if t not in close.columns:
L166             recovered = False
L167             for alias in _yf_variants(t):
L168                 try:
L169                     s = yf.Ticker(alias).history(period="5d", auto_adjust=True)["Close"]
L170                     if isinstance(s, pd.Series) and s.notna().sum() > 0:
L171                         recovered = True
L172                         alias_fixed.append((t, alias))
L173                         break
L174                 except Exception:
L175                     pass
L176             if not recovered:
L177                 nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
L178             ok.append(t); per_ticker_missing.setdefault(t, {"dates":set(),"max_gap":0}); continue
L179
L180         s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
L181         isna = s.isna().values; idx = s.index
L182         total_nan = int(isna.sum()); cur=max_gap=0
L183         dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
L184         for v in isna:
L185             if v: cur+=1
L186             else:
L187                 if cur>0: max_gap=max(max_gap,cur); cur=0
L188         if cur>0: max_gap=max(max_gap,cur)
L189         per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
L190         if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
L191         else: ok.append(t)
L192
L193     ms = _now_ms()-t0
L194     total = len(tickers)
L195     bad = list(dict.fromkeys([*nf, *missing]))
L196     level = "HEALTHY" if not bad else ("DOWN" if total > 0 and len(bad) >= total else "DEGRADED")
L197     det = f"YF_PRICE:{level} bad={len(bad)}/{total} latency={_fmt_ms(ms)} {_latency_icon(ms)}"
L198     meta = {"level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
L199             "per_ticker_missing":per_ticker_missing,"alias_fixed":alias_fixed,"bad":bad}
L200     return det, meta
L201
L202 # ==== YF: fast_info health
L203 def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
L204     t0 = _now_ms()
L205     tk = yf.Tickers(" ".join(tickers))
L206     bad=[]
L207     for t in tickers:
L208         try:
L209             v = tk.tickers[t].fast_info.get("lastPrice", None)
L210             if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
L211         except Exception: bad.append(t)
L212     ms=_now_ms()-t0
L213     total=len(tickers)
L214     level = "HEALTHY" if not bad else ("DOWN" if total > 0 and len(bad) >= total else "DEGRADED")
L215     det = f"YF_INFO:{level} bad={len(bad)}/{total} latency={_fmt_ms(ms)} {_latency_icon(ms)}"
L216     return det, {"level":level,"latency_ms":ms,"bad":bad}
L217
L218 # ==== YF: financials health (CFO/Capex/FCF)
L219 _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
L220                "capex":["Capital Expenditure","Capital Expenditures"]}
L221 def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
L222     if df is None or df.empty: return None
L223     idx_lower = {str(i).lower():i for i in df.index}
L224     for n in names:
L225         k = n.lower()
L226         if k in idx_lower: return df.loc[idx_lower[k]]
L227     return None
L228 def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
L229     if s is None or s.empty: return None
L230     v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L231 def _latest(s: pd.Series|None) -> float|None:
L232     if s is None or s.empty: return None
L233     v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L234
L235 def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
L236     t0=_now_ms(); bad=[]
L237     def one(t):
L238         try:
L239             tk = yf.Ticker(t)
L240             qcf = tk.quarterly_cashflow
L241             cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
L242             cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
L243             fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L244             cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
L245             if any(v is None for v in (cfo,cap,fcf)):
L246                 acf = tk.cashflow
L247                 if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
L248                 if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
L249                 if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L250             return None if all(v is not None for v in (cfo,cap,fcf)) else t
L251         except Exception: return t
L252     with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
L253         for r in ex.map(one, tickers):
L254             if r: bad.append(r)
L255     ms=_now_ms()-t0
L256     total=len(tickers)
L257     level = "HEALTHY" if not bad else ("DOWN" if total > 0 and len(bad) >= total else "DEGRADED")
L258     det = f"YF_FIN:{level} bad={len(bad)}/{total} latency={_fmt_ms(ms)} {_latency_icon(ms)}"
L259     return det, {"level":level,"latency_ms":ms,"bad":bad}
L260
L261 # ==== Finnhub: cash-flow fallback
L262 _FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L263 _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L264
L265 def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L266     for i in range(retries):
L267         r = session.get(url, params=params, timeout=15)
L268         if r.status_code==429:
L269             time.sleep(min(2**i*sleep_s, 4.0)); continue
L270         r.raise_for_status(); return r.json()
L271     r.raise_for_status()
L272
L273 def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
L274     if not FINN_KEY:
L275         det = f"FINNHUB:SKIPPED bad=0/{len(tickers)} latency=0ms {_latency_icon(0)} (no key)"
L276         return det, dict(level="SKIPPED",bad=[],latency_ms=0)
L277     t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
L278     for sym in tickers:
L279         try:
L280             j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
L281             arr=j.get("cashFlow") or []
L282             def pick(item,keys):
L283                 for k in keys:
L284                     if k in item and item[k] is not None: return item[k]
L285             cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
L286             cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
L287             cfo_ttm = np.nansum([np.nan if v is None else float(v) for v in cfo_vals]) if any(v is not None for v in cfo_vals) else None
L288             cap_ttm = np.nansum([np.nan if v is None else float(v) for v in cap_vals]) if any(v is not None for v in cap_vals) else None
L289             if cfo_ttm is None or cap_ttm is None:
L290                 j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"annual","limit":1,"token":FINN_KEY})
L291                 arr=j.get("cashFlow") or []
L292                 if arr:
L293                     item0=arr[0]
L294                     if cfo_ttm is None:
L295                         v=pick(item0,_FINN_CFO_KEYS); 
L296                         if v is not None: cfo_ttm=float(v)
L297                     if cap_ttm is None:
L298                         v=pick(item0,_FINN_CAPEX_KEYS); 
L299                         if v is not None: cap_ttm=float(v)
L300             if cfo_ttm is None or cap_ttm is None: bad.append(sym)
L301         except Exception: bad.append(sym)
L302     ms=_now_ms()-t0
L303     total=len(tickers)
L304     level="HEALTHY" if not bad else ("DOWN" if total>0 and len(bad)>=total else "DEGRADED")
L305     det = f"FINNHUB:{level} bad={len(bad)}/{total} latency={_fmt_ms(ms)} {_latency_icon(ms)}"
L306     return det,{"level":level,"latency_ms":ms,"bad":bad}
L307
L308 # ==== SEC: companyfacts (Revenue/EPS) health
L309 SEC_REV_TAGS=["Revenues","RevenueFromContractWithCustomerExcludingAssessedTax","SalesRevenueNet","SalesRevenueGoodsNet","SalesRevenueServicesNet","Revenue"]
L310 SEC_EPS_TAGS=["EarningsPerShareDiluted","EarningsPerShareBasicAndDiluted","EarningsPerShare","EarningsPerShareBasic"]
L311
L312 def _units_for_tags(facts: dict, spaces: List[str], tags: List[str]) -> list:
L313     got=[]
L314     for sp in spaces:
L315         d=(facts.get("facts") or {}).get(sp) or {}
L316         for tg in tags:
L317             arr=(d.get(tg) or {}).get("units") or {}
L318             for unit, vals in (arr.items() if isinstance(arr,dict) else []):
L319                 if isinstance(vals,list) and vals: got.append(vals)
L320     return got
L321
L322 def _series_q_and_a(arrs: list) -> Tuple[list, list]:
L323     q_pairs,a_pairs=[],[]
L324     for vals in arrs:
L325         for v in vals:
L326             try:
L327                 dt=v.get("end") or v.get("fy"); val=float(v.get("val")); form=(v.get("form") or "").upper()
L328                 if "10-Q" in form or "6-K" in form or form=="Q": q_pairs.append((dt,val))
L329                 elif "10-K" in form or "20-F" in form or form=="K": a_pairs.append((dt,val))
L330             except Exception: pass
L331     q_pairs=sorted(q_pairs,key=lambda x: str(x[0]),reverse=True)
L332     a_pairs=sorted(a_pairs,key=lambda x: str(x[0]),reverse=True)
L333     return q_pairs,a_pairs
L334
L335 def sec_health(tickers: List[str]) -> Tuple[str, Dict]:
L336     t0=_now_ms(); t2cik=_sec_ticker_map(); bad=[]
L337     if not t2cik:
L338         ms=_now_ms()-t0
L339         det = f"SEC:SKIPPED bad=0/{len(tickers)} latency={_fmt_ms(ms)} {_latency_icon(ms)} (no SEC_CONTACT_EMAIL/403)"
L340         return det, {"level":"SKIPPED","latency_ms":ms,"bad":[]}
L341     for t in tickers:
L342         # '.'ã¨'-'ã®ã‚†ã‚‰ãã‚’è¨±å®¹ã—ãŸç°¡æ˜“ãƒãƒƒãƒ
L343         cands = [(t or "").upper(), (t or "").upper().replace(".","-"), (t or "").upper().replace("-",""), (t or "").upper().replace(".","")]
L344         cik = next((t2cik.get(x) for x in cands if t2cik.get(x)), None)
L345         if not cik:
L346             bad.append(t); continue
L347         try:
L348             j=_sec_get(f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json")
L349             if j is None: bad.append(t); continue
L350             rev_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_REV_TAGS)
L351             eps_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_EPS_TAGS)
L352             rev_q,rev_a=_series_q_and_a(rev_arr); eps_q,eps_a=_series_q_and_a(eps_arr)
L353             if not (rev_q or rev_a) or not (eps_q or eps_a): bad.append(t)
L354         except Exception: bad.append(t)
L355         time.sleep(0.30)
L356     ms=_now_ms()-t0
L357     total=len(tickers)
L358     level="HEALTHY" if not bad else ("DOWN" if total>0 and len(bad)>=total else "DEGRADED")
L359     det = f"SEC:{level} bad={len(bad)}/{total} latency={_fmt_ms(ms)} {_latency_icon(ms)}"
L360     return det,{"level":level,"latency_ms":ms,"bad":bad}
L361
L362 # ==== Orchestration
L363 def main():
L364     cur_path, cand_path = _autodiscover_csv()
L365     if not cur_path or not cand_path:
L366         msg = f"âš ï¸ CSV not found. cur={cur_path} cand={cand_path} (set CSV_CURRENT/CSV_CANDIDATE or place files)"
L367         print(msg); _post_slack(msg)
L368         if SOFT_FAIL: sys.exit(0)
L369         sys.exit(78)
L370
L371     tickers=sorted(set(_read_tickers(cur_path)+_read_tickers(cand_path)))
L372     if not tickers:
L373         msg = f"âš ï¸ No tickers from CSV. cur={cur_path} cand={cand_path}"
L374         print(msg); _post_slack(msg)
L375         if SOFT_FAIL: sys.exit(0)
L376         sys.exit(78)
L377
L378     det_price,meta_price=yf_price_health(tickers)
L379     det_info ,meta_info =yf_fastinfo_health(tickers)
L380     det_fin  ,meta_fin  =yf_financials_health(tickers)
L381     det_sec  ,meta_sec  =sec_health(tickers)
L382
L383     need_finn=meta_fin["bad"]
L384     det_finn,meta_finn  =finnhub_health(need_finn if need_finn else tickers[:0])
L385
L386     levels_map = {
L387         "YF_PRICE": meta_price["level"],
L388         "YF_INFO" : meta_info ["level"],
L389         "YF_FIN"  : meta_fin  ["level"],
L390         "SEC"     : meta_sec  ["level"],
L391         "FINNHUB" : meta_finn.get("level","SKIPPED"),
L392     }
L393     pri={"DOWN":3,"DEGRADED":2,"HEALTHY":1,"SKIPPED":0}
L394     core_levels = [lvl for api,lvl in levels_map.items() if api not in OPTIONAL_APIS]
L395     core_worst = max(core_levels, key=lambda x: pri.get(x,0)) if core_levels else "HEALTHY"
L396     all_worst  = max(levels_map.values(), key=lambda x: pri.get(x,0))
L397     worst = "DEGRADED" if (all_worst=="DOWN" and core_worst!="DOWN") else all_worst
L398     emoji={"HEALTHY":"âœ…","DEGRADED":"âš ï¸","DOWN":"ğŸ›‘"}.get(worst,"â„¹ï¸")
L399
L400     # ä¾¡æ ¼ç³»åˆ—ã®å…±é€šéšœå®³ï¼ˆåŒä¸€æ—¥ã ã‘ã®æ¬ æãŒéåŠï¼‰ç°¡æ˜“æ¤œçŸ¥
L401     outage_note=""
L402     try:
L403         from collections import Counter
L404         missing_dates=meta_price.get("per_ticker_missing",{})
L405         date_counter=Counter(); one_day_missing=0
L406         for _,info in missing_dates.items():
L407             dates=info.get("dates",set()); max_gap=info.get("max_gap",0)
L408             if len(dates)==1 and max_gap==1:
L409                 one_day_missing+=1; date_counter.update(dates)
L410         threshold=max(1,len(tickers)//2)
L411         if one_day_missing>=threshold:
L412             (missing_day,hits),=date_counter.most_common(1)
L413             outage_note=f" | OUTAGE: common_missing_day={missing_day} hits={hits}"
L414             if worst=="HEALTHY": worst="DEGRADED"; emoji="ğŸŸ "
L415     except Exception:
L416         pass
L417
L418     LABELS = {
L419         "YF_PRICE": "price",
L420         "YF_INFO": "fast_info",
L421         "YF_FIN": "financials (CFO/Capex/FCF)",
L422         "FINNHUB": "cash-flow (fallback)",
L423         "SEC": "companyfacts (revenue/eps)",
L424     }
L425
L426     def icon_for(level: str) -> str:
L427         return {"HEALTHY":"âœ…","DEGRADED":"âš ï¸","DOWN":"ğŸ›‘","SKIPPED":"â­ï¸"}.get(level, "â„¹ï¸")
L428
L429     def _fmt_block(detail: str, key: str) -> str:
L430         _, _, metrics = detail.partition(":")
L431         metrics = metrics.lstrip()
L432         heading = f"{icon_for(levels_map.get(key, ''))} {key}"
L433         label = LABELS.get(key)
L434         if label:
L435             heading += f" ({label})"
L436         return f"{heading}:\n{metrics}"
L437
L438     status_order = [
L439         ("YF_PRICE", det_price),
L440         ("YF_INFO", det_info),
L441         ("YF_FIN", det_fin),
L442         ("FINNHUB", det_finn),
L443         ("SEC", det_sec),
L444     ]
L445
L446     status_lines = [f"{emoji} API_HEALTH {worst}{outage_note} (exit_on={EXIT_ON_LEVEL})"]
L447     status_lines.extend(_fmt_block(detail, key) for key, detail in status_order)
L448     summary = "\n".join(status_lines)
L449     has_problem=("DEGRADED" in worst) or ("DOWN" in worst)
L450
L451     if has_problem:
L452         def all_list(xs): return ", ".join(xs)
L453         lines=[]
L454         price_bad = meta_price.get("bad") or []
L455         if price_bad:
L456             lines.append("ğŸ†–YF_PRICE NG:\n" + all_list(price_bad))
L457         if meta_info.get("bad"):
L458             lines.append("ğŸ†–YF_INFO NG:\n" + all_list(meta_info["bad"]))
L459         if meta_fin.get("bad"):
L460             lines.append("ğŸ†–YF_FIN NG:\n" + all_list(meta_fin["bad"]))
L461         if meta_finn.get("bad"):
L462             lines.append("ğŸ†–FINNHUB NG:\n" + all_list(meta_finn["bad"]))
L463         if meta_sec.get("bad"):
L464             lines.append("ğŸ†–SEC NG:\n" + all_list(meta_sec["bad"]))
L465         text=summary + ("\n" + "\n".join(lines) if lines else "")
L466     else:
L467         text=summary
L468
L469     # å¤‰ãªãƒ†ã‚£ãƒƒã‚«ãƒ¼ã¯æ¯å›å…¨ä»¶é€šå ±
L470     def pair_all(pairs): return ", ".join(f"{a}->{b}" for (a,b) in pairs)
L471     def list_all(xs): return ", ".join(xs)
L472     alias_fixed = meta_price.get("alias_fixed", [])
L473     still_missing = meta_price.get("nf", [])
L474     weird_lines = []
L475     if alias_fixed:
L476         weird_lines.append("Weird tickers (alias fixed):\n" + pair_all(alias_fixed))
L477     if still_missing:
L478         weird_lines.append("Weird tickers (not found):\n" + list_all(still_missing))
L479     if weird_lines:
L480         text = text + "\n" + "\n".join(weird_lines)
L481
L482     print(text); _post_slack(text)
L483     if SOFT_FAIL: sys.exit(0)
L484     # é€€å‡ºåˆ¤å®šï¼šã‚³ã‚¢APIã‚’å„ªå…ˆã€‚OPTIONALãŒDOWNã§ã‚‚ coreãŒHEALTHY/DEGRADEDãªã‚‰ç·©å’Œã€‚
L485     exit_by = core_worst if core_worst!="HEALTHY" else worst
L486     def _rank(x): return {"HEALTHY":1,"DEGRADED":2,"DOWN":3}.get(x,0)
L487     if _rank(exit_by) < _rank(EXIT_ON_LEVEL): sys.exit(0)
L488     sys.exit(20 if exit_by=="DOWN" else 10)
L489
L490 if __name__=="__main__":
L491     main()
```

## <.github/workflows/api-health.yml>
```text
L1 name: api-health-probe
L2 on:
L3   push:
L4     branches: [ main ]
L5
L6 jobs:
L7   probe:
L8     runs-on: ubuntu-latest
L9     timeout-minutes: 10
L10     steps:
L11       - uses: actions/checkout@v4
L12       - uses: actions/setup-python@v5
L13         with:
L14           python-version: "3.11"
L15       - name: Install deps
L16         run: |
L17           python -m pip install --upgrade pip
L18           pip install yfinance pandas numpy requests
L19       - name: Run API health probe
L20         env:
L21           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L22           FINNHUB_API_KEY:   ${{ secrets.FINNHUB_API_KEY }}
L23           SEC_CONTACT_EMAIL: ${{ secrets.SEC_CONTACT_EMAIL }}
L24           EXIT_ON_LEVEL:     DOWN
L25           YF_PERIOD:         1y
L26           YF_MIN_LEN:        "120"
L27           TIMEOUT_MS_WARN:   "5000"
L28           SOFT_FAIL:         "0"
L29         run: |
L30           python tools/api_health_probe.py
L31       - name: Mark job outcome
L32         if: always()
L33         run: echo "Done."
```
