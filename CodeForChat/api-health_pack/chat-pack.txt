# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: tools/api_health_probe.py, .github/workflows/api-health.yml
# ‰ΩúÊàêÊó•ÊôÇ: 2025-09-24 18:23:09 (JST)
# ‰Ωø„ÅÑÊñπ: ‰∏ã„ÅÆ„ÉÅ„É£„É≥„ÇØ„ÇíÈ†Ü„Å´Ë≤º„Çå„Å∞„Åì„ÅÆ„ÉÅ„É£„ÉÉ„Éà„ÅßÂÖ®‰ΩìÊääÊè°„Åß„Åç„Åæ„Åô„ÄÇ
# Ê≥®Ë®ò: ÂêÑ„Éï„Ç°„Ç§„É´„ÅØÂÄãÂà•„Å´ L1.. „ÅßË°åÁï™Âè∑‰ªò‰∏é„ÄÇ
---

## <tools/api_health_probe.py>
```text
L1 #!/usr/bin/env python3
L2 # -*- coding: utf-8 -*-
L3 """
L4 api_health_probe.py ‚Äî ÈÅ∏ÂÆö„Éó„É≠„Ç∞„É©„É†‰æùÂ≠òAPIÔºàYahoo Finance / SEC / FinnhubÔºâ„ÅÆÁ∑èÂêà„Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ
L5
L6 Ê©üËÉΩ:
L7 - CSVËá™ÂãïÊ§úÂá∫Ôºàcurrent*/candidate*Ôºâ
L8 - ÂêÑAPI„ÅÆ„Éò„É´„Çπ: YF‰æ°Ê†º/YF fast_info/YFË≤°Âãô/SEC companyfacts/Finnhub cash-flow
L9 - ÈÅÖÂª∂Ê∏¨ÂÆö„Éª„Åó„Åç„ÅÑÂÄ§SLOWË°®Á§∫
L10 - ÂÖ±ÈÄöÊ¨†ÊêçÊó•„ÅÆÁ∞°ÊòìOUTAGEÊ§úÁü•Ôºà‰æ°Ê†ºÁ≥ªÂàó„Éô„Éº„ÇπÔºâ
L11 - ‚ÄúÂ§â„Å™„ÉÜ„Ç£„ÉÉ„Ç´„Éº‚Äù„ÅÆÂ∏∏ÊôÇÈÄöÂ†±Ôºàalias„ÅßÂõûÂæ© / not foundÔºâ
L12 - SlackÈÄöÁü•„ÅØ„Ç¢„Ç§„Ç≥„É≥‰ªò„Åç„ÄÅNGÈäòÊüÑ„ÅØÊîπË°å„Åó„Å¶ÂÖ®‰ª∂ÂàóÊåô
L13 - EXIT_ON_LEVEL „ÅßCI„ÅÆÂ§±ÊïóÂü∫Ê∫ñ„ÇíÂà∂Âæ°ÔºàÊó¢ÂÆöDEGRADED„ÄÅworkflow„ÅßDOWN„Å´Ë®≠ÂÆöÊé®Â•®Ôºâ
L14 - Finnhub„ÅØ‰ªªÊÑèAPIÔºàOPTIONAL_APIS=FINNHUBÔºâÔºùÂçòÁã¨DOWN„Åß„ÇÇÂÖ®‰Ωì„ÅØÊúÄÂ§ßDEGRADED
L15
L16 Env:
L17   SLACK_WEBHOOK_URL=[ÂøÖÈ†à] Slack Incoming Webhook
L18   FINNHUB_API_KEY   [‰ªªÊÑè]
L19   SEC_CONTACT_EMAIL [Êé®Â•®]  # ÁÑ°„ÅÑÂ†¥Âêà„ÅØSEC„ÇíSKIPPEDÔºà403ÂõûÈÅøÔºâ
L20   # ÂæåÊñπ‰∫íÊèõ: SEC_EMAIL „Åå„ÅÇ„Çå„Å∞ SEC_CONTACT_EMAIL „ÅÆ‰ª£Êõø„Å®„Åó„Å¶‰ΩøÁî®
L21   CSV_CURRENT=./current.csv
L22   CSV_CANDIDATE=./candidate.csv
L23   YF_PERIOD=1y
L24   YF_MIN_LEN=120
L25   TIMEOUT_MS_WARN=5000
L26   MAX_WORKERS=8
L27   OPTIONAL_APIS=FINNHUB
L28   EXIT_ON_LEVEL=DEGRADED  # workflowÂÅ¥„Åß DOWN „ÇíÊåáÂÆö„Åô„Çã„Å®‚ÄúDOWN„ÅÆÊôÇ„Å†„Åë‚ÄùÂ§±Êïó
L29   SOFT_FAIL=0             # 1„Å™„ÇâÂ∏∏„Å´exit 0
L30 """
L31 import os, sys, time, json, math, csv, re, concurrent.futures as cf
L32 from typing import List, Dict, Tuple
L33 import pandas as pd
L34 import numpy as np
L35 import requests
L36 import yfinance as yf
L37
L38 # ==== Settings
L39 CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
L40 CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
L41 YF_PERIOD   = os.getenv("YF_PERIOD","1y")
L42 YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
L43 TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
L44 SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
L45 FINN_KEY      = os.getenv("FINNHUB_API_KEY")
L46 SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
L47 # SEC„É°„Éº„É´„ÅØ SEC_CONTACT_EMAIL „ÇíÂÑ™ÂÖàÔºàÂæåÊñπ‰∫íÊèõ„Åß SEC_EMAILÔºâ
L48 SEC_CONTACT_EMAIL = (os.getenv("SEC_CONTACT_EMAIL") or os.getenv("SEC_EMAIL") or "").strip()
L49 MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
L50 OPTIONAL_APIS = set([x.strip().upper() for x in os.getenv("OPTIONAL_APIS","FINNHUB").split(",") if x.strip()])
L51 EXIT_ON_LEVEL = os.getenv("EXIT_ON_LEVEL","DEGRADED").upper()
L52
L53 # ==== Utils
L54 def _now_ms() -> int: return int(time.time()*1000)
L55
L56 def _post_slack(text: str):
L57     if not SLACK_WEBHOOK:
L58         print("[SLACK] webhook missing; print only\n"+text); return
L59     try:
L60         r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=8)
L61         print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
L62     except Exception as e: print(f"[SLACK] send error: {e}")
L63
L64 def _read_tickers(path: str) -> List[str]:
L65     if not os.path.exists(path): return []
L66     try:
L67         df = pd.read_csv(path)
L68         for c in ["ticker","symbol","Symbol","Ticker"]:
L69             if c in df.columns:
L70                 col = df[c].astype(str).str.strip()
L71                 return [t for t in col if t and t.lower()!="nan"]
L72         with open(path, newline="") as f:
L73             rd = csv.reader(f)
L74             vals = [row[0].strip() for row in rd if row]
L75             if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
L76             return [v for v in vals if v]
L77     except Exception:
L78         return []
L79
L80 def _autodiscover_csv() -> tuple[str|None, str|None]:
L81     cur, cand = (CSV_CURRENT if os.path.exists(CSV_CURRENT) else None,
L82                  CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None)
L83     if cur and cand: return cur, cand
L84     for root, _, files in os.walk(".", topdown=True):
L85         for fn in files:
L86             if not fn.lower().endswith(".csv"): continue
L87             p = os.path.join(root, fn); fl = fn.lower()
L88             if "current" in fl and not cur: cur = p
L89             if "candidate" in fl and not cand: cand = p
L90         if cur and cand: break
L91     return cur, cand
L92
L93 def _fmt_ms(ms: int) -> str:
L94     return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"
L95
L96 # ==== SEC helpers
L97 def _sec_headers():
L98     """
L99     SEC„ÅØÈÄ£Áµ°ÂÖà‰ªò„ÅçUser-Agent/From„ÅåÊé®Â•®ÔºàSEC_CONTACT_EMAILÔºâ„ÄÇ
L100     ÈÄ£Áµ°ÂÖà„ÅåÁ©∫„Åß„ÇÇÂãï„Åã„Åô„Åå„ÄÅ403ÊôÇ„ÅØ‰∏ä‰Ωç„ÅßSKIP„ÄÇ
L101     """
L102     mail = SEC_CONTACT_EMAIL
L103     ua   = f"api-health-probe/1 ({mail})" if mail else "api-health-probe/1"
L104     h    = {"User-Agent": ua[:200], "Accept": "application/json"}
L105     if mail:
L106         h["From"] = mail[:200]
L107     return h
L108
L109 def _sec_get(url: str, params=None, retries=3, sleep_s: float=0.5):
L110     last_err = None
L111     for i in range(retries):
L112         try:
L113             r = requests.get(url, params=params or {}, headers=_sec_headers(), timeout=15)
L114             if r.status_code == 429:
L115                 time.sleep(min(2**i*sleep_s, 4.0)); continue
L116             if r.status_code == 403:
L117                 return None
L118             r.raise_for_status()
L119             return r.json()
L120         except Exception as e:
L121             last_err = e
L122             time.sleep(min(2**i*sleep_s, 2.0))
L123     return None
L124
L125 def _sec_ticker_map() -> Dict[str,str]:
L126     j = _sec_get("https://www.sec.gov/files/company_tickers.json")
L127     if j is None: return {}
L128     out={}
L129     it=(j.values() if isinstance(j,dict) else j)
L130     for item in it:
L131         try:
L132             t=(item.get("ticker") or item.get("TICKER") or "").upper()
L133             cik=str(item.get("cik_str") or item.get("CIK") or "").zfill(10)
L134             if t and cik: out[t]=cik
L135         except Exception: continue
L136     return out
L137
L138 # ==== Yahoo Finance: ticker variants (for recovery)
L139 def _yf_variants(sym: str):
L140     s = (sym or "").upper()
L141     cands = []
L142     def add(x):
L143         if x and x not in cands: cands.append(x)
L144     add(s)
L145     add(s.replace(".","-"))            # BRK.B -> BRK-B, PBR.A -> PBR-A
L146     add(re.sub(r"[.\-^]", "", s))      # Ë®òÂè∑Èô§Âéª
L147     return cands
L148
L149 # ==== YF: price series health
L150 def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
L151     t0 = _now_ms()
L152     data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
L153     close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
L154
L155     per_ticker_missing = {}
L156     nf=[]          # ‰∏ÄÊã¨„Åß„ÇÇÂà•ÂêçÂÜçË©¶Ë°å„Åß„ÇÇÂèñÂæó„Åß„Åç„Åö
L157     missing=[]     # Âàó„ÅØ„ÅÇ„Çã„ÅåNaN/‰∏çË∂≥
L158     ok=[]          # ÂïèÈ°å„Å™„Åó
L159     alias_fixed=[] # (orig, alias) Âà•Âêç„ÅßÂõûÂæ©
L160
L161     for t in tickers:
L162         if t not in close.columns:
L163             recovered = False
L164             for alias in _yf_variants(t):
L165                 try:
L166                     s = yf.Ticker(alias).history(period="5d", auto_adjust=True)["Close"]
L167                     if isinstance(s, pd.Series) and s.notna().sum() > 0:
L168                         recovered = True
L169                         alias_fixed.append((t, alias))
L170                         break
L171                 except Exception:
L172                     pass
L173             if not recovered:
L174                 nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
L175             ok.append(t); per_ticker_missing.setdefault(t, {"dates":set(),"max_gap":0}); continue
L176
L177         s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
L178         isna = s.isna().values; idx = s.index
L179         total_nan = int(isna.sum()); cur=max_gap=0
L180         dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
L181         for v in isna:
L182             if v: cur+=1
L183             else:
L184                 if cur>0: max_gap=max(max_gap,cur); cur=0
L185         if cur>0: max_gap=max(max_gap,cur)
L186         per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
L187         if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
L188         else: ok.append(t)
L189
L190     ms = _now_ms()-t0
L191     level = "HEALTHY" if len(ok)==len(tickers) else ("DEGRADED" if len(ok)>=len(tickers)//2 else "DOWN")
L192     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L193     det = f"YF_PRICE:{level} ok={len(ok)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}"
L194     meta = {"level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
L195             "per_ticker_missing":per_ticker_missing,"alias_fixed":alias_fixed}
L196     return det, meta
L197
L198 # ==== YF: fast_info health
L199 def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
L200     t0 = _now_ms()
L201     tk = yf.Tickers(" ".join(tickers))
L202     bad=[]
L203     for t in tickers:
L204         try:
L205             v = tk.tickers[t].fast_info.get("lastPrice", None)
L206             if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
L207         except Exception: bad.append(t)
L208     ms=_now_ms()-t0
L209     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L210     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L211     return f"YF_INFO:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L212         "level":level,"latency_ms":ms,"bad":bad
L213     }
L214
L215 # ==== YF: financials health (CFO/Capex/FCF)
L216 _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
L217                "capex":["Capital Expenditure","Capital Expenditures"]}
L218 def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
L219     if df is None or df.empty: return None
L220     idx_lower = {str(i).lower():i for i in df.index}
L221     for n in names:
L222         k = n.lower()
L223         if k in idx_lower: return df.loc[idx_lower[k]]
L224     return None
L225 def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
L226     if s is None or s.empty: return None
L227     v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L228 def _latest(s: pd.Series|None) -> float|None:
L229     if s is None or s.empty: return None
L230     v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L231
L232 def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
L233     t0=_now_ms(); bad=[]
L234     def one(t):
L235         try:
L236             tk = yf.Ticker(t)
L237             qcf = tk.quarterly_cashflow
L238             cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
L239             cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
L240             fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L241             cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
L242             if any(v is None for v in (cfo,cap,fcf)):
L243                 acf = tk.cashflow
L244                 if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
L245                 if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
L246                 if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L247             return None if all(v is not None for v in (cfo,cap,fcf)) else t
L248         except Exception: return t
L249     with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
L250         for r in ex.map(one, tickers):
L251             if r: bad.append(r)
L252     ms=_now_ms()-t0
L253     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L254     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L255     return f"YF_FIN:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L256         "level":level,"latency_ms":ms,"bad":bad
L257     }
L258
L259 # ==== Finnhub: cash-flow fallback
L260 _FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L261 _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L262
L263 def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L264     for i in range(retries):
L265         r = session.get(url, params=params, timeout=15)
L266         if r.status_code==429:
L267             time.sleep(min(2**i*sleep_s, 4.0)); continue
L268         r.raise_for_status(); return r.json()
L269     r.raise_for_status()
L270
L271 def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
L272     if not FINN_KEY:
L273         return "FINNHUB:SKIPPED (no key)", dict(level="SKIPPED",bad=[])
L274     t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
L275     for sym in tickers:
L276         try:
L277             j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
L278             arr=j.get("cashFlow") or []
L279             def pick(item,keys):
L280                 for k in keys:
L281                     if k in item and item[k] is not None: return item[k]
L282             cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
L283             cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
L284             cfo_ttm = np.nansum([np.nan if v is None else float(v) for v in cfo_vals]) if any(v is not None for v in cfo_vals) else None
L285             cap_ttm = np.nansum([np.nan if v is None else float(v) for v in cap_vals]) if any(v is not None for v in cap_vals) else None
L286             if cfo_ttm is None or cap_ttm is None:
L287                 j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"annual","limit":1,"token":FINN_KEY})
L288                 arr=j.get("cashFlow") or []
L289                 if arr:
L290                     item0=arr[0]
L291                     if cfo_ttm is None:
L292                         v=pick(item0,_FINN_CFO_KEYS); 
L293                         if v is not None: cfo_ttm=float(v)
L294                     if cap_ttm is None:
L295                         v=pick(item0,_FINN_CAPEX_KEYS); 
L296                         if v is not None: cap_ttm=float(v)
L297             if cfo_ttm is None or cap_ttm is None: bad.append(sym)
L298         except Exception: bad.append(sym)
L299     ms=_now_ms()-t0
L300     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L301     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L302     return f"FINNHUB:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L303         "level":level,"latency_ms":ms,"bad":bad
L304     }
L305
L306 # ==== SEC: companyfacts (Revenue/EPS) health
L307 SEC_REV_TAGS=["Revenues","RevenueFromContractWithCustomerExcludingAssessedTax","SalesRevenueNet","SalesRevenueGoodsNet","SalesRevenueServicesNet","Revenue"]
L308 SEC_EPS_TAGS=["EarningsPerShareDiluted","EarningsPerShareBasicAndDiluted","EarningsPerShare","EarningsPerShareBasic"]
L309
L310 def _units_for_tags(facts: dict, spaces: List[str], tags: List[str]) -> list:
L311     got=[]
L312     for sp in spaces:
L313         d=(facts.get("facts") or {}).get(sp) or {}
L314         for tg in tags:
L315             arr=(d.get(tg) or {}).get("units") or {}
L316             for unit, vals in (arr.items() if isinstance(arr,dict) else []):
L317                 if isinstance(vals,list) and vals: got.append(vals)
L318     return got
L319
L320 def _series_q_and_a(arrs: list) -> Tuple[list, list]:
L321     q_pairs,a_pairs=[],[]
L322     for vals in arrs:
L323         for v in vals:
L324             try:
L325                 dt=v.get("end") or v.get("fy"); val=float(v.get("val")); form=(v.get("form") or "").upper()
L326                 if "10-Q" in form or "6-K" in form or form=="Q": q_pairs.append((dt,val))
L327                 elif "10-K" in form or "20-F" in form or form=="K": a_pairs.append((dt,val))
L328             except Exception: pass
L329     q_pairs=sorted(q_pairs,key=lambda x: str(x[0]),reverse=True)
L330     a_pairs=sorted(a_pairs,key=lambda x: str(x[0]),reverse=True)
L331     return q_pairs,a_pairs
L332
L333 def sec_health(tickers: List[str]) -> Tuple[str, Dict]:
L334     t0=_now_ms(); t2cik=_sec_ticker_map(); bad=[]
L335     if not t2cik:
L336         ms=_now_ms()-t0
L337         det = f"SEC:SKIPPED (no SEC_CONTACT_EMAIL/403) latency={_fmt_ms(ms)}"
L338         return det, {"level":"SKIPPED","latency_ms":ms,"bad":[]}
L339     for t in tickers:
L340         # '.'„Å®'-'„ÅÆ„ÇÜ„Çâ„Åé„ÇíË®±ÂÆπ„Åó„ÅüÁ∞°Êòì„Éû„ÉÉ„ÉÅ
L341         cands = [(t or "").upper(), (t or "").upper().replace(".","-"), (t or "").upper().replace("-",""), (t or "").upper().replace(".","")]
L342         cik = next((t2cik.get(x) for x in cands if t2cik.get(x)), None)
L343         if not cik:
L344             bad.append(t); continue
L345         try:
L346             j=_sec_get(f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json")
L347             if j is None: bad.append(t); continue
L348             rev_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_REV_TAGS)
L349             eps_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_EPS_TAGS)
L350             rev_q,rev_a=_series_q_and_a(rev_arr); eps_q,eps_a=_series_q_and_a(eps_arr)
L351             if not (rev_q or rev_a) or not (eps_q or eps_a): bad.append(t)
L352         except Exception: bad.append(t)
L353         time.sleep(0.30)
L354     ms=_now_ms()-t0
L355     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L356     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L357     return f"SEC:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L358         "level":level,"latency_ms":ms,"bad":bad
L359     }
L360
L361 # ==== Orchestration
L362 def main():
L363     cur_path, cand_path = _autodiscover_csv()
L364     if not cur_path or not cand_path:
L365         msg = f"‚ö†Ô∏è CSV not found. cur={cur_path} cand={cand_path} (set CSV_CURRENT/CSV_CANDIDATE or place files)"
L366         print(msg); _post_slack(msg)
L367         if SOFT_FAIL: sys.exit(0)
L368         sys.exit(78)
L369
L370     tickers=sorted(set(_read_tickers(cur_path)+_read_tickers(cand_path)))
L371     if not tickers:
L372         msg = f"‚ö†Ô∏è No tickers from CSV. cur={cur_path} cand={cand_path}"
L373         print(msg); _post_slack(msg)
L374         if SOFT_FAIL: sys.exit(0)
L375         sys.exit(78)
L376
L377     det_price,meta_price=yf_price_health(tickers)
L378     det_info ,meta_info =yf_fastinfo_health(tickers)
L379     det_fin  ,meta_fin  =yf_financials_health(tickers)
L380     det_sec  ,meta_sec  =sec_health(tickers)
L381
L382     need_finn=meta_fin["bad"]
L383     det_finn,meta_finn  =finnhub_health(need_finn if need_finn else tickers[:0])
L384
L385     levels_map = {
L386         "YF_PRICE": meta_price["level"],
L387         "YF_INFO" : meta_info ["level"],
L388         "YF_FIN"  : meta_fin  ["level"],
L389         "SEC"     : meta_sec  ["level"],
L390         "FINNHUB" : meta_finn.get("level","SKIPPED"),
L391     }
L392     pri={"DOWN":3,"DEGRADED":2,"HEALTHY":1,"SKIPPED":0}
L393     core_levels = [lvl for api,lvl in levels_map.items() if api not in OPTIONAL_APIS]
L394     core_worst = max(core_levels, key=lambda x: pri.get(x,0)) if core_levels else "HEALTHY"
L395     all_worst  = max(levels_map.values(), key=lambda x: pri.get(x,0))
L396     worst = "DEGRADED" if (all_worst=="DOWN" and core_worst!="DOWN") else all_worst
L397     emoji={"HEALTHY":"‚úÖ","DEGRADED":"‚ö†Ô∏è","DOWN":"üõë"}.get(worst,"‚ÑπÔ∏è")
L398
L399     # ‰æ°Ê†ºÁ≥ªÂàó„ÅÆÂÖ±ÈÄöÈöúÂÆ≥ÔºàÂêå‰∏ÄÊó•„Å†„Åë„ÅÆÊ¨†Êêç„ÅåÈÅéÂçäÔºâÁ∞°ÊòìÊ§úÁü•
L400     outage_note=""
L401     try:
L402         from collections import Counter
L403         missing_dates=meta_price.get("per_ticker_missing",{})
L404         date_counter=Counter(); one_day_missing=0
L405         for _,info in missing_dates.items():
L406             dates=info.get("dates",set()); max_gap=info.get("max_gap",0)
L407             if len(dates)==1 and max_gap==1:
L408                 one_day_missing+=1; date_counter.update(dates)
L409         threshold=max(1,len(tickers)//2)
L410         if one_day_missing>=threshold:
L411             (missing_day,hits),=date_counter.most_common(1)
L412             outage_note=f" | OUTAGE: common_missing_day={missing_day} hits={hits}"
L413             if worst=="HEALTHY": worst="DEGRADED"; emoji="üü†"
L414     except Exception:
L415         pass
L416
L417     # ÂêÑAPI„ÅÆ„Ç¢„Ç§„Ç≥„É≥‰ªò‰∏é
L418     def icon_for(level: str) -> str:
L419         return {"HEALTHY":"‚úÖ","DEGRADED":"‚ö†Ô∏è","DOWN":"üõë","SKIPPED":"‚è≠Ô∏è"}.get(level, "‚ÑπÔ∏è")
L420     det_price = f"{icon_for(levels_map['YF_PRICE'])} {det_price}"
L421     det_info  = f"{icon_for(levels_map['YF_INFO' ])} {det_info}"
L422     det_fin   = f"{icon_for(levels_map['YF_FIN'  ])} {det_fin}"
L423     det_sec   = f"{icon_for(levels_map['SEC'     ])} {det_sec}"
L424     det_finn  = f"{icon_for(levels_map['FINNHUB' ])} {det_finn}"
L425
L426     summary=f"{emoji} API_HEALTH {worst}{outage_note} (exit_on={EXIT_ON_LEVEL})\n{det_price} | {det_info} | {det_fin} | {det_sec} | {det_finn}"
L427     has_problem=("DEGRADED" in worst) or ("DOWN" in worst)
L428
L429     if has_problem:
L430         def all_list(xs): return ", ".join(xs)
L431         lines=[]
L432         if meta_price["missing"] or meta_price["nf"]:
L433             xs=[*meta_price["nf"],*meta_price["missing"]]
L434             lines.append("YF_PRICE NG:\n" + all_list(xs))
L435         if meta_info["bad"]:
L436             lines.append("YF_INFO NG:\n" + all_list(meta_info["bad"]))
L437         if meta_fin["bad"]:
L438             lines.append("YF_FIN NG:\n" + all_list(meta_fin["bad"]))
L439         if meta_sec["bad"]:
L440             lines.append("SEC NG:\n" + all_list(meta_sec["bad"]))
L441         if meta_finn.get("bad"):
L442             lines.append("FINNHUB NG:\n" + all_list(meta_finn["bad"]))
L443         text=summary + ("\n" + "\n".join(lines) if lines else "")
L444     else:
L445         text=summary
L446
L447     # Â§â„Å™„ÉÜ„Ç£„ÉÉ„Ç´„Éº„ÅØÊØéÂõûÂÖ®‰ª∂ÈÄöÂ†±
L448     def pair_all(pairs): return ", ".join(f"{a}->{b}" for (a,b) in pairs)
L449     def list_all(xs): return ", ".join(xs)
L450     alias_fixed = meta_price.get("alias_fixed", [])
L451     still_missing = meta_price.get("nf", [])
L452     weird_lines = []
L453     if alias_fixed:
L454         weird_lines.append("Weird tickers (alias fixed):\n" + pair_all(alias_fixed))
L455     if still_missing:
L456         weird_lines.append("Weird tickers (not found):\n" + list_all(still_missing))
L457     if weird_lines:
L458         text = text + "\n" + "\n".join(weird_lines)
L459
L460     print(text); _post_slack(text)
L461     if SOFT_FAIL: sys.exit(0)
L462     # ÈÄÄÂá∫Âà§ÂÆöÔºö„Ç≥„Ç¢API„ÇíÂÑ™ÂÖà„ÄÇOPTIONAL„ÅåDOWN„Åß„ÇÇ core„ÅåHEALTHY/DEGRADED„Å™„ÇâÁ∑©Âíå„ÄÇ
L463     exit_by = core_worst if core_worst!="HEALTHY" else worst
L464     def _rank(x): return {"HEALTHY":1,"DEGRADED":2,"DOWN":3}.get(x,0)
L465     if _rank(exit_by) < _rank(EXIT_ON_LEVEL): sys.exit(0)
L466     sys.exit(20 if exit_by=="DOWN" else 10)
L467
L468 if __name__=="__main__":
L469     main()
```

## <.github/workflows/api-health.yml>
```text
L1 name: api-health-probe
L2 on:
L3   push:
L4     branches: [ main ]
L5
L6 jobs:
L7   probe:
L8     runs-on: ubuntu-latest
L9     timeout-minutes: 10
L10     steps:
L11       - uses: actions/checkout@v4
L12       - name: Show repo tree (CSV check)
L13         run: |
L14           echo "== ls -R (top 300 lines) =="
L15           ls -R | head -n 300 || true
L16           echo "== probable csv files =="
L17           (git ls-files | grep -Ei '(current|candidate).*\.csv$' || true)
L18       - uses: actions/setup-python@v5
L19         with:
L20           python-version: "3.11"
L21       - name: Install deps
L22         run: |
L23           python -m pip install --upgrade pip
L24           pip install yfinance pandas numpy requests
L25       - name: Run API health probe
L26         env:
L27           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L28           FINNHUB_API_KEY:   ${{ secrets.FINNHUB_API_KEY }}
L29           # SEC„É°„Éº„É´„ÅØÈÅ∏ÂÆö„Å®Âêå„ÅòÂêçÂâç„ÅÆ„Ç∑„Éº„ÇØ„É¨„ÉÉ„ÉàÔºàSEC_CONTACT_EMAILÔºâ„Åã„ÇâÊ∏°„Åô
L30           SEC_CONTACT_EMAIL: ${{ secrets.SEC_CONTACT_EMAIL }}
L31           # Âà§ÂÆö: DOWN „ÅÆ„Å®„Åç„Å†„ÅëÂ§±ÊïóÔºàDEGRADED„ÅØÊàêÂäüÔºâ
L32           EXIT_ON_LEVEL:     DOWN
L33           # ‰ªªÊÑè„ÅÆ„Éë„É©„É°„Éº„ÇøÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶Ôºâ
L34           YF_PERIOD:         1y
L35           YF_MIN_LEN:        "120"
L36           TIMEOUT_MS_WARN:   "5000"
L37           SOFT_FAIL:         "0"
L38         run: |
L39           python tools/api_health_probe.py
L40       - name: Mark job outcome
L41         if: always()
L42         run: echo "Done."
```
