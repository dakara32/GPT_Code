# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: tools/api_health_probe.py, .github/workflows/api-health.yml
# 作成日時: 2025-09-24 17:32:11 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <tools/api_health_probe.py>
```text
L1 #!/usr/bin/env python3
L2 # -*- coding: utf-8 -*-
L3 """
L4 api_health_probe.py — 選定プログラム依存API（Yahoo Finance / SEC / Finnhub）の総合ヘルスチェック
L5 Usage:
L6   export SLACK_WEBHOOK_URL=...
L7   export FINNHUB_API_KEY=...            # 任意（無ければ FinnhubはSKIPPED）
L8   export SEC_EMAIL=you@example.com      # 推奨（SEC User-Agent に使用）
L9   python tools/api_health_probe.py
L10 Env (optional):
L11   CSV_CURRENT=./current.csv
L12   CSV_CANDIDATE=./candidate.csv
L13   YF_PERIOD=1y
L14   YF_MIN_LEN=120
L15   TIMEOUT_MS_WARN=5000
L16   MAX_WORKERS=8
L17   SOFT_FAIL=0   # 1なら常にexit 0
L18 Exit codes:
L19   HEALTHY=0, DEGRADED=10, DOWN=20 （SOFT_FAIL=1なら常に0）
L20 """
L21 import os, sys, time, json, math, csv, re, concurrent.futures as cf
L22 from typing import List, Dict, Tuple
L23 import pandas as pd
L24 import numpy as np
L25 import requests
L26 import yfinance as yf
L27
L28 # ---- Settings
L29 CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
L30 CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
L31 YF_PERIOD   = os.getenv("YF_PERIOD","1y")
L32 YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
L33 TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
L34 SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
L35 FINN_KEY    = os.getenv("FINNHUB_API_KEY")
L36 SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
L37 SEC_EMAIL   = os.getenv("SEC_EMAIL","")
L38 MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
L39 # “任意API”の扱い：ここに列挙されたAPIがDOWNでも全体は最大DEGRADED止まり
L40 OPTIONAL_APIS = set([x.strip().upper() for x in os.getenv("OPTIONAL_APIS","FINNHUB").split(",") if x.strip()])
L41 # 退出条件（既定: DEGRADED）。DOWNにすれば「DOWNの時だけ失敗」
L42 EXIT_ON_LEVEL = os.getenv("EXIT_ON_LEVEL","DEGRADED").upper()
L43
L44 # ---- Utils
L45 def _now_ms() -> int: return int(time.time()*1000)
L46
L47 def _post_slack(text: str):
L48     if not SLACK_WEBHOOK:
L49         print("[SLACK] webhook missing; print only\n"+text); return
L50     try:
L51         r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=5)
L52         print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
L53     except Exception as e: print(f"[SLACK] send error: {e}")
L54
L55 def _read_tickers(path: str) -> List[str]:
L56     if not os.path.exists(path): return []
L57     # 'ticker','symbol','Symbol','Ticker' の列に対応。無ければ1列CSVも許容。
L58     try:
L59         df = pd.read_csv(path)
L60         for c in ["ticker","symbol","Symbol","Ticker"]:
L61             if c in df.columns:
L62                 col = df[c].astype(str).str.strip()
L63                 return [t for t in col if t and t.lower()!="nan"]
L64         with open(path, newline="") as f:
L65             rd = csv.reader(f)
L66             vals = [row[0].strip() for row in rd if row]
L67             if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
L68             return [v for v in vals if v]
L69     except Exception:
L70         return []
L71
L72 def _autodiscover_csv() -> tuple[str|None, str|None]:
L73     """
L74     リポジトリ内から current*.csv / candidate*.csv を再帰探索し、最初に見つけたものを返す。
L75     明示指定（ENV）があればそれを優先。見つからなければ None。
L76     """
L77     cur = CSV_CURRENT if os.path.exists(CSV_CURRENT) else None
L78     cand = CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None
L79     if cur and cand:
L80         return cur, cand
L81
L82     for root, _, files in os.walk(".", topdown=True):
L83         for fn in files:
L84             if not fn.lower().endswith(".csv"):
L85                 continue
L86             path = os.path.join(root, fn)
L87             name = fn.lower()
L88             if not cur and "current" in name:
L89                 cur = path
L90             if not cand and "candidate" in name:
L91                 cand = path
L92         if cur and cand:
L93             break
L94     return cur, cand
L95
L96 def _fmt_ms(ms: int) -> str:
L97     return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"
L98
L99 # ---- Ticker 正規化（YF用）
L100 def _yf_variants(sym: str):
L101     s = (sym or "").upper()
L102     cands = []
L103     def add(x):
L104         if x and x not in cands: cands.append(x)
L105     add(s)
L106     add(s.replace(".","-"))   # BRK.B -> BRK-B, PBR.A -> PBR-A
L107     add(re.sub(r"[.\-^]", "", s))  # 記号除去
L108     return cands
L109
L110 # ================================================================
L111 # Yahoo Finance: price series ヘルス
L112 # ================================================================
L113 def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
L114     t0 = _now_ms()
L115     data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
L116     close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
L117     per_ticker_missing = {}
L118     nf=[]          # 一括でも別名再試行でも取得できず
L119     missing=[]     # 列はあるがNaN/不足
L120     ok=[]          # 問題なし
L121     alias_fixed=[] # (orig, alias) 別名で回復
L122     for t in tickers:
L123         if t not in close.columns:
L124             # 簡易ノーマライズ後、個別で5dだけ再取得して最低限の生存確認
L125             recovered = False
L126             for alias in _yf_variants(t):
L127                 try:
L128                     s = yf.Ticker(alias).history(period="5d", auto_adjust=True)["Close"]
L129                     if isinstance(s, pd.Series) and s.notna().sum() > 0:
L130                         recovered = True
L131                         alias_fixed.append((t, alias))
L132                         break
L133                 except Exception:
L134                     pass
L135             if not recovered:
L136                 nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
L137             # 再取得で回復した場合はOK扱い（dates/max_gapは空のまま）
L138             ok.append(t); per_ticker_missing.setdefault(t, {"dates":set(),"max_gap":0}); continue
L139         s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
L140         isna = s.isna().values; idx = s.index
L141         total_nan = int(isna.sum()); cur=max_gap=0
L142         dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
L143         for v in isna:
L144             if v: cur+=1
L145             else:
L146                 if cur>0: max_gap=max(max_gap,cur); cur=0
L147         if cur>0: max_gap=max(max_gap,cur)
L148         per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
L149         if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
L150         else: ok.append(t)
L151     ms = _now_ms()-t0
L152     level = "HEALTHY" if len(ok)==len(tickers) else ("DEGRADED" if len(ok)>=len(tickers)//2 else "DOWN")
L153     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L154     return f"YF_PRICE:{level} ok={len(ok)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L155         "level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
L156         "per_ticker_missing":per_ticker_missing,
L157         "alias_fixed": alias_fixed
L158     }
L159
L160 # ================================================================
L161 # Yahoo Finance: fast_info.lastPrice ヘルス
L162 # ================================================================
L163 def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
L164     t0 = _now_ms(); tk = yf.Tickers(" ".join(tickers)); bad=[]
L165     for t in tickers:
L166         try:
L167             v = tk.tickers[t].fast_info.get("lastPrice", None)
L168             if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
L169         except Exception: bad.append(t)
L170     ms=_now_ms()-t0
L171     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L172     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L173     return f"YF_INFO:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L174         "level":level,"latency_ms":ms,"bad":bad
L175     }
L176
L177 # ================================================================
L178 # Yahoo Finance: financials（CFO/Capex/FCF）ヘルス
L179 # ================================================================
L180 _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
L181                "capex":["Capital Expenditure","Capital Expenditures"]}
L182 def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
L183     if df is None or df.empty: return None
L184     idx_lower = {str(i).lower():i for i in df.index}
L185     for n in names:
L186         k = n.lower()
L187         if k in idx_lower: return df.loc[idx_lower[k]]
L188     return None
L189 def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
L190     if s is None or s.empty: return None
L191     v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L192 def _latest(s: pd.Series|None) -> float|None:
L193     if s is None or s.empty: return None
L194     v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L195
L196 def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
L197     t0=_now_ms(); bad=[]
L198     def one(t):
L199         try:
L200             tk = yf.Ticker(t)
L201             qcf = tk.quarterly_cashflow
L202             cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
L203             cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
L204             fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L205             cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
L206             if any(v is None for v in (cfo,cap,fcf)):
L207                 acf = tk.cashflow
L208                 if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
L209                 if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
L210                 if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L211             return None if all(v is not None for v in (cfo,cap,fcf)) else t
L212         except Exception: return t
L213     with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
L214         for r in ex.map(one, tickers):
L215             if r: bad.append(r)
L216     ms=_now_ms()-t0
L217     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L218     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L219     return f"YF_FIN:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L220         "level":level,"latency_ms":ms,"bad":bad
L221     }
L222
L223 # ================================================================
L224 # Finnhub: cash-flow（CFO/Capex）ヘルス（フォールバック）
L225 # ================================================================
L226 _FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L227 _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L228
L229 def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L230     for i in range(retries):
L231         r = session.get(url, params=params, timeout=15)
L232         if r.status_code==429:
L233             time.sleep(min(2**i*sleep_s, 4.0)); continue
L234         r.raise_for_status(); return r.json()
L235     r.raise_for_status()
L236
L237 def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
L238     if not FINN_KEY:
L239         return "FINNHUB:SKIPPED (no key)", dict(level="SKIPPED",bad=[])
L240     t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
L241     for sym in tickers:
L242         try:
L243             j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
L244             arr=j.get("cashFlow") or []
L245             def pick(item,keys):
L246                 for k in keys:
L247                     if k in item and item[k] is not None: return item[k]
L248             cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
L249             cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
L250             cfo_ttm = np.nansum([np.nan if v is None else float(v) for v in cfo_vals]) if any(v is not None for v in cfo_vals) else None
L251             cap_ttm = np.nansum([np.nan if v is None else float(v) for v in cap_vals]) if any(v is not None for v in cap_vals) else None
L252             if cfo_ttm is None or cap_ttm is None:
L253                 j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"annual","limit":1,"token":FINN_KEY})
L254                 arr=j.get("cashFlow") or []
L255                 if arr:
L256                     item0=arr[0]
L257                     if cfo_ttm is None:
L258                         v=pick(item0,_FINN_CFO_KEYS); 
L259                         if v is not None: cfo_ttm=float(v)
L260                     if cap_ttm is None:
L261                         v=pick(item0,_FINN_CAPEX_KEYS); 
L262                         if v is not None: cap_ttm=float(v)
L263             if cfo_ttm is None or cap_ttm is None: bad.append(sym)
L264         except Exception: bad.append(sym)
L265     ms=_now_ms()-t0
L266     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L267     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L268     return f"FINNHUB:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L269         "level":level,"latency_ms":ms,"bad":bad
L270     }
L271
L272 # ================================================================
L273 # SEC: companyfacts（Revenue/EPS）ヘルス
L274 # ================================================================
L275 def _sec_headers():
L276     """
L277     SECは連絡先付きUser-Agent/Fromを強く推奨・一部で必須。
L278     SEC_EMAILが空なら最低限のUAにしつつ、403発生時は上位でSKIP扱いにする。
L279     """
L280     ua = (f"api-health-probe/1 (+mailto:{SEC_EMAIL})" if SEC_EMAIL else "api-health-probe/1")
L281     hdr = {
L282         "User-Agent": ua[:200],
L283         "Accept": "application/json",
L284     }
L285     if SEC_EMAIL:
L286         hdr["From"] = SEC_EMAIL[:200]
L287     return hdr
L288
L289 def _sec_get(url: str, params=None, retries=3, sleep_s: float=0.5):
L290     """
L291     403やネットワークエラーは上位でSKIP判定できるよう None を返す。
L292     """
L293     for i in range(retries):
L294         try:
L295             r = requests.get(url, params=params or {}, headers=_sec_headers(), timeout=15)
L296             if r.status_code==429:
L297                 time.sleep(min(2**i*sleep_s, 4.0)); continue
L298             if r.status_code==403:
L299                 # UA/From未設定やアクセス制限。上位でSKIP。
L300                 return None
L301             r.raise_for_status(); return r.json()
L302         except Exception:
L303             time.sleep(min(2**i*sleep_s, 2.0))
L304     return None
L305
L306 def _sec_ticker_map() -> Dict[str,str]:
L307     j = _sec_get("https://www.sec.gov/files/company_tickers.json")
L308     if j is None:
L309         return {}
L310     out={}
L311     it=(j.values() if isinstance(j,dict) else j)
L312     for item in it:
L313         try:
L314             t=(item.get("ticker") or item.get("TICKER") or "").upper()
L315             cik=str(item.get("cik_str") or item.get("CIK") or "").zfill(10)
L316             if t and cik: out[t]=cik
L317         except Exception: continue
L318     return out
L319
L320 SEC_REV_TAGS=["Revenues","RevenueFromContractWithCustomerExcludingAssessedTax","SalesRevenueNet","SalesRevenueGoodsNet","SalesRevenueServicesNet","Revenue"]
L321 SEC_EPS_TAGS=["EarningsPerShareDiluted","EarningsPerShareBasicAndDiluted","EarningsPerShare","EarningsPerShareBasic"]
L322
L323 def _normalize_for_sec(sym: str) -> List[str]:
L324     s=(sym or "").upper(); outs=[]; add=lambda x: outs.append(x) if x and x not in outs else None
L325     add(s); add(s.replace(".","-")); add(s.replace("-","")); add(s.replace(".","")); return outs
L326
L327 def _units_for_tags(facts: dict, spaces: List[str], tags: List[str]) -> list:
L328     got=[]
L329     for sp in spaces:
L330         d=(facts.get("facts") or {}).get(sp) or {}
L331         for tg in tags:
L332             arr=(d.get(tg) or {}).get("units") or {}
L333             for unit, vals in (arr.items() if isinstance(arr,dict) else []):
L334                 if isinstance(vals,list) and vals: got.append(vals)
L335     return got
L336
L337 def _series_q_and_a(arrs: list) -> Tuple[list, list]:
L338     q_pairs,a_pairs=[],[]
L339     for vals in arrs:
L340         for v in vals:
L341             try:
L342                 dt=v.get("end") or v.get("fy"); val=float(v.get("val")); form=(v.get("form") or "").upper()
L343                 if "10-Q" in form or "6-K" in form or form=="Q": q_pairs.append((dt,val))
L344                 elif "10-K" in form or "20-F" in form or form=="K": a_pairs.append((dt,val))
L345             except Exception: pass
L346     q_pairs=sorted(q_pairs,key=lambda x: str(x[0]),reverse=True)
L347     a_pairs=sorted(a_pairs,key=lambda x: str(x[0]),reverse=True)
L348     return q_pairs,a_pairs
L349
L350 def sec_health(tickers: List[str]) -> Tuple[str, Dict]:
L351     t0=_now_ms(); t2cik=_sec_ticker_map(); bad=[]
L352     # CIKマップが取れない（403/ネット断/UA未設定など）はSKIPPED
L353     if not t2cik:
L354         ms=_now_ms()-t0
L355         note="no SEC_EMAIL/403" if not SEC_EMAIL else "SEC endpoint blocked"
L356         det=f"SEC:SKIPPED ({note}) latency={_fmt_ms(ms)}"
L357         return det,{"level":"SKIPPED","latency_ms":ms,"bad":[]}
L358     for t in tickers:
L359         cands=_normalize_for_sec(t); cik=next((t2cik.get(x) for x in cands if t2cik.get(x)), None)
L360         if not cik: bad.append(t); continue
L361         try:
L362             j=_sec_get(f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json")
L363             if j is None:
L364                 bad.append(t); continue
L365             rev_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_REV_TAGS)
L366             eps_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_EPS_TAGS)
L367             rev_q,rev_a=_series_q_and_a(rev_arr); eps_q,eps_a=_series_q_and_a(eps_arr)
L368             if not (rev_q or rev_a) or not (eps_q or eps_a): bad.append(t)
L369         except Exception: bad.append(t)
L370         time.sleep(0.30)  # SEC負荷配慮
L371     ms=_now_ms()-t0
L372     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L373     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L374     return f"SEC:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L375         "level":level,"latency_ms":ms,"bad":bad
L376     }
L377
L378 # ================================================================
L379 # Orchestration
L380 # ================================================================
L381 def main():
L382     cur_path, cand_path = _autodiscover_csv()
L383     if not cur_path or not cand_path:
L384         msg = f"⚠️ CSV not found. cur={cur_path} cand={cand_path} (set CSV_CURRENT/CSV_CANDIDATE or place files)"
L385         print(msg); _post_slack(msg)
L386         if SOFT_FAIL:
L387             sys.exit(0)
L388         sys.exit(78)
L389
L390     tickers=sorted(set(_read_tickers(cur_path)+_read_tickers(cand_path)))
L391     if not tickers:
L392         msg = f"⚠️ No tickers from CSV. cur={cur_path} cand={cand_path}"
L393         print(msg); _post_slack(msg)
L394         if SOFT_FAIL:
L395             sys.exit(0)
L396         sys.exit(78)
L397
L398     # YF
L399     det_price,meta_price=yf_price_health(tickers)
L400     det_info ,meta_info =yf_fastinfo_health(tickers)
L401     det_fin  ,meta_fin  =yf_financials_health(tickers)
L402
L403     # SEC
L404     det_sec  ,meta_sec  =sec_health(tickers)
L405
L406     # Finnhub（必要時のみ。YF財務NG銘柄へのフォールバック検証）
L407     need_finn=meta_fin["bad"]
L408     det_finn,meta_finn  =finnhub_health(need_finn if need_finn else tickers[:0])
L409
L410     # API別レベル
L411     levels_map = {
L412         "YF_PRICE": meta_price["level"],
L413         "YF_INFO" : meta_info ["level"],
L414         "YF_FIN"  : meta_fin  ["level"],
L415         "SEC"     : meta_sec  ["level"],
L416         "FINNHUB" : meta_finn.get("level","SKIPPED"),
L417     }
L418     pri={"DOWN":3,"DEGRADED":2,"HEALTHY":1,"SKIPPED":0}
L419     # コアAPI（OPTIONAL_APIS 以外）のワースト
L420     core_levels = [lvl for api,lvl in levels_map.items() if api not in OPTIONAL_APIS]
L421     core_worst = max(core_levels, key=lambda x: pri.get(x,0)) if core_levels else "HEALTHY"
L422     # 全体ワースト（表示用）
L423     all_worst  = max(levels_map.values(), key=lambda x: pri.get(x,0))
L424     # ただし、DOWN が OPTIONAL_APIS のみから来ている場合は全体を DEGRADED までに抑制
L425     if all_worst=="DOWN" and core_worst!="DOWN":
L426         worst = "DEGRADED"
L427     else:
L428         worst = all_worst
L429     emoji={"HEALTHY":"✅","DEGRADED":"⚠️","DOWN":"🛑"}.get(worst,"ℹ️")
L430
L431     # 共通障害（同一日だけの欠損が過半）を簡易検知（価格系列ベース）
L432     outage_note=""
L433     try:
L434         from collections import Counter
L435         missing_dates=meta_price.get("per_ticker_missing",{})
L436         date_counter=Counter(); one_day_missing=0
L437         for _,info in missing_dates.items():
L438             dates=info.get("dates",set()); max_gap=info.get("max_gap",0)
L439             if len(dates)==1 and max_gap==1:
L440                 one_day_missing+=1; date_counter.update(dates)
L441         threshold=max(1,len(tickers)//2)
L442         if one_day_missing>=threshold:
L443             (missing_day,hits),=date_counter.most_common(1)
L444             outage_note=f" | OUTAGE: common_missing_day={missing_day} hits={hits}"
L445             if worst=="HEALTHY":
L446                 worst="DEGRADED"; emoji="🟠"
L447     except Exception:
L448         pass
L449
L450     summary=f"{emoji} API_HEALTH {worst}{outage_note} (exit_on={EXIT_ON_LEVEL})\n{det_price} | {det_info} | {det_fin} | {det_sec} | {det_finn}"
L451     has_problem=("DEGRADED" in worst) or ("DOWN" in worst)
L452
L453     if has_problem:
L454         def head_problem(xs): return ", ".join(xs[:10]) + (f" …(+{len(xs)-10})" if len(xs)>10 else "")
L455         lines=[]
L456         if meta_price["missing"] or meta_price["nf"]:
L457             xs=[*meta_price["nf"],*meta_price["missing"]]; lines.append(f"YF_PRICE NG: {head_problem(xs)}")
L458         if meta_info["bad"]:  lines.append(f"YF_INFO NG: {head_problem(meta_info['bad'])}")
L459         if meta_fin["bad"]:   lines.append(f"YF_FIN NG: {head_problem(meta_fin['bad'])}")
L460         if meta_sec["bad"]:   lines.append(f"SEC NG: {head_problem(meta_sec['bad'])}")
L461         if meta_finn.get("bad"): lines.append(f"FINNHUB NG: {head_problem(meta_finn['bad'])}")
L462         text=summary + ("\n" + "\n".join(lines) if lines else "")
L463     else:
L464         text=summary
L465
L466     # “変なティッカー”は毎回通報
L467     def head_pair(pairs):
L468         xs=[f"{a}->{b}" for (a,b) in pairs[:10]]
L469         return ", ".join(xs) + (f" …(+{len(pairs)-10})" if len(pairs)>10 else "")
L470     def head(xs):
L471         return ", ".join(xs[:10]) + (f" …(+{len(xs)-10})" if len(xs)>10 else "")
L472     alias_fixed = meta_price.get("alias_fixed", [])
L473     still_missing = meta_price.get("nf", [])
L474     weird_lines = []
L475     if alias_fixed:
L476         weird_lines.append(f"Weird tickers (alias fixed): {head_pair(alias_fixed)}")
L477     if still_missing:
L478         weird_lines.append(f"Weird tickers (not found): {head(still_missing)}")
L479     if weird_lines:
L480         text = text + "\n" + "\n".join(weird_lines)
L481
L482     print(text); _post_slack(text)
L483     if SOFT_FAIL: sys.exit(0)
L484     # 退出判定：基準は“コアAPIの状態”。OPTIONALがDOWNでも coreがHEALTHY/DEGRADEDなら緩和。
L485     exit_by = core_worst if core_worst!="HEALTHY" else worst
L486     def _rank(x): return {"HEALTHY":1,"DEGRADED":2,"DOWN":3}.get(x,0)
L487     # EXIT_ON_LEVEL 未満なら成功終了
L488     if _rank(exit_by) < _rank(EXIT_ON_LEVEL):
L489         sys.exit(0)
L490     sys.exit(20 if exit_by=="DOWN" else 10)
L491
L492 if __name__=="__main__":
L493     main()
```

## <.github/workflows/api-health.yml>
```text
L1 name: api-health-probe
L2 on:
L3   push:
L4     branches: [ main ]
L5
L6 jobs:
L7   probe:
L8     runs-on: ubuntu-latest
L9     timeout-minutes: 10
L10     steps:
L11       - uses: actions/checkout@v4
L12       - name: Show repo tree (CSV check)
L13         run: |
L14           echo "== ls -R for quick CSV check =="
L15           ls -R | head -n 300
L16           echo "== grep probable csv files =="
L17           (git ls-files | grep -Ei '(current|candidate).*\.csv$' || true)
L18       - uses: actions/setup-python@v5
L19         with:
L20           python-version: "3.11"
L21       - name: Install deps
L22         run: |
L23           python -m pip install --upgrade pip
L24           pip install yfinance pandas numpy requests
L25       - name: Run API health probe
L26         env:
L27           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L28           FINNHUB_API_KEY:   ${{ secrets.FINNHUB_API_KEY }}
L29           SEC_EMAIL:         ${{ secrets.SEC_EMAIL }}
L30           # 上書きしたい場合だけ指定（例: CSV_CURRENT: data/current.csv）
L31           # CSV_CURRENT:       current.csv
L32           # CSV_CANDIDATE:     candidate.csv
L33           YF_PERIOD:         1y
L34           YF_MIN_LEN:        "120"
L35           TIMEOUT_MS_WARN:   "5000"
L36           SOFT_FAIL:         "0"
L37           EXIT_ON_LEVEL:     DOWN
L38         run: |
L39           python tools/api_health_probe.py
```
