# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: tools/api_health_probe.py, .github/workflows/api-health.yml
# ‰ΩúÊàêÊó•ÊôÇ: 2025-09-24 16:29:29 (JST)
# ‰Ωø„ÅÑÊñπ: ‰∏ã„ÅÆ„ÉÅ„É£„É≥„ÇØ„ÇíÈ†Ü„Å´Ë≤º„Çå„Å∞„Åì„ÅÆ„ÉÅ„É£„ÉÉ„Éà„ÅßÂÖ®‰ΩìÊääÊè°„Åß„Åç„Åæ„Åô„ÄÇ
# Ê≥®Ë®ò: ÂêÑ„Éï„Ç°„Ç§„É´„ÅØÂÄãÂà•„Å´ L1.. „ÅßË°åÁï™Âè∑‰ªò‰∏é„ÄÇ
---

## <tools/api_health_probe.py>
```text
L1 #!/usr/bin/env python3
L2 # -*- coding: utf-8 -*-
L3 """
L4 api_health_probe.py ‚Äî ÈÅ∏ÂÆö„Éó„É≠„Ç∞„É©„É†‰æùÂ≠òAPIÔºàYahoo Finance / SEC / FinnhubÔºâ„ÅÆÁ∑èÂêà„Éò„É´„Çπ„ÉÅ„Çß„ÉÉ„ÇØ
L5 Usage:
L6   export SLACK_WEBHOOK_URL=...
L7   export FINNHUB_API_KEY=...            # ‰ªªÊÑèÔºàÁÑ°„Åë„Çå„Å∞ Finnhub„ÅØSKIPPEDÔºâ
L8   export SEC_EMAIL=you@example.com      # Êé®Â•®ÔºàSEC User-Agent „Å´‰ΩøÁî®Ôºâ
L9   python tools/api_health_probe.py
L10 Env (optional):
L11   CSV_CURRENT=./current.csv
L12   CSV_CANDIDATE=./candidate.csv
L13   YF_PERIOD=1y
L14   YF_MIN_LEN=120
L15   TIMEOUT_MS_WARN=5000
L16   MAX_WORKERS=8
L17   SOFT_FAIL=0   # 1„Å™„ÇâÂ∏∏„Å´exit 0
L18 Exit codes:
L19   HEALTHY=0, DEGRADED=10, DOWN=20 ÔºàSOFT_FAIL=1„Å™„ÇâÂ∏∏„Å´0Ôºâ
L20 """
L21 import os, sys, time, json, math, csv, concurrent.futures as cf
L22 from typing import List, Dict, Tuple
L23 import pandas as pd
L24 import numpy as np
L25 import requests
L26 import yfinance as yf
L27
L28 # ---- Settings
L29 CSV_CURRENT = os.getenv("CSV_CURRENT","./current.csv")
L30 CSV_CANDIDATE= os.getenv("CSV_CANDIDATE","./candidate.csv")
L31 YF_PERIOD   = os.getenv("YF_PERIOD","1y")
L32 YF_MIN_LEN  = int(os.getenv("YF_MIN_LEN","120"))
L33 TIMEOUT_MS_WARN = int(os.getenv("TIMEOUT_MS_WARN","5000"))
L34 SOFT_FAIL   = os.getenv("SOFT_FAIL","0") == "1"
L35 FINN_KEY    = os.getenv("FINNHUB_API_KEY")
L36 SLACK_WEBHOOK = os.getenv("SLACK_WEBHOOK_URL") or os.getenv("SLACK_WEBHOOK")
L37 SEC_EMAIL   = os.getenv("SEC_EMAIL","")
L38 MAX_WORKERS = int(os.getenv("MAX_WORKERS","8"))
L39
L40 # ---- Utils
L41 def _now_ms() -> int: return int(time.time()*1000)
L42
L43 def _post_slack(text: str):
L44     if not SLACK_WEBHOOK:
L45         print("[SLACK] webhook missing; print only\n"+text); return
L46     try:
L47         r = requests.post(SLACK_WEBHOOK, json={"text": text}, timeout=5)
L48         print(f"[SLACK] status={r.status_code}"); r.raise_for_status()
L49     except Exception as e: print(f"[SLACK] send error: {e}")
L50
L51 def _read_tickers(path: str) -> List[str]:
L52     if not os.path.exists(path): return []
L53     # 'ticker','symbol','Symbol','Ticker' „ÅÆÂàó„Å´ÂØæÂøú„ÄÇÁÑ°„Åë„Çå„Å∞1ÂàóCSV„ÇÇË®±ÂÆπ„ÄÇ
L54     try:
L55         df = pd.read_csv(path)
L56         for c in ["ticker","symbol","Symbol","Ticker"]:
L57             if c in df.columns:
L58                 col = df[c].astype(str).str.strip()
L59                 return [t for t in col if t and t.lower()!="nan"]
L60         with open(path, newline="") as f:
L61             rd = csv.reader(f)
L62             vals = [row[0].strip() for row in rd if row]
L63             if vals and vals[0].lower() in ("ticker","symbol"): vals = vals[1:]
L64             return [v for v in vals if v]
L65     except Exception:
L66         return []
L67
L68 def _autodiscover_csv() -> tuple[str|None, str|None]:
L69     """
L70     „É™„Éù„Ç∏„Éà„É™ÂÜÖ„Åã„Çâ current*.csv / candidate*.csv „ÇíÂÜçÂ∏∞Êé¢Á¥¢„Åó„ÄÅÊúÄÂàù„Å´Ë¶ã„Å§„Åë„Åü„ÇÇ„ÅÆ„ÇíËøî„Åô„ÄÇ
L71     ÊòéÁ§∫ÊåáÂÆöÔºàENVÔºâ„Åå„ÅÇ„Çå„Å∞„Åù„Çå„ÇíÂÑ™ÂÖà„ÄÇË¶ã„Å§„Åã„Çâ„Å™„Åë„Çå„Å∞ None„ÄÇ
L72     """
L73     cur = CSV_CURRENT if os.path.exists(CSV_CURRENT) else None
L74     cand = CSV_CANDIDATE if os.path.exists(CSV_CANDIDATE) else None
L75     if cur and cand:
L76         return cur, cand
L77
L78     for root, _, files in os.walk(".", topdown=True):
L79         for fn in files:
L80             if not fn.lower().endswith(".csv"):
L81                 continue
L82             path = os.path.join(root, fn)
L83             name = fn.lower()
L84             if not cur and "current" in name:
L85                 cur = path
L86             if not cand and "candidate" in name:
L87                 cand = path
L88         if cur and cand:
L89             break
L90     return cur, cand
L91
L92 def _fmt_ms(ms: int) -> str:
L93     return f"{ms}ms" if ms < 1000 else f"{ms/1000:.2f}s"
L94
L95 # ================================================================
L96 # Yahoo Finance: price series „Éò„É´„Çπ
L97 # ================================================================
L98 def yf_price_health(tickers: List[str]) -> Tuple[str, Dict]:
L99     t0 = _now_ms()
L100     data = yf.download(tickers, period=YF_PERIOD, auto_adjust=True, progress=False, threads=True)
L101     close = data["Close"] if isinstance(data, pd.DataFrame) and "Close" in data else pd.DataFrame()
L102     per_ticker_missing = {}; nf=[]; missing=[]; ok=[]
L103     for t in tickers:
L104         if t not in close.columns:
L105             nf.append(t); per_ticker_missing[t]={"dates":set(),"max_gap":0}; continue
L106         s = close[t]; n = s.shape[0]; nn = int(s.notna().sum())
L107         isna = s.isna().values; idx = s.index
L108         total_nan = int(isna.sum()); cur=max_gap=0
L109         dates = set(str(d.date()) for d,v in zip(idx,isna) if v)
L110         for v in isna:
L111             if v: cur+=1
L112             else:
L113                 if cur>0: max_gap=max(max_gap,cur); cur=0
L114         if cur>0: max_gap=max(max_gap,cur)
L115         per_ticker_missing[t] = {"dates":dates,"max_gap":max_gap}
L116         if nn==0 or total_nan>0 or n<YF_MIN_LEN: missing.append(t)
L117         else: ok.append(t)
L118     ms = _now_ms()-t0
L119     level = "HEALTHY" if len(ok)==len(tickers) else ("DEGRADED" if len(ok)>=len(tickers)//2 else "DOWN")
L120     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L121     return f"YF_PRICE:{level} ok={len(ok)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L122         "level":level,"latency_ms":ms,"ok":ok,"nf":nf,"missing":missing,
L123         "per_ticker_missing":per_ticker_missing
L124     }
L125
L126 # ================================================================
L127 # Yahoo Finance: fast_info.lastPrice „Éò„É´„Çπ
L128 # ================================================================
L129 def yf_fastinfo_health(tickers: List[str]) -> Tuple[str, Dict]:
L130     t0 = _now_ms(); tk = yf.Tickers(" ".join(tickers)); bad=[]
L131     for t in tickers:
L132         try:
L133             v = tk.tickers[t].fast_info.get("lastPrice", None)
L134             if v is None or (isinstance(v,float) and math.isnan(v)): bad.append(t)
L135         except Exception: bad.append(t)
L136     ms=_now_ms()-t0
L137     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L138     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L139     return f"YF_INFO:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L140         "level":level,"latency_ms":ms,"bad":bad
L141     }
L142
L143 # ================================================================
L144 # Yahoo Finance: financialsÔºàCFO/Capex/FCFÔºâ„Éò„É´„Çπ
L145 # ================================================================
L146 _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"],
L147                "capex":["Capital Expenditure","Capital Expenditures"]}
L148 def _pick_row(df: pd.DataFrame, names: List[str]) -> pd.Series|None:
L149     if df is None or df.empty: return None
L150     idx_lower = {str(i).lower():i for i in df.index}
L151     for n in names:
L152         k = n.lower()
L153         if k in idx_lower: return df.loc[idx_lower[k]]
L154     return None
L155 def _sum_last_n(s: pd.Series|None, n:int) -> float|None:
L156     if s is None or s.empty: return None
L157     v = s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L158 def _latest(s: pd.Series|None) -> float|None:
L159     if s is None or s.empty: return None
L160     v = s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L161
L162 def yf_financials_health(tickers: List[str]) -> Tuple[str, Dict]:
L163     t0=_now_ms(); bad=[]
L164     def one(t):
L165         try:
L166             tk = yf.Ticker(t)
L167             qcf = tk.quarterly_cashflow
L168             cfo_q = _pick_row(qcf, _CF_ALIASES["cfo"])
L169             cap_q = _pick_row(qcf, _CF_ALIASES["capex"])
L170             fcf_q = _pick_row(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L171             cfo = _sum_last_n(cfo_q,4); cap = _sum_last_n(cap_q,4); fcf = _sum_last_n(fcf_q,4)
L172             if any(v is None for v in (cfo,cap,fcf)):
L173                 acf = tk.cashflow
L174                 if cfo is None: cfo=_latest(_pick_row(acf,_CF_ALIASES["cfo"]))
L175                 if cap is None: cap=_latest(_pick_row(acf,_CF_ALIASES["capex"]))
L176                 if fcf is None: fcf=_latest(_pick_row(acf,["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L177             return None if all(v is not None for v in (cfo,cap,fcf)) else t
L178         except Exception: return t
L179     with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
L180         for r in ex.map(one, tickers):
L181             if r: bad.append(r)
L182     ms=_now_ms()-t0
L183     level = "HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L184     slow = " SLOW" if ms>=TIMEOUT_MS_WARN else ""
L185     return f"YF_FIN:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}", {
L186         "level":level,"latency_ms":ms,"bad":bad
L187     }
L188
L189 # ================================================================
L190 # Finnhub: cash-flowÔºàCFO/CapexÔºâ„Éò„É´„ÇπÔºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºâ
L191 # ================================================================
L192 _FINN_CFO_KEYS   = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L193 _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L194
L195 def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L196     for i in range(retries):
L197         r = session.get(url, params=params, timeout=15)
L198         if r.status_code==429:
L199             time.sleep(min(2**i*sleep_s, 4.0)); continue
L200         r.raise_for_status(); return r.json()
L201     r.raise_for_status()
L202
L203 def finnhub_health(tickers: List[str]) -> Tuple[str, Dict]:
L204     if not FINN_KEY:
L205         return "FINNHUB:SKIPPED (no key)", dict(level="SKIPPED",bad=[])
L206     t0=_now_ms(); base="https://finnhub.io/api/v1"; s=requests.Session(); bad=[]
L207     for sym in tickers:
L208         try:
L209             j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"quarterly","limit":8,"token":FINN_KEY})
L210             arr=j.get("cashFlow") or []
L211             def pick(item,keys):
L212                 for k in keys:
L213                     if k in item and item[k] is not None: return item[k]
L214             cfo_vals=[pick(x,_FINN_CFO_KEYS) for x in arr[:4]]
L215             cap_vals=[pick(x,_FINN_CAPEX_KEYS) for x in arr[:4]]
L216             cfo_ttm = np.nansum([np.nan if v is None else float(v) for v in cfo_vals]) if any(v is not None for v in cfo_vals) else None
L217             cap_ttm = np.nansum([np.nan if v is None else float(v) for v in cap_vals]) if any(v is not None for v in cap_vals) else None
L218             if cfo_ttm is None or cap_ttm is None:
L219                 j=_finn_get(s,f"{base}/stock/cash-flow",{"symbol":sym,"frequency":"annual","limit":1,"token":FINN_KEY})
L220                 arr=j.get("cashFlow") or []
L221                 if arr:
L222                     item0=arr[0]
L223                     if cfo_ttm is None:
L224                         v=pick(item0,_FINN_CFO_KEYS); 
L225                         if v is not None: cfo_ttm=float(v)
L226                     if cap_ttm is None:
L227                         v=pick(item0,_FINN_CAPEX_KEYS); 
L228                         if v is not None: cap_ttm=float(v)
L229             if cfo_ttm is None or cap_ttm is None: bad.append(sym)
L230         except Exception: bad.append(sym)
L231     ms=_now_ms()-t0
L232     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L233     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L234     return f"FINNHUB:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L235         "level":level,"latency_ms":ms,"bad":bad
L236     }
L237
L238 # ================================================================
L239 # SEC: companyfactsÔºàRevenue/EPSÔºâ„Éò„É´„Çπ
L240 # ================================================================
L241 def _sec_headers():
L242     """
L243     SEC„ÅØÈÄ£Áµ°ÂÖà‰ªò„ÅçUser-Agent/From„ÇíÂº∑„ÅèÊé®Â•®„Éª‰∏ÄÈÉ®„ÅßÂøÖÈ†à„ÄÇ
L244     SEC_EMAIL„ÅåÁ©∫„Å™„ÇâÊúÄ‰ΩéÈôê„ÅÆUA„Å´„Åó„Å§„Å§„ÄÅ403Áô∫ÁîüÊôÇ„ÅØ‰∏ä‰Ωç„ÅßSKIPÊâ±„ÅÑ„Å´„Åô„Çã„ÄÇ
L245     """
L246     ua = (f"api-health-probe/1 (+mailto:{SEC_EMAIL})" if SEC_EMAIL else "api-health-probe/1")
L247     hdr = {
L248         "User-Agent": ua[:200],
L249         "Accept": "application/json",
L250     }
L251     if SEC_EMAIL:
L252         hdr["From"] = SEC_EMAIL[:200]
L253     return hdr
L254
L255 def _sec_get(url: str, params=None, retries=3, sleep_s: float=0.5):
L256     """
L257     403„ÇÑ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Ç®„É©„Éº„ÅØ‰∏ä‰Ωç„ÅßSKIPÂà§ÂÆö„Åß„Åç„Çã„Çà„ÅÜ None „ÇíËøî„Åô„ÄÇ
L258     """
L259     for i in range(retries):
L260         try:
L261             r = requests.get(url, params=params or {}, headers=_sec_headers(), timeout=15)
L262             if r.status_code==429:
L263                 time.sleep(min(2**i*sleep_s, 4.0)); continue
L264             if r.status_code==403:
L265                 # UA/FromÊú™Ë®≠ÂÆö„ÇÑ„Ç¢„ÇØ„Çª„ÇπÂà∂Èôê„ÄÇ‰∏ä‰Ωç„ÅßSKIP„ÄÇ
L266                 return None
L267             r.raise_for_status(); return r.json()
L268         except Exception:
L269             time.sleep(min(2**i*sleep_s, 2.0))
L270     return None
L271
L272 def _sec_ticker_map() -> Dict[str,str]:
L273     j = _sec_get("https://www.sec.gov/files/company_tickers.json")
L274     if j is None:
L275         return {}
L276     out={}
L277     it=(j.values() if isinstance(j,dict) else j)
L278     for item in it:
L279         try:
L280             t=(item.get("ticker") or item.get("TICKER") or "").upper()
L281             cik=str(item.get("cik_str") or item.get("CIK") or "").zfill(10)
L282             if t and cik: out[t]=cik
L283         except Exception: continue
L284     return out
L285
L286 SEC_REV_TAGS=["Revenues","RevenueFromContractWithCustomerExcludingAssessedTax","SalesRevenueNet","SalesRevenueGoodsNet","SalesRevenueServicesNet","Revenue"]
L287 SEC_EPS_TAGS=["EarningsPerShareDiluted","EarningsPerShareBasicAndDiluted","EarningsPerShare","EarningsPerShareBasic"]
L288
L289 def _normalize_for_sec(sym: str) -> List[str]:
L290     s=(sym or "").upper(); outs=[]; add=lambda x: outs.append(x) if x and x not in outs else None
L291     add(s); add(s.replace(".","-")); add(s.replace("-","")); add(s.replace(".","")); return outs
L292
L293 def _units_for_tags(facts: dict, spaces: List[str], tags: List[str]) -> list:
L294     got=[]
L295     for sp in spaces:
L296         d=(facts.get("facts") or {}).get(sp) or {}
L297         for tg in tags:
L298             arr=(d.get(tg) or {}).get("units") or {}
L299             for unit, vals in (arr.items() if isinstance(arr,dict) else []):
L300                 if isinstance(vals,list) and vals: got.append(vals)
L301     return got
L302
L303 def _series_q_and_a(arrs: list) -> Tuple[list, list]:
L304     q_pairs,a_pairs=[],[]
L305     for vals in arrs:
L306         for v in vals:
L307             try:
L308                 dt=v.get("end") or v.get("fy"); val=float(v.get("val")); form=(v.get("form") or "").upper()
L309                 if "10-Q" in form or "6-K" in form or form=="Q": q_pairs.append((dt,val))
L310                 elif "10-K" in form or "20-F" in form or form=="K": a_pairs.append((dt,val))
L311             except Exception: pass
L312     q_pairs=sorted(q_pairs,key=lambda x: str(x[0]),reverse=True)
L313     a_pairs=sorted(a_pairs,key=lambda x: str(x[0]),reverse=True)
L314     return q_pairs,a_pairs
L315
L316 def sec_health(tickers: List[str]) -> Tuple[str, Dict]:
L317     t0=_now_ms(); t2cik=_sec_ticker_map(); bad=[]
L318     # CIK„Éû„ÉÉ„Éó„ÅåÂèñ„Çå„Å™„ÅÑÔºà403/„Éç„ÉÉ„ÉàÊñ≠/UAÊú™Ë®≠ÂÆö„Å™„Å©Ôºâ„ÅØSKIPPED
L319     if not t2cik:
L320         ms=_now_ms()-t0
L321         note="no SEC_EMAIL/403" if not SEC_EMAIL else "SEC endpoint blocked"
L322         det=f"SEC:SKIPPED ({note}) latency={_fmt_ms(ms)}"
L323         return det,{"level":"SKIPPED","latency_ms":ms,"bad":[]}
L324     for t in tickers:
L325         cands=_normalize_for_sec(t); cik=next((t2cik.get(x) for x in cands if t2cik.get(x)), None)
L326         if not cik: bad.append(t); continue
L327         try:
L328             j=_sec_get(f"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json")
L329             if j is None:
L330                 bad.append(t); continue
L331             rev_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_REV_TAGS)
L332             eps_arr=_units_for_tags(j,["us-gaap","ifrs-full"],SEC_EPS_TAGS)
L333             rev_q,rev_a=_series_q_and_a(rev_arr); eps_q,eps_a=_series_q_and_a(eps_arr)
L334             if not (rev_q or rev_a) or not (eps_q or eps_a): bad.append(t)
L335         except Exception: bad.append(t)
L336         time.sleep(0.30)  # SECË≤†Ëç∑ÈÖçÊÖÆ
L337     ms=_now_ms()-t0
L338     level="HEALTHY" if not bad else ("DEGRADED" if len(bad)<=len(tickers)//2 else "DOWN")
L339     slow=" SLOW" if ms>=TIMEOUT_MS_WARN else ""
L340     return f"SEC:{level} bad={len(bad)}/{len(tickers)} latency={_fmt_ms(ms)}{slow}",{
L341         "level":level,"latency_ms":ms,"bad":bad
L342     }
L343
L344 # ================================================================
L345 # Orchestration
L346 # ================================================================
L347 def main():
L348     cur_path, cand_path = _autodiscover_csv()
L349     if not cur_path or not cand_path:
L350         msg = f"‚ö†Ô∏è CSV not found. cur={cur_path} cand={cand_path} (set CSV_CURRENT/CSV_CANDIDATE or place files)"
L351         print(msg); _post_slack(msg)
L352         if SOFT_FAIL:
L353             sys.exit(0)
L354         sys.exit(78)
L355
L356     tickers=sorted(set(_read_tickers(cur_path)+_read_tickers(cand_path)))
L357     if not tickers:
L358         msg = f"‚ö†Ô∏è No tickers from CSV. cur={cur_path} cand={cand_path}"
L359         print(msg); _post_slack(msg)
L360         if SOFT_FAIL:
L361             sys.exit(0)
L362         sys.exit(78)
L363
L364     # YF
L365     det_price,meta_price=yf_price_health(tickers)
L366     det_info ,meta_info =yf_fastinfo_health(tickers)
L367     det_fin  ,meta_fin  =yf_financials_health(tickers)
L368
L369     # SEC
L370     det_sec  ,meta_sec  =sec_health(tickers)
L371
L372     # FinnhubÔºàÂøÖË¶ÅÊôÇ„ÅÆ„Åø„ÄÇYFË≤°ÂãôNGÈäòÊüÑ„Å∏„ÅÆ„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ§úË®ºÔºâ
L373     need_finn=meta_fin["bad"]
L374     det_finn,meta_finn  =finnhub_health(need_finn if need_finn else tickers[:0])
L375
L376     # ÊúÄÊÇ™„É¨„Éô„É´
L377     levels=[meta_price["level"],meta_info["level"],meta_fin["level"],meta_sec["level"],meta_finn.get("level","SKIPPED")]
L378     pri={"DOWN":3,"DEGRADED":2,"HEALTHY":1,"SKIPPED":0}
L379     worst=max(levels,key=lambda x: pri.get(x,0))
L380     emoji={"HEALTHY":"‚úÖ","DEGRADED":"‚ö†Ô∏è","DOWN":"üõë"}.get(worst,"‚ÑπÔ∏è")
L381
L382     # ÂÖ±ÈÄöÈöúÂÆ≥ÔºàÂêå‰∏ÄÊó•„Å†„Åë„ÅÆÊ¨†Êêç„ÅåÈÅéÂçäÔºâ„ÇíÁ∞°ÊòìÊ§úÁü•Ôºà‰æ°Ê†ºÁ≥ªÂàó„Éô„Éº„ÇπÔºâ
L383     outage_note=""
L384     try:
L385         from collections import Counter
L386         missing_dates=meta_price.get("per_ticker_missing",{})
L387         date_counter=Counter(); one_day_missing=0
L388         for _,info in missing_dates.items():
L389             dates=info.get("dates",set()); max_gap=info.get("max_gap",0)
L390             if len(dates)==1 and max_gap==1:
L391                 one_day_missing+=1; date_counter.update(dates)
L392         threshold=max(1,len(tickers)//2)
L393         if one_day_missing>=threshold:
L394             (missing_day,hits),=date_counter.most_common(1)
L395             outage_note=f" | OUTAGE: common_missing_day={missing_day} hits={hits}"
L396             if worst=="HEALTHY":
L397                 worst="DEGRADED"; emoji="üü†"
L398     except Exception:
L399         pass
L400
L401     summary=f"{emoji} API_HEALTH {worst}{outage_note}\n{det_price} | {det_info} | {det_fin} | {det_sec} | {det_finn}"
L402     has_problem=("DEGRADED" in worst) or ("DOWN" in worst)
L403
L404     if has_problem:
L405         def head(xs): return ", ".join(xs[:10]) + (f" ‚Ä¶(+{len(xs)-10})" if len(xs)>10 else "")
L406         lines=[]
L407         if meta_price["missing"] or meta_price["nf"]:
L408             xs=[*meta_price["nf"],*meta_price["missing"]]; lines.append(f"YF_PRICE NG: {head(xs)}")
L409         if meta_info["bad"]:  lines.append(f"YF_INFO NG: {head(meta_info['bad'])}")
L410         if meta_fin["bad"]:   lines.append(f"YF_FIN NG: {head(meta_fin['bad'])}")
L411         if meta_sec["bad"]:   lines.append(f"SEC NG: {head(meta_sec['bad'])}")
L412         if meta_finn.get("bad"): lines.append(f"FINNHUB NG: {head(meta_finn['bad'])}")
L413         text=summary + ("\n" + "\n".join(lines) if lines else "")
L414     else:
L415         text=summary
L416
L417     print(text); _post_slack(text)
L418     if SOFT_FAIL: sys.exit(0)
L419     sys.exit(0 if worst=="HEALTHY" else 10 if worst=="DEGRADED" else 20)
L420
L421 if __name__=="__main__":
L422     main()
```

## <.github/workflows/api-health.yml>
```text
L1 name: api-health-probe
L2 on:
L3   push:
L4     branches: [ main ]
L5
L6 jobs:
L7   probe:
L8     runs-on: ubuntu-latest
L9     timeout-minutes: 10
L10     steps:
L11       - uses: actions/checkout@v4
L12       - name: Show repo tree (CSV check)
L13         run: |
L14           echo "== ls -R for quick CSV check =="
L15           ls -R | head -n 300
L16           echo "== grep probable csv files =="
L17           (git ls-files | grep -Ei '(current|candidate).*\.csv$' || true)
L18       - uses: actions/setup-python@v5
L19         with:
L20           python-version: "3.11"
L21       - name: Install deps
L22         run: |
L23           python -m pip install --upgrade pip
L24           pip install yfinance pandas numpy requests
L25       - name: Run API health probe
L26         env:
L27           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L28           FINNHUB_API_KEY:   ${{ secrets.FINNHUB_API_KEY }}
L29           SEC_EMAIL:         ${{ secrets.SEC_EMAIL }}
L30           # ‰∏äÊõ∏„Åç„Åó„Åü„ÅÑÂ†¥Âêà„Å†„ÅëÊåáÂÆöÔºà‰æã: CSV_CURRENT: data/current.csvÔºâ
L31           # CSV_CURRENT:       current.csv
L32           # CSV_CANDIDATE:     candidate.csv
L33           YF_PERIOD:         1y
L34           YF_MIN_LEN:        "120"
L35           TIMEOUT_MS_WARN:   "5000"
L36           SOFT_FAIL:         "0"
L37         run: |
L38           python tools/api_health_probe.py
```
