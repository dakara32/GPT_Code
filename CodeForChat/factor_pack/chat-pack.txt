# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-19 08:59:05 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰, è¨ˆç®—ã¯ scorer.py'''
L2 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L3 BONUS_COEFF = 0.55  # æ¨å¥¨: æ”»ã‚=0.45 / ä¸­åº¸=0.55 / å®ˆã‚Š=0.65
L4 SWAP_DELTA_Z = 0.15   # åƒ…å·®åˆ¤å®š: Ïƒã®15%ã€‚(ç·©ã‚=0.10 / æ¨™æº–=0.15 / å›ºã‚=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+ã“ã®é †ä½ä»¥å†…ã®ç¾è¡Œã¯ä¿æŒã€‚(ç²˜ã‚Šå¼±=2 / æ¨™æº–=3 / ç²˜ã‚Šå¼·=4ã€œ5)
L6 import os, time, requests
L7 import logging
L8 from time import perf_counter
L9 from dataclasses import dataclass
L10 from typing import Any, Dict, List
L11 from concurrent.futures import ThreadPoolExecutor
L12 import numpy as np
L13 import pandas as pd
L14 import yfinance as yf
L15 from scipy.stats import zscore  # used via scorer
L16 from scorer import Scorer, ttm_div_yield_portfolio
L17 import config
L18
L19 # ãã®ä»–
L20 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L21
L22 logger = logging.getLogger(__name__)
L23 if debug_mode:
L24     logging.basicConfig(level=logging.INFO, force=True)
L25 else:
L26     logging.basicConfig(level=logging.WARNING, force=True)
L27
L28 class T:
L29     t = perf_counter()
L30     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L31
L32 T.log("start")
L33
L34 # === ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ ===
L35 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L36 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L37 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L38 N_G, N_D = config.N_G, config.N_D  # G/Dæ ã‚µã‚¤ã‚ºï¼ˆNORMALåŸºæº–: G12/D8ï¼‰
L39 g_weights = {'GROWTH_F':0.35,'MOM':0.55,'VOL':-0.10}
L40 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L41 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L42 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L43 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L44
L45 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L46 corrM = 45
L47 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L48 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L49
L50 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L51 try: CROSS_MU_GD
L52 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L53
L54 # å‡ºåŠ›é–¢é€£
L55 RESULTS_DIR = "results"
L56 os.makedirs(RESULTS_DIR, exist_ok=True)
L57
L58 # === å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config ===
L59 @dataclass(frozen=True)
L60 class InputBundle:
L61     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L62     cand: List[str]
L63     tickers: List[str]
L64     bench: str
L65     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L66     px: pd.DataFrame                # data['Close']
L67     spx: pd.Series                  # data['Close'][bench]
L68     tickers_bulk: object            # yfinance.Tickers
L69     info: Dict[str, dict]           # yfinance info per ticker
L70     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L71     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L72     returns: pd.DataFrame           # px[tickers].pct_change()
L73
L74 @dataclass(frozen=True)
L75 class FeatureBundle:
L76     df: pd.DataFrame
L77     df_z: pd.DataFrame
L78     g_score: pd.Series
L79     d_score_all: pd.Series
L80     missing_logs: pd.DataFrame
L81     df_full: pd.DataFrame | None = None
L82     df_full_z: pd.DataFrame | None = None
L83     scaler: Any | None = None
L84
L85 @dataclass(frozen=True)
L86 class SelectionBundle:
L87     resG: dict
L88     resD: dict
L89     top_G: List[str]
L90     top_D: List[str]
L91     init_G: List[str]
L92     init_D: List[str]
L93
L94 @dataclass(frozen=True)
L95 class WeightsConfig:
L96     g: Dict[str,float]
L97     d: Dict[str,float]
L98
L99 @dataclass(frozen=True)
L100 class DRRSParams:
L101     corrM: int
L102     shrink: float
L103     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L104     D: Dict[str,float]
L105     cross_mu_gd: float
L106
L107 @dataclass(frozen=True)
L108 class PipelineConfig:
L109     weights: WeightsConfig
L110     drrs: DRRSParams
L111     price_max: float
L112     debug_mode: bool = False
L113
L114 # === å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ ===
L115 # (unused local utils removed â€“ use scorer.py versions if needed)
L116
L117 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L118
L119 def _post_slack(payload: dict):
L120     url = os.getenv("SLACK_WEBHOOK_URL")
L121     if not url: print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L122     try:
L123         requests.post(url, json=payload).raise_for_status()
L124     except Exception as e:
L125         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L126
L127 def _slack_send_text_chunks(url: str, text: str, chunk: int = 2800) -> None:
L128     """Slackã¸ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²é€ä¿¡ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å½¢å¼ï¼‰ã€‚"""
L129
L130     def _post_text(payload: str) -> None:
L131         try:
L132             resp = requests.post(url, json={"text": payload})
L133             print(f"[DBG] debug_post status={getattr(resp, 'status_code', None)} size={len(payload)}")
L134             if resp is not None:
L135                 resp.raise_for_status()
L136         except Exception as e:
L137             print(f"[ERR] debug_post_failed: {e}")
L138
L139     body = str(text or "").strip()
L140     if not body:
L141         print("[DBG] skip debug send: empty body")
L142         return
L143
L144     lines = body.splitlines()
L145     block: list[str] = []
L146     block_len = 0
L147
L148     def _flush() -> None:
L149         nonlocal block, block_len
L150         if not block:
L151             return
L152         payload = "```" + "\n".join(block) + "```"
L153         _post_text(payload)
L154         block, block_len = [], 0
L155
L156     for raw in lines:
L157         line = raw or ""
L158         while len(line) > chunk:
L159             head, line = line[:chunk], line[chunk:]
L160             _flush()
L161             _post_text("```" + head + "```")
L162         add_len = len(line) if not block else len(line) + 1
L163         if block and block_len + add_len > chunk:
L164             _flush()
L165             add_len = len(line)
L166         block.append(line)
L167         block_len += add_len
L168     _flush()
L169
L170 def _disjoint_keepG(top_G, top_D, poolD):
L171     """Gé‡è¤‡ã‚’Dã‹ã‚‰é™¤å»ã—ã€poolDã§é †æ¬¡è£œå……ï¼ˆæ¯æ¸‡æ™‚ã¯å…ƒéŠ˜æŸ„ç¶­æŒï¼‰ã€‚"""
L172     used, D, i = set(top_G), list(top_D), 0
L173     for j, t in enumerate(D):
L174         if t in used:
L175             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L176                 i += 1
L177             if i < len(poolD):
L178                 D[j] = poolD[i]; used.add(D[j]); i += 1
L179     return top_G, D
L180
L181
L182 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L183                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L184     import pandas as pd, numpy as np
L185     sel = list(pick)
L186     if not sel: return sel
L187     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L188     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L189     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L190     thresh = kth - delta_z * sigma
L191     ranked_all = agg.sort_values(ascending=False)
L192     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L193     for t in cand:
L194         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L195         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L196         if within_score or within_rank:
L197             non_inc = [x for x in sel if x not in incumbents]
L198             if not non_inc: break
L199             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L200             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L201                 sel.remove(weakest); sel.append(t)
L202     if len(sel) > n_target:
L203         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L204     return sel
L205
L206
L207 # === Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ ===
L208 class Input:
L209     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L210         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L211         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L212
L213     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L214     @staticmethod
L215     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L216         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L217         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L218         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L219
L220     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L221
L222     @staticmethod
L223     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L224         if df is None or df.empty: return None
L225         idx_lower={str(i).lower():i for i in df.index}
L226         for n in names:
L227             k=n.lower()
L228             if k in idx_lower: return df.loc[idx_lower[k]]
L229         return None
L230
L231     @staticmethod
L232     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L233         if s is None or s.empty: return None
L234         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L235
L236     @staticmethod
L237     def _latest(s: pd.Series|None) -> float|None:
L238         if s is None or s.empty: return None
L239         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L240
L241     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L242         from concurrent.futures import ThreadPoolExecutor, as_completed
L243         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L244
L245         def one(t: str):
L246             try:
L247                 tk = yf.Ticker(t)  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯æ¸¡ã•ãªã„ï¼ˆYFãŒcurl_cffiã§ç®¡ç†ï¼‰
L248                 qcf = tk.quarterly_cashflow
L249                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L250                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L251                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L252                 if any(v is None for v in (cfo, capex, fcf)):
L253                     acf = tk.cashflow
L254                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L255                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L256                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L257             except Exception as e:
L258                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L259             n=np.nan
L260             return {"ticker":t,
L261                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L262                     "capex_ttm_yf": n if capex is None else capex,
L263                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L264
L265         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L266         with ThreadPoolExecutor(max_workers=mw) as ex:
L267             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L268         return pd.DataFrame(rows).set_index("ticker")
L269
L270     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L271     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L272
L273     @staticmethod
L274     def _first_key(d: dict, keys: list[str]):
L275         for k in keys:
L276             if k in d and d[k] is not None: return d[k]
L277         return None
L278
L279     @staticmethod
L280     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L281         for i in range(retries):
L282             r = session.get(url, params=params, timeout=15)
L283             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L284             r.raise_for_status(); return r.json()
L285         r.raise_for_status()
L286
L287     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L288         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L289         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L290         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L291         for sym in tickers:
L292             cfo_ttm = capex_ttm = None
L293             try:
L294                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L295                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L296                 for item in arr[:4]:
L297                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L298                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L299                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L300             except Exception: pass
L301             if cfo_ttm is None or capex_ttm is None:
L302                 try:
L303                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L304                     arr = j.get("cashFlow") or []
L305                     if arr:
L306                         item0 = arr[0]
L307                         if cfo_ttm is None:
L308                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L309                             if v is not None: cfo_ttm = float(v)
L310                         if capex_ttm is None:
L311                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L312                             if v is not None: capex_ttm = float(v)
L313                 except Exception: pass
L314             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L315         return pd.DataFrame(rows).set_index("ticker")
L316
L317     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L318         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L319         T.log("financials (yf) done")
L320         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L321         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L322         if need:
L323             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L324             df = yf_df.join(fh_df, how="left")
L325             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L326                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L327             print("[T] financials (finnhub) done (fallback only)")
L328         else:
L329             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L330             print("[T] financials (finnhub) skipped (no missing)")
L331         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L332         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L333         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L334         fcf_calc = cfo - capex
L335         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L336         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L337         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L338         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L339         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L340         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L341         return df[cols].sort_index()
L342
L343     def _build_eps_df(self, tickers, tickers_bulk, info):
L344         eps_rows=[]
L345         for t in tickers:
L346             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L347             try:
L348                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L349                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L350                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L351                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L352                     eps_q = qearn["Earnings"].iloc[-1]/so
L353             except Exception: pass
L354             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L355         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L356
L357     def prepare_data(self):
L358         """Fetch price and fundamental data for all tickers."""
L359         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L360         for t in self.cand:
L361             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L362             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L363         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L364         T.log("price cap filter done (CAND_PRICE_MAX)")
L365         tickers = sorted(set(self.exist + cand_f))
L366         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L367         data = yf.download(tickers + [self.bench], period="600d",
L368                            auto_adjust=True, progress=False, threads=False)
L369         T.log("yf.download done")
L370         px = data["Close"].dropna(how="all", axis=1).ffill(limit=2)
L371         spx = data["Close"][self.bench].reindex(px.index).ffill()
L372         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0ãªã‚‰ç„¡åŠ¹ï¼ˆæ—¢å®šï¼‰
L373         if clip_days > 0:
L374             px  = px.tail(clip_days + 1)
L375             spx = spx.tail(clip_days + 1)
L376             logger.info("[T] price window clipped by env: %d rows (PRICE_CLIP_DAYS=%d)", len(px), clip_days)
L377         else:
L378             logger.info("[T] price window clip skipped; rows=%d", len(px))
L379         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L380         for t in tickers:
L381             try:
L382                 info[t] = tickers_bulk.tickers[t].info
L383             except Exception as e:
L384                 logger.info("[warn] %s: info fetch failed (%s)", t, e)
L385                 info[t] = {}
L386         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L387         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L388         T.log("eps/fcf prep done")
L389         returns = px[tickers].pct_change()
L390         T.log("price prep/returns done")
L391         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L392
L393 # === Selectorï¼šç›¸é–¢ä½æ¸›ãƒ»é¸å®šï¼ˆã‚¹ã‚³ã‚¢ï¼†ãƒªã‚¿ãƒ¼ãƒ³ã ã‘èª­ã‚€ï¼‰ ===
L394 class Selector:
L395     # ---- DRRS helpersï¼ˆSelectorå°‚ç”¨ï¼‰ ----
L396     @staticmethod
L397     def _z_np(X: np.ndarray) -> np.ndarray:
L398         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L399         return (np.nan_to_num(X)-m)/s
L400
L401     @classmethod
L402     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L403         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L404         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L405         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L406         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L407         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L408
L409     @classmethod
L410     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L411         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L412         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L413         if k==0: return []
L414         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L415         for _ in range(k):
L416             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L417             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L418             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L419         return sorted(S)
L420
L421     @staticmethod
L422     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L423         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L424         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L425
L426     @classmethod
L427     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L428         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L429         while improved and passes<max_pass:
L430             improved, passes = False, passes+1
L431             for i,out in enumerate(list(S)):
L432                 for inn in range(len(score)):
L433                     if inn in S: continue
L434                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L435                     if v>best+1e-10: S, best, improved = cand, v, True; break
L436                 if improved: break
L437         return S, best
L438
L439     @staticmethod
L440     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L441         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L442         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L443         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L444         return float(s[idx].sum() - lam*within - mu*cross)
L445
L446     @classmethod
L447     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L448         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L449         while improved and passes<max_pass:
L450             improved, passes = False, passes+1
L451             for i,out in enumerate(list(S)):
L452                 for inn in range(N):
L453                     if inn in S: continue
L454                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L455                     if v>best+1e-10: S, best, improved = cand, v, True; break
L456                 if improved: break
L457         return S, best
L458
L459     @staticmethod
L460     def avg_corr(C: np.ndarray, idx) -> float:
L461         k = len(idx); P = C[np.ix_(idx, idx)]
L462         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L463
L464     @classmethod
L465     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L466         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L467         union = [t for t in pool_tickers if t in returns_df.columns]
L468         for t in g_fixed:
L469             if t not in union: union.append(t)
L470         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L471         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L472         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L473         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L474         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L475         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L476         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L477         if len(g_eff)>0 and mu>0.0:
L478             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L479         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L480         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L481         selected_tickers = [pool_eff[i] for i in S]
L482         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L483
L484     # ---- é¸å®šï¼ˆã‚¹ã‚³ã‚¢ Series / returns ã ã‘ã‚’å—ã‘ã‚‹ï¼‰----
L485 # === Outputï¼šå‡ºåŠ›æ•´å½¢ã¨é€ä¿¡ï¼ˆè¡¨ç¤ºãƒ»Slackï¼‰ ===
L486 class Output:
L487
L488     def __init__(self, debug=None):
L489         # self.debug ã¯ä½¿ã‚ãªã„ï¼ˆäº’æ›ã®ãŸã‚å¼•æ•°ã¯å—ã‘ã‚‹ãŒç„¡è¦–ï¼‰
L490         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = self.debug_table = None
L491         self.g_title = self.d_title = ""
L492         self.g_formatters = self.d_formatters = {}
L493         # ä½ã‚¹ã‚³ã‚¢ï¼ˆGSC+DSCï¼‰Top10 è¡¨ç¤º/é€ä¿¡ç”¨
L494         self.low10_table = None
L495         self.debug_text = ""   # ãƒ‡ãƒãƒƒã‚°ç”¨æœ¬æ–‡ã¯ã“ã“ã«ä¸€æœ¬åŒ–
L496         self._debug_logged = False
L497
L498     # --- è¡¨ç¤ºï¼ˆå…ƒ display_results ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L499     def display_results(self, *, exist, bench, df_z, g_score, d_score_all,
L500                         init_G, init_D, top_G, top_D, **kwargs):
L501         logger.info("ğŸ“Œ reached display_results")
L502         pd.set_option('display.float_format','{:.3f}'.format)
L503         print("ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ")
L504         if self.miss_df is not None and not self.miss_df.empty:
L505             print("Missing Data:")
L506             print(self.miss_df.to_string(index=False))
L507
L508         # ---- è¡¨ç¤ºç”¨ï¼šChanges/Near-Miss ã®ã‚¹ã‚³ã‚¢æºã‚’â€œæœ€çµ‚é›†è¨ˆâ€ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚· ----
L509         try:
L510             sc = getattr(self, "_sc", None)
L511             agg_G = getattr(sc, "_agg_G", None)
L512             agg_D = getattr(sc, "_agg_D", None)
L513         except Exception:
L514             sc = agg_G = agg_D = None
L515         class _SeriesProxy:
L516             __slots__ = ("primary", "fallback")
L517             def __init__(self, primary, fallback): self.primary, self.fallback = primary, fallback
L518             def get(self, key, default=None):
L519                 try:
L520                     v = self.primary.get(key) if hasattr(self.primary, "get") else None
L521                     if v is not None and not (isinstance(v, float) and v != v):
L522                         return v
L523                 except Exception:
L524                     pass
L525                 try:
L526                     return self.fallback.get(key) if hasattr(self.fallback, "get") else default
L527                 except Exception:
L528                     return default
L529         g_score = _SeriesProxy(agg_G, g_score)
L530         d_score_all = _SeriesProxy(agg_D, d_score_all)
L531         near_G = getattr(sc, "_near_G", []) if sc else []
L532         near_D = getattr(sc, "_near_D", []) if sc else []
L533
L534         extra_G = [t for t in init_G if t not in top_G][:5]; G_UNI = top_G + extra_G
L535         gsc_series = pd.Series({t: g_score.get(t) for t in G_UNI}, name='GSC')
L536         self.g_table = pd.concat([df_z.loc[G_UNI,['GROWTH_F','MOM','TRD','VOL']], gsc_series], axis=1)
L537         self.g_table.index = [t + ("â­ï¸" if t in top_G else "") for t in G_UNI]
L538         self.g_formatters = {col:"{:.2f}".format for col in ['GROWTH_F','MOM','TRD','VOL']}; self.g_formatters['GSC'] = "{:.3f}".format
L539         self.g_title = (f"[Gæ  / {N_G} / {_fmt_w(g_weights)} / corrM={corrM} / "
L540                         f"LB={DRRS_G['lookback']} nPC={DRRS_G['n_pc']} Î³={DRRS_G['gamma']} Î»={DRRS_G['lam']} Î·={DRRS_G['eta']} shrink={DRRS_SHRINK}]")
L541         if near_G:
L542             add = [t for t in near_G if t not in set(G_UNI)][:10]
L543             if len(add) < 10:
L544                 try:
L545                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L546                     out_now = sorted(set(exist) - set(top_G + top_D))  # ä»Šå› OUT
L547                     used = set(G_UNI + add)
L548                     def _push(lst):
L549                         nonlocal add, used
L550                         for t in lst:
L551                             if len(add) == 10: break
L552                             if t in aggG.index and t not in used:
L553                                 add.append(t); used.add(t)
L554                     _push(out_now)           # â‘  ä»Šå› OUT ã‚’å„ªå…ˆ
L555                     _push(list(aggG.index))  # â‘¡ ã¾ã è¶³ã‚Šãªã‘ã‚Œã°ä¸Šä½ã§å……å¡«
L556                 except Exception:
L557                     pass
L558             if add:
L559                 near_tbl = pd.concat([df_z.loc[add,['GROWTH_F','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L560                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L561         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L562
L563         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L564         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L565         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L566         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L567         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L568         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L569         import scorer
L570         dw_eff = scorer.D_WEIGHTS_EFF
L571         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L572                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L573         if near_D:
L574             add = [t for t in near_D if t not in set(D_UNI)][:10]
L575             if add:
L576                 d_disp2 = pd.DataFrame(index=add)
L577                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L578                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L579                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L580         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L581
L582         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L583         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L584         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L585
L586         self.io_table = pd.DataFrame({
L587             'IN': pd.Series(in_list),
L588             '/ OUT': pd.Series(out_list)
L589         })
L590         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L591         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L592         self.io_table['GSC'] = pd.Series(g_list)
L593         self.io_table['DSC'] = pd.Series(d_list)
L594
L595         print("Changes:")
L596         print(self.io_table.to_string(index=False))
L597
L598         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False, threads=False)['Close'].ffill(limit=2)
L599         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L600         for name,ticks in portfolios.items():
L601             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L602             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L603             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L604             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L605             if len(ticks)>=2:
L606                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L607                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L608                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L609             else: RAW_rho = RESID_rho = np.nan
L610             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L611         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L612         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L613         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L614         def _fmt_row(s):
L615             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L616         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L617         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L618         try:
L619             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L620             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L621             all_scores = all_scores.dropna(subset=['G_plus_D'])
L622             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L623             print("Low Score Candidates (GSC+DSC bottom 10):")
L624             print(self.low10_table.to_string())
L625         except Exception as e:
L626             print(f"[warn] low-score ranking failed: {e}")
L627             self.low10_table = None
L628         self.debug_text = ""
L629         if debug_mode:
L630             logger.info("debug_mode=True: df_z dump handled in scorer; skipping factor-side debug output")
L631         else:
L632             logger.debug(
L633                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L634                 debug_mode, True
L635             )
L636         self._debug_logged = True
L637
L638     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L639     def notify_slack(self):
L640         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L641
L642         if not SLACK_WEBHOOK_URL:
L643             print("âš ï¸ SLACK_WEBHOOK_URL not set (main report skipped)")
L644             return
L645
L646         def _filter_suffix_from(spec: dict, group: str) -> str:
L647             g = spec.get(group, {})
L648             parts = [str(m) for m in g.get("pre_mask", [])]
L649             for k, v in (g.get("pre_filter", {}) or {}).items():
L650                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L651                 name = {"beta": "Î²"}.get(base, base)
L652                 try:
L653                     val = f"{float(v):g}"
L654                 except Exception:
L655                     val = str(v)
L656                 parts.append(f"{name}{op}{val}")
L657             return "" if not parts else " / filter:" + " & ".join(parts)
L658
L659         def _inject_filter_suffix(title: str, group: str) -> str:
L660             suf = _filter_suffix_from(FILTER_SPEC, group)
L661             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L662
L663         def _blk(title, tbl, fmt=None, drop=()):
L664             if tbl is None or getattr(tbl, 'empty', False):
L665                 return f"{title}\n(é¸å®šãªã—)\n"
L666             if drop and hasattr(tbl, 'columns'):
L667                 keep = [c for c in tbl.columns if c not in drop]
L668                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L669             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L670
L671         message = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L672         if self.miss_df is not None and not self.miss_df.empty:
L673             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L674         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L675         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L676         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L677         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L678
L679         try:
L680             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L681             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L682             if r is not None:
L683                 r.raise_for_status()
L684         except Exception as e:
L685             print(f"[ERR] main_post_failed: {e}")
L686
L687 def _infer_g_universe(feature_df, selected12=None, near5=None):
L688     try:
L689         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L690         if out: return out
L691     except Exception:
L692         pass
L693     base = set()
L694     for lst in (selected12 or []), (near5 or []):
L695         for x in (lst or []): base.add(x)
L696     return list(base) if base else list(feature_df.index)
L697
L698 def _fmt_with_fire_mark(tickers, feature_df):
L699     out = []
L700     for t in tickers or []:
L701         try:
L702             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L703             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L704             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L705         except Exception:
L706             out.append(t)
L707     return out
L708
L709 def _label_recent_event(t, feature_df):
L710     try:
L711         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L712         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L713         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L714         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L715         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L716     except Exception:
L717         pass
L718     return t
L719
L720 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L721
L722 def io_build_input_bundle() -> InputBundle:
L723     """
L724     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L725     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L726     """
L727     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L728     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L729
L730 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L731               n_target: int) -> tuple[list, float, float, float]:
L732     """
L733     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L734     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L735     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L736     """
L737     sc.cfg = cfg
L738
L739     if hasattr(sc, "score_build_features"):
L740         feat = sc.score_build_features(inb)
L741         if not hasattr(sc, "_feat_logged"):
L742             T.log("features built (scorer)")
L743             sc._feat_logged = True
L744         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L745     else:
L746         fb = sc.aggregate_scores(inb, cfg)
L747         if not hasattr(sc, "_feat_logged"):
L748             T.log("features built (scorer)")
L749             sc._feat_logged = True
L750         sc._feat = fb
L751         agg = fb.g_score if group == "G" else fb.d_score_all
L752         if group == "D" and hasattr(fb, "df"):
L753             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L754
L755     if hasattr(sc, "filter_candidates"):
L756         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L757
L758     selector = Selector()
L759     if hasattr(sc, "select_diversified"):
L760         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L761             selector=selector, prev_tickers=None,
L762             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L763             cross_mu=cfg.drrs.cross_mu_gd)
L764     else:
L765         if group == "G":
L766             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L767             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L768                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L769                 lam=cfg.drrs.G.get("lam", 0.68),
L770                 lookback=cfg.drrs.G.get("lookback", 252),
L771                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L772         else:
L773             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L774             g_fixed = getattr(sc, "_top_G", None)
L775             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L776                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L777                 lam=cfg.drrs.D.get("lam", 0.85),
L778                 lookback=cfg.drrs.D.get("lookback", 504),
L779                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L780                 mu=cfg.drrs.cross_mu_gd)
L781         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L782         sum_sc = res["sum_score"]; obj = res["objective"]
L783         if group == "D":
L784             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L785             T.log("selection finalized (G/D)")
L786     try:
L787         inc = [t for t in exist if t in agg.index]
L788         pick = _sticky_keep_current(
L789             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L790             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L791         )
L792     except Exception as _e:
L793         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L794     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L795     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L796     try:
L797         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L798         near10 = list(pool.sort_values(ascending=False).head(10).index)
L799         setattr(sc, f"_near_{group}", near10)
L800         setattr(sc, f"_agg_{group}", agg)
L801     except Exception:
L802         pass
L803
L804     if group == "D":
L805         T.log("save done")
L806     if group == "G":
L807         sc._top_G = pick
L808     return pick, avg_r, sum_sc, obj
L809
L810 def run_pipeline() -> SelectionBundle:
L811     """
L812     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L813     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L814     """
L815     inb = io_build_input_bundle()
L816     cfg = PipelineConfig(
L817         weights=WeightsConfig(g=g_weights, d=D_weights),
L818         drrs=DRRSParams(
L819             corrM=corrM, shrink=DRRS_SHRINK,
L820             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L821         ),
L822         price_max=CAND_PRICE_MAX,
L823         debug_mode=debug_mode
L824     )
L825     sc = Scorer()
L826     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L827     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L828     alpha = Scorer.spx_to_alpha(inb.spx)
L829     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L830     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L831     sc._top_G = top_G
L832     try:
L833         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L834         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L835     except Exception:
L836         pass
L837     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L838     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L839     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L840     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L841     fb = getattr(sc, "_feat", None)
L842     near_G = getattr(sc, "_near_G", [])
L843     selected12 = list(top_G)
L844     df = fb.df if fb is not None else pd.DataFrame()
L845     guni = _infer_g_universe(df, selected12, near_G)
L846     try:
L847         fire_recent = [t for t in guni
L848                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L849                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L850     except Exception: fire_recent = []
L851
L852     lines = [
L853         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L854         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L855         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L856         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L857
L858     if fire_recent:
L859         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L860         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L861     else:
L862         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L863
L864     try:
L865         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L866         if webhook:
L867             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L868     except Exception:
L869         pass
L870
L871     out = Output()
L872     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L873     try: out._sc = sc
L874     except Exception: pass
L875     if hasattr(sc, "_feat"):
L876         try:
L877             fb = sc._feat
L878             out.miss_df = fb.missing_logs
L879             out.display_results(
L880                 exist=exist,
L881                 bench=bench,
L882                 df_z=fb.df_z,
L883                 g_score=fb.g_score,
L884                 d_score_all=fb.d_score_all,
L885                 init_G=top_G,
L886                 init_D=top_D,
L887                 top_G=top_G,
L888                 top_D=top_D,
L889                 df_full_z=getattr(fb, "df_full_z", None),
L890                 prev_G=getattr(sc, "_prev_G", exist),
L891                 prev_D=getattr(sc, "_prev_D", exist),
L892             )
L893         except Exception:
L894             pass
L895     out.notify_slack()
L896     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L897               "sum_score": sumG, "objective": objG},
L898         resD={"tickers": top_D, "avg_res_corr": avgD,
L899               "sum_score": sumD, "objective": objD},
L900         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L901
L902     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L903     try:
L904         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L905               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L906               .sort_values("G_plus_D")
L907               .head(10)
L908               .round(3))
L909         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L910         _post_slack({"text": f"```{low_msg}```"})
L911     except Exception as _e:
L912         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L913
L914     return sb
L915
L916 if __name__ == "__main__":
L917     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1.4826 * mad + 1e-9)
L82     if np.nanstd(z) < 1e-9:
L83         r = v.rank(method="average", na_option="keep")
L84         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L85     return pd.Series(z, index=v.index, dtype=float)
L86
L87
L88 def _dump_dfz(df_z: pd.DataFrame, debug_mode: bool, max_rows: int = 400, ndigits: int = 3) -> None:
L89     """df_z ã‚’ System log(INFO) ã¸ãƒ€ãƒ³ãƒ—ã™ã‚‹ç°¡æ½”ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£."""
L90     if not debug_mode:
L91         return
L92     try:
L93         view = df_z.copy()
L94         view = view.apply(
L95             lambda s: s.round(ndigits)
L96             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L97             else s
L98         )
L99         if len(view) > max_rows:
L100             view = view.iloc[:max_rows]
L101
L102         # === NaNã‚µãƒãƒªï¼ˆåˆ—ã”ã¨ã®æ¬ æä»¶æ•° ä¸Šä½20ï¼‰ ===
L103         try:
L104             nan_counts = df_z.isna().sum().sort_values(ascending=False)
L105             top_nan = nan_counts[nan_counts > 0].head(20)
L106             if len(top_nan) > 0:
L107                 logger.info("NaN columns (top20):\n%s", top_nan.to_string())
L108             else:
L109                 logger.info("NaN columns: none")
L110         except Exception as exc:
L111             logger.warning("nan summary failed: %s", exc)
L112
L113         # === Zeroã‚µãƒãƒªï¼ˆåˆ—ã”ã¨ã®ã‚¼ãƒ­æ¯”ç‡ ä¸Šä½20ï¼‰ ===
L114         try:
L115             zero_counts = ((df_z == 0) & (~df_z.isna())).sum()
L116             nonnull_counts = (~df_z.isna()).sum()
L117             zero_ratio = (zero_counts / nonnull_counts).sort_values(ascending=False)
L118             top_zero = zero_ratio[zero_ratio > 0].head(20)
L119             if len(top_zero) > 0:
L120                 logger.info(
L121                     "Zero-dominated columns (top20):\n%s",
L122                     top_zero.to_string(float_format=lambda x: f"{x:.2%}"),
L123                 )
L124             else:
L125                 logger.info("Zero-dominated columns: none")
L126         except Exception as exc:
L127             logger.warning("zero summary failed: %s", exc)
L128
L129         logger.info("===== DF_Z DUMP START =====")
L130         logger.info("\n%s", view.to_string(max_rows=None, max_cols=None))
L131         logger.info("===== DF_Z DUMP END =====")
L132     except Exception as exc:
L133         logger.warning("df_z dump failed: %s", exc)
L134
L135 def _safe_div(a, b):
L136     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L137     except Exception: return np.nan
L138
L139 def _safe_last(series: pd.Series, default=np.nan):
L140     try: return float(series.iloc[-1])
L141     except Exception: return default
L142
L143 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L144
L145 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L146 class Scorer:
L147     """
L148     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L149     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L150     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L151     """
L152
L153     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L154     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L155     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L156
L157     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L158     @staticmethod
L159     def _validate_ib_for_scorer(ib: Any):
L160         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L161         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L162         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L163         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L164         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L165         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L166         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L167
L168     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L169     @staticmethod
L170     def trend(s: pd.Series):
L171         if len(s)<200: return np.nan
L172         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L173         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L174         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L175         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L176         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L177         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L178         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L179         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L180         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L181         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L182         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L183         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L184
L185     @staticmethod
L186     def rs(s, b):
L187         n, nb = len(s), len(b)
L188         if n<60 or nb<60: return np.nan
L189         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L190         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L191         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L192
L193     @staticmethod
L194     def tr_str(s):
L195         if s is None:
L196             return np.nan
L197         s = s.ffill(limit=2).dropna()
L198         if len(s) < 50:
L199             return np.nan
L200         ma50 = s.rolling(50, min_periods=50).mean()
L201         last_ma = ma50.iloc[-1]
L202         last_px = s.iloc[-1]
L203         return float(last_px/last_ma - 1.0) if pd.notna(last_ma) and pd.notna(last_px) else np.nan
L204
L205     @staticmethod
L206     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L207         r = (s/b).dropna()
L208         if len(r) < win: return np.nan
L209         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L210         try: return float(np.polyfit(x, y, 1)[0])
L211         except Exception: return np.nan
L212
L213     @staticmethod
L214     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L215         ev = info_t.get('enterpriseValue', np.nan)
L216         if pd.notna(ev) and ev>0: return float(ev)
L217         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L218         try:
L219             bs = tk.quarterly_balance_sheet
L220             if bs is not None and not bs.empty:
L221                 c = bs.columns[0]
L222                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L223                     if k in bs.index: debt = float(bs.loc[k,c]); break
L224                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L225                     if k in bs.index: cash = float(bs.loc[k,c]); break
L226         except Exception: pass
L227         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L228         return np.nan
L229
L230     @staticmethod
L231     def dividend_status(ticker: str) -> str:
L232         t = yf.Ticker(ticker)
L233         try:
L234             if not t.dividends.empty: return "has"
L235         except Exception: return "unknown"
L236         try:
L237             a = t.actions
L238             if (a is not None and not a.empty and "Stock Splits" in a.columns and a["Stock Splits"].abs().sum()>0): return "none_confident"
L239         except Exception: pass
L240         try:
L241             fi = t.fast_info
L242             if any(getattr(fi,k,None) for k in ("last_dividend_date","dividend_rate","dividend_yield")): return "maybe_missing"
L243         except Exception: pass
L244         return "unknown"
L245
L246     @staticmethod
L247     def div_streak(t):
L248         try:
L249             divs = yf.Ticker(t).dividends.dropna(); ann = divs.groupby(divs.index.year).sum(); ann = ann[ann.index<pd.Timestamp.today().year]
L250             years, streak = sorted(ann.index), 0
L251             for i in range(len(years)-1,0,-1):
L252                 if ann[years[i]] > ann[years[i-1]]: streak += 1
L253                 else: break
L254             return streak
L255         except Exception: return 0
L256
L257     @staticmethod
L258     def fetch_finnhub_metrics(symbol):
L259         api_key = os.environ.get("FINNHUB_API_KEY")
L260         if not api_key: return {}
L261         url, params = "https://finnhub.io/api/v1/stock/metric", {"symbol":symbol,"metric":"all","token":api_key}
L262         try:
L263             r = requests.get(url, params=params, timeout=10); r.raise_for_status(); m = r.json().get("metric",{})
L264             return {'EPS':m.get('epsGrowthTTMYoy'),'REV':m.get('revenueGrowthTTMYoy'),'ROE':m.get('roeTTM'),'BETA':m.get('beta'),'DIV':m.get('dividendYieldIndicatedAnnual'),'FCF':(m.get('freeCashFlowTTM')/m.get('enterpriseValue')) if m.get('freeCashFlowTTM') and m.get('enterpriseValue') else None}
L265         except Exception: return {}
L266
L267     @staticmethod
L268     def calc_beta(series: pd.Series, market: pd.Series, lookback=252):
L269         r, m = series.pct_change().dropna(), market.pct_change().dropna()
L270         n = min(len(r), len(m), lookback)
L271         if n<60: return np.nan
L272         r, m = r.iloc[-n:], m.iloc[-n:]; cov, var = np.cov(r, m)[0,1], np.var(m)
L273         return np.nan if var==0 else cov/var
L274
L275     @staticmethod
L276     def spx_to_alpha(spx: pd.Series, bands=(0.03,0.10), w=(0.6,0.4),
L277                      span=5, q=(0.20,0.40), alphas=(0.05,0.08,0.10)) -> float:
L278         """
L279         S&P500æŒ‡æ•°ã®ã¿ã‹ã‚‰æ“¬ä¼¼breadthã‚’ä½œã‚Šã€å±¥æ­´åˆ†ä½ã§Î±ã‚’æ®µéšæ±ºå®šã€‚
L280         bands=(Â±3%, Â±10%), w=(50DMA,200DMA), åˆ†ä½q=(20%,40%), alphas=(ä½,ä¸­,é«˜)
L281         """
L282         ma50, ma200 = spx.rolling(50).mean(), spx.rolling(200).mean()
L283         b50, b200 = ((spx/ma50 - 1)+bands[0])/(2*bands[0]), ((spx/ma200 - 1)+bands[1])/(2*bands[1])
L284         hist = (w[0]*b50 + w[1]*b200).clip(0,1).ewm(span=span).mean()
L285         b, (lo, mid) = float(hist.iloc[-1]), (float(hist.quantile(q[0])), float(hist.quantile(q[1])))
L286         return alphas[0] if b < lo else alphas[1] if b < mid else alphas[2]
L287
L288     @staticmethod
L289     def soft_cap_effective_scores(scores: pd.Series|dict, sectors: dict, cap=2, alpha=0.08) -> pd.Series:
L290         """
L291         åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼capè¶…éï¼ˆ3æœ¬ç›®ä»¥é™ï¼‰ã« Î±Ã—æ®µéšæ¸›ç‚¹ã‚’èª²ã—ãŸâ€œæœ‰åŠ¹ã‚¹ã‚³ã‚¢â€Seriesã‚’è¿”ã™ã€‚
L292         æˆ»ã‚Šå€¤ã¯é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã€‚
L293         """
L294         s = pd.Series(scores, dtype=float); order = s.sort_values(ascending=False).index
L295         cnt, pen = {}, {}
L296         for t in order:
L297             sec = sectors.get(t, "U"); cnt[sec] = cnt.get(sec,0) + 1; pen[t] = alpha*max(0, cnt[sec]-cap)
L298         return (s - pd.Series(pen)).sort_values(ascending=False)
L299
L300     @staticmethod
L301     def pick_top_softcap(scores: pd.Series|dict, sectors: dict, N: int, cap=2, alpha=0.08, hard: int|None=5) -> list[str]:
L302         """
L303         soft-capé©ç”¨å¾Œã®ä¸Šä½Nãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚hard>0ãªã‚‰éå¸¸ç”¨ãƒãƒ¼ãƒ‰ä¸Šé™ã§åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼è¶…éã‚’é–“å¼•ãï¼ˆæ—¢å®š=5ï¼‰ã€‚
L304         """
L305         eff = Scorer.soft_cap_effective_scores(scores, sectors, cap, alpha)
L306         if not hard:
L307             return list(eff.head(N).index)
L308         pick, used = [], {}
L309         for t in eff.index:
L310             s = sectors.get(t, "U")
L311             if used.get(s,0) < hard:
L312                 pick.append(t); used[s] = used.get(s,0) + 1
L313             if len(pick) == N: break
L314         return pick
L315
L316     @staticmethod
L317     def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L318         """
L319         å„å–¶æ¥­æ—¥ã® trend_template åˆæ ¼æœ¬æ•°ï¼ˆåˆæ ¼â€œæœ¬æ•°â€=Cï¼‰ã‚’è¿”ã™ã€‚
L320         - px: åˆ—=tickerï¼ˆãƒ™ãƒ³ãƒã¯å«ã‚ãªã„ï¼‰
L321         - spx: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Seriesï¼ˆpx.index ã«æ•´åˆ—ï¼‰
L322         - win_days: æœ«å°¾ã®è¨ˆç®—å¯¾è±¡å–¶æ¥­æ—¥æ•°ï¼ˆNoneâ†’å…¨ä½“ã€æ—¢å®š600ã¯å‘¼ã³å‡ºã—å´æŒ‡å®šï¼‰
L323         ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼†rollingã®ã¿ã§è»½é‡ã€‚æ¬ æã¯ False æ‰±ã„ã€‚
L324         """
L325         import numpy as np, pandas as pd
L326         if px is None or px.empty:
L327             return pd.Series(dtype=int)
L328         px = px.dropna(how="all", axis=1)
L329         if win_days and win_days > 0:
L330             px = px.tail(win_days)
L331         if px.empty:
L332             return pd.Series(dtype=int)
L333         spx = spx.reindex(px.index).ffill()
L334
L335         ma50  = px.rolling(50).mean()
L336         ma150 = px.rolling(150).mean()
L337         ma200 = px.rolling(200).mean()
L338
L339         tt = (px > ma150)
L340         tt &= (px > ma200)
L341         tt &= (ma150 > ma200)
L342         tt &= (ma200 - ma200.shift(21) > 0)
L343         tt &= (ma50  > ma150)
L344         tt &= (ma50  > ma200)
L345         tt &= (px    > ma50)
L346
L347         lo252 = px.rolling(252).min()
L348         hi252 = px.rolling(252).max()
L349         tt &= (px.divide(lo252).sub(1.0) >= 0.30)   # P_OVER_LOW52 >= 0.30
L350         tt &= (px >= (0.75 * hi252))                # NEAR_52W_HIGH >= -0.25
L351
L352         r12  = px.divide(px.shift(252)).sub(1.0)
L353         br12 = spx.divide(spx.shift(252)).sub(1.0)
L354         r1   = px.divide(px.shift(22)).sub(1.0)
L355         br1  = spx.divide(spx.shift(22)).sub(1.0)
L356         rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L357         tt &= (rs >= 0.10)
L358
L359         return tt.fillna(False).sum(axis=1).astype(int)
L360
L361     # ---- ã‚¹ã‚³ã‚¢é›†è¨ˆï¼ˆDTO/Configã‚’å—ã‘å–ã‚Šã€FeatureBundleã‚’è¿”ã™ï¼‰ ----
L362     def aggregate_scores(self, ib: Any, cfg):
L363         if cfg is None:
L364             raise ValueError("cfg is required; pass factor.PipelineConfig")
L365         self._validate_ib_for_scorer(ib)
L366
L367         px, spx, tickers = ib.px, ib.spx, ib.tickers
L368         tickers_bulk, info, eps_df, fcf_df = ib.tickers_bulk, ib.info, ib.eps_df, ib.fcf_df
L369
L370         df, missing_logs = pd.DataFrame(index=tickers), []
L371         for t in tickers:
L372             d, s = info[t], px[t]; ev = self.ev_fallback(d, tickers_bulk.tickers[t])
L373             # --- åŸºæœ¬ç‰¹å¾´ ---
L374             df.loc[t,'TR']   = self.trend(s)
L375             df.loc[t,'EPS']  = eps_df.loc[t,'EPS_TTM'] if t in eps_df.index else np.nan
L376             df.loc[t,'REV']  = d.get('revenueGrowth',np.nan)
L377             df.loc[t,'ROE']  = d.get('returnOnEquity',np.nan)
L378             df.loc[t,'BETA'] = self.calc_beta(s, spx, lookback=252)
L379
L380             # --- é…å½“ï¼ˆæ¬ æè£œå®Œå«ã‚€ï¼‰ ---
L381             div = d.get('dividendYield') if d.get('dividendYield') is not None else d.get('trailingAnnualDividendYield')
L382             if div is None or pd.isna(div):
L383                 try:
L384                     divs = yf.Ticker(t).dividends
L385                     if divs is not None and not divs.empty:
L386                         last_close = s.iloc[-1]; div_1y = divs[divs.index >= (divs.index.max() - pd.Timedelta(days=365))].sum()
L387                         if last_close and last_close>0: div = float(div_1y/last_close)
L388                 except Exception: pass
L389             df.loc[t,'DIV'] = 0.0 if (div is None or pd.isna(div)) else float(div)
L390
L391             # --- FCF/EV ---
L392             fcf_val = fcf_df.loc[t,'FCF_TTM'] if t in fcf_df.index else np.nan
L393             df.loc[t,'FCF'] = (fcf_val/ev) if (pd.notna(fcf_val) and pd.notna(ev) and ev>0) else np.nan
L394
L395             # --- ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ»ãƒœãƒ©é–¢é€£ ---
L396             df.loc[t,'RS'], df.loc[t,'TR_str'] = self.rs(s, spx), self.tr_str(s)
L397             r, rm = s.pct_change().dropna(), spx.pct_change().dropna()
L398             n = int(min(len(r), len(rm)))
L399
L400             DOWNSIDE_DEV = np.nan
L401             if n>=60:
L402                 r6 = r.iloc[-min(len(r),126):]; neg = r6[r6<0]
L403                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L404             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L405
L406             MDD_1Y = np.nan
L407             try:
L408                 w = s.iloc[-min(len(s),252):].dropna()
L409                 if len(w)>=30:
L410                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L411             except Exception: pass
L412             df.loc[t,'MDD_1Y'] = MDD_1Y
L413
L414             RESID_VOL = np.nan
L415             if n>=120:
L416                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L417                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L418                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L419                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L420             df.loc[t,'RESID_VOL'] = RESID_VOL
L421
L422             DOWN_OUTPERF = np.nan
L423             if n>=60:
L424                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L425                 if mask.sum()>=10:
L426                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L427                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L428             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L429
L430             # --- é•·æœŸç§»å‹•å¹³å‡/ä½ç½® ---
L431             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L432             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L433
L434             # --- é…å½“ã®è©³ç´°ç³» ---
L435             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L436             try:
L437                 divs = yf.Ticker(t).dividends.dropna()
L438                 if not divs.empty:
L439                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L440                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L441                     ann = divs.groupby(divs.index.year).sum()
L442                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L443                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L444                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L445                 so = d.get('sharesOutstanding',None)
L446                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L447                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L448             except Exception: pass
L449             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L450
L451             # --- è²¡å‹™å®‰å®šæ€§ ---
L452             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L453
L454             # --- EPS å¤‰å‹• ---
L455             EPS_VAR_8Q = np.nan
L456             try:
L457                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L458                 if qe is not None and not qe.empty and so:
L459                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L460                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L461             except Exception: pass
L462             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L463
L464             # --- ã‚µã‚¤ã‚º/æµå‹•æ€§ ---
L465             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L466             try:
L467                 vol_series = ib.data['Volume'][t].dropna()
L468                 if len(vol_series)>=5 and len(s)==len(vol_series):
L469                     dv = (vol_series*s).rolling(60).mean(); adv60 = float(dv.iloc[-1])
L470             except Exception: pass
L471             df.loc[t,'ADV60_USD'] = adv60
L472
L473             # --- å£²ä¸Š/åˆ©ç›Šã®åŠ é€Ÿåº¦ç­‰ ---
L474             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L475             REV_YOY = REV_ANNUAL_STREAK = np.nan
L476             EPS_YOY = np.nan
L477             try:
L478                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L479                 rev_series = None
L480                 if qe is not None and not qe.empty and 'Revenue' in qe.columns:
L481                     rev_series = pd.to_numeric(qe['Revenue'], errors='coerce')
L482                 else:
L483                     qf = tickers_bulk.tickers[t].quarterly_financials
L484                     if qf is not None and not qf.empty and 'Total Revenue' in qf.index:
L485                         rev_series = pd.to_numeric(qf.loc['Total Revenue'], errors='coerce')
L486                         try:
L487                             rev_series = rev_series.sort_index()
L488                         except Exception:
L489                             pass
L490
L491                 if rev_series is not None and rev_series.dropna().shape[0] >= 2:
L492                     r = rev_series.dropna().astype(float)
L493                     yoy = r.pct_change(4).replace([np.inf, -np.inf], np.nan)
L494                     yoy_valid = yoy.dropna()
L495                     if not yoy_valid.empty:
L496                         REV_Q_YOY = float(yoy_valid.iloc[-1])
L497                         if len(yoy_valid) >= 2:
L498                             yoy_delta = yoy_valid.diff().dropna()
L499                             if not yoy_delta.empty:
L500                                 REV_YOY_ACC = float(yoy_delta.iloc[-1])
L501                             tail_len = min(4, len(yoy_valid))
L502                             tail = yoy_valid.iloc[-tail_len:]
L503                             if len(tail) >= 2:
L504                                 REV_YOY_VAR = float(tail.std(ddof=1))
L505                     if len(r) >= 8:
L506                         annual = r.rolling(4).sum().dropna()
L507                         if len(annual) >= 2:
L508                             prev = annual.iloc[-2]
L509                             if prev not in (None, 0) and not pd.isna(prev):
L510                                 REV_YOY = float((annual.iloc[-1] - prev) / prev)
L511                             streak_series = (annual.diff() > 0).astype(int).rolling(4, min_periods=1).sum()
L512                             if not streak_series.empty and pd.notna(streak_series.iloc[-1]):
L513                                 REV_ANNUAL_STREAK = int(streak_series.iloc[-1])
L514                 if qe is not None and not getattr(qe, "empty", True) and 'Earnings' in qe.columns and so:
L515                     eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L516                     if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L517                         EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L518                         try:
L519                             g_eps = eps_series.groupby(eps_series.index.year)
L520                             ann_eps, cnt_eps = g_eps.sum(), g_eps.count()
L521                             ann_eps = ann_eps[cnt_eps >= 4]
L522                             if len(ann_eps) >= 2:
L523                                 eps_yoy = ann_eps.pct_change().dropna()
L524                                 if not eps_yoy.empty:
L525                                     EPS_YOY = float(eps_yoy.iloc[-1])
L526                         except Exception:
L527                             pass
L528             except Exception: pass
L529             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'] = REV_Q_YOY, EPS_Q_YOY
L530             df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_YOY_ACC, REV_YOY_VAR
L531             df.loc[t,'REV_YOY'] = REV_YOY
L532             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L533             df.loc[t,'EPS_YOY'] = EPS_YOY
L534
L535             # --- Rule of 40 ã‚„å‘¨è¾º ---
L536             total_rev_ttm = d.get('totalRevenue',np.nan)
L537             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L538             df.loc[t,'FCF_MGN'] = FCF_MGN
L539             rule40 = np.nan
L540             try:
L541                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L542             except Exception: pass
L543             df.loc[t,'RULE40'] = rule40
L544
L545             # --- ãƒˆãƒ¬ãƒ³ãƒ‰è£œåŠ© ---
L546             sma50  = s.rolling(50).mean()
L547             sma150 = s.rolling(150).mean()
L548             sma200 = s.rolling(200).mean()
L549             p = _safe_last(s)
L550
L551             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L552                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L553             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L554                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L555
L556             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L557             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L558
L559             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L560             if len(sma200.dropna()) >= 21:
L561                 cur200 = _safe_last(sma200)
L562                 old2001 = float(sma200.iloc[-21])
L563                 if old2001:
L564                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L565
L566             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L567             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L568             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L569             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L570             if len(sma200.dropna())>=105:
L571                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L572                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L573             # NEW: 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ãã®ã€Œæ—¥æ•°ã€
L574             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L575             try:
L576                 s200 = sma200.dropna()
L577                 if len(s200) >= 2:
L578                     diff200 = s200.diff()
L579                     up = 0
L580                     for v in diff200.iloc[::-1]:
L581                         if pd.isna(v) or v <= 0:
L582                             break
L583                         up += 1
L584                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L585             except Exception:
L586                 pass
L587             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L588             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L589             if hi52 and hi52>0 and pd.notna(p):
L590                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L591             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L592             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L593
L594             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L595
L596             # --- æ¬ æãƒ¡ãƒ¢ ---
L597             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L598             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L599             if need_finnhub:
L600                 fin_data = self.fetch_finnhub_metrics(t)
L601                 for col in need_finnhub:
L602                     val = fin_data.get(col)
L603                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L604             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L605                 if pd.isna(df.loc[t,col]):
L606                     if col=='DIV':
L607                         status = self.dividend_status(t)
L608                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L609                     else:
L610                         missing_logs.append({'Ticker':t,'Column':col})
L611
L612         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L613             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L614             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L615             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L616             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L617             c5 = (row.get('TR_str', np.nan) > 0)
L618             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L619             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L620             c8 = (row.get('RS', np.nan) >= 0.10)
L621             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L622
L623         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L624         assert 'trend_template' in df.columns
L625
L626         # === ZåŒ–ã¨åˆæˆ ===
L627         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L628
L629         df_z = pd.DataFrame(index=df.index)
L630         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L631         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L632         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L633
L634         # === Growthæ·±æ˜ã‚Šç³»ï¼ˆæ¬ æä¿æŒz + RAWä½µè¼‰ï¼‰ ===
L635         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L636         for col in grw_cols:
L637             if col in df.columns:
L638                 raw = pd.to_numeric(df[col], errors="coerce")
L639                 df_z[col] = robust_z_keepnan(raw)
L640                 df_z[f'{col}_RAW'] = raw
L641         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L642             if k in df.columns and k not in df_z.columns:
L643                 raw = pd.to_numeric(df[k], errors="coerce")
L644                 df_z[k] = robust_z_keepnan(raw)
L645                 df_z[f'{k}_RAW'] = raw
L646         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L647
L648         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L649         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L650         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L651
L652         # EPSãŒèµ¤å­—ã§ã‚‚FCFãŒé»’å­—ãªã‚‰å®Ÿè³ªé»’å­—ã¨ã¿ãªã™
L653         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L654         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L655
L656         # ===== ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ãƒ­ãƒ¼ãƒ—ç®—å‡º =====
L657         def zpos(x):
L658             arr = robust_z(x)
L659             idx = getattr(x, 'index', df_z.index)
L660             return pd.Series(arr, index=idx).fillna(0.0)
L661
L662         def relu(x):
L663             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L664             return ser.clip(lower=0).fillna(0.0)
L665
L666         # å£²ä¸Šãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ãƒ­ãƒ¼ãƒ—ï¼ˆå››åŠæœŸï¼‰
L667         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L668         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L669         slope_rev_combo = slope_rev - 0.25*noise_rev
L670         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L671         df_z['TREND_SLOPE_REV'] = slope_rev_combo.clip(-3.0, 3.0)
L672
L673         # EPSãƒˆãƒ¬ãƒ³ãƒ‰ã‚¹ãƒ­ãƒ¼ãƒ—ï¼ˆå››åŠæœŸï¼‰
L674         slope_eps = 0.60*zpos(df_z['EPS_Q_YOY']) + 0.40*zpos(df_z['EPS_POS'])
L675         df_z['TREND_SLOPE_EPS_RAW'] = slope_eps
L676         df_z['TREND_SLOPE_EPS'] = slope_eps.clip(-3.0, 3.0)
L677
L678         # å¹´æ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆã‚µãƒ–ï¼‰
L679         slope_rev_yr = zpos(df_z['REV_YOY'])
L680         slope_eps_yr = zpos(df_z.get('EPS_YOY', pd.Series(0.0, index=df.index)))
L681         streak_base = df['REV_ANN_STREAK'].clip(lower=0).fillna(0)
L682         streak_yr = streak_base / (streak_base.abs() + 1.0)
L683         slope_rev_yr_combo = 0.7*slope_rev_yr + 0.3*streak_yr
L684         df_z['TREND_SLOPE_REV_YR_RAW'] = slope_rev_yr_combo
L685         df_z['TREND_SLOPE_REV_YR'] = slope_rev_yr_combo.clip(-3.0, 3.0)
L686         df_z['TREND_SLOPE_EPS_YR_RAW'] = slope_eps_yr
L687         df_z['TREND_SLOPE_EPS_YR'] = slope_eps_yr.clip(-3.0, 3.0)
L688
L689         # ===== æ–°GRWåˆæˆå¼ï¼ˆSEPAå¯„ã‚Šã‚·ãƒ•ãƒˆï¼‰ =====
L690         _nz = lambda name: df_z.get(name, pd.Series(0.0, index=df_z.index)).fillna(0.0)
L691         grw_combo = (
L692               0.20*_nz('REV_Q_YOY')
L693             + 0.10*_nz('REV_YOY_ACC')
L694             + 0.10*_nz('REV_ANN_STREAK')
L695             - 0.05*_nz('REV_YOY_VAR')
L696             + 0.10*_nz('TREND_SLOPE_REV')
L697             + 0.15*_nz('EPS_Q_YOY')
L698             + 0.05*_nz('EPS_POS')
L699             + 0.20*_nz('TREND_SLOPE_EPS')
L700             + 0.05*_nz('TREND_SLOPE_REV_YR')
L701             + 0.03*_nz('TREND_SLOPE_EPS_YR')
L702             + 0.10*_nz('FCF_MGN')
L703             + 0.05*_nz('RULE40')
L704         )
L705         df_z['GROWTH_F_RAW'] = grw_combo
L706         df_z['GROWTH_F'] = robust_z(grw_combo).clip(-3.0, 3.0)
L707
L708         # Debug dump for GRW composition (console OFF by default; enable only with env)
L709         if bool(os.getenv("GRW_CONSOLE_DEBUG")):
L710             try:
L711                 i = df_z[['GROWTH_F', 'GROWTH_F_RAW']].copy()
L712                 i.sort_values('GROWTH_F', ascending=False, inplace=True)
L713                 limit = max(0, min(40, len(i)))
L714                 print("[DEBUG: GRW]")
L715                 for t in i.index[:limit]:
L716                     row = i.loc[t]
L717                     parts = [f"GROWTH_F={row['GROWTH_F']:.3f}"]
L718                     if pd.notna(row.get('GROWTH_F_RAW')):
L719                         parts.append(f"GROWTH_F_RAW={row['GROWTH_F_RAW']:.3f}")
L720                     print(f"Ticker: {t} | " + " ".join(parts))
L721                 print()
L722             except Exception as exc:
L723                 print(f"[ERR] GRW debug dump failed: {exc}")
L724
L725         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L726             + 0.15*df_z['TR_str']
L727             + 0.15*df_z['RS_SLOPE_6W']
L728             + 0.15*df_z['RS_SLOPE_13W']
L729             + 0.10*df_z['MA200_SLOPE_5M']
L730             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L731         df_z['VOL'] = robust_z(df['BETA'])
L732         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L733         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L734
L735         _dump_dfz(df_z=df_z, debug_mode=getattr(cfg, "debug_mode", False))
L736
L737         # === begin: BIO LOSS PENALTY =====================================
L738         try:
L739             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L740         except Exception:
L741             penalty_z = 0.8
L742
L743         def _is_bio_like(t: str) -> bool:
L744             inf = info.get(t, {}) if isinstance(info, dict) else {}
L745             sec = str(inf.get("sector", "")).lower()
L746             ind = str(inf.get("industry", "")).lower()
L747             if "health" not in sec:
L748                 return False
L749             keys = ("biotech", "biopharma", "pharma")
L750             return any(k in ind for k in keys)
L751
L752         tickers_s = pd.Index(df_z.index)
L753         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L754         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L755         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L756
L757         if bool(mask_bio_loss.any()) and penalty_z > 0:
L758             df_z.loc[mask_bio_loss, "GROWTH_F"] = df_z.loc[mask_bio_loss, "GROWTH_F"] - penalty_z
L759             df_z["GROWTH_F"] = df_z["GROWTH_F"].clip(-3.0, 3.0)
L760         # === end: BIO LOSS PENALTY =======================================
L761
L762         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L763         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L764
L765         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L766         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L767         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L768         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L769
L770         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L771         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L772         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L773
L774         d_comp = pd.concat({
L775             'QAL': df_z['D_QAL'],
L776             'YLD': df_z['D_YLD'],
L777             'VOL': df_z['D_VOL_RAW'],
L778             'TRD': df_z['D_TRD']
L779         }, axis=1)
L780         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L781         globals()['D_WEIGHTS_EFF'] = dw.copy()
L782         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L783
L784         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L785         mask = df['trend_template']
L786         if not bool(mask.any()):
L787             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L788                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L789                 (df.get('RS', np.nan) >= 0.08) &
L790                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L791                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L792                 (df.get('MA150_OVER_200', np.nan) > 0) &
L793                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L794                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L795             df['trend_template'] = mask
L796
L797         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L798         g_score = g_score_all.loc[mask]
L799         Scorer.g_score = g_score
L800         df_z['GSC'] = g_score_all
L801         df_z['DSC'] = d_score_all
L802
L803         try:
L804             current = (pd.read_csv("current_tickers.csv")
L805                   .iloc[:, 0]
L806                   .str.upper()
L807                   .tolist())
L808         except FileNotFoundError:
L809             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L810             current = []
L811
L812         mask_bonus = g_score.index.isin(current)
L813         if mask_bonus.any():
L814             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L815             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L816             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L817             sigma_g = g_score.std()
L818             if pd.isna(sigma_g):
L819                 sigma_g = 0.0
L820             bonus_g = round(k * sigma_g, 3)
L821             g_score.loc[mask_bonus] += bonus_g
L822             Scorer.g_score = g_score
L823             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L824             sigma_d = d_score_all.std()
L825             if pd.isna(sigma_d):
L826                 sigma_d = 0.0
L827             bonus_d = round(k * sigma_d, 3)
L828             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L829
L830         try:
L831             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L832         except Exception:
L833             pass
L834
L835         df_full = df.copy()
L836         df_full_z = df_z.copy()
L837
L838         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L839         return FeatureBundle(df=df,
L840             df_z=df_z,
L841             g_score=g_score,
L842             d_score_all=d_score_all,
L843             missing_logs=pd.DataFrame(missing_logs),
L844             df_full=df_full,
L845             df_full_z=df_full_z,
L846             scaler=None)
L847
L848 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L849     """
L850     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L851     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L852       - G_BREAKOUT_recent_5d : bool
L853       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L854       - G_PULLBACK_recent_5d : bool
L855       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L856       - G_PIVOT_price        : float
L857     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L858     """
L859     try:
L860         px   = bundle.px                      # çµ‚å€¤ DataFrame
L861         hi   = bundle.data['High']
L862         lo   = bundle.data['Low']
L863         vol  = bundle.data['Volume']
L864         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L865
L866         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L867         g_universe = getattr(self_obj, "g_universe", None)
L868         if g_universe is None:
L869             try:
L870                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L871             except Exception:
L872                 g_universe = list(feature_df.index)
L873         if not g_universe:
L874             return feature_df
L875
L876         # æŒ‡æ¨™
L877         px = px.ffill(limit=2)
L878         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L879         ma50  = px[g_universe].rolling(50).mean()
L880         ma150 = px[g_universe].rolling(150).mean()
L881         ma200 = px[g_universe].rolling(200).mean()
L882         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L883         vol20 = vol[g_universe].rolling(20).mean()
L884         vol50 = vol[g_universe].rolling(50).mean()
L885
L886         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L887         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L888                             & (ma150 > ma200) & (ma200.diff() > 0)
L889
L890         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L891         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L892
L893         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L894         bench_aligned = bench.reindex(px.index).ffill()
L895         rs = px[g_universe].div(bench_aligned, axis=0)
L896         rs_high = rs.rolling(252).max().shift(1)
L897
L898         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L899         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L900                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L901         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L902
L903         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L904         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L905         volume_dryup = (vol20 / vol50) <= 1.0
L906         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L907         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L908         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L909
L910         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L911         rows = []
L912         for t in g_universe:
L913             def _recent_and_date(s, win):
L914                 sw = s[t].iloc[-win:]
L915                 if sw.any():
L916                     d = sw[sw].index[-1]
L917                     return True, d.strftime("%Y-%m-%d")
L918                 return False, ""
L919             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L920             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L921             rows.append((t, {
L922                 "G_BREAKOUT_recent_5d": br_recent,
L923                 "G_BREAKOUT_last_date": br_date,
L924                 "G_PULLBACK_recent_5d": pb_recent,
L925                 "G_PULLBACK_last_date": pb_date,
L926                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L927             }))
L928         flags = pd.DataFrame({k: v for k, v in rows}).T
L929
L930         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L931         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L932         for c in cols:
L933             if c not in feature_df.columns:
L934                 feature_df[c] = np.nan
L935         feature_df.loc[flags.index, flags.columns] = flags
L936
L937     except Exception:
L938         pass
L939     return feature_df
L940
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v3
L24
L25       - name: Setup Python
L26         uses: actions/setup-python@v5
L27         with:
L28           python-version: '3.x'
L29           cache: 'pip'
L30           cache-dependency-path: requirements.txt
L31
L32       - name: Install dependencies
L33         run: pip install -r requirements.txt
L34
L35       - name: Prepare results directory
L36         run: mkdir -p results
L37
L38       - name: Run factor & scoring
L39         env:
L40           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L41           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L42           FIN_THREADS: "8"
L43         run: python factor.py
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**ï¼ˆNORMAL åŸºæº–ï¼‰
L7
L8 ## Barbell Growth-Defenseæ–¹é‡
L9 - Growthæ  **12éŠ˜æŸ„**ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L10 - Defenseæ  **8éŠ˜æŸ„**ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L11 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L12
L13 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L14 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**ï¼ˆåŸºæº– N_G=12ï¼‰
L15 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L16   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L17   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= ceil(1.5Ã—12)ï¼‰
L18   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L19 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L20
L21 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L22  - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23  - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **14%**
L24  - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ20Ã—5%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L25
L26 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨â€œä¿æœ‰éŠ˜æŸ„æ•°â€ï¼ˆMMFâ‰’ç¾é‡‘ï¼‰
L27 *å„æ =5%ï¼ˆ20éŠ˜æŸ„å‡ç­‰ï¼‰ã€‚ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œæ™‚ã¯**Gã®æ æ•°ã®ã¿**èª¿æ•´ã—ã€å¤–ã—ãŸæ ã¯ç¾é‡‘ã¨ã—ã¦ä¿æŒã€‚*
L28
L29 - **NORMAL:** G **12** / D **8** / ç¾é‡‘åŒ–æ  **0**  
L30 - **CAUTION:** G **10** / D **8** / ç¾é‡‘åŒ–æ  **2**ï¼ˆ= 10%ï¼‰  
L31 - **EMERG:** G **8**  / D **8** / ç¾é‡‘åŒ–æ  **4**ï¼ˆ= 20%ï¼‰  
L32
L33 > å®Ÿé‹ç”¨ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚è§£é™¤æ™‚ã¯factorä¸Šä½ã‹ã‚‰è£œå……ã€‚
L34
L35 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
L36 - **åŸºæœ¬TS (ãƒ¢ãƒ¼ãƒ‰åˆ¥):** NORMAL **15%** / CAUTION **13%** / EMERG **10%**
L37 - å«ã¿ç›ŠãŒ **+30% / +60% / +100%** åˆ°é”ã§ã€åŸºæœ¬ã‹ã‚‰ **-3pt / -6pt / -8pt** å¼•ãä¸Šã’
L38 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L39
L40 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰æ‰‹é †
L41 ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã§**ã‚¢ãƒ©ãƒ¼ãƒˆ**ãŒå‡ºãŸå ´åˆï¼ˆåˆè¨ˆ|drift| ãŒãƒ¢ãƒ¼ãƒ‰é–¾å€¤ã‚’è¶…éã€EMERGé™¤ãï¼‰ã€ç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãã§ä¸‹è¨˜ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
L42
L43 1. **å£²å´ï¼ˆå¿…é ˆï¼‰**  
L44    Slackãƒ†ãƒ¼ãƒ–ãƒ«ã® **Î”qty ãŒãƒã‚¤ãƒŠã‚¹ã®éŠ˜æŸ„ã‚’å£²å´** ã™ã‚‹ï¼ˆå¯„ä»˜ãæˆè¡Œæ¨å¥¨ï¼‰ã€‚  
L45    ã“ã‚Œã¯ã€ŒåŠæˆ»ã—ã€è¨ˆç®—ã«åŸºã¥ãéé‡é‡ã®å‰Šæ¸›ã‚’æ„å‘³ã™ã‚‹ã€‚
L46
L47 2. **è³¼å…¥ï¼ˆä»»æ„ãƒ»åŠæˆ»ã—ç›®å®‰ï¼‰**  
L48    åŠæˆ»ã—å¾Œã®åˆè¨ˆ|drift|ã‚’**ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ï¼ˆSlackãƒ˜ãƒƒãƒ€ã«è¡¨ç¤ºï¼‰**ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ã‚’ç›®å®‰ã«ã€  
L49    **ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—**ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ï¼ˆÎ”qtyãŒãƒ—ãƒ©ã‚¹ã®éŠ˜æŸ„ã‚’å„ªå…ˆã—ã¦ã‚‚ã‚ˆã„ï¼‰ã€‚
L50
L51 3. **ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã®å†è¨­å®šï¼ˆå¿…é ˆï¼‰**  
L52    ã™ã¹ã¦ã®ä¿æœ‰éŠ˜æŸ„ã«ã¤ã„ã¦ã€æœ€æ–°ã®è©•ä¾¡é¡ã«åˆã‚ã›ã¦TSã‚’**å†ç™ºæ³¨ï¼æ›´æ–°**ã™ã‚‹ã€‚  
L53    ãƒ«ãƒ¼ãƒ«ã¯ä¸‹è¨˜ï¼ˆåˆ©ç›Šåˆ°é”ã§æ®µéšçš„ã«ã‚¿ã‚¤ãƒˆåŒ–ï¼‰ï¼š  
L54    - **åŸºæœ¬TS:** -15%  
L55    - **+30% åˆ°é” â†’ TS -12%**  
L56    - **+60% åˆ°é” â†’ TS -9%**  
L57    - **+100% åˆ°é” â†’ TS -7%**  
L58    â€»ã‚¹ãƒˆãƒƒãƒ—ä¾¡æ ¼ã®å¼•ãä¸Šã’ã¯è¨±å¯ã€**å¼•ãä¸‹ã’ã¯ä¸å¯**ï¼ˆåˆ©ç›Šä¿å…¨ã®åŸå‰‡ï¼‰ã€‚
L59
L60 4. **ä¾‹å¤–ï¼ˆEMERGãƒ¢ãƒ¼ãƒ‰ï¼‰**  
L61    ç·Šæ€¥(EMERG)ã§ã¯**ãƒ‰ãƒªãƒ•ãƒˆç”±æ¥ã®å£²è²·ã¯åœæ­¢ï¼ˆâˆï¼‰**ã€‚20éŠ˜æŸ„Ã—å„5%ã¸ã®**å…¨æˆ»ã—**ã®ã¿è¨±å®¹ã€‚
L62
L63 5. **å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°**
L64    - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L65    - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
L66
L67 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †ï¼ˆè¶…ã‚·ãƒ³ãƒ—ãƒ«ï¼‰
L68 ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€**Gã®æ æ•°ã ã‘**ã‚’èª¿æ•´ã™ã‚‹ï¼š
L69 1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰  
L70    - â­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚  
L71    - **`current_tickers.csv` ã‹ã‚‰å¤–ã™GéŠ˜æŸ„ã®è¡Œã‚’å‰Šé™¤**ï¼ˆï¼ãã®æ ã¯ç¾é‡‘åŒ–ï¼‰ã€‚
L72 2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**  
L73    - å¤–ã—ãŸæ ã¯ç¾é‡‘ï¼ˆã¾ãŸã¯MMFç›¸å½“ï¼‰ã§ãƒ—ãƒ¼ãƒ«ã€‚  
L74 3. **å¾©å¸°æ™‚ã®è£œå……**ï¼ˆNORMALã¸ï¼‰  
L75    - **`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ **ï¼ˆfactorä¸Šä½ã‹ã‚‰ï¼‰ã€‚  
L76    - ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚
L77
L78 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦è‡ªå‹•ã§å‡ç­‰æ¯”ç‡ãŒå†è¨ˆç®—ã•ã‚Œã‚‹ã€‚
L79
L80 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L81 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L82 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L83
L84 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L85 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L86
L87 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L88 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L89 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/factor_design.md>
```text
L1 # factor.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®éŠ˜æŸ„ã¨æ¤œè¨ä¸­ã®éŠ˜æŸ„ç¾¤ã‚’åŒæ™‚ã«æ‰±ã†éŠ˜æŸ„é¸å®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
L5 - ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨DRRSé¸å®šã‚’è¡Œã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚
L6   - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚æ¼ã‚ŒãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L7   - IN/OUTã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨OUTå´ã®ä½ã‚¹ã‚³ã‚¢éŠ˜æŸ„
L8   - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨
L9   - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ•´ç†ç”¨ï¼‰
L10
L11 ## å…¨ä½“ãƒ•ãƒ­ãƒ¼
L12 1. **Input** â€“ `current_tickers.csv`ã¨`candidate_tickers.csv`ã‚’èª­ã¿è¾¼ã¿ã€yfinanceã‚„Finnhubã®APIã‹ã‚‰ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦`InputBundle`ã‚’æ•´å‚™ã€‚
L13 2. **Score Calculation** â€“ ScorerãŒç‰¹å¾´é‡ã‚’è¨ˆç®—ã—å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã—ã¦`FeatureBundle`ã‚’ç”Ÿæˆã€‚
L14 3. **Correlation Reduction & Selection** â€“ SelectorãŒDRRSãƒ­ã‚¸ãƒƒã‚¯ã§ç›¸é–¢ã‚’æŠ‘ãˆã¤ã¤G/DéŠ˜æŸ„ã‚’é¸å®šã—`SelectionBundle`ã‚’å¾—ã‚‹ã€‚
L15 4. **Output** â€“ æ¡ç”¨çµæœã¨å‘¨è¾ºæƒ…å ±ã‚’è¡¨ãƒ»Slacké€šçŸ¥ã¨ã—ã¦å‡ºåŠ›ã€‚
L16
L17 ```mermaid
L18 flowchart LR
L19   A[Input\nAPI & å‰å‡¦ç†] --> B[Score Calculation\nç‰¹å¾´é‡ãƒ»å› å­åˆæˆ]
L20   B --> C[Correlation Reduction\nDRRSé¸å®š]
L21   C --> D[Output\nSlacké€šçŸ¥]
L22 ```
L23
L24 ## å®šæ•°ãƒ»è¨­å®š
L25 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L26 | --- | --- | --- |
L27 | `exist` / `cand` | ç¾è¡Œãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æ¤œè¨ä¸­éŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ | ã‚¹ã‚³ã‚¢å¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã®æ§‹æˆã€å€™è£œæ•´ç† |
L28 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L29 | `CAND_PRICE_MAX` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | é«˜é¡éŠ˜æŸ„ã®äº‹å‰é™¤å¤– |
L30 | `N_G` / `N_D` | G/Dæ¡ç”¨æ ã®ä»¶æ•°ï¼ˆ**æ—¢å®š: 12 / 8**ï¼‰ | æœ€çµ‚çš„ã«é¸ã¶éŠ˜æŸ„æ•°ã®åˆ¶ç´„ |
L31 | `g_weights` / `D_weights` | å„å› å­ã®é‡ã¿dict | G/Dã‚¹ã‚³ã‚¢åˆæˆ |
L32 | `D_BETA_MAX` | Dãƒã‚±ãƒƒãƒˆã®è¨±å®¹Î²ä¸Šé™ | é«˜Î²éŠ˜æŸ„ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ |
L33 | `FILTER_SPEC` | G/Dã”ã¨ã®å‰å‡¦ç†ãƒ•ã‚£ãƒ«ã‚¿ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¹ã‚¯ã‚„Î²ä¸Šé™è¨­å®š |
L34 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L35 | `DRRS_G` / `DRRS_D` | DRRSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç›¸é–¢ä½æ¸›è¨­å®š |
L36 | `DRRS_SHRINK` | æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å®‰å®šåŒ– |
L37 | `CROSS_MU_GD` | G-Dé–“ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ | 2ãƒã‚±ãƒƒãƒˆåŒæ™‚æœ€é©åŒ–ã§ç›¸é–¢æŠ‘åˆ¶ |
L38 | `RESULTS_DIR` | é¸å®šçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `_save_sel`/`_load_prev`ã®å…¥å‡ºåŠ› |
L39
L40 é¸å®šçµæœã¯`results/`é…ä¸‹ã«JSONã¨ã—ã¦ä¿å­˜ã—ã€æ¬¡å›å®Ÿè¡Œæ™‚ã«`_load_prev`ã§èª­ã¿è¾¼ã‚“ã§é¸å®šæ¡ä»¶ã«åæ˜ ã€‚
L41
L42 ## DTO/Config
L43 å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨è¨­å®šå€¤ã€‚å¤‰æ•°ã®æ„å‘³åˆã„ã¨åˆ©ç”¨ç®‡æ‰€ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚
L44
L45 ### InputBundleï¼ˆInput â†’ Scorerï¼‰
L46 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L47 | --- | --- | --- |
L48 | `cand` | å€™è£œéŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆ | OUTãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æ¯é›†å›£ |
L49 | `tickers` | ç¾è¡Œ+å€™è£œã‚’åˆã‚ã›ãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ | ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®— |
L50 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L51 | `data` | yfinanceã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœï¼ˆéšå±¤åˆ—ï¼‰ | `px`/`spx`/ãƒªã‚¿ãƒ¼ãƒ³ç­‰ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿ |
L52 | `px` | `data['Close']`ã ã‘ã‚’æŠœãå‡ºã—ãŸä¾¡æ ¼ç³»åˆ— | æŒ‡æ¨™è¨ˆç®—ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ç”Ÿæˆ |
L53 | `spx` | `data['Close'][bench]` ã®Series | `rs`ã‚„`calc_beta`ã®åŸºæº–æŒ‡æ•° |
L54 | `tickers_bulk` | `yf.Tickers`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | `info`ç­‰ã®ä¸€æ‹¬å–å¾— |
L55 | `info` | ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã®yfinanceæƒ…å ±dict | ã‚»ã‚¯ã‚¿ãƒ¼åˆ¤å®šã‚„EPSè£œå®Œ |
L56 | `eps_df` | EPS TTM/ç›´è¿‘EPSç­‰ã‚’ã¾ã¨ã‚ãŸè¡¨ | æˆé•·æŒ‡æ¨™ã®ç®—å‡º |
L57 | `fcf_df` | CFOãƒ»CapExãƒ»FCF TTMã¨æƒ…å ±æºãƒ•ãƒ©ã‚° | FCF/EVã‚„é…å½“ã‚«ãƒãƒ¬ãƒƒã‚¸ |
L58 | `returns` | `px.pct_change()`ã®ãƒªã‚¿ãƒ¼ãƒ³è¡¨ | ç›¸é–¢è¡Œåˆ—ãƒ»DRRSè¨ˆç®— |
L59
L60 ### FeatureBundleï¼ˆScorer â†’ Selectorï¼‰
L61 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L62 | --- | --- | --- |
L63 | `df` | è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™ã®ç”Ÿå€¤ãƒ†ãƒ¼ãƒ–ãƒ« | ãƒ‡ãƒãƒƒã‚°ãƒ»å‡ºåŠ›è¡¨ç¤º |
L64 | `df_z` | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å¾ŒZã‚¹ã‚³ã‚¢åŒ–ã—ãŸæŒ‡æ¨™è¡¨ | å› å­ã‚¹ã‚³ã‚¢åˆæˆã€é¸å®šåŸºæº– |
L65 | `g_score` | Gãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ | Gé¸å®šã€IN/OUTæ¯”è¼ƒ |
L66 | `d_score_all` | Dãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ï¼ˆå…¨éŠ˜æŸ„ï¼‰ | Dé¸å®šã€ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
L67 | `missing_logs` | æ¬ ææŒ‡æ¨™ã¨è£œå®ŒçŠ¶æ³ã®ãƒ­ã‚° | ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ |
L68
L69 ### SelectionBundleï¼ˆSelector â†’ Outputï¼‰
L70 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L71 | --- | --- | --- |
L72 | `resG` | Gé¸å®šçµæœã®è©³ç´°dictï¼ˆ`tickers`ã€ç›®çš„å€¤ç­‰ï¼‰ | çµæœä¿å­˜ãƒ»å¹³å‡ç›¸é–¢ãªã©ã®æŒ‡æ¨™è¡¨ç¤º |
L73 | `resD` | Dé¸å®šçµæœã®è©³ç´°dict | åŒä¸Š |
L74 | `top_G` | æœ€çµ‚æ¡ç”¨Gãƒ†ã‚£ãƒƒã‚«ãƒ¼ | æ–°ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ |
L75 | `top_D` | æœ€çµ‚æ¡ç”¨Dãƒ†ã‚£ãƒƒã‚«ãƒ¼ | åŒä¸Š |
L76 | `init_G` | DRRSå‰ã®GåˆæœŸå€™è£œ | æƒœã—ãã‚‚å¤–ã‚ŒãŸéŠ˜æŸ„è¡¨ç¤º |
L77 | `init_D` | DRRSå‰ã®DåˆæœŸå€™è£œ | åŒä¸Š |
L78
L79 ### WeightsConfig
L80 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L81 | --- | --- | --- |
L82 | `g` | Gå› å­ï¼ˆGRW/MOM/VOLï¼‰ã®é‡ã¿dict | `g_score`åˆæˆ |
L83 | `d` | Då› å­ï¼ˆD_QAL/D_YLD/D_VOL_RAW/D_TRDï¼‰ã®é‡ã¿dict | `d_score_all`åˆæˆ |
L84
L85 ### DRRSParams
L86 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L87 | --- | --- | --- |
L88 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L89 | `shrink` | æ®‹å·®ç›¸é–¢ã®ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å¯¾è§’å¼·èª¿ |
L90 | `G` | Gãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dictï¼ˆ`lookback`ç­‰ï¼‰ | `select_bucket_drrs`è¨­å®š |
L91 | `D` | Dãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | åŒä¸Š |
L92 | `cross_mu_gd` | G-Dã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°Î¼ | `select_buckets`ã®ç›®çš„é–¢æ•° |
L93
L94 ### PipelineConfig
L95 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L96 | --- | --- | --- |
L97 | `weights` | `WeightsConfig`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | ã‚¹ã‚³ã‚¢åˆæˆã®é‡ã¿å‚ç…§ |
L98 | `drrs` | `DRRSParams`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | é¸å®šã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šå€¤ |
L99 | `price_max` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | Inputæ®µéšã§ã®ãƒ•ã‚£ãƒ«ã‚¿ |
L100
L101 ## å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
L102 - `winsorize_s` / `robust_z` : å¤–ã‚Œå€¤å‡¦ç†ã¨Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L103 - `_safe_div` / `_safe_last` : ä¾‹å¤–ã‚’æ½°ã—ãŸåˆ†å‰²ãƒ»æœ«å°¾å–å¾—ã€‚
L104 - `_load_prev` / `_save_sel` : é¸å®šçµæœã®èª­ã¿æ›¸ãã€‚
L105
L106 ## ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
L107 ### Step1: Input
L108 `current_tickers.csv`ã®ç¾è¡ŒéŠ˜æŸ„ã¨`candidate_tickers.csv`ã®æ¤œè¨ä¸­éŠ˜æŸ„ã‚’èµ·ç‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã™ã‚‹ã€‚å¤–éƒ¨I/Oã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€`prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¯**yfinanceã‚’å„ªå…ˆã—ã€æ¬ æãŒã‚ã‚‹æŒ‡æ¨™ã®ã¿Finnhub APIã§è£œå®Œ**ã™ã‚‹ã€‚
L109 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L110 - `impute_eps_ttm` : å››åŠæœŸEPSÃ—4ã§TTMã‚’æ¨å®šã—æ¬ ææ™‚ã®ã¿å·®ã—æ›¿ãˆã€‚
L111 - `fetch_cfo_capex_ttm_yf` : yfinanceã®å››åŠæœŸ/å¹´æ¬¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‹ã‚‰CFOãƒ»CapExãƒ»FCF TTMã‚’ç®—å‡ºã€‚
L112 - `fetch_cfo_capex_ttm_finnhub` : yfinanceã§æ¬ ã‘ãŸéŠ˜æŸ„ã®ã¿Finnhub APIã§è£œå®Œã€‚
L113 - `compute_fcf_with_fallback` : yfinanceå€¤ã‚’åŸºæº–ã«Finnhubå€¤ã§ç©´åŸ‹ã‚ã—ã€CFO/CapEx/FCFã¨æƒ…å ±æºãƒ•ãƒ©ã‚°ã‚’è¿”ã™ã€‚
L114 - `_build_eps_df` : `info`ã‚„`quarterly_earnings`ã‹ã‚‰EPS TTMã¨ç›´è¿‘EPSã‚’è¨ˆç®—ã—ã€`impute_eps_ttm`ã§è£œå®Œã€‚
L115 - `prepare_data` :
L116     0. CSVã‹ã‚‰ç¾è¡ŒéŠ˜æŸ„ã¨å€™è£œéŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
L117     1. å€™è£œéŠ˜æŸ„ã®ç¾åœ¨å€¤ã‚’å–å¾—ã—ä¾¡æ ¼ä¸Šé™ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
L118     2. æ—¢å­˜+å€™è£œã‹ã‚‰å¯¾è±¡ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’æ±ºå®šã—ã€ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆyfinanceï¼‰ã€‚
L119     3. yfinanceå€¤ã‚’åŸºã«EPS/FCFãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç³»åˆ—ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ¬ æã‚»ãƒ«ã¯Finnhubå‘¼ã³å‡ºã—ã§ç©´åŸ‹ã‚ã€‚
L120     4. ä¸Šè¨˜ã‚’`InputBundle`ã«æ ¼ç´ã—ã¦è¿”ã™ã€‚
L121
L122 ### Step2: Score Calculation (Scorer)
L123 ç‰¹å¾´é‡è¨ˆç®—ã¨ã‚¹ã‚³ã‚¢åˆæˆã‚’æ‹…å½“ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L124
L125 #### è£œåŠ©é–¢æ•°
L126 - `trend(s)` : 50/150/200æ—¥ç§»å‹•å¹³å‡ã‚„52é€±ãƒ¬ãƒ³ã‚¸ã‹ã‚‰-0.5ã€œ0.5ã§æ§‹æˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ã€‚
L127 - `rs(s,b)` / `tr_str(s)` / `rs_line_slope(s,b,win)` : ç›¸å¯¾å¼·ã•ã‚„çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã€RSå›å¸°å‚¾ãã‚’ç®—å‡ºã€‚
L128 - `ev_fallback` : `enterpriseValue`æ¬ ææ™‚ã«è² å‚µãƒ»ç¾é‡‘ã‹ã‚‰EVã‚’æ¨å®šã€‚
L129 - `dividend_status` / `div_streak` : é…å½“æœªè¨­å®šçŠ¶æ³ã®åˆ¤å®šã¨å¢—é…å¹´æ•°ã‚«ã‚¦ãƒ³ãƒˆã€‚
L130 - `fetch_finnhub_metrics` : Finnhub APIã‹ã‚‰EPSæˆé•·ãƒ»ROEãƒ»Î²ãªã©ä¸è¶³æŒ‡æ¨™ã‚’å–å¾—ã€‚
L131 - `calc_beta` : ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å…±åˆ†æ•£ã‹ã‚‰Î²ã‚’ç®—å‡ºã€‚
L132 - `spx_to_alpha` : S&P500ã®ä½ç½®æƒ…å ±ã‹ã‚‰DRRSã§ç”¨ã„ã‚‹Î±ã‚’æ¨å®šã€‚
L133 - `soft_cap_effective_scores` / `pick_top_softcap` : ã‚»ã‚¯ã‚¿ãƒ¼ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ—ä»˜ãã‚¹ã‚³ã‚¢èª¿æ•´ã¨ä¸Šä½æŠ½å‡ºã€‚
L134
L135 **è£œåŠ©é–¢æ•°ã¨ç”ŸæˆæŒ‡æ¨™**
L136
L137 | è£œåŠ©é–¢æ•° | ç”ŸæˆæŒ‡æ¨™ | ç•¥ç§° |
L138 | --- | --- | --- |
L139 | `trend` | ãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ | `TR` |
L140 | `rs` | ç›¸å¯¾å¼·ã• | `RS` |
L141 | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç·šã®ä¹–é›¢ | `TR_str` |
L142 | `rs_line_slope` | RSç·šã®å›å¸°å‚¾ã | `RS_SLOPE_*` |
L143 | `calc_beta` | Î² | `BETA` |
L144 | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° | `DIV_STREAK` |
L145
L146 #### `aggregate_scores` è©³ç´°
L147 1. å„éŠ˜æŸ„ã®ä¾¡æ ¼ç³»åˆ—ã‚„`info`ã‚’åŸºã«ä»¥ä¸‹ã‚’ç®—å‡ºã€‚
L148    - **ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ **: `TR`ã€`RS`ã€`TR_str`ã€å¤šæ§˜ãªç§»å‹•å¹³å‡æ¯”ã€`RS_SLOPE_*`ãªã©ã€‚
L149    - **ãƒªã‚¹ã‚¯**: `BETA`ã€`DOWNSIDE_DEV`ã€`MDD_1Y`ã€`RESID_VOL`ã€`DOWN_OUTPERF`ã€`EXT_200`ç­‰ã€‚
L150    - **é…å½“**: `DIV`ã€`DIV_TTM_PS`ã€`DIV_VAR5`ã€`DIV_YOY`ã€`DIV_FCF_COVER`ã€`DIV_STREAK`ã€‚
L151    - **è²¡å‹™ãƒ»æˆé•·**: `EPS`ã€`REV`ã€`ROE`ã€`FCF/EV`ã€`REV_Q_YOY`ã€`EPS_Q_YOY`ã€`REV_YOY_ACC`ã€`REV_YOY_VAR`ã€`REV_ANN_STREAK`ã€`RULE40`ã€`FCF_MGN` ç­‰ã€‚
L152    - **å®‰å®šæ€§/ã‚µã‚¤ã‚º**: `DEBT2EQ`ã€`CURR_RATIO`ã€`MARKET_CAP`ã€`ADV60_USD`ã€`EPS_VAR_8Q`ãªã©ã€‚
L153 2. æŒ‡æ¨™æ¬ æã¯Finnhub APIç­‰ã§è£œå®Œã—ã€æœªå–å¾—é …ç›®ã‚’`missing_logs`ã«è¨˜éŒ²ã€‚
L154 3. `winsorize_s`â†’`robust_z`ã§æ¨™æº–åŒ–ã—`df_z`ã¸ä¿å­˜ã€‚ã‚µã‚¤ã‚ºãƒ»æµå‹•æ€§ã¯å¯¾æ•°å¤‰æ›ã€‚
L155 4. æ­£è¦åŒ–æ¸ˆæŒ‡æ¨™ã‹ã‚‰å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã€‚
L156    - å„å› å­ã®æ§‹æˆã¨é‡ã¿ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
L157      - **GRW**: 0.30Ã—`REV` + 0.20Ã—`EPS_Q_YOY` + 0.15Ã—`REV_Q_YOY` + 0.15Ã—`REV_YOY_ACC` + 0.10Ã—`RULE40` + 0.10Ã—`FCF_MGN` + 0.10Ã—`REV_ANN_STREAK` âˆ’ 0.05Ã—`REV_YOY_VAR`ã€‚
L158      - **MOM**: 0.40Ã—`RS` + 0.15Ã—`TR_str` + 0.15Ã—`RS_SLOPE_6W` + 0.15Ã—`RS_SLOPE_13W` + 0.10Ã—`MA200_SLOPE_5M` + 0.10Ã—`MA200_UP_STREAK_D`ã€‚
L159      - **VOL**: `BETA`å˜ä½“ã‚’ä½¿ç”¨ã€‚
L160      - **QAL**: 0.60Ã—`FCF_W` + 0.40Ã—`ROE_W`ã§ä½œæˆã€‚
L161      - **YLD**: 0.30Ã—`DIV` + 0.70Ã—`DIV_STREAK`ã€‚
L162      - **D_QAL**: 0.35Ã—`QAL` + 0.20Ã—`FCF` + 0.15Ã—`CURR_RATIO` âˆ’ 0.15Ã—`DEBT2EQ` âˆ’ 0.15Ã—`EPS_VAR_8Q`ã€‚
L163      - **D_YLD**: 0.45Ã—`DIV` + 0.25Ã—`DIV_STREAK` + 0.20Ã—`DIV_FCF_COVER` âˆ’ 0.10Ã—`DIV_VAR5`ã€‚
L164      - **D_VOL_RAW**: 0.40Ã—`DOWNSIDE_DEV` + 0.22Ã—`RESID_VOL` + 0.18Ã—`MDD_1Y` âˆ’ 0.10Ã—`DOWN_OUTPERF` âˆ’ 0.05Ã—`EXT_200` âˆ’ 0.08Ã—`SIZE` âˆ’ 0.10Ã—`LIQ` + 0.10Ã—`BETA`ã€‚
L165      - **D_TRD**: 0.40Ã—`MA200_SLOPE_5M` âˆ’ 0.30Ã—`EXT_200` + 0.15Ã—`NEAR_52W_HIGH` + 0.15Ã—`TR`ã€‚
L166     - ä¸»ãªæŒ‡æ¨™ã®ç•¥ç§°ã¨æ„å‘³:
L167
L168       | ç•¥ç§° | è£œåŠ©é–¢æ•° | æ¦‚è¦ |
L169       | --- | --- | --- |
L170       | TR | `trend` | 50/150/200æ—¥ç§»å‹•å¹³å‡ã¨52é€±ãƒ¬ãƒ³ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ |
L171       | RS | `rs` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹ç›¸å¯¾å¼·ã•ï¼ˆ12M/1Mãƒªã‚¿ãƒ¼ãƒ³å·®ï¼‰ |
L172       | TR_str | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ |
L173       | RS_SLOPE_6W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®6é€±å›å¸°å‚¾ã |
L174       | RS_SLOPE_13W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®13é€±å›å¸°å‚¾ã |
L175       | MA200_SLOPE_5M | - | 200æ—¥ç§»å‹•å¹³å‡ã®5ã‹æœˆé¨°è½ç‡ |
L176       | MA200_UP_STREAK_D | - | 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ã„ãŸæ—¥æ•° |
L177       | BETA | `calc_beta` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹Î² |
L178       | DOWNSIDE_DEV | - | ä¸‹æ–¹ãƒªã‚¿ãƒ¼ãƒ³ã®ã¿ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L179       | RESID_VOL | - | Î²ã§èª¿æ•´ã—ãŸæ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L180       | MDD_1Y | - | éå»1å¹´ã®æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ |
L181       | DOWN_OUTPERF | - | å¸‚å ´ä¸‹è½æ—¥ã«å¯¾ã™ã‚‹å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ |
L182       | EXT_200 | - | 200æ—¥ç§»å‹•å¹³å‡ã‹ã‚‰ã®çµ¶å¯¾ä¹–é›¢ç‡ |
L183       | NEAR_52W_HIGH | - | 52é€±é«˜å€¤ã¾ã§ã®ä¸‹æ–¹è·é›¢ï¼ˆ0=é«˜å€¤ï¼‰ |
L184       | FCF_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®FCF/EV |
L185       | ROE_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®ROE |
L186       | FCF | - | FCF/EV |
L187       | QAL | - | FCF_Wã¨ROE_Wã‚’çµ„ã¿åˆã‚ã›ãŸå“è³ªã‚¹ã‚³ã‚¢ |
L188       | CURR_RATIO | - | æµå‹•æ¯”ç‡ |
L189       | DEBT2EQ | - | è² å‚µè³‡æœ¬å€ç‡ |
L190       | EPS_VAR_8Q | - | EPSã®8å››åŠæœŸæ¨™æº–åå·® |
L191       | DIV | - | å¹´ç‡æ›ç®—é…å½“åˆ©å›ã‚Š |
L192       | DIV_STREAK | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° |
L193       | DIV_FCF_COVER | - | é…å½“ã®FCFã‚«ãƒãƒ¬ãƒƒã‚¸ |
L194       | DIV_VAR5 | - | 5å¹´é…å½“å¤‰å‹•ç‡ |
L195       | DIV_TTM_PS | - | 1æ ªå½“ãŸã‚ŠTTMé…å½“ |
L196       | DIV_YOY | - | å‰å¹´æ¯”é…å½“æˆé•·ç‡ |
L197       | REV | - | å£²ä¸Šæˆé•·ç‡TTM |
L198       | EPS_Q_YOY | - | å››åŠæœŸEPSã®å‰å¹´åŒæœŸæ¯” |
L199       | REV_Q_YOY | - | å››åŠæœŸå£²ä¸Šã®å‰å¹´åŒæœŸæ¯” |
L200       | REV_YOY_ACC | - | å£²ä¸Šæˆé•·ç‡ã®åŠ é€Ÿåˆ† |
L201       | RULE40 | - | å£²ä¸Šæˆé•·ç‡ã¨FCFãƒãƒ¼ã‚¸ãƒ³ã®åˆè¨ˆ |
L202       | FCF_MGN | - | FCFãƒãƒ¼ã‚¸ãƒ³ |
L203       | REV_ANN_STREAK | - | å¹´æ¬¡å£²ä¸Šæˆé•·ã®é€£ç¶šå¹´æ•° |
L204       | REV_YOY_VAR | - | å¹´æ¬¡å£²ä¸Šæˆé•·ç‡ã®å¤‰å‹•æ€§ |
L205       | SIZE | - | æ™‚ä¾¡ç·é¡ã®å¯¾æ•°å€¤ |
L206       | LIQ | - | 60æ—¥å¹³å‡å‡ºæ¥é«˜ãƒ‰ãƒ«ã®å¯¾æ•°å€¤ |
L207    - Gãƒã‚±ãƒƒãƒˆ: `GRW`ã€`MOM`ã€`VOL`ã‚’`cfg.weights.g`ï¼ˆ0.40/0.45/-0.15ï¼‰ã§åŠ é‡ã—`g_score`ã‚’å¾—ã‚‹ã€‚
L208    - Dãƒã‚±ãƒƒãƒˆ: `D_QAL`ã€`D_YLD`ã€`D_VOL_RAW`ã€`D_TRD`ã‚’`cfg.weights.d`ï¼ˆ0.15/0.15/-0.45/0.25ï¼‰ã§åŠ é‡ã—`d_score_all`ã‚’ç®—å‡ºã€‚
L209    - ã‚»ã‚¯ã‚¿ãƒ¼capã«ã‚ˆã‚‹`soft_cap_effective_scores`ã‚’é©ç”¨ã—ã€Gæ¡ç”¨éŠ˜æŸ„ã«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€‚
L210 5. `_apply_growth_entry_flags`ã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®ç™ºç«çŠ¶æ³ã‚’ä»˜åŠ ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L211
L212 ### Step3: Correlation Reduction & Selection (Selector)
L213 DRRSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç›¸é–¢ã‚’æŠ‘ãˆãŸéŠ˜æŸ„é¸å®šã‚’è¡Œã„ã€`SelectionBundle`ã‚’è¿”ã™ã€‚`results/`ã«ä¿å­˜ã•ã‚ŒãŸå‰å›é¸å®šï¼ˆ`G_selection.json` / `D_selection.json`ï¼‰ã‚’`_load_prev`ã§èª­ã¿è¾¼ã¿ã€ç›®çš„å€¤ãŒå¤§ããæ‚ªåŒ–ã—ãªã„é™ã‚Šç¶­æŒã™ã‚‹ã€‚æ–°ã—ã„æ¡ç”¨é›†åˆã¯`_save_sel`ã§JSONã«æ›¸ãå‡ºã—æ¬¡å›ä»¥é™ã®å…¥åŠ›ã«å‚™ãˆã‚‹ã€‚
L214 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L215 - `residual_corr` : åç›Šç‡è¡Œåˆ—ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã—ã€ä¸Šä½ä¸»æˆåˆ†ã‚’é™¤å»ã—ãŸæ®‹å·®ã‹ã‚‰ç›¸é–¢è¡Œåˆ—ã‚’æ±‚ã‚ã€å¹³å‡ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯ã€‚
L216 - `rrqr_like_det` : ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘ã—ãŸQRåˆ†è§£é¢¨ã®æ‰‹é †ã§åˆæœŸå€™è£œã‚’kä»¶æŠ½å‡ºã—ã€ã‚¹ã‚³ã‚¢ã®é«˜ã„éç›¸é–¢ãªé›†åˆã‚’å¾—ã‚‹ã€‚
L217 - `swap_local_det` / `swap_local_det_cross` : `sum(score) - Î»*within_corr - Î¼*cross_corr`ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ã€å…¥ã‚Œæ›¿ãˆæ¢ç´¢ã§å±€æ‰€çš„ã«æœ€é©åŒ–ã€‚
L218 - `select_bucket_drrs` : ãƒ—ãƒ¼ãƒ«éŠ˜æŸ„ã¨ã‚¹ã‚³ã‚¢ã‹ã‚‰æ®‹å·®ç›¸é–¢ã‚’è¨ˆç®—ã—ã€ä¸Šè¨˜2æ®µéš(åˆæœŸé¸æŠâ†’å…¥ã‚Œæ›¿ãˆ)ã§kéŠ˜æŸ„ã‚’æ±ºå®šã€‚éå»æ¡ç”¨éŠ˜æŸ„ã¨ã®æ¯”è¼ƒã§ç›®çš„å€¤ãŒåŠ£åŒ–ã—ãªã‘ã‚Œã°ç¶­æŒã™ã‚‹ã€‚
L219 - `select_buckets` : Gãƒã‚±ãƒƒãƒˆã‚’é¸å®šå¾Œã€ãã®çµæœã‚’é™¤ã„ãŸå€™è£œã‹ã‚‰Dãƒã‚±ãƒƒãƒˆã‚’é¸ã¶ã€‚Dé¸å®šæ™‚ã¯Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ã‚’ä»˜ä¸ã—ã€ä¸¡ãƒã‚±ãƒƒãƒˆã®åˆ†æ•£ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
L220
L221 #### ç›¸é–¢ä½æ¸›ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°
L222 1. **æ®‹å·®ç›¸é–¢è¡Œåˆ—ã®æ§‹ç¯‰ (`residual_corr`)**
L223    - ãƒªã‚¿ãƒ¼ãƒ³è¡Œåˆ—`R`ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L224    - SVDã§ä¸Šä½`n_pc`ä¸»æˆåˆ†`F`ã‚’æ±‚ã‚ã€æœ€å°äºŒä¹—ã§ä¿‚æ•°`B`ã‚’ç®—å‡ºã—æ®‹å·®`E = Z - F@B`ã‚’å¾—ã‚‹ã€‚
L225    - `E`ã®ç›¸é–¢è¡Œåˆ—`C`ã‚’è¨ˆç®—ã—ã€å¹³å‡çµ¶å¯¾ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯é‡`shrink_eff`ã‚’è£œæ­£ã—ã¦å¯¾è§’ã‚’å¼·èª¿ã€‚
L226 2. **åˆæœŸå€™è£œã®æŠ½å‡º (`rrqr_like_det`)**
L227    - ã‚¹ã‚³ã‚¢ã‚’0-1æ­£è¦åŒ–ã—ãŸé‡ã¿`w`ã¨ã—ã€`Z*(1+Î³w)`ã§åˆ—ãƒãƒ«ãƒ ã‚’å¼·èª¿ã€‚
L228    - æ®‹å·®ãƒãƒ«ãƒ æœ€å¤§ã®åˆ—ã‚’é€æ¬¡é¸ã³ã€QRãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã£ã¦éç›¸é–¢ã‹ã¤é«˜ã‚¹ã‚³ã‚¢ãª`k`éŠ˜æŸ„é›†åˆ`S0`ã‚’å¾—ã‚‹ã€‚
L229 3. **å±€æ‰€æ¢ç´¢ (`swap_local_det` / `swap_local_det_cross`)**
L230    - ç›®çš„é–¢æ•°`Î£z_score âˆ’ Î»Â·within_corr âˆ’ Î¼Â·cross_corr`ã‚’æœ€å¤§åŒ–ã€‚
L231    - é¸æŠé›†åˆã®å„éŠ˜æŸ„ã‚’ä»–å€™è£œã¨å…¥ã‚Œæ›¿ãˆã€æ”¹å–„ãŒãªããªã‚‹ã¾ã§ã¾ãŸã¯`max_pass`å›ã¾ã§æ¢ç´¢ã€‚
L232    - `swap_local_det_cross`ã¯Gãƒã‚±ãƒƒãƒˆã¨ã®ã‚¯ãƒ­ã‚¹ç›¸é–¢è¡Œåˆ—`C_cross`ã‚’ä½¿ç”¨ã—ã€ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’ä»˜ä¸ã€‚
L233 4. **éå»æ¡ç”¨ã®ç¶­æŒã¨ã‚¯ãƒ­ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ (`select_bucket_drrs` / `select_buckets`)**
L234    - å±€æ‰€æ¢ç´¢çµæœ`S`ã¨éå»é›†åˆ`P`ã®ç›®çš„å€¤ã‚’æ¯”è¼ƒã—ã€`S`ãŒ`P`ã‚ˆã‚Š`Î·`æœªæº€ã®æ”¹å–„ãªã‚‰`P`ã‚’ç¶­æŒã€‚
L235    - `select_buckets`ã§ã¯Gã‚’å…ˆã«æ±ºå®šã—ã€Dé¸å®šæ™‚ã«Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’åŠ ãˆã¦ã‚¯ãƒ­ã‚¹åˆ†æ•£ã‚’æŠ‘åˆ¶ã€‚
L236
L237 ### Step4: Output
L238 é¸å®šçµæœã‚’å¯è¦–åŒ–ã—å…±æœ‰ã™ã‚‹å·¥ç¨‹ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦æ¨™æº–å‡ºåŠ›ã¨Slackã¸é€ã‚‹ã€‚
L239 - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚é¸å¤–ã¨ãªã£ãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L240 - IN/OUTãƒªã‚¹ãƒˆã¨OUTéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ï¼ˆä½å¾—ç‚¹éŠ˜æŸ„ã‚’ç¢ºèªã—ã‚„ã™ãï¼‰
L241 - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨ï¼ˆçµ„å…¥ã‚Œãƒ»é™¤å¤–ã€ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼‰
L242 - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
L243
L244 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L245 - `display_results` : ä¸Šè¨˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŠ ãˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚„åˆ†æ•£åŒ–æŒ‡æ¨™ã‚’è¡¨ç¤ºã€‚
L246 - `notify_slack` : Slack Webhookã¸åŒå†…å®¹ã‚’é€ä¿¡ã€‚
L247 - è£œåŠ©:`_avg_offdiag`ã€`_resid_avg_rho`ã€`_raw_avg_rho`ã€`_cross_block_raw_rho`ã€‚
L248
L249 ## ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
L250 1. `PipelineConfig`ã‚’æ§‹ç¯‰ã€‚
L251 2. **Step1** `Input.prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚
L252 3. **Step2** `Scorer.aggregate_scores`ã§`FeatureBundle`ã‚’å–å¾—ã€‚
L253 4. **Step3** `Selector.select_buckets`ã§`SelectionBundle`ã‚’ç®—å‡ºã€‚
L254 5. **Step4** `Output.display_results`ã¨`notify_slack`ã§çµæœã‚’å‡ºåŠ›ã€‚
```
