# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰, è¨ˆç®—ã¯ scorer.py'''
L2 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L3 BONUS_COEFF = 0.4   # æ”»ã‚=0.3 / ä¸­åº¸=0.4 / å®ˆã‚Š=0.5
L4 import os, time, requests
L5 from time import perf_counter
L6 from dataclasses import dataclass
L7 from typing import Dict, List
L8 from concurrent.futures import ThreadPoolExecutor
L9 import numpy as np
L10 import pandas as pd
L11 import yfinance as yf
L12 from scipy.stats import zscore  # used via scorer
L13 from scorer import Scorer, ttm_div_yield_portfolio
L14
L15 class T:
L16     t = perf_counter()
L17     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L18
L19 T.log("start")
L20
L21 # === ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ ===
L22 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L23 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L24 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L25 N_G, N_D = 12, 13  # G/Dæ ã‚µã‚¤ã‚º
L26 g_weights = {'GRW':0.40,'MOM':0.45,'VOL':-0.15}
L27 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L28 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L29 D_weights = {'QAL':0.15,'YLD':0.15,'VOL':-0.45,'TRD':0.25}
L30 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L31
L32 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L33 corrM = 45
L34 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L35 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L36
L37 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L38 try: CROSS_MU_GD
L39 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L40
L41 # å‡ºåŠ›é–¢é€£
L42 RESULTS_DIR = "results"
L43 os.makedirs(RESULTS_DIR, exist_ok=True)
L44
L45 # ãã®ä»–
L46 debug_mode, FINNHUB_API_KEY = False, os.environ.get("FINNHUB_API_KEY")
L47
L48 # === å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config ===
L49 @dataclass(frozen=True)
L50 class InputBundle:
L51     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L52     cand: List[str]
L53     tickers: List[str]
L54     bench: str
L55     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L56     px: pd.DataFrame                # data['Close']
L57     spx: pd.Series                  # data['Close'][bench]
L58     tickers_bulk: object            # yfinance.Tickers
L59     info: Dict[str, dict]           # yfinance info per ticker
L60     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L61     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L62     returns: pd.DataFrame           # px[tickers].pct_change()
L63
L64 @dataclass(frozen=True)
L65 class FeatureBundle:
L66     df: pd.DataFrame
L67     df_z: pd.DataFrame
L68     g_score: pd.Series
L69     d_score_all: pd.Series
L70     missing_logs: pd.DataFrame
L71
L72 @dataclass(frozen=True)
L73 class SelectionBundle:
L74     resG: dict
L75     resD: dict
L76     top_G: List[str]
L77     top_D: List[str]
L78     init_G: List[str]
L79     init_D: List[str]
L80
L81 @dataclass(frozen=True)
L82 class WeightsConfig:
L83     g: Dict[str,float]
L84     d: Dict[str,float]
L85
L86 @dataclass(frozen=True)
L87 class DRRSParams:
L88     corrM: int
L89     shrink: float
L90     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L91     D: Dict[str,float]
L92     cross_mu_gd: float
L93
L94 @dataclass(frozen=True)
L95 class PipelineConfig:
L96     weights: WeightsConfig
L97     drrs: DRRSParams
L98     price_max: float
L99
L100 # === å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ ===
L101 # (unused local utils removed â€“ use scorer.py versions if needed)
L102
L103 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L104
L105 def _post_slack(payload: dict):
L106     url = os.getenv("SLACK_WEBHOOK_URL")
L107     if not url: print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L108     try:
L109         requests.post(url, json=payload).raise_for_status()
L110     except Exception as e:
L111         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L112
L113 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L114
L115 def _slack_debug(text: str, chunk=2800):
L116     i = 0
L117     while i < len(text):
L118         j = min(len(text), i + chunk)
L119         k = text.rfind("\n", i, j)
L120         j = k if k > i + 100 else j
L121         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L122         i = j
L123
L124 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L125     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC"]
L126     all_cols = _env_true("DEBUG_ALL_COLS", False)
L127     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L128
L129     Gp, Dp = set(prevG or []), set(prevD or [])
L130     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L131     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L132
L133     show_near = _env_true("DEBUG_NEAR5", True)
L134     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L135     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L136     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L137     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L138     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L139     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L140
L141     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L142     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L143
L144     def _fmt_near(lbl, ser, lst):
L145         if ser is None: return f"{lbl}: off"
L146         g = ser.get
L147         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L148         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L149
L150     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L151           _fmt_near("G near10", gs, g_miss),
L152           _fmt_near("D near10", ds, d_miss),
L153           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L154           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L155
L156     tbl="(df_z or columns not available)"
L157     if not fb.df_z.empty and cols:
L158         idx=[t for t in focus if t in fb.df_z.index]
L159         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L160
L161     miss_txt=""
L162     if _env_true("DEBUG_MISSING_LOGS", False):
L163         miss=getattr(fb,"missing_logs",None)
L164         if miss is not None and not miss.empty:
L165             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L166
L167     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L168
L169 def _disjoint_keepG(top_G, top_D, poolD):
L170     """Gé‡è¤‡ã‚’Dã‹ã‚‰é™¤å»ã—ã€poolDã§é †æ¬¡è£œå……ï¼ˆæ¯æ¸‡æ™‚ã¯å…ƒéŠ˜æŸ„ç¶­æŒï¼‰ã€‚"""
L171     used, D, i = set(top_G), list(top_D), 0
L172     for j, t in enumerate(D):
L173         if t in used:
L174             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L175                 i += 1
L176             if i < len(poolD):
L177                 D[j] = poolD[i]; used.add(D[j]); i += 1
L178     return top_G, D
L179
L180
L181 # === Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ ===
L182 class Input:
L183     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L184         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L185         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L186
L187     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L188     @staticmethod
L189     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L190         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L191         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L192         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L193
L194     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L195
L196     @staticmethod
L197     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L198         if df is None or df.empty: return None
L199         idx_lower={str(i).lower():i for i in df.index}
L200         for n in names:
L201             k=n.lower()
L202             if k in idx_lower: return df.loc[idx_lower[k]]
L203         return None
L204
L205     @staticmethod
L206     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L207         if s is None or s.empty: return None
L208         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L209
L210     @staticmethod
L211     def _latest(s: pd.Series|None) -> float|None:
L212         if s is None or s.empty: return None
L213         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L214
L215     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L216         from concurrent.futures import ThreadPoolExecutor, as_completed
L217         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L218
L219         def one(t: str):
L220             try:
L221                 tk = yf.Ticker(t)  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯æ¸¡ã•ãªã„ï¼ˆYFãŒcurl_cffiã§ç®¡ç†ï¼‰
L222                 qcf = tk.quarterly_cashflow
L223                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L224                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L225                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L226                 if any(v is None for v in (cfo, capex, fcf)):
L227                     acf = tk.cashflow
L228                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L229                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L230                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L231             except Exception as e:
L232                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L233             n=np.nan
L234             return {"ticker":t,
L235                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L236                     "capex_ttm_yf": n if capex is None else capex,
L237                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L238
L239         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L240         with ThreadPoolExecutor(max_workers=mw) as ex:
L241             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L242         return pd.DataFrame(rows).set_index("ticker")
L243
L244     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L245     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L246
L247     @staticmethod
L248     def _first_key(d: dict, keys: list[str]):
L249         for k in keys:
L250             if k in d and d[k] is not None: return d[k]
L251         return None
L252
L253     @staticmethod
L254     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L255         for i in range(retries):
L256             r = session.get(url, params=params, timeout=15)
L257             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L258             r.raise_for_status(); return r.json()
L259         r.raise_for_status()
L260
L261     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L262         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L263         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L264         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L265         for sym in tickers:
L266             cfo_ttm = capex_ttm = None
L267             try:
L268                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L269                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L270                 for item in arr[:4]:
L271                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L272                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L273                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L274             except Exception: pass
L275             if cfo_ttm is None or capex_ttm is None:
L276                 try:
L277                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L278                     arr = j.get("cashFlow") or []
L279                     if arr:
L280                         item0 = arr[0]
L281                         if cfo_ttm is None:
L282                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L283                             if v is not None: cfo_ttm = float(v)
L284                         if capex_ttm is None:
L285                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L286                             if v is not None: capex_ttm = float(v)
L287                 except Exception: pass
L288             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L289         return pd.DataFrame(rows).set_index("ticker")
L290
L291     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L292         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L293         T.log("financials (yf) done")
L294         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L295         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L296         if need:
L297             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L298             df = yf_df.join(fh_df, how="left")
L299             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L300                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L301             print("[T] financials (finnhub) done (fallback only)")
L302         else:
L303             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L304             print("[T] financials (finnhub) skipped (no missing)")
L305         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L306         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L307         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L308         fcf_calc = cfo - capex
L309         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L310         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L311         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L312         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L313         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L314         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L315         return df[cols].sort_index()
L316
L317     def _build_eps_df(self, tickers, tickers_bulk, info):
L318         eps_rows=[]
L319         for t in tickers:
L320             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L321             try:
L322                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L323                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L324                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L325                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L326                     eps_q = qearn["Earnings"].iloc[-1]/so
L327             except Exception: pass
L328             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L329         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L330
L331     def prepare_data(self):
L332         """Fetch price and fundamental data for all tickers."""
L333         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L334         for t in self.cand:
L335             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L336             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L337         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L338         T.log("price cap filter done (CAND_PRICE_MAX)")
L339         tickers = sorted(set(self.exist + cand_f))
L340         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L341         data = yf.download(tickers + [self.bench], period="600d", auto_adjust=True, progress=False)
L342         T.log("yf.download done")
L343         px, spx = data["Close"], data["Close"][self.bench]
L344         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0ãªã‚‰ç„¡åŠ¹ï¼ˆæ—¢å®šï¼‰
L345         if clip_days > 0:
L346             px  = px.tail(clip_days + 1)
L347             spx = spx.tail(clip_days + 1)
L348             print(f"[T] price window clipped by env: {len(px)} rows (PRICE_CLIP_DAYS={clip_days})")
L349         else:
L350             print(f"[T] price window clip skipped; rows={len(px)}")
L351         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L352         for t in tickers:
L353             try: info[t] = tickers_bulk.tickers[t].info
L354             except Exception as e: print(f"{t}: info fetch failed ({e})"); info[t] = {}
L355         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L356         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L357         T.log("eps/fcf prep done")
L358         returns = px[tickers].pct_change()
L359         T.log("price prep/returns done")
L360         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L361
L362 # === Selectorï¼šç›¸é–¢ä½æ¸›ãƒ»é¸å®šï¼ˆã‚¹ã‚³ã‚¢ï¼†ãƒªã‚¿ãƒ¼ãƒ³ã ã‘èª­ã‚€ï¼‰ ===
L363 class Selector:
L364     # ---- DRRS helpersï¼ˆSelectorå°‚ç”¨ï¼‰ ----
L365     @staticmethod
L366     def _z_np(X: np.ndarray) -> np.ndarray:
L367         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L368         return (np.nan_to_num(X)-m)/s
L369
L370     @classmethod
L371     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L372         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L373         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L374         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L375         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L376         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L377
L378     @classmethod
L379     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L380         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L381         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L382         if k==0: return []
L383         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L384         for _ in range(k):
L385             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L386             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L387             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L388         return sorted(S)
L389
L390     @staticmethod
L391     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L392         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L393         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L394
L395     @classmethod
L396     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L397         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L398         while improved and passes<max_pass:
L399             improved, passes = False, passes+1
L400             for i,out in enumerate(list(S)):
L401                 for inn in range(len(score)):
L402                     if inn in S: continue
L403                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L404                     if v>best+1e-10: S, best, improved = cand, v, True; break
L405                 if improved: break
L406         return S, best
L407
L408     @staticmethod
L409     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L410         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L411         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L412         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L413         return float(s[idx].sum() - lam*within - mu*cross)
L414
L415     @classmethod
L416     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L417         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L418         while improved and passes<max_pass:
L419             improved, passes = False, passes+1
L420             for i,out in enumerate(list(S)):
L421                 for inn in range(N):
L422                     if inn in S: continue
L423                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L424                     if v>best+1e-10: S, best, improved = cand, v, True; break
L425                 if improved: break
L426         return S, best
L427
L428     @staticmethod
L429     def avg_corr(C: np.ndarray, idx) -> float:
L430         k = len(idx); P = C[np.ix_(idx, idx)]
L431         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L432
L433     @classmethod
L434     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L435         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L436         union = [t for t in pool_tickers if t in returns_df.columns]
L437         for t in g_fixed:
L438             if t not in union: union.append(t)
L439         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L440         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L441         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L442         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L443         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L444         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L445         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L446         if len(g_eff)>0 and mu>0.0:
L447             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L448         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L449         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L450         selected_tickers = [pool_eff[i] for i in S]
L451         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L452
L453     # ---- é¸å®šï¼ˆã‚¹ã‚³ã‚¢ Series / returns ã ã‘ã‚’å—ã‘ã‚‹ï¼‰----
L454 # === Outputï¼šå‡ºåŠ›æ•´å½¢ã¨é€ä¿¡ï¼ˆè¡¨ç¤ºãƒ»Slackï¼‰ ===
L455 class Output:
L456
L457     def __init__(self, debug=False):
L458         self.debug = debug
L459         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = self.debug_table = None
L460         self.g_title = self.d_title = ""
L461         self.g_formatters = self.d_formatters = {}
L462         # ä½ã‚¹ã‚³ã‚¢ï¼ˆGSC+DSCï¼‰Top10 è¡¨ç¤º/é€ä¿¡ç”¨
L463         self.low10_table = None
L464
L465     # --- è¡¨ç¤ºï¼ˆå…ƒ display_results ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L466     def display_results(self, *, exist, bench, df_z, g_score, d_score_all,
L467                         init_G, init_D, top_G, top_D, **kwargs):
L468         pd.set_option('display.float_format','{:.3f}'.format)
L469         print("ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ")
L470         if self.miss_df is not None and not self.miss_df.empty:
L471             print("Missing Data:")
L472             print(self.miss_df.to_string(index=False))
L473
L474         # ---- è¡¨ç¤ºç”¨ï¼šChanges/Near-Miss ã®ã‚¹ã‚³ã‚¢æºã‚’â€œæœ€çµ‚é›†è¨ˆâ€ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚· ----
L475         try:
L476             sc = getattr(self, "_sc", None)
L477             agg_G = getattr(sc, "_agg_G", None)
L478             agg_D = getattr(sc, "_agg_D", None)
L479         except Exception:
L480             sc = agg_G = agg_D = None
L481         class _SeriesProxy:
L482             __slots__ = ("primary", "fallback")
L483             def __init__(self, primary, fallback): self.primary, self.fallback = primary, fallback
L484             def get(self, key, default=None):
L485                 try:
L486                     v = self.primary.get(key) if hasattr(self.primary, "get") else None
L487                     if v is not None and not (isinstance(v, float) and v != v):
L488                         return v
L489                 except Exception:
L490                     pass
L491                 try:
L492                     return self.fallback.get(key) if hasattr(self.fallback, "get") else default
L493                 except Exception:
L494                     return default
L495         g_score = _SeriesProxy(agg_G, g_score)
L496         d_score_all = _SeriesProxy(agg_D, d_score_all)
L497         near_G = getattr(sc, "_near_G", []) if sc else []
L498         near_D = getattr(sc, "_near_D", []) if sc else []
L499
L500         extra_G = [t for t in init_G if t not in top_G][:5]; G_UNI = top_G + extra_G
L501         gsc_series = pd.Series({t: g_score.get(t) for t in G_UNI}, name='GSC')
L502         self.g_table = pd.concat([df_z.loc[G_UNI,['GRW','MOM','TRD','VOL']], gsc_series], axis=1)
L503         self.g_table.index = [t + ("â­ï¸" if t in top_G else "") for t in G_UNI]
L504         self.g_formatters = {col:"{:.2f}".format for col in ['GRW','MOM','TRD','VOL']}; self.g_formatters['GSC'] = "{:.3f}".format
L505         self.g_title = (f"[Gæ  / {N_G} / {_fmt_w(g_weights)} / corrM={corrM} / "
L506                         f"LB={DRRS_G['lookback']} nPC={DRRS_G['n_pc']} Î³={DRRS_G['gamma']} Î»={DRRS_G['lam']} Î·={DRRS_G['eta']} shrink={DRRS_SHRINK}]")
L507         if near_G:
L508             add = [t for t in near_G if t not in set(G_UNI)][:10]
L509             if len(add) < 10:
L510                 try:
L511                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L512                     out_now = sorted(set(exist) - set(top_G + top_D))  # ä»Šå› OUT
L513                     used = set(G_UNI + add)
L514                     def _push(lst):
L515                         nonlocal add, used
L516                         for t in lst:
L517                             if len(add) == 10: break
L518                             if t in aggG.index and t not in used:
L519                                 add.append(t); used.add(t)
L520                     _push(out_now)           # â‘  ä»Šå› OUT ã‚’å„ªå…ˆ
L521                     _push(list(aggG.index))  # â‘¡ ã¾ã è¶³ã‚Šãªã‘ã‚Œã°ä¸Šä½ã§å……å¡«
L522                 except Exception:
L523                     pass
L524             if add:
L525                 near_tbl = pd.concat([df_z.loc[add,['GRW','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L526                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L527         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L528
L529         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L530         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L531         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L532         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L533         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L534         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L535         import scorer
L536         dw_eff = scorer.D_WEIGHTS_EFF
L537         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L538                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L539         if near_D:
L540             add = [t for t in near_D if t not in set(D_UNI)][:10]
L541             if add:
L542                 d_disp2 = pd.DataFrame(index=add)
L543                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L544                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L545                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L546         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L547
L548         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L549         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L550         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L551
L552         self.io_table = pd.DataFrame({
L553             'IN': pd.Series(in_list),
L554             '/ OUT': pd.Series(out_list)
L555         })
L556         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L557         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L558         self.io_table['GSC'] = pd.Series(g_list)
L559         self.io_table['DSC'] = pd.Series(d_list)
L560
L561         print("Changes:")
L562         print(self.io_table.to_string(index=False))
L563
L564         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L565         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L566         for name,ticks in portfolios.items():
L567             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L568             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L569             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L570             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L571             if len(ticks)>=2:
L572                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L573                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L574                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L575             else: RAW_rho = RESID_rho = np.nan
L576             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L577         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L578         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L579         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L580         def _fmt_row(s):
L581             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L582         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L583         if self.debug:
L584             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L585             print("Debug Data:"); print(self.debug_table.to_string())
L586
L587         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L588         try:
L589             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L590             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L591             all_scores = all_scores.dropna(subset=['G_plus_D'])
L592             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L593             print("Low Score Candidates (GSC+DSC bottom 10):")
L594             print(self.low10_table.to_string())
L595         except Exception as e:
L596             print(f"[warn] low-score ranking failed: {e}")
L597             self.low10_table = None
L598
L599     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L600     def notify_slack(self):
L601         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L602         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L603         def _filter_suffix_from(spec: dict, group: str) -> str:
L604             g = spec.get(group, {})
L605             parts = [str(m) for m in g.get("pre_mask", [])]
L606             for k, v in (g.get("pre_filter", {}) or {}).items():
L607                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L608                 name = {"beta": "Î²"}.get(base, base)
L609                 try: val = f"{float(v):g}"
L610                 except: val = str(v)
L611                 parts.append(f"{name}{op}{val}")
L612             return "" if not parts else " / filter:" + " & ".join(parts)
L613         def _inject_filter_suffix(title: str, group: str) -> str:
L614             suf = _filter_suffix_from(FILTER_SPEC, group)
L615             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L616         def _blk(title, tbl, fmt=None, drop=()):
L617             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(é¸å®šãªã—)\n"
L618             if drop and hasattr(tbl,'columns'):
L619                 keep = [c for c in tbl.columns if c not in drop]
L620                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L621             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L622
L623         g_title = _inject_filter_suffix(self.g_title, "G")
L624         d_title = _inject_filter_suffix(self.d_title, "D")
L625         message  = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L626         if self.miss_df is not None and not self.miss_df.empty:
L627             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L628         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L629         message += _blk(d_title, self.d_table, self.d_formatters)
L630         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L631         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L632         if self.debug and self.debug_table is not None:
L633             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L634         payload = {"text": message}
L635         try:
L636             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L637         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L638
L639 def _infer_g_universe(feature_df, selected12=None, near5=None):
L640     try:
L641         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L642         if out: return out
L643     except Exception:
L644         pass
L645     base = set()
L646     for lst in (selected12 or []), (near5 or []):
L647         for x in (lst or []): base.add(x)
L648     return list(base) if base else list(feature_df.index)
L649
L650 def _fmt_with_fire_mark(tickers, feature_df):
L651     out = []
L652     for t in tickers or []:
L653         try:
L654             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L655             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L656             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L657         except Exception:
L658             out.append(t)
L659     return out
L660
L661 def _label_recent_event(t, feature_df):
L662     try:
L663         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L664         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L665         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L666         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L667         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L668     except Exception:
L669         pass
L670     return t
L671
L672 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L673
L674 def io_build_input_bundle() -> InputBundle:
L675     """
L676     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L677     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L678     """
L679     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L680     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L681
L682 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L683               n_target: int) -> tuple[list, float, float, float]:
L684     """
L685     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L686     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L687     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L688     """
L689     sc.cfg = cfg
L690
L691     if hasattr(sc, "score_build_features"):
L692         feat = sc.score_build_features(inb)
L693         if not hasattr(sc, "_feat_logged"):
L694             T.log("features built (scorer)")
L695             sc._feat_logged = True
L696         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L697     else:
L698         fb = sc.aggregate_scores(inb, cfg)
L699         if not hasattr(sc, "_feat_logged"):
L700             T.log("features built (scorer)")
L701             sc._feat_logged = True
L702         sc._feat = fb
L703         agg = fb.g_score if group == "G" else fb.d_score_all
L704         if group == "D" and hasattr(fb, "df"):
L705             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L706
L707     if hasattr(sc, "filter_candidates"):
L708         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L709
L710     selector = Selector()
L711     if hasattr(sc, "select_diversified"):
L712         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L713             selector=selector, prev_tickers=None,
L714             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L715             cross_mu=cfg.drrs.cross_mu_gd)
L716     else:
L717         if group == "G":
L718             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L719             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L720                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L721                 lam=cfg.drrs.G.get("lam", 0.68),
L722                 lookback=cfg.drrs.G.get("lookback", 252),
L723                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L724         else:
L725             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L726             g_fixed = getattr(sc, "_top_G", None)
L727             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L728                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L729                 lam=cfg.drrs.D.get("lam", 0.85),
L730                 lookback=cfg.drrs.D.get("lookback", 504),
L731                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L732                 mu=cfg.drrs.cross_mu_gd)
L733         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L734         sum_sc = res["sum_score"]; obj = res["objective"]
L735         if group == "D":
L736             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L737             T.log("selection finalized (G/D)")
L738     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L739     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L740     try:
L741         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L742         near10 = list(pool.sort_values(ascending=False).head(10).index)
L743         setattr(sc, f"_near_{group}", near10)
L744         setattr(sc, f"_agg_{group}", agg)
L745     except Exception:
L746         pass
L747
L748     if group == "D":
L749         T.log("save done")
L750     if group == "G":
L751         sc._top_G = pick
L752     return pick, avg_r, sum_sc, obj
L753
L754 def run_pipeline() -> SelectionBundle:
L755     """
L756     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L757     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L758     """
L759     inb = io_build_input_bundle()
L760     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L761         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L762                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L763         price_max=CAND_PRICE_MAX)
L764     sc = Scorer()
L765     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L766     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L767     alpha = Scorer.spx_to_alpha(inb.spx)
L768     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L769     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L770     sc._top_G = top_G
L771     try:
L772         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L773         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L774     except Exception:
L775         pass
L776     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L777     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L778     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L779     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L780     fb = getattr(sc, "_feat", None)
L781     near_G = getattr(sc, "_near_G", [])
L782     selected12 = list(top_G)
L783     df = fb.df if fb is not None else pd.DataFrame()
L784     guni = _infer_g_universe(df, selected12, near_G)
L785     try:
L786         fire_recent = [t for t in guni
L787                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L788                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L789     except Exception: fire_recent = []
L790
L791     lines = [
L792         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L793         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L794         f"é¸å®š12: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else "é¸å®š12: ãªã—",
L795         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L796
L797     if fire_recent:
L798         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L799         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L800     else:
L801         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L802
L803     try:
L804         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L805         if webhook:
L806             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L807     except Exception:
L808         pass
L809
L810     out = Output(debug=debug_mode)
L811     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L812     try: out._sc = sc
L813     except Exception: pass
L814     if hasattr(sc, "_feat"):
L815         try:
L816             out.miss_df = sc._feat.missing_logs
L817             out.display_results(exist=exist, bench=bench, df_z=sc._feat.df_z,
L818                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L819                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D)
L820         except Exception:
L821             pass
L822     out.notify_slack()
L823     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L824               "sum_score": sumG, "objective": objG},
L825         resD={"tickers": top_D, "avg_res_corr": avgD,
L826               "sum_score": sumD, "objective": objD},
L827         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L828
L829     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L830     try:
L831         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L832               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L833               .sort_values("G_plus_D")
L834               .head(10)
L835               .round(3))
L836         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L837                "```"
L838                + _low_df.to_string(index=True, index_names=False)
L839                + "\n```")
L840     except Exception as _e:
L841         _slack(f"Low Score Candidates: ä½œæˆå¤±æ•—: {_e}")
L842
L843     if debug_mode:
L844         try:
L845             _slack_debug(_compact_debug(fb, sb, [], []))
L846         except Exception as e:
L847             print(f"[debug skipped] {e}")
L848
L849     return sb
L850
L851 if __name__ == "__main__":
L852     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None: return float(c)
L43     try:
L44         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L45         return float(h.iloc[-1]) if len(h) else np.nan
L46     except Exception:
L47         return np.nan
L48
L49 def _ttm_div_sum(t, lookback_days=400):
L50     try:
L51         div = yf.Ticker(t).dividends
L52         if div is None or len(div) == 0: return 0.0
L53         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L54         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L55         return ttm if ttm > 0 else float(div.tail(4).sum())
L56     except Exception:
L57         return 0.0
L58
L59 def ttm_div_yield_portfolio(tickers, price_map=None):
L60     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L61     return float(np.mean(ys)) if ys else 0.0
L62
L63 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L64 def winsorize_s(s: pd.Series, p=0.02):
L65     if s is None or s.dropna().empty: return s
L66     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L67
L68 def robust_z(s: pd.Series, p=0.02):
L69     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L70
L71 def _safe_div(a, b):
L72     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L73     except Exception: return np.nan
L74
L75 def _safe_last(series: pd.Series, default=np.nan):
L76     try: return float(series.iloc[-1])
L77     except Exception: return default
L78
L79 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L80
L81 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L82 class Scorer:
L83     """
L84     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L85     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L86     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L87     """
L88
L89     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L90     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L91     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L92
L93     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L94     @staticmethod
L95     def _validate_ib_for_scorer(ib: Any):
L96         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L97         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L98         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L99         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L100         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L101         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L102         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L103
L104     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L105     @staticmethod
L106     def trend(s: pd.Series):
L107         if len(s)<200: return np.nan
L108         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L109         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L110         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L111         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L112         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L113         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L114         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L115         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L116         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L117         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L118         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L119         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L120
L121     @staticmethod
L122     def rs(s, b):
L123         n, nb = len(s), len(b)
L124         if n<60 or nb<60: return np.nan
L125         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L126         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L127         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L128
L129     @staticmethod
L130     def tr_str(s):
L131         if len(s)<50: return np.nan
L132         return s.iloc[-1]/s.rolling(50).mean().iloc[-1] - 1
L133
L134     @staticmethod
L135     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L136         r = (s/b).dropna()
L137         if len(r) < win: return np.nan
L138         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L139         try: return float(np.polyfit(x, y, 1)[0])
L140         except Exception: return np.nan
L141
L142     @staticmethod
L143     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L144         ev = info_t.get('enterpriseValue', np.nan)
L145         if pd.notna(ev) and ev>0: return float(ev)
L146         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L147         try:
L148             bs = tk.quarterly_balance_sheet
L149             if bs is not None and not bs.empty:
L150                 c = bs.columns[0]
L151                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L152                     if k in bs.index: debt = float(bs.loc[k,c]); break
L153                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L154                     if k in bs.index: cash = float(bs.loc[k,c]); break
L155         except Exception: pass
L156         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L157         return np.nan
L158
L159     @staticmethod
L160     def dividend_status(ticker: str) -> str:
L161         t = yf.Ticker(ticker)
L162         try:
L163             if not t.dividends.empty: return "has"
L164         except Exception: return "unknown"
L165         try:
L166             a = t.actions
L167             if (a is not None and not a.empty and "Stock Splits" in a.columns and a["Stock Splits"].abs().sum()>0): return "none_confident"
L168         except Exception: pass
L169         try:
L170             fi = t.fast_info
L171             if any(getattr(fi,k,None) for k in ("last_dividend_date","dividend_rate","dividend_yield")): return "maybe_missing"
L172         except Exception: pass
L173         return "unknown"
L174
L175     @staticmethod
L176     def div_streak(t):
L177         try:
L178             divs = yf.Ticker(t).dividends.dropna(); ann = divs.groupby(divs.index.year).sum(); ann = ann[ann.index<pd.Timestamp.today().year]
L179             years, streak = sorted(ann.index), 0
L180             for i in range(len(years)-1,0,-1):
L181                 if ann[years[i]] > ann[years[i-1]]: streak += 1
L182                 else: break
L183             return streak
L184         except Exception: return 0
L185
L186     @staticmethod
L187     def fetch_finnhub_metrics(symbol):
L188         api_key = os.environ.get("FINNHUB_API_KEY")
L189         if not api_key: return {}
L190         url, params = "https://finnhub.io/api/v1/stock/metric", {"symbol":symbol,"metric":"all","token":api_key}
L191         try:
L192             r = requests.get(url, params=params, timeout=10); r.raise_for_status(); m = r.json().get("metric",{})
L193             return {'EPS':m.get('epsGrowthTTMYoy'),'REV':m.get('revenueGrowthTTMYoy'),'ROE':m.get('roeTTM'),'BETA':m.get('beta'),'DIV':m.get('dividendYieldIndicatedAnnual'),'FCF':(m.get('freeCashFlowTTM')/m.get('enterpriseValue')) if m.get('freeCashFlowTTM') and m.get('enterpriseValue') else None}
L194         except Exception: return {}
L195
L196     @staticmethod
L197     def calc_beta(series: pd.Series, market: pd.Series, lookback=252):
L198         r, m = series.pct_change().dropna(), market.pct_change().dropna()
L199         n = min(len(r), len(m), lookback)
L200         if n<60: return np.nan
L201         r, m = r.iloc[-n:], m.iloc[-n:]; cov, var = np.cov(r, m)[0,1], np.var(m)
L202         return np.nan if var==0 else cov/var
L203
L204     @staticmethod
L205     def spx_to_alpha(spx: pd.Series, bands=(0.03,0.10), w=(0.6,0.4),
L206                      span=5, q=(0.20,0.40), alphas=(0.05,0.08,0.10)) -> float:
L207         """
L208         S&P500æŒ‡æ•°ã®ã¿ã‹ã‚‰æ“¬ä¼¼breadthã‚’ä½œã‚Šã€å±¥æ­´åˆ†ä½ã§Î±ã‚’æ®µéšæ±ºå®šã€‚
L209         bands=(Â±3%, Â±10%), w=(50DMA,200DMA), åˆ†ä½q=(20%,40%), alphas=(ä½,ä¸­,é«˜)
L210         """
L211         ma50, ma200 = spx.rolling(50).mean(), spx.rolling(200).mean()
L212         b50, b200 = ((spx/ma50 - 1)+bands[0])/(2*bands[0]), ((spx/ma200 - 1)+bands[1])/(2*bands[1])
L213         hist = (w[0]*b50 + w[1]*b200).clip(0,1).ewm(span=span).mean()
L214         b, (lo, mid) = float(hist.iloc[-1]), (float(hist.quantile(q[0])), float(hist.quantile(q[1])))
L215         return alphas[0] if b < lo else alphas[1] if b < mid else alphas[2]
L216
L217     @staticmethod
L218     def soft_cap_effective_scores(scores: pd.Series|dict, sectors: dict, cap=2, alpha=0.08) -> pd.Series:
L219         """
L220         åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼capè¶…éï¼ˆ3æœ¬ç›®ä»¥é™ï¼‰ã« Î±Ã—æ®µéšæ¸›ç‚¹ã‚’èª²ã—ãŸâ€œæœ‰åŠ¹ã‚¹ã‚³ã‚¢â€Seriesã‚’è¿”ã™ã€‚
L221         æˆ»ã‚Šå€¤ã¯é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã€‚
L222         """
L223         s = pd.Series(scores, dtype=float); order = s.sort_values(ascending=False).index
L224         cnt, pen = {}, {}
L225         for t in order:
L226             sec = sectors.get(t, "U"); cnt[sec] = cnt.get(sec,0) + 1; pen[t] = alpha*max(0, cnt[sec]-cap)
L227         return (s - pd.Series(pen)).sort_values(ascending=False)
L228
L229     @staticmethod
L230     def pick_top_softcap(scores: pd.Series|dict, sectors: dict, N: int, cap=2, alpha=0.08, hard: int|None=5) -> list[str]:
L231         """
L232         soft-capé©ç”¨å¾Œã®ä¸Šä½Nãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚hard>0ãªã‚‰éå¸¸ç”¨ãƒãƒ¼ãƒ‰ä¸Šé™ã§åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼è¶…éã‚’é–“å¼•ãï¼ˆæ—¢å®š=5ï¼‰ã€‚
L233         """
L234         eff = Scorer.soft_cap_effective_scores(scores, sectors, cap, alpha)
L235         if not hard:
L236             return list(eff.head(N).index)
L237         pick, used = [], {}
L238         for t in eff.index:
L239             s = sectors.get(t, "U")
L240             if used.get(s,0) < hard:
L241                 pick.append(t); used[s] = used.get(s,0) + 1
L242             if len(pick) == N: break
L243         return pick
L244
L245     @staticmethod
L246     def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L247         """
L248         å„å–¶æ¥­æ—¥ã® trend_template åˆæ ¼æœ¬æ•°ï¼ˆåˆæ ¼â€œæœ¬æ•°â€=Cï¼‰ã‚’è¿”ã™ã€‚
L249         - px: åˆ—=tickerï¼ˆãƒ™ãƒ³ãƒã¯å«ã‚ãªã„ï¼‰
L250         - spx: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Seriesï¼ˆpx.index ã«æ•´åˆ—ï¼‰
L251         - win_days: æœ«å°¾ã®è¨ˆç®—å¯¾è±¡å–¶æ¥­æ—¥æ•°ï¼ˆNoneâ†’å…¨ä½“ã€æ—¢å®š600ã¯å‘¼ã³å‡ºã—å´æŒ‡å®šï¼‰
L252         ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼†rollingã®ã¿ã§è»½é‡ã€‚æ¬ æã¯ False æ‰±ã„ã€‚
L253         """
L254         import numpy as np, pandas as pd
L255         if px is None or px.empty:
L256             return pd.Series(dtype=int)
L257         px = px.dropna(how="all", axis=1)
L258         if win_days and win_days > 0:
L259             px = px.tail(win_days)
L260         if px.empty:
L261             return pd.Series(dtype=int)
L262         spx = spx.reindex(px.index).ffill()
L263
L264         ma50  = px.rolling(50).mean()
L265         ma150 = px.rolling(150).mean()
L266         ma200 = px.rolling(200).mean()
L267
L268         tt = (px > ma150)
L269         tt &= (px > ma200)
L270         tt &= (ma150 > ma200)
L271         tt &= (ma200 - ma200.shift(21) > 0)
L272         tt &= (ma50  > ma150)
L273         tt &= (ma50  > ma200)
L274         tt &= (px    > ma50)
L275
L276         lo252 = px.rolling(252).min()
L277         hi252 = px.rolling(252).max()
L278         tt &= (px.divide(lo252).sub(1.0) >= 0.30)   # P_OVER_LOW52 >= 0.30
L279         tt &= (px >= (0.75 * hi252))                # NEAR_52W_HIGH >= -0.25
L280
L281         r12  = px.divide(px.shift(252)).sub(1.0)
L282         br12 = spx.divide(spx.shift(252)).sub(1.0)
L283         r1   = px.divide(px.shift(22)).sub(1.0)
L284         br1  = spx.divide(spx.shift(22)).sub(1.0)
L285         rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L286         tt &= (rs >= 0.10)
L287
L288         return tt.fillna(False).sum(axis=1).astype(int)
L289
L290     # ---- ã‚¹ã‚³ã‚¢é›†è¨ˆï¼ˆDTO/Configã‚’å—ã‘å–ã‚Šã€FeatureBundleã‚’è¿”ã™ï¼‰ ----
L291     def aggregate_scores(self, ib: Any, cfg):
L292         if cfg is None:
L293             raise ValueError("cfg is required; pass factor.PipelineConfig")
L294         self._validate_ib_for_scorer(ib)
L295
L296         px, spx, tickers = ib.px, ib.spx, ib.tickers
L297         tickers_bulk, info, eps_df, fcf_df = ib.tickers_bulk, ib.info, ib.eps_df, ib.fcf_df
L298
L299         df, missing_logs = pd.DataFrame(index=tickers), []
L300         for t in tickers:
L301             d, s = info[t], px[t]; ev = self.ev_fallback(d, tickers_bulk.tickers[t])
L302             # --- åŸºæœ¬ç‰¹å¾´ ---
L303             df.loc[t,'TR']   = self.trend(s)
L304             df.loc[t,'EPS']  = eps_df.loc[t,'EPS_TTM'] if t in eps_df.index else np.nan
L305             df.loc[t,'REV']  = d.get('revenueGrowth',np.nan)
L306             df.loc[t,'ROE']  = d.get('returnOnEquity',np.nan)
L307             df.loc[t,'BETA'] = self.calc_beta(s, spx, lookback=252)
L308
L309             # --- é…å½“ï¼ˆæ¬ æè£œå®Œå«ã‚€ï¼‰ ---
L310             div = d.get('dividendYield') if d.get('dividendYield') is not None else d.get('trailingAnnualDividendYield')
L311             if div is None or pd.isna(div):
L312                 try:
L313                     divs = yf.Ticker(t).dividends
L314                     if divs is not None and not divs.empty:
L315                         last_close = s.iloc[-1]; div_1y = divs[divs.index >= (divs.index.max() - pd.Timedelta(days=365))].sum()
L316                         if last_close and last_close>0: div = float(div_1y/last_close)
L317                 except Exception: pass
L318             df.loc[t,'DIV'] = 0.0 if (div is None or pd.isna(div)) else float(div)
L319
L320             # --- FCF/EV ---
L321             fcf_val = fcf_df.loc[t,'FCF_TTM'] if t in fcf_df.index else np.nan
L322             df.loc[t,'FCF'] = (fcf_val/ev) if (pd.notna(fcf_val) and pd.notna(ev) and ev>0) else np.nan
L323
L324             # --- ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ»ãƒœãƒ©é–¢é€£ ---
L325             df.loc[t,'RS'], df.loc[t,'TR_str'] = self.rs(s, spx), self.tr_str(s)
L326             r, rm = s.pct_change().dropna(), spx.pct_change().dropna()
L327             n = int(min(len(r), len(rm)))
L328
L329             DOWNSIDE_DEV = np.nan
L330             if n>=60:
L331                 r6 = r.iloc[-min(len(r),126):]; neg = r6[r6<0]
L332                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L333             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L334
L335             MDD_1Y = np.nan
L336             try:
L337                 w = s.iloc[-min(len(s),252):].dropna()
L338                 if len(w)>=30:
L339                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L340             except Exception: pass
L341             df.loc[t,'MDD_1Y'] = MDD_1Y
L342
L343             RESID_VOL = np.nan
L344             if n>=120:
L345                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L346                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L347                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L348                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L349             df.loc[t,'RESID_VOL'] = RESID_VOL
L350
L351             DOWN_OUTPERF = np.nan
L352             if n>=60:
L353                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L354                 if mask.sum()>=10:
L355                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L356                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L357             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L358
L359             # --- é•·æœŸç§»å‹•å¹³å‡/ä½ç½® ---
L360             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L361             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L362
L363             # --- é…å½“ã®è©³ç´°ç³» ---
L364             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L365             try:
L366                 divs = yf.Ticker(t).dividends.dropna()
L367                 if not divs.empty:
L368                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L369                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L370                     ann = divs.groupby(divs.index.year).sum()
L371                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L372                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L373                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L374                 so = d.get('sharesOutstanding',None)
L375                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L376                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L377             except Exception: pass
L378             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L379
L380             # --- è²¡å‹™å®‰å®šæ€§ ---
L381             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L382
L383             # --- EPS å¤‰å‹• ---
L384             EPS_VAR_8Q = np.nan
L385             try:
L386                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L387                 if qe is not None and not qe.empty and so:
L388                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L389                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L390             except Exception: pass
L391             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L392
L393             # --- ã‚µã‚¤ã‚º/æµå‹•æ€§ ---
L394             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L395             try:
L396                 vol_series = ib.data['Volume'][t].dropna()
L397                 if len(vol_series)>=5 and len(s)==len(vol_series):
L398                     dv = (vol_series*s).rolling(60).mean(); adv60 = float(dv.iloc[-1])
L399             except Exception: pass
L400             df.loc[t,'ADV60_USD'] = adv60
L401
L402             # --- å£²ä¸Š/åˆ©ç›Šã®åŠ é€Ÿåº¦ç­‰ ---
L403             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L404             REV_ANNUAL_STREAK = np.nan
L405             try:
L406                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L407                 if qe is not None and not qe.empty:
L408                     if 'Revenue' in qe.columns:
L409                         rev = qe['Revenue'].dropna().astype(float)
L410                         if len(rev)>=5: REV_Q_YOY = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5])
L411                         if len(rev)>=6:
L412                             yoy_now = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5]); yoy_prev = _safe_div(rev.iloc[-2]-rev.iloc[-6], rev.iloc[-6])
L413                             if pd.notna(yoy_now) and pd.notna(yoy_prev): REV_YOY_ACC = yoy_now - yoy_prev
L414                         yoy_list=[]
L415                         for k in range(1,5):
L416                             if len(rev)>=4+k:
L417                                 y = _safe_div(rev.iloc[-k]-rev.iloc[-(k+4)], rev.iloc[-(k+4)])
L418                                 if pd.notna(y): yoy_list.append(y)
L419                         if len(yoy_list)>=2: REV_YOY_VAR = float(np.std(yoy_list, ddof=1))
L420                         # NEW: å¹´æ¬¡ã®æŒç¶šæ€§ï¼ˆç›´è¿‘ã‹ã‚‰é¡ã£ã¦å‰å¹´æ¯”ãƒ—ãƒ©ã‚¹ãŒä½•å¹´é€£ç¶šã‹ã€å››åŠæœŸ4æœ¬æƒã†å®Œå…¨å¹´ã®ã¿ï¼‰
L421                         try:
L422                             g = rev.groupby(rev.index.year)
L423                             ann_sum, cnt = g.sum(), g.count()
L424                             ann_sum = ann_sum[cnt >= 4]
L425                             if len(ann_sum) >= 3:
L426                                 yoy = ann_sum.pct_change().dropna()
L427                                 streak = 0
L428                                 for v in yoy.iloc[::-1]:
L429                                     if pd.isna(v) or v <= 0:
L430                                         break
L431                                     streak += 1
L432                                 REV_ANNUAL_STREAK = float(streak)
L433                         except Exception:
L434                             pass
L435                     if 'Earnings' in qe.columns and so:
L436                         eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L437                         if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L438                             EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L439             except Exception: pass
L440             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'], df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_Q_YOY, EPS_Q_YOY, REV_YOY_ACC, REV_YOY_VAR
L441             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L442
L443             # --- Rule of 40 ã‚„å‘¨è¾º ---
L444             total_rev_ttm = d.get('totalRevenue',np.nan)
L445             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L446             df.loc[t,'FCF_MGN'] = FCF_MGN
L447             rule40 = np.nan
L448             try:
L449                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L450             except Exception: pass
L451             df.loc[t,'RULE40'] = rule40
L452
L453             # --- ãƒˆãƒ¬ãƒ³ãƒ‰è£œåŠ© ---
L454             sma50  = s.rolling(50).mean()
L455             sma150 = s.rolling(150).mean()
L456             sma200 = s.rolling(200).mean()
L457             p = _safe_last(s)
L458
L459             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L460                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L461             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L462                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L463
L464             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L465             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L466
L467             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L468             if len(sma200.dropna()) >= 21:
L469                 cur200 = _safe_last(sma200)
L470                 old2001 = float(sma200.iloc[-21])
L471                 if old2001:
L472                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L473
L474             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L475             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L476             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L477             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L478             if len(sma200.dropna())>=105:
L479                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L480                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L481             # NEW: 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ãã®ã€Œæ—¥æ•°ã€
L482             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L483             try:
L484                 s200 = sma200.dropna()
L485                 if len(s200) >= 2:
L486                     diff200 = s200.diff()
L487                     up = 0
L488                     for v in diff200.iloc[::-1]:
L489                         if pd.isna(v) or v <= 0:
L490                             break
L491                         up += 1
L492                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L493             except Exception:
L494                 pass
L495             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L496             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L497             if hi52 and hi52>0 and pd.notna(p):
L498                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L499             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L500             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L501
L502             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L503
L504             # --- æ¬ æãƒ¡ãƒ¢ ---
L505             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L506             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L507             if need_finnhub:
L508                 fin_data = self.fetch_finnhub_metrics(t)
L509                 for col in need_finnhub:
L510                     val = fin_data.get(col)
L511                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L512             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L513                 if pd.isna(df.loc[t,col]):
L514                     if col=='DIV':
L515                         status = self.dividend_status(t)
L516                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L517                     else:
L518                         missing_logs.append({'Ticker':t,'Column':col})
L519
L520         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L521             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L522             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L523             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L524             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L525             c5 = (row.get('TR_str', np.nan) > 0)
L526             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L527             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L528             c8 = (row.get('RS', np.nan) >= 0.10)
L529             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L530
L531         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L532         assert 'trend_template' in df.columns
L533
L534         # === ZåŒ–ã¨åˆæˆ ===
L535         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L536
L537         df_z = pd.DataFrame(index=df.index)
L538         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L539         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L540         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L541         for col in ['REV_Q_YOY','EPS_Q_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']: df_z[col] = robust_z(df[col])
L542         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L543
L544         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L545         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L546         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L547         df_z['GROWTH_F']  = robust_z(0.25*df_z['REV']          # â†“0.30â†’0.25
L548             + 0.20*df_z['EPS_Q_YOY']
L549             + 0.15*df_z['REV_Q_YOY']
L550             + 0.15*df_z['REV_YOY_ACC']
L551             + 0.10*df_z['RULE40']
L552             + 0.10*df_z['FCF_MGN']
L553             + 0.10*df_z['EPS']          # â˜…è¿½åŠ ï¼šé»’å­—å„ªé‡ï¼èµ¤å­—æ¸›ç‚¹
L554             + 0.05*df_z['REV_ANN_STREAK']
L555             - 0.05*df_z['REV_YOY_VAR']).clip(-3.0,3.0)
L556         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L557             + 0.15*df_z['TR_str']
L558             + 0.15*df_z['RS_SLOPE_6W']
L559             + 0.15*df_z['RS_SLOPE_13W']
L560             + 0.10*df_z['MA200_SLOPE_5M']
L561             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L562         df_z['VOL'] = robust_z(df['BETA'])
L563         df_z.rename(columns={'GROWTH_F':'GRW','MOM_F':'MOM','QUALITY_F':'QAL','YIELD_F':'YLD'}, inplace=True)
L564
L565         # === begin: BIO LOSS PENALTY =====================================
L566         try:
L567             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L568         except Exception:
L569             penalty_z = 0.8
L570
L571         def _is_bio_like(t: str) -> bool:
L572             inf = info.get(t, {}) if isinstance(info, dict) else {}
L573             sec = str(inf.get("sector", "")).lower()
L574             ind = str(inf.get("industry", "")).lower()
L575             if "health" not in sec:
L576                 return False
L577             keys = ("biotech", "biopharma", "pharma")
L578             return any(k in ind for k in keys)
L579
L580         tickers_s = pd.Index(df_z.index)
L581         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L582         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L583         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L584
L585         if bool(mask_bio_loss.any()) and penalty_z > 0:
L586             df_z.loc[mask_bio_loss, "GRW"] = df_z.loc[mask_bio_loss, "GRW"] - penalty_z
L587             df_z["GRW"] = df_z["GRW"].clip(-3.0, 3.0)
L588         # === end: BIO LOSS PENALTY =======================================
L589
L590         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L591         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L592
L593         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L594         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L595         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L596         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L597
L598         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L599         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L600         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L601
L602         d_comp = pd.concat({
L603             'QAL': df_z['D_QAL'],
L604             'YLD': df_z['D_YLD'],
L605             'VOL': df_z['D_VOL_RAW'],
L606             'TRD': df_z['D_TRD']
L607         }, axis=1)
L608         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L609         globals()['D_WEIGHTS_EFF'] = dw.copy()
L610         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L611
L612         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L613         mask = df['trend_template']
L614         if not bool(mask.any()):
L615             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L616                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L617                 (df.get('RS', np.nan) >= 0.08) &
L618                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L619                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L620                 (df.get('MA150_OVER_200', np.nan) > 0) &
L621                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L622                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L623             df['trend_template'] = mask
L624
L625         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L626         g_score = g_score_all.loc[mask]
L627         Scorer.g_score = g_score
L628         df_z['GSC'] = g_score_all
L629         df_z['DSC'] = d_score_all
L630
L631         try:
L632             current = (pd.read_csv("current_tickers.csv")
L633                   .iloc[:, 0]
L634                   .str.upper()
L635                   .tolist())
L636         except FileNotFoundError:
L637             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L638             current = []
L639
L640         mask_bonus = g_score.index.isin(current)
L641         if mask_bonus.any():
L642             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L643             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L644             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L645             sigma_g = g_score.std()
L646             if pd.isna(sigma_g):
L647                 sigma_g = 0.0
L648             bonus_g = round(k * sigma_g, 3)
L649             g_score.loc[mask_bonus] += bonus_g
L650             Scorer.g_score = g_score
L651             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L652             sigma_d = d_score_all.std()
L653             if pd.isna(sigma_d):
L654                 sigma_d = 0.0
L655             bonus_d = round(k * sigma_d, 3)
L656             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L657
L658         try:
L659             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L660         except Exception:
L661             pass
L662
L663         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L664         return FeatureBundle(df=df,
L665             df_z=df_z,
L666             g_score=g_score,
L667             d_score_all=d_score_all,
L668             missing_logs=pd.DataFrame(missing_logs))
L669
L670 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L671     """
L672     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L673     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L674       - G_BREAKOUT_recent_5d : bool
L675       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L676       - G_PULLBACK_recent_5d : bool
L677       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L678       - G_PIVOT_price        : float
L679     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L680     """
L681     try:
L682         px   = bundle.px                      # çµ‚å€¤ DataFrame
L683         hi   = bundle.data['High']
L684         lo   = bundle.data['Low']
L685         vol  = bundle.data['Volume']
L686         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L687
L688         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L689         g_universe = getattr(self_obj, "g_universe", None)
L690         if g_universe is None:
L691             try:
L692                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L693             except Exception:
L694                 g_universe = list(feature_df.index)
L695         if not g_universe:
L696             return feature_df
L697
L698         # æŒ‡æ¨™
L699         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L700         ma50  = px[g_universe].rolling(50).mean()
L701         ma150 = px[g_universe].rolling(150).mean()
L702         ma200 = px[g_universe].rolling(200).mean()
L703         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L704         vol20 = vol[g_universe].rolling(20).mean()
L705         vol50 = vol[g_universe].rolling(50).mean()
L706
L707         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L708         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L709                             & (ma150 > ma200) & (ma200.diff() > 0)
L710
L711         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L712         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L713
L714         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L715         bench_aligned = bench.reindex(px.index).ffill()
L716         rs = px[g_universe].div(bench_aligned, axis=0)
L717         rs_high = rs.rolling(252).max().shift(1)
L718
L719         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L720         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L721                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L722         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L723
L724         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L725         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L726         volume_dryup = (vol20 / vol50) <= 1.0
L727         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L728         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L729         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L730
L731         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L732         rows = []
L733         for t in g_universe:
L734             def _recent_and_date(s, win):
L735                 sw = s[t].iloc[-win:]
L736                 if sw.any():
L737                     d = sw[sw].index[-1]
L738                     return True, d.strftime("%Y-%m-%d")
L739                 return False, ""
L740             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L741             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L742             rows.append((t, {
L743                 "G_BREAKOUT_recent_5d": br_recent,
L744                 "G_BREAKOUT_last_date": br_date,
L745                 "G_PULLBACK_recent_5d": pb_recent,
L746                 "G_PULLBACK_last_date": pb_date,
L747                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L748             }))
L749         flags = pd.DataFrame({k: v for k, v in rows}).T
L750
L751         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L752         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L753         for c in cols:
L754             if c not in feature_df.columns:
L755                 feature_df[c] = np.nan
L756         feature_df.loc[flags.index, flags.columns] = flags
L757
L758     except Exception:
L759         pass
L760     return feature_df
L761
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v3
L24
L25       - name: Setup Python
L26         uses: actions/setup-python@v5
L27         with:
L28           python-version: '3.x'
L29           cache: 'pip'
L30           cache-dependency-path: requirements.txt
L31
L32       - name: Install dependencies
L33         run: pip install -r requirements.txt
L34
L35       - name: Prepare results directory
L36         run: mkdir -p results
L37
L38       - name: Run factor & scoring
L39         env:
L40           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L41           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L42           FIN_THREADS: "8"
L43         run: python factor.py
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 25éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š4%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6
L7 ## Barbell Growth-Defenseæ–¹é‡
L8 - Growthæ 12éŠ˜æŸ„ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L9 - Defenseæ 13éŠ˜æŸ„ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L10 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L11
L12 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L13 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**
L14 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L15   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L16   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= 1.5Ã—N_Gï¼‰
L17   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L18 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯18æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯36æœ¬ä»¥ä¸Šï¼‰
L19
L20 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L21 - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **10%**
L22 - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23 - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ25Ã—4%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L24
L25 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ï¼ˆçµ±ä¸€ï¼‰
L26 - G/D å…±é€šã® **åŸºæœ¬TS=15%**
L27 - å«ã¿ç›ŠãŒ **+20% / +40% / +60%** åˆ°é”ã§ TS ã‚’ **12% / 9% / 7%** ã«æ®µéšå¼•ãä¸Šã’
L28 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L29
L30 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L31 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L32 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L33
L34 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L35 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L36
L37 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L38 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L39 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/factor_design.md>
```text
L1 # factor.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®éŠ˜æŸ„ã¨æ¤œè¨ä¸­ã®éŠ˜æŸ„ç¾¤ã‚’åŒæ™‚ã«æ‰±ã†éŠ˜æŸ„é¸å®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
L5 - ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨DRRSé¸å®šã‚’è¡Œã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚
L6   - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚æ¼ã‚ŒãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L7   - IN/OUTã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨OUTå´ã®ä½ã‚¹ã‚³ã‚¢éŠ˜æŸ„
L8   - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨
L9   - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ•´ç†ç”¨ï¼‰
L10
L11 ## å…¨ä½“ãƒ•ãƒ­ãƒ¼
L12 1. **Input** â€“ `current_tickers.csv`ã¨`candidate_tickers.csv`ã‚’èª­ã¿è¾¼ã¿ã€yfinanceã‚„Finnhubã®APIã‹ã‚‰ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦`InputBundle`ã‚’æ•´å‚™ã€‚
L13 2. **Score Calculation** â€“ ScorerãŒç‰¹å¾´é‡ã‚’è¨ˆç®—ã—å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã—ã¦`FeatureBundle`ã‚’ç”Ÿæˆã€‚
L14 3. **Correlation Reduction & Selection** â€“ SelectorãŒDRRSãƒ­ã‚¸ãƒƒã‚¯ã§ç›¸é–¢ã‚’æŠ‘ãˆã¤ã¤G/DéŠ˜æŸ„ã‚’é¸å®šã—`SelectionBundle`ã‚’å¾—ã‚‹ã€‚
L15 4. **Output** â€“ æ¡ç”¨çµæœã¨å‘¨è¾ºæƒ…å ±ã‚’è¡¨ãƒ»Slacké€šçŸ¥ã¨ã—ã¦å‡ºåŠ›ã€‚
L16
L17 ```mermaid
L18 flowchart LR
L19   A[Input\nAPI & å‰å‡¦ç†] --> B[Score Calculation\nç‰¹å¾´é‡ãƒ»å› å­åˆæˆ]
L20   B --> C[Correlation Reduction\nDRRSé¸å®š]
L21   C --> D[Output\nSlacké€šçŸ¥]
L22 ```
L23
L24 ## å®šæ•°ãƒ»è¨­å®š
L25 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L26 | --- | --- | --- |
L27 | `exist` / `cand` | ç¾è¡Œãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æ¤œè¨ä¸­éŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ | ã‚¹ã‚³ã‚¢å¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã®æ§‹æˆã€å€™è£œæ•´ç† |
L28 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L29 | `CAND_PRICE_MAX` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | é«˜é¡éŠ˜æŸ„ã®äº‹å‰é™¤å¤– |
L30 | `N_G` / `N_D` | G/Dæ¡ç”¨æ ã®ä»¶æ•° | æœ€çµ‚çš„ã«é¸ã¶éŠ˜æŸ„æ•°ã®åˆ¶ç´„ |
L31 | `g_weights` / `D_weights` | å„å› å­ã®é‡ã¿dict | G/Dã‚¹ã‚³ã‚¢åˆæˆ |
L32 | `D_BETA_MAX` | Dãƒã‚±ãƒƒãƒˆã®è¨±å®¹Î²ä¸Šé™ | é«˜Î²éŠ˜æŸ„ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ |
L33 | `FILTER_SPEC` | G/Dã”ã¨ã®å‰å‡¦ç†ãƒ•ã‚£ãƒ«ã‚¿ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¹ã‚¯ã‚„Î²ä¸Šé™è¨­å®š |
L34 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L35 | `DRRS_G` / `DRRS_D` | DRRSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç›¸é–¢ä½æ¸›è¨­å®š |
L36 | `DRRS_SHRINK` | æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å®‰å®šåŒ– |
L37 | `CROSS_MU_GD` | G-Dé–“ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ | 2ãƒã‚±ãƒƒãƒˆåŒæ™‚æœ€é©åŒ–ã§ç›¸é–¢æŠ‘åˆ¶ |
L38 | `RESULTS_DIR` | é¸å®šçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `_save_sel`/`_load_prev`ã®å…¥å‡ºåŠ› |
L39
L40 é¸å®šçµæœã¯`results/`é…ä¸‹ã«JSONã¨ã—ã¦ä¿å­˜ã—ã€æ¬¡å›å®Ÿè¡Œæ™‚ã«`_load_prev`ã§èª­ã¿è¾¼ã‚“ã§é¸å®šæ¡ä»¶ã«åæ˜ ã€‚
L41
L42 ## DTO/Config
L43 å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨è¨­å®šå€¤ã€‚å¤‰æ•°ã®æ„å‘³åˆã„ã¨åˆ©ç”¨ç®‡æ‰€ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚
L44
L45 ### InputBundleï¼ˆInput â†’ Scorerï¼‰
L46 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L47 | --- | --- | --- |
L48 | `cand` | å€™è£œéŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆ | OUTãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æ¯é›†å›£ |
L49 | `tickers` | ç¾è¡Œ+å€™è£œã‚’åˆã‚ã›ãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ | ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®— |
L50 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L51 | `data` | yfinanceã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœï¼ˆéšå±¤åˆ—ï¼‰ | `px`/`spx`/ãƒªã‚¿ãƒ¼ãƒ³ç­‰ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿ |
L52 | `px` | `data['Close']`ã ã‘ã‚’æŠœãå‡ºã—ãŸä¾¡æ ¼ç³»åˆ— | æŒ‡æ¨™è¨ˆç®—ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ç”Ÿæˆ |
L53 | `spx` | `data['Close'][bench]` ã®Series | `rs`ã‚„`calc_beta`ã®åŸºæº–æŒ‡æ•° |
L54 | `tickers_bulk` | `yf.Tickers`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | `info`ç­‰ã®ä¸€æ‹¬å–å¾— |
L55 | `info` | ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã®yfinanceæƒ…å ±dict | ã‚»ã‚¯ã‚¿ãƒ¼åˆ¤å®šã‚„EPSè£œå®Œ |
L56 | `eps_df` | EPS TTM/ç›´è¿‘EPSç­‰ã‚’ã¾ã¨ã‚ãŸè¡¨ | æˆé•·æŒ‡æ¨™ã®ç®—å‡º |
L57 | `fcf_df` | CFOãƒ»CapExãƒ»FCF TTMã¨æƒ…å ±æºãƒ•ãƒ©ã‚° | FCF/EVã‚„é…å½“ã‚«ãƒãƒ¬ãƒƒã‚¸ |
L58 | `returns` | `px.pct_change()`ã®ãƒªã‚¿ãƒ¼ãƒ³è¡¨ | ç›¸é–¢è¡Œåˆ—ãƒ»DRRSè¨ˆç®— |
L59
L60 ### FeatureBundleï¼ˆScorer â†’ Selectorï¼‰
L61 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L62 | --- | --- | --- |
L63 | `df` | è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™ã®ç”Ÿå€¤ãƒ†ãƒ¼ãƒ–ãƒ« | ãƒ‡ãƒãƒƒã‚°ãƒ»å‡ºåŠ›è¡¨ç¤º |
L64 | `df_z` | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å¾ŒZã‚¹ã‚³ã‚¢åŒ–ã—ãŸæŒ‡æ¨™è¡¨ | å› å­ã‚¹ã‚³ã‚¢åˆæˆã€é¸å®šåŸºæº– |
L65 | `g_score` | Gãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ | Gé¸å®šã€IN/OUTæ¯”è¼ƒ |
L66 | `d_score_all` | Dãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ï¼ˆå…¨éŠ˜æŸ„ï¼‰ | Dé¸å®šã€ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
L67 | `missing_logs` | æ¬ ææŒ‡æ¨™ã¨è£œå®ŒçŠ¶æ³ã®ãƒ­ã‚° | ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ |
L68
L69 ### SelectionBundleï¼ˆSelector â†’ Outputï¼‰
L70 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L71 | --- | --- | --- |
L72 | `resG` | Gé¸å®šçµæœã®è©³ç´°dictï¼ˆ`tickers`ã€ç›®çš„å€¤ç­‰ï¼‰ | çµæœä¿å­˜ãƒ»å¹³å‡ç›¸é–¢ãªã©ã®æŒ‡æ¨™è¡¨ç¤º |
L73 | `resD` | Dé¸å®šçµæœã®è©³ç´°dict | åŒä¸Š |
L74 | `top_G` | æœ€çµ‚æ¡ç”¨Gãƒ†ã‚£ãƒƒã‚«ãƒ¼ | æ–°ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ |
L75 | `top_D` | æœ€çµ‚æ¡ç”¨Dãƒ†ã‚£ãƒƒã‚«ãƒ¼ | åŒä¸Š |
L76 | `init_G` | DRRSå‰ã®GåˆæœŸå€™è£œ | æƒœã—ãã‚‚å¤–ã‚ŒãŸéŠ˜æŸ„è¡¨ç¤º |
L77 | `init_D` | DRRSå‰ã®DåˆæœŸå€™è£œ | åŒä¸Š |
L78
L79 ### WeightsConfig
L80 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L81 | --- | --- | --- |
L82 | `g` | Gå› å­ï¼ˆGRW/MOM/VOLï¼‰ã®é‡ã¿dict | `g_score`åˆæˆ |
L83 | `d` | Då› å­ï¼ˆD_QAL/D_YLD/D_VOL_RAW/D_TRDï¼‰ã®é‡ã¿dict | `d_score_all`åˆæˆ |
L84
L85 ### DRRSParams
L86 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L87 | --- | --- | --- |
L88 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L89 | `shrink` | æ®‹å·®ç›¸é–¢ã®ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å¯¾è§’å¼·èª¿ |
L90 | `G` | Gãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dictï¼ˆ`lookback`ç­‰ï¼‰ | `select_bucket_drrs`è¨­å®š |
L91 | `D` | Dãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | åŒä¸Š |
L92 | `cross_mu_gd` | G-Dã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°Î¼ | `select_buckets`ã®ç›®çš„é–¢æ•° |
L93
L94 ### PipelineConfig
L95 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L96 | --- | --- | --- |
L97 | `weights` | `WeightsConfig`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | ã‚¹ã‚³ã‚¢åˆæˆã®é‡ã¿å‚ç…§ |
L98 | `drrs` | `DRRSParams`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | é¸å®šã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šå€¤ |
L99 | `price_max` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | Inputæ®µéšã§ã®ãƒ•ã‚£ãƒ«ã‚¿ |
L100
L101 ## å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
L102 - `winsorize_s` / `robust_z` : å¤–ã‚Œå€¤å‡¦ç†ã¨Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L103 - `_safe_div` / `_safe_last` : ä¾‹å¤–ã‚’æ½°ã—ãŸåˆ†å‰²ãƒ»æœ«å°¾å–å¾—ã€‚
L104 - `_load_prev` / `_save_sel` : é¸å®šçµæœã®èª­ã¿æ›¸ãã€‚
L105
L106 ## ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
L107 ### Step1: Input
L108 `current_tickers.csv`ã®ç¾è¡ŒéŠ˜æŸ„ã¨`candidate_tickers.csv`ã®æ¤œè¨ä¸­éŠ˜æŸ„ã‚’èµ·ç‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã™ã‚‹ã€‚å¤–éƒ¨I/Oã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€`prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¯**yfinanceã‚’å„ªå…ˆã—ã€æ¬ æãŒã‚ã‚‹æŒ‡æ¨™ã®ã¿Finnhub APIã§è£œå®Œ**ã™ã‚‹ã€‚
L109 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L110 - `impute_eps_ttm` : å››åŠæœŸEPSÃ—4ã§TTMã‚’æ¨å®šã—æ¬ ææ™‚ã®ã¿å·®ã—æ›¿ãˆã€‚
L111 - `fetch_cfo_capex_ttm_yf` : yfinanceã®å››åŠæœŸ/å¹´æ¬¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‹ã‚‰CFOãƒ»CapExãƒ»FCF TTMã‚’ç®—å‡ºã€‚
L112 - `fetch_cfo_capex_ttm_finnhub` : yfinanceã§æ¬ ã‘ãŸéŠ˜æŸ„ã®ã¿Finnhub APIã§è£œå®Œã€‚
L113 - `compute_fcf_with_fallback` : yfinanceå€¤ã‚’åŸºæº–ã«Finnhubå€¤ã§ç©´åŸ‹ã‚ã—ã€CFO/CapEx/FCFã¨æƒ…å ±æºãƒ•ãƒ©ã‚°ã‚’è¿”ã™ã€‚
L114 - `_build_eps_df` : `info`ã‚„`quarterly_earnings`ã‹ã‚‰EPS TTMã¨ç›´è¿‘EPSã‚’è¨ˆç®—ã—ã€`impute_eps_ttm`ã§è£œå®Œã€‚
L115 - `prepare_data` :
L116     0. CSVã‹ã‚‰ç¾è¡ŒéŠ˜æŸ„ã¨å€™è£œéŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
L117     1. å€™è£œéŠ˜æŸ„ã®ç¾åœ¨å€¤ã‚’å–å¾—ã—ä¾¡æ ¼ä¸Šé™ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
L118     2. æ—¢å­˜+å€™è£œã‹ã‚‰å¯¾è±¡ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’æ±ºå®šã—ã€ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆyfinanceï¼‰ã€‚
L119     3. yfinanceå€¤ã‚’åŸºã«EPS/FCFãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç³»åˆ—ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ¬ æã‚»ãƒ«ã¯Finnhubå‘¼ã³å‡ºã—ã§ç©´åŸ‹ã‚ã€‚
L120     4. ä¸Šè¨˜ã‚’`InputBundle`ã«æ ¼ç´ã—ã¦è¿”ã™ã€‚
L121
L122 ### Step2: Score Calculation (Scorer)
L123 ç‰¹å¾´é‡è¨ˆç®—ã¨ã‚¹ã‚³ã‚¢åˆæˆã‚’æ‹…å½“ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L124
L125 #### è£œåŠ©é–¢æ•°
L126 - `trend(s)` : 50/150/200æ—¥ç§»å‹•å¹³å‡ã‚„52é€±ãƒ¬ãƒ³ã‚¸ã‹ã‚‰-0.5ã€œ0.5ã§æ§‹æˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ã€‚
L127 - `rs(s,b)` / `tr_str(s)` / `rs_line_slope(s,b,win)` : ç›¸å¯¾å¼·ã•ã‚„çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã€RSå›å¸°å‚¾ãã‚’ç®—å‡ºã€‚
L128 - `ev_fallback` : `enterpriseValue`æ¬ ææ™‚ã«è² å‚µãƒ»ç¾é‡‘ã‹ã‚‰EVã‚’æ¨å®šã€‚
L129 - `dividend_status` / `div_streak` : é…å½“æœªè¨­å®šçŠ¶æ³ã®åˆ¤å®šã¨å¢—é…å¹´æ•°ã‚«ã‚¦ãƒ³ãƒˆã€‚
L130 - `fetch_finnhub_metrics` : Finnhub APIã‹ã‚‰EPSæˆé•·ãƒ»ROEãƒ»Î²ãªã©ä¸è¶³æŒ‡æ¨™ã‚’å–å¾—ã€‚
L131 - `calc_beta` : ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å…±åˆ†æ•£ã‹ã‚‰Î²ã‚’ç®—å‡ºã€‚
L132 - `spx_to_alpha` : S&P500ã®ä½ç½®æƒ…å ±ã‹ã‚‰DRRSã§ç”¨ã„ã‚‹Î±ã‚’æ¨å®šã€‚
L133 - `soft_cap_effective_scores` / `pick_top_softcap` : ã‚»ã‚¯ã‚¿ãƒ¼ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ—ä»˜ãã‚¹ã‚³ã‚¢èª¿æ•´ã¨ä¸Šä½æŠ½å‡ºã€‚
L134
L135 **è£œåŠ©é–¢æ•°ã¨ç”ŸæˆæŒ‡æ¨™**
L136
L137 | è£œåŠ©é–¢æ•° | ç”ŸæˆæŒ‡æ¨™ | ç•¥ç§° |
L138 | --- | --- | --- |
L139 | `trend` | ãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ | `TR` |
L140 | `rs` | ç›¸å¯¾å¼·ã• | `RS` |
L141 | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç·šã®ä¹–é›¢ | `TR_str` |
L142 | `rs_line_slope` | RSç·šã®å›å¸°å‚¾ã | `RS_SLOPE_*` |
L143 | `calc_beta` | Î² | `BETA` |
L144 | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° | `DIV_STREAK` |
L145
L146 #### `aggregate_scores` è©³ç´°
L147 1. å„éŠ˜æŸ„ã®ä¾¡æ ¼ç³»åˆ—ã‚„`info`ã‚’åŸºã«ä»¥ä¸‹ã‚’ç®—å‡ºã€‚
L148    - **ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ **: `TR`ã€`RS`ã€`TR_str`ã€å¤šæ§˜ãªç§»å‹•å¹³å‡æ¯”ã€`RS_SLOPE_*`ãªã©ã€‚
L149    - **ãƒªã‚¹ã‚¯**: `BETA`ã€`DOWNSIDE_DEV`ã€`MDD_1Y`ã€`RESID_VOL`ã€`DOWN_OUTPERF`ã€`EXT_200`ç­‰ã€‚
L150    - **é…å½“**: `DIV`ã€`DIV_TTM_PS`ã€`DIV_VAR5`ã€`DIV_YOY`ã€`DIV_FCF_COVER`ã€`DIV_STREAK`ã€‚
L151    - **è²¡å‹™ãƒ»æˆé•·**: `EPS`ã€`REV`ã€`ROE`ã€`FCF/EV`ã€`REV_Q_YOY`ã€`EPS_Q_YOY`ã€`REV_YOY_ACC`ã€`REV_YOY_VAR`ã€`REV_ANN_STREAK`ã€`RULE40`ã€`FCF_MGN` ç­‰ã€‚
L152    - **å®‰å®šæ€§/ã‚µã‚¤ã‚º**: `DEBT2EQ`ã€`CURR_RATIO`ã€`MARKET_CAP`ã€`ADV60_USD`ã€`EPS_VAR_8Q`ãªã©ã€‚
L153 2. æŒ‡æ¨™æ¬ æã¯Finnhub APIç­‰ã§è£œå®Œã—ã€æœªå–å¾—é …ç›®ã‚’`missing_logs`ã«è¨˜éŒ²ã€‚
L154 3. `winsorize_s`â†’`robust_z`ã§æ¨™æº–åŒ–ã—`df_z`ã¸ä¿å­˜ã€‚ã‚µã‚¤ã‚ºãƒ»æµå‹•æ€§ã¯å¯¾æ•°å¤‰æ›ã€‚
L155 4. æ­£è¦åŒ–æ¸ˆæŒ‡æ¨™ã‹ã‚‰å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã€‚
L156    - å„å› å­ã®æ§‹æˆã¨é‡ã¿ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
L157      - **GRW**: 0.30Ã—`REV` + 0.20Ã—`EPS_Q_YOY` + 0.15Ã—`REV_Q_YOY` + 0.15Ã—`REV_YOY_ACC` + 0.10Ã—`RULE40` + 0.10Ã—`FCF_MGN` + 0.10Ã—`REV_ANN_STREAK` âˆ’ 0.05Ã—`REV_YOY_VAR`ã€‚
L158      - **MOM**: 0.40Ã—`RS` + 0.15Ã—`TR_str` + 0.15Ã—`RS_SLOPE_6W` + 0.15Ã—`RS_SLOPE_13W` + 0.10Ã—`MA200_SLOPE_5M` + 0.10Ã—`MA200_UP_STREAK_D`ã€‚
L159      - **VOL**: `BETA`å˜ä½“ã‚’ä½¿ç”¨ã€‚
L160      - **QAL**: 0.60Ã—`FCF_W` + 0.40Ã—`ROE_W`ã§ä½œæˆã€‚
L161      - **YLD**: 0.30Ã—`DIV` + 0.70Ã—`DIV_STREAK`ã€‚
L162      - **D_QAL**: 0.35Ã—`QAL` + 0.20Ã—`FCF` + 0.15Ã—`CURR_RATIO` âˆ’ 0.15Ã—`DEBT2EQ` âˆ’ 0.15Ã—`EPS_VAR_8Q`ã€‚
L163      - **D_YLD**: 0.45Ã—`DIV` + 0.25Ã—`DIV_STREAK` + 0.20Ã—`DIV_FCF_COVER` âˆ’ 0.10Ã—`DIV_VAR5`ã€‚
L164      - **D_VOL_RAW**: 0.40Ã—`DOWNSIDE_DEV` + 0.22Ã—`RESID_VOL` + 0.18Ã—`MDD_1Y` âˆ’ 0.10Ã—`DOWN_OUTPERF` âˆ’ 0.05Ã—`EXT_200` âˆ’ 0.08Ã—`SIZE` âˆ’ 0.10Ã—`LIQ` + 0.10Ã—`BETA`ã€‚
L165      - **D_TRD**: 0.40Ã—`MA200_SLOPE_5M` âˆ’ 0.30Ã—`EXT_200` + 0.15Ã—`NEAR_52W_HIGH` + 0.15Ã—`TR`ã€‚
L166     - ä¸»ãªæŒ‡æ¨™ã®ç•¥ç§°ã¨æ„å‘³:
L167
L168       | ç•¥ç§° | è£œåŠ©é–¢æ•° | æ¦‚è¦ |
L169       | --- | --- | --- |
L170       | TR | `trend` | 50/150/200æ—¥ç§»å‹•å¹³å‡ã¨52é€±ãƒ¬ãƒ³ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ |
L171       | RS | `rs` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹ç›¸å¯¾å¼·ã•ï¼ˆ12M/1Mãƒªã‚¿ãƒ¼ãƒ³å·®ï¼‰ |
L172       | TR_str | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ |
L173       | RS_SLOPE_6W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®6é€±å›å¸°å‚¾ã |
L174       | RS_SLOPE_13W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®13é€±å›å¸°å‚¾ã |
L175       | MA200_SLOPE_5M | - | 200æ—¥ç§»å‹•å¹³å‡ã®5ã‹æœˆé¨°è½ç‡ |
L176       | MA200_UP_STREAK_D | - | 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ã„ãŸæ—¥æ•° |
L177       | BETA | `calc_beta` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹Î² |
L178       | DOWNSIDE_DEV | - | ä¸‹æ–¹ãƒªã‚¿ãƒ¼ãƒ³ã®ã¿ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L179       | RESID_VOL | - | Î²ã§èª¿æ•´ã—ãŸæ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L180       | MDD_1Y | - | éå»1å¹´ã®æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ |
L181       | DOWN_OUTPERF | - | å¸‚å ´ä¸‹è½æ—¥ã«å¯¾ã™ã‚‹å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ |
L182       | EXT_200 | - | 200æ—¥ç§»å‹•å¹³å‡ã‹ã‚‰ã®çµ¶å¯¾ä¹–é›¢ç‡ |
L183       | NEAR_52W_HIGH | - | 52é€±é«˜å€¤ã¾ã§ã®ä¸‹æ–¹è·é›¢ï¼ˆ0=é«˜å€¤ï¼‰ |
L184       | FCF_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®FCF/EV |
L185       | ROE_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®ROE |
L186       | FCF | - | FCF/EV |
L187       | QAL | - | FCF_Wã¨ROE_Wã‚’çµ„ã¿åˆã‚ã›ãŸå“è³ªã‚¹ã‚³ã‚¢ |
L188       | CURR_RATIO | - | æµå‹•æ¯”ç‡ |
L189       | DEBT2EQ | - | è² å‚µè³‡æœ¬å€ç‡ |
L190       | EPS_VAR_8Q | - | EPSã®8å››åŠæœŸæ¨™æº–åå·® |
L191       | DIV | - | å¹´ç‡æ›ç®—é…å½“åˆ©å›ã‚Š |
L192       | DIV_STREAK | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° |
L193       | DIV_FCF_COVER | - | é…å½“ã®FCFã‚«ãƒãƒ¬ãƒƒã‚¸ |
L194       | DIV_VAR5 | - | 5å¹´é…å½“å¤‰å‹•ç‡ |
L195       | DIV_TTM_PS | - | 1æ ªå½“ãŸã‚ŠTTMé…å½“ |
L196       | DIV_YOY | - | å‰å¹´æ¯”é…å½“æˆé•·ç‡ |
L197       | REV | - | å£²ä¸Šæˆé•·ç‡TTM |
L198       | EPS_Q_YOY | - | å››åŠæœŸEPSã®å‰å¹´åŒæœŸæ¯” |
L199       | REV_Q_YOY | - | å››åŠæœŸå£²ä¸Šã®å‰å¹´åŒæœŸæ¯” |
L200       | REV_YOY_ACC | - | å£²ä¸Šæˆé•·ç‡ã®åŠ é€Ÿåˆ† |
L201       | RULE40 | - | å£²ä¸Šæˆé•·ç‡ã¨FCFãƒãƒ¼ã‚¸ãƒ³ã®åˆè¨ˆ |
L202       | FCF_MGN | - | FCFãƒãƒ¼ã‚¸ãƒ³ |
L203       | REV_ANN_STREAK | - | å¹´æ¬¡å£²ä¸Šæˆé•·ã®é€£ç¶šå¹´æ•° |
L204       | REV_YOY_VAR | - | å¹´æ¬¡å£²ä¸Šæˆé•·ç‡ã®å¤‰å‹•æ€§ |
L205       | SIZE | - | æ™‚ä¾¡ç·é¡ã®å¯¾æ•°å€¤ |
L206       | LIQ | - | 60æ—¥å¹³å‡å‡ºæ¥é«˜ãƒ‰ãƒ«ã®å¯¾æ•°å€¤ |
L207    - Gãƒã‚±ãƒƒãƒˆ: `GRW`ã€`MOM`ã€`VOL`ã‚’`cfg.weights.g`ï¼ˆ0.40/0.45/-0.15ï¼‰ã§åŠ é‡ã—`g_score`ã‚’å¾—ã‚‹ã€‚
L208    - Dãƒã‚±ãƒƒãƒˆ: `D_QAL`ã€`D_YLD`ã€`D_VOL_RAW`ã€`D_TRD`ã‚’`cfg.weights.d`ï¼ˆ0.15/0.15/-0.45/0.25ï¼‰ã§åŠ é‡ã—`d_score_all`ã‚’ç®—å‡ºã€‚
L209    - ã‚»ã‚¯ã‚¿ãƒ¼capã«ã‚ˆã‚‹`soft_cap_effective_scores`ã‚’é©ç”¨ã—ã€Gæ¡ç”¨éŠ˜æŸ„ã«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€‚
L210 5. `_apply_growth_entry_flags`ã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®ç™ºç«çŠ¶æ³ã‚’ä»˜åŠ ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L211
L212 ### Step3: Correlation Reduction & Selection (Selector)
L213 DRRSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç›¸é–¢ã‚’æŠ‘ãˆãŸéŠ˜æŸ„é¸å®šã‚’è¡Œã„ã€`SelectionBundle`ã‚’è¿”ã™ã€‚`results/`ã«ä¿å­˜ã•ã‚ŒãŸå‰å›é¸å®šï¼ˆ`G_selection.json` / `D_selection.json`ï¼‰ã‚’`_load_prev`ã§èª­ã¿è¾¼ã¿ã€ç›®çš„å€¤ãŒå¤§ããæ‚ªåŒ–ã—ãªã„é™ã‚Šç¶­æŒã™ã‚‹ã€‚æ–°ã—ã„æ¡ç”¨é›†åˆã¯`_save_sel`ã§JSONã«æ›¸ãå‡ºã—æ¬¡å›ä»¥é™ã®å…¥åŠ›ã«å‚™ãˆã‚‹ã€‚
L214 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L215 - `residual_corr` : åç›Šç‡è¡Œåˆ—ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã—ã€ä¸Šä½ä¸»æˆåˆ†ã‚’é™¤å»ã—ãŸæ®‹å·®ã‹ã‚‰ç›¸é–¢è¡Œåˆ—ã‚’æ±‚ã‚ã€å¹³å‡ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯ã€‚
L216 - `rrqr_like_det` : ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘ã—ãŸQRåˆ†è§£é¢¨ã®æ‰‹é †ã§åˆæœŸå€™è£œã‚’kä»¶æŠ½å‡ºã—ã€ã‚¹ã‚³ã‚¢ã®é«˜ã„éç›¸é–¢ãªé›†åˆã‚’å¾—ã‚‹ã€‚
L217 - `swap_local_det` / `swap_local_det_cross` : `sum(score) - Î»*within_corr - Î¼*cross_corr`ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ã€å…¥ã‚Œæ›¿ãˆæ¢ç´¢ã§å±€æ‰€çš„ã«æœ€é©åŒ–ã€‚
L218 - `select_bucket_drrs` : ãƒ—ãƒ¼ãƒ«éŠ˜æŸ„ã¨ã‚¹ã‚³ã‚¢ã‹ã‚‰æ®‹å·®ç›¸é–¢ã‚’è¨ˆç®—ã—ã€ä¸Šè¨˜2æ®µéš(åˆæœŸé¸æŠâ†’å…¥ã‚Œæ›¿ãˆ)ã§kéŠ˜æŸ„ã‚’æ±ºå®šã€‚éå»æ¡ç”¨éŠ˜æŸ„ã¨ã®æ¯”è¼ƒã§ç›®çš„å€¤ãŒåŠ£åŒ–ã—ãªã‘ã‚Œã°ç¶­æŒã™ã‚‹ã€‚
L219 - `select_buckets` : Gãƒã‚±ãƒƒãƒˆã‚’é¸å®šå¾Œã€ãã®çµæœã‚’é™¤ã„ãŸå€™è£œã‹ã‚‰Dãƒã‚±ãƒƒãƒˆã‚’é¸ã¶ã€‚Dé¸å®šæ™‚ã¯Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ã‚’ä»˜ä¸ã—ã€ä¸¡ãƒã‚±ãƒƒãƒˆã®åˆ†æ•£ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
L220
L221 #### ç›¸é–¢ä½æ¸›ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°
L222 1. **æ®‹å·®ç›¸é–¢è¡Œåˆ—ã®æ§‹ç¯‰ (`residual_corr`)**
L223    - ãƒªã‚¿ãƒ¼ãƒ³è¡Œåˆ—`R`ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L224    - SVDã§ä¸Šä½`n_pc`ä¸»æˆåˆ†`F`ã‚’æ±‚ã‚ã€æœ€å°äºŒä¹—ã§ä¿‚æ•°`B`ã‚’ç®—å‡ºã—æ®‹å·®`E = Z - F@B`ã‚’å¾—ã‚‹ã€‚
L225    - `E`ã®ç›¸é–¢è¡Œåˆ—`C`ã‚’è¨ˆç®—ã—ã€å¹³å‡çµ¶å¯¾ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯é‡`shrink_eff`ã‚’è£œæ­£ã—ã¦å¯¾è§’ã‚’å¼·èª¿ã€‚
L226 2. **åˆæœŸå€™è£œã®æŠ½å‡º (`rrqr_like_det`)**
L227    - ã‚¹ã‚³ã‚¢ã‚’0-1æ­£è¦åŒ–ã—ãŸé‡ã¿`w`ã¨ã—ã€`Z*(1+Î³w)`ã§åˆ—ãƒãƒ«ãƒ ã‚’å¼·èª¿ã€‚
L228    - æ®‹å·®ãƒãƒ«ãƒ æœ€å¤§ã®åˆ—ã‚’é€æ¬¡é¸ã³ã€QRãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã£ã¦éç›¸é–¢ã‹ã¤é«˜ã‚¹ã‚³ã‚¢ãª`k`éŠ˜æŸ„é›†åˆ`S0`ã‚’å¾—ã‚‹ã€‚
L229 3. **å±€æ‰€æ¢ç´¢ (`swap_local_det` / `swap_local_det_cross`)**
L230    - ç›®çš„é–¢æ•°`Î£z_score âˆ’ Î»Â·within_corr âˆ’ Î¼Â·cross_corr`ã‚’æœ€å¤§åŒ–ã€‚
L231    - é¸æŠé›†åˆã®å„éŠ˜æŸ„ã‚’ä»–å€™è£œã¨å…¥ã‚Œæ›¿ãˆã€æ”¹å–„ãŒãªããªã‚‹ã¾ã§ã¾ãŸã¯`max_pass`å›ã¾ã§æ¢ç´¢ã€‚
L232    - `swap_local_det_cross`ã¯Gãƒã‚±ãƒƒãƒˆã¨ã®ã‚¯ãƒ­ã‚¹ç›¸é–¢è¡Œåˆ—`C_cross`ã‚’ä½¿ç”¨ã—ã€ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’ä»˜ä¸ã€‚
L233 4. **éå»æ¡ç”¨ã®ç¶­æŒã¨ã‚¯ãƒ­ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ (`select_bucket_drrs` / `select_buckets`)**
L234    - å±€æ‰€æ¢ç´¢çµæœ`S`ã¨éå»é›†åˆ`P`ã®ç›®çš„å€¤ã‚’æ¯”è¼ƒã—ã€`S`ãŒ`P`ã‚ˆã‚Š`Î·`æœªæº€ã®æ”¹å–„ãªã‚‰`P`ã‚’ç¶­æŒã€‚
L235    - `select_buckets`ã§ã¯Gã‚’å…ˆã«æ±ºå®šã—ã€Dé¸å®šæ™‚ã«Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’åŠ ãˆã¦ã‚¯ãƒ­ã‚¹åˆ†æ•£ã‚’æŠ‘åˆ¶ã€‚
L236
L237 ### Step4: Output
L238 é¸å®šçµæœã‚’å¯è¦–åŒ–ã—å…±æœ‰ã™ã‚‹å·¥ç¨‹ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦æ¨™æº–å‡ºåŠ›ã¨Slackã¸é€ã‚‹ã€‚
L239 - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚é¸å¤–ã¨ãªã£ãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L240 - IN/OUTãƒªã‚¹ãƒˆã¨OUTéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ï¼ˆä½å¾—ç‚¹éŠ˜æŸ„ã‚’ç¢ºèªã—ã‚„ã™ãï¼‰
L241 - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨ï¼ˆçµ„å…¥ã‚Œãƒ»é™¤å¤–ã€ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼‰
L242 - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
L243
L244 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L245 - `display_results` : ä¸Šè¨˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŠ ãˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚„åˆ†æ•£åŒ–æŒ‡æ¨™ã‚’è¡¨ç¤ºã€‚
L246 - `notify_slack` : Slack Webhookã¸åŒå†…å®¹ã‚’é€ä¿¡ã€‚
L247 - è£œåŠ©:`_avg_offdiag`ã€`_resid_avg_rho`ã€`_raw_avg_rho`ã€`_cross_block_raw_rho`ã€‚
L248
L249 ## ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
L250 1. `PipelineConfig`ã‚’æ§‹ç¯‰ã€‚
L251 2. **Step1** `Input.prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚
L252 3. **Step2** `Scorer.aggregate_scores`ã§`FeatureBundle`ã‚’å–å¾—ã€‚
L253 4. **Step3** `Selector.select_buckets`ã§`SelectionBundle`ã‚’ç®—å‡ºã€‚
L254 5. **Step4** `Output.display_results`ã¨`notify_slack`ã§çµæœã‚’å‡ºåŠ›ã€‚
```
