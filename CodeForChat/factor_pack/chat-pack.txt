# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <factor.py>
```text
L1 """
L2 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
L3 â”ƒ ROLE of factor.py                                     â”ƒ
L4 â”ƒ  - Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰     â”ƒ
L5 â”ƒ  - è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¡ç‚¹/ãƒ•ã‚£ãƒ«ã‚¿/ç›¸é–¢ä½æ¸›ï¼‰ã¯ scorer.py â”ƒ
L6 â”ƒ  - ã“ã“ã§ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…/å¤‰æ›´ã—ãªã„                   â”ƒ
L7 â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
L8 """
L9 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L10 BONUS_COEFF = 0.4   # æ”»ã‚=0.3 / ä¸­åº¸=0.4 / å®ˆã‚Š=0.5
L11 import os, json, time, requests
L12 from time import perf_counter
L13 from dataclasses import dataclass
L14 from typing import Dict, List
L15 from concurrent.futures import ThreadPoolExecutor
L16 import numpy as np
L17 import pandas as pd
L18 import yfinance as yf
L19 from scipy.stats import zscore  # used via scorer
L20 from scorer import Scorer, ttm_div_yield_portfolio
L21
L22
L23 class T:
L24     t = perf_counter()
L25     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L26
L27
L28 T.log("start")
L29
L30 # ===== ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ =====
L31 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L32 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L33 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L34 N_G, N_D = 12, 13  # G/Dæ ã‚µã‚¤ã‚º
L35 g_weights = {'GRW':0.40,'MOM':0.45,'VOL':-0.15}
L36 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L37 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L38 D_weights = {'QAL':0.15,'YLD':0.15,'VOL':-0.45,'TRD':0.25}
L39 def _fmt_w(w): return " ".join(f"{k}{int(v*100)}" for k,v in w.items())
L40
L41 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L42 corrM = 45
L43 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L44 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L45
L46 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L47 try: CROSS_MU_GD
L48 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L49
L50 # å‡ºåŠ›é–¢é€£
L51 RESULTS_DIR = "results"
L52 os.makedirs(RESULTS_DIR, exist_ok=True)
L53
L54 # ãã®ä»–
L55 debug_mode, FINNHUB_API_KEY = False, os.environ.get("FINNHUB_API_KEY")
L56
L57
L58 # ===== å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config =====
L59 @dataclass(frozen=True)
L60 class InputBundle:
L61     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L62     cand: List[str]
L63     tickers: List[str]
L64     bench: str
L65     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L66     px: pd.DataFrame                # data['Close']
L67     spx: pd.Series                  # data['Close'][bench]
L68     tickers_bulk: object            # yfinance.Tickers
L69     info: Dict[str, dict]           # yfinance info per ticker
L70     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L71     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L72     returns: pd.DataFrame           # px[tickers].pct_change()
L73
L74 @dataclass(frozen=True)
L75 class FeatureBundle:
L76     df: pd.DataFrame
L77     df_z: pd.DataFrame
L78     g_score: pd.Series
L79     d_score_all: pd.Series
L80     missing_logs: pd.DataFrame
L81
L82 @dataclass(frozen=True)
L83 class SelectionBundle:
L84     resG: dict
L85     resD: dict
L86     top_G: List[str]
L87     top_D: List[str]
L88     init_G: List[str]
L89     init_D: List[str]
L90
L91 @dataclass(frozen=True)
L92 class WeightsConfig:
L93     g: Dict[str,float]
L94     d: Dict[str,float]
L95
L96 @dataclass(frozen=True)
L97 class DRRSParams:
L98     corrM: int
L99     shrink: float
L100     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L101     D: Dict[str,float]
L102     cross_mu_gd: float
L103
L104 @dataclass(frozen=True)
L105 class PipelineConfig:
L106     weights: WeightsConfig
L107     drrs: DRRSParams
L108     price_max: float
L109
L110
L111 # ===== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ =====
L112 # (unused local utils removed â€“ use scorer.py versions if needed)
L113
L114 def _env_true(name: str, default=False):
L115     v = os.getenv(name)
L116     return (v or str(default)).strip().lower() == "true"
L117
L118 def _post_slack(payload: dict):
L119     url = os.getenv("SLACK_WEBHOOK_URL")
L120     if not url: 
L121         print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L122     try:
L123         requests.post(url, json=payload).raise_for_status()
L124     except Exception as e:
L125         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L126
L127 def _slack(message, code=False):
L128     _post_slack({"text": f"```{message}```" if code else message})
L129
L130 def _slack_debug(text: str, chunk=2800):
L131     i = 0
L132     while i < len(text):
L133         j = min(len(text), i+chunk); k = text.rfind("\n", i, j); j = k if k > i+100 else j
L134         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L135         i = j
L136
L137 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L138     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC"]
L139     all_cols = _env_true("DEBUG_ALL_COLS", False)
L140     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L141
L142     Gp, Dp = set(prevG or []), set(prevD or [])
L143     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L144     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L145
L146     show_near = _env_true("DEBUG_NEAR5", True)
L147     gs = getattr(fb,"g_score",None); ds = getattr(fb,"d_score_all",None)
L148     gs = gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None
L149     ds = ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None
L150     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L151     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L152     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L153
L154     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L155     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L156
L157     def _fmt_near(lbl, ser, lst):
L158         if ser is None: return f"{lbl}: off"
L159         parts=[f"{t}:{ser.get(t,float('nan')):.3f}" if pd.notna(ser.get(t)) else f"{t}:nan" for t in lst]
L160         return f"{lbl}: "+(", ".join(parts) if parts else "-")
L161
L162     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L163           _fmt_near("G near10", gs, g_miss),
L164           _fmt_near("D near10", ds, d_miss),
L165           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L166           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L167
L168     tbl="(df_z or columns not available)"
L169     if not fb.df_z.empty and cols:
L170         idx=[t for t in focus if t in fb.df_z.index]
L171         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L172
L173     miss_txt=""
L174     if _env_true("DEBUG_MISSING_LOGS", False):
L175         miss=getattr(fb,"missing_logs",None)
L176         if miss is not None and not miss.empty:
L177             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L178
L179     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L180
L181 def _disjoint_keepG(top_G, top_D, poolD):
L182     """
L183     Gã«å«ã¾ã‚Œã‚‹éŠ˜æŸ„ã‚’Dã‹ã‚‰é™¤å»ã—ã€Dã¯poolDï¼ˆæ¬¡ç‚¹ï¼‰ã§è£œå……ã™ã‚‹ã€‚
L184     - å¼•æ•°:
L185         top_G: List[str]  â€¦ Gæœ€çµ‚12éŠ˜æŸ„
L186         top_D: List[str]  â€¦ Dæœ€çµ‚13éŠ˜æŸ„ï¼ˆé‡è¤‡ã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰
L187         poolD: List[str]  â€¦ Då€™è£œã®é †ä½ãƒªã‚¹ãƒˆï¼ˆtop_Dã‚’å«ã‚€ä¸Šä½æ‹¡å¼µï¼‰
L188     - æˆ»ã‚Šå€¤: (top_G, top_D_disjoint)
L189     - æŒ™å‹•:
L190         1) Dã«Gé‡è¤‡ãŒã‚ã‚Œã°é †ã«ç½®æ›
L191         2) ç½®æ›å€™è£œã¯ poolD ã‹ã‚‰ã€æ—¢ä½¿ç”¨(GâˆªD)ã‚’é¿ã‘ã¦å‰ã‹ã‚‰æ¡ç”¨
L192         3) è£œå……åˆ†ãŒå°½ããŸå ´åˆã¯å…ƒã®éŠ˜æŸ„ã‚’æ®‹ã™ï¼ˆå®‰å…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
L193     """
L194     used, D, i = set(top_G), list(top_D), 0
L195     for j, t in enumerate(D):
L196         if t in used:
L197             while i < len(poolD) and (poolD[i] in used or poolD[i] in D): i += 1
L198             if i < len(poolD): D[j] = poolD[i]; used.add(D[j]); i += 1
L199     return top_G, D
L200
L201 _state_file = lambda: os.path.join(RESULTS_DIR, "breadth_state.json")
L202 def load_mode(default: str="NORMAL") -> str:
L203     try:
L204         m = json.loads(open(_state_file()).read()).get("mode", default)
L205         return m if m in ("EMERG","CAUTION","NORMAL") else default
L206     except Exception: return default
L207 def save_mode(mode: str):
L208     try: open(_state_file(),"w").write(json.dumps({"mode": mode}))
L209     except Exception: pass
L210
L211 # --- Breadthâ†’è‡ªå‹•ã—ãã„å€¤â†’ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹â†’Slackå…ˆé ­è¡Œã‚’ä½œæˆ ---
L212 def _build_breadth_lead_lines(inb) -> tuple[list[str], str]:
L213     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L214     C_ts = Scorer.trend_template_breadth_series(inb.px[inb.tickers], inb.spx, win_days=win)
L215     if C_ts.empty: raise RuntimeError("breadth series empty")
L216     warmup = int(os.getenv("BREADTH_WARMUP_DAYS", "252"))
L217     base = C_ts.iloc[warmup:] if len(C_ts) > warmup else C_ts
L218     C_full = int(C_ts.iloc[-1])
L219     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L220     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L221     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L222     th_in_rec, th_out_rec, th_norm_rec = max(N_G, q05), max(int(np.ceil(1.5*N_G)), q20), max(3*N_G, q60)
L223     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L224     th_in, th_out, th_norm, th_src = (th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•") if use_calib else (
L225         int(os.getenv("GTT_EMERG_IN",    str(N_G))),
L226         int(os.getenv("GTT_EMERG_OUT",   str(int(1.5*N_G)))),
L227         int(os.getenv("GTT_CAUTION_OUT", str(3*N_G))),
L228         "æ‰‹å‹•"
L229     )
L230     prev = load_mode("NORMAL")
L231     if   prev == "EMERG":  mode = "EMERG" if (C_full < th_out) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L232     elif prev == "CAUTION": mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L233     else:                   mode = "EMERG" if (C_full < th_in) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L234     save_mode(mode)
L235     _MODE_JA = {"EMERG":"ç·Šæ€¥", "CAUTION":"è­¦æˆ’", "NORMAL":"é€šå¸¸"}; _MODE_EMOJI = {"EMERG":"ğŸš¨", "CAUTION":"âš ï¸", "NORMAL":"ğŸŸ¢"}
L236     mode_ja, emoji, eff_days = _MODE_JA.get(mode, mode), _MODE_EMOJI.get(mode, "â„¹ï¸"), len(base)
L237     lead_lines = [
L238         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*", f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*", "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L239         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬", f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬", f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L240         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L241         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬", f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬", f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L242     ]
L243     return lead_lines, mode
L244
L245
L246 # ===== Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ =====
L247 class Input:
L248     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L249         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L250         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L251
L252     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L253     @staticmethod
L254     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L255         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L256         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L257         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L258
L259     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L260
L261     @staticmethod
L262     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L263         if df is None or df.empty: return None
L264         idx_lower = {str(i).lower(): i for i in df.index}
L265         for name in names:
L266             key = name.lower()
L267             if key in idx_lower: return df.loc[idx_lower[key]]
L268         return None
L269
L270     @staticmethod
L271     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L272         if s is None or s.empty: return None
L273         vals = s.dropna().astype(float); return None if vals.empty else vals.iloc[:n].sum()
L274
L275     @staticmethod
L276     def _latest(s: pd.Series|None) -> float|None:
L277         if s is None or s.empty: return None
L278         vals = s.dropna().astype(float); return vals.iloc[0] if not vals.empty else None
L279
L280     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L281         from concurrent.futures import ThreadPoolExecutor, as_completed
L282         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L283
L284         def one(t: str):
L285             try:
L286                 tk = yf.Ticker(t)  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯æ¸¡ã•ãªã„ï¼ˆYFãŒcurl_cffiã§ç®¡ç†ï¼‰
L287                 qcf = tk.quarterly_cashflow
L288                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L289                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L290                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L291                 if any(v is None for v in (cfo, capex, fcf)):
L292                     acf = tk.cashflow
L293                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L294                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L295                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L296             except Exception as e:
L297                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L298             n=np.nan
L299             return {"ticker":t,
L300                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L301                     "capex_ttm_yf": n if capex is None else capex,
L302                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L303
L304         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L305         with ThreadPoolExecutor(max_workers=mw) as ex:
L306             for f in as_completed(ex.submit(one,t) for t in tickers): rows.append(f.result())
L307         return pd.DataFrame(rows).set_index("ticker")
L308
L309     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L310     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L311
L312     @staticmethod
L313     def _first_key(d: dict, keys: list[str]):
L314         for k in keys:
L315             if k in d and d[k] is not None: return d[k]
L316         return None
L317
L318     @staticmethod
L319     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L320         for i in range(retries):
L321             r = session.get(url, params=params, timeout=15)
L322             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L323             r.raise_for_status(); return r.json()
L324         r.raise_for_status()
L325
L326     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L327         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L328         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L329         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L330         for sym in tickers:
L331             cfo_ttm = capex_ttm = None
L332             try:
L333                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L334                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L335                 for item in arr[:4]:
L336                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L337                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L338                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L339             except Exception: pass
L340             if cfo_ttm is None or capex_ttm is None:
L341                 try:
L342                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L343                     arr = j.get("cashFlow") or []
L344                     if arr:
L345                         item0 = arr[0]
L346                         if cfo_ttm is None:
L347                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L348                             if v is not None: cfo_ttm = float(v)
L349                         if capex_ttm is None:
L350                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L351                             if v is not None: capex_ttm = float(v)
L352                 except Exception: pass
L353             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L354         return pd.DataFrame(rows).set_index("ticker")
L355
L356     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L357         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L358         T.log("financials (yf) done")
L359         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L360         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L361         if need:
L362             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L363             df = yf_df.join(fh_df, how="left")
L364             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L365                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L366             print("[T] financials (finnhub) done (fallback only)")
L367         else:
L368             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L369             print("[T] financials (finnhub) skipped (no missing)")
L370         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L371         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L372         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L373         fcf_calc = cfo - capex
L374         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L375         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L376         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L377         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L378         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L379         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L380         return df[cols].sort_index()
L381
L382     def _build_eps_df(self, tickers, tickers_bulk, info):
L383         eps_rows=[]
L384         for t in tickers:
L385             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L386             try:
L387                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L388                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L389                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L390                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L391                     eps_q = qearn["Earnings"].iloc[-1]/so
L392             except Exception: pass
L393             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L394         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L395
L396     def prepare_data(self):
L397         """Fetch price and fundamental data for all tickers."""
L398         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L399         for t in self.cand:
L400             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L401             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L402         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L403         T.log("price cap filter done (CAND_PRICE_MAX)")
L404         tickers = sorted(set(self.exist + cand_f))
L405         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L406         data = yf.download(tickers + [self.bench], period="600d", auto_adjust=True, progress=False)
L407         T.log("yf.download done")
L408         px, spx = data["Close"], data["Close"][self.bench]
L409         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0ãªã‚‰ç„¡åŠ¹ï¼ˆæ—¢å®šï¼‰
L410         if clip_days > 0:
L411             px  = px.tail(clip_days + 1)
L412             spx = spx.tail(clip_days + 1)
L413             print(f"[T] price window clipped by env: {len(px)} rows (PRICE_CLIP_DAYS={clip_days})")
L414         else:
L415             print(f"[T] price window clip skipped; rows={len(px)}")
L416         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L417         for t in tickers:
L418             try: info[t] = tickers_bulk.tickers[t].info
L419             except Exception as e: print(f"{t}: info fetch failed ({e})"); info[t] = {}
L420         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L421         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L422         T.log("eps/fcf prep done")
L423         returns = px[tickers].pct_change()
L424         T.log("price prep/returns done")
L425         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L426
L427
L428 # ===== Selectorï¼šç›¸é–¢ä½æ¸›ãƒ»é¸å®šï¼ˆã‚¹ã‚³ã‚¢ï¼†ãƒªã‚¿ãƒ¼ãƒ³ã ã‘èª­ã‚€ï¼‰ =====
L429 class Selector:
L430     # ---- DRRS helpersï¼ˆSelectorå°‚ç”¨ï¼‰ ----
L431     @staticmethod
L432     def _z_np(X: np.ndarray) -> np.ndarray:
L433         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L434         return (np.nan_to_num(X)-m)/s
L435
L436     @classmethod
L437     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L438         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L439         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L440         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L441         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L442         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L443
L444     @classmethod
L445     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L446         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L447         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L448         if k==0: return []
L449         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L450         for _ in range(k):
L451             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L452             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L453             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L454         return sorted(S)
L455
L456     @staticmethod
L457     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L458         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L459         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L460
L461     @classmethod
L462     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L463         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L464         while improved and passes<max_pass:
L465             improved, passes = False, passes+1
L466             for i,out in enumerate(list(S)):
L467                 for inn in range(len(score)):
L468                     if inn in S: continue
L469                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L470                     if v>best+1e-10: S, best, improved = cand, v, True; break
L471                 if improved: break
L472         return S, best
L473
L474     @staticmethod
L475     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L476         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L477         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L478         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L479         return float(s[idx].sum() - lam*within - mu*cross)
L480
L481     @classmethod
L482     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L483         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L484         while improved and passes<max_pass:
L485             improved, passes = False, passes+1
L486             for i,out in enumerate(list(S)):
L487                 for inn in range(N):
L488                     if inn in S: continue
L489                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L490                     if v>best+1e-10: S, best, improved = cand, v, True; break
L491                 if improved: break
L492         return S, best
L493
L494     @staticmethod
L495     def avg_corr(C: np.ndarray, idx) -> float:
L496         k = len(idx); P = C[np.ix_(idx, idx)]
L497         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L498
L499     @classmethod
L500     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L501         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L502         union = [t for t in pool_tickers if t in returns_df.columns]
L503         for t in g_fixed:
L504             if t not in union: union.append(t)
L505         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L506         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L507         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L508         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L509         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L510         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L511         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L512         if len(g_eff)>0 and mu>0.0:
L513             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L514         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L515         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L516         selected_tickers = [pool_eff[i] for i in S]
L517         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L518
L519     # ---- é¸å®šï¼ˆã‚¹ã‚³ã‚¢ Series / returns ã ã‘ã‚’å—ã‘ã‚‹ï¼‰----
L520 # ===== Outputï¼šå‡ºåŠ›æ•´å½¢ã¨é€ä¿¡ï¼ˆè¡¨ç¤ºãƒ»Slackï¼‰ =====
L521 class Output:
L522
L523     def __init__(self, debug=False):
L524         self.debug = debug
L525         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = self.debug_table = None
L526         self.g_title = self.d_title = ""
L527         self.g_formatters = self.d_formatters = {}
L528         # ä½ã‚¹ã‚³ã‚¢ï¼ˆGSC+DSCï¼‰Top10 è¡¨ç¤º/é€ä¿¡ç”¨
L529         self.low10_table = None
L530
L531     # --- è¡¨ç¤ºï¼ˆå…ƒ display_results ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L532     def display_results(self, *, exist, bench, df_z, g_score, d_score_all,
L533                         init_G, init_D, top_G, top_D, **kwargs):
L534         pd.set_option('display.float_format','{:.3f}'.format)
L535         print("ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ")
L536         if self.miss_df is not None and not self.miss_df.empty:
L537             print("Missing Data:")
L538             print(self.miss_df.to_string(index=False))
L539
L540         # ---- è¡¨ç¤ºç”¨ï¼šChanges/Near-Miss ã®ã‚¹ã‚³ã‚¢æºã‚’â€œæœ€çµ‚é›†è¨ˆâ€ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚· ----
L541         try:
L542             sc = getattr(self, "_sc", None)
L543             agg_G = getattr(sc, "_agg_G", None)
L544             agg_D = getattr(sc, "_agg_D", None)
L545         except Exception:
L546             sc = agg_G = agg_D = None
L547         class _SeriesProxy:
L548             __slots__ = ("primary", "fallback")
L549             def __init__(self, primary, fallback): self.primary, self.fallback = primary, fallback
L550             def get(self, key, default=None):
L551                 try:
L552                     v = self.primary.get(key) if hasattr(self.primary, "get") else None
L553                     if v is not None and not (isinstance(v, float) and v != v):
L554                         return v
L555                 except Exception:
L556                     pass
L557                 try:
L558                     return self.fallback.get(key) if hasattr(self.fallback, "get") else default
L559                 except Exception:
L560                     return default
L561         g_score = _SeriesProxy(agg_G, g_score)
L562         d_score_all = _SeriesProxy(agg_D, d_score_all)
L563         near_G = getattr(sc, "_near_G", []) if sc else []
L564         near_D = getattr(sc, "_near_D", []) if sc else []
L565
L566         extra_G = [t for t in init_G if t not in top_G][:5]; G_UNI = top_G + extra_G
L567         gsc_series = pd.Series({t: g_score.get(t) for t in G_UNI}, name='GSC')
L568         self.g_table = pd.concat([df_z.loc[G_UNI,['GRW','MOM','TRD','VOL']], gsc_series], axis=1)
L569         self.g_table.index = [t + ("â­ï¸" if t in top_G else "") for t in G_UNI]
L570         self.g_formatters = {col:"{:.2f}".format for col in ['GRW','MOM','TRD','VOL']}; self.g_formatters['GSC'] = "{:.3f}".format
L571         self.g_title = (f"[Gæ  / {N_G} / {_fmt_w(g_weights)} / corrM={corrM} / "
L572                         f"LB={DRRS_G['lookback']} nPC={DRRS_G['n_pc']} Î³={DRRS_G['gamma']} Î»={DRRS_G['lam']} Î·={DRRS_G['eta']} shrink={DRRS_SHRINK}]")
L573         if near_G:
L574             add = [t for t in near_G if t not in set(G_UNI)][:10]
L575             if len(add) < 10:
L576                 try:
L577                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L578                     out_now = sorted(set(exist) - set(top_G + top_D))  # ä»Šå› OUT
L579                     used = set(G_UNI + add)
L580                     def _push(lst):
L581                         nonlocal add, used
L582                         for t in lst:
L583                             if len(add) == 10: break
L584                             if t in aggG.index and t not in used:
L585                                 add.append(t); used.add(t)
L586                     _push(out_now)           # â‘  ä»Šå› OUT ã‚’å„ªå…ˆ
L587                     _push(list(aggG.index))  # â‘¡ ã¾ã è¶³ã‚Šãªã‘ã‚Œã°ä¸Šä½ã§å……å¡«
L588                 except Exception:
L589                     pass
L590             if add:
L591                 near_tbl = pd.concat([df_z.loc[add,['GRW','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L592                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L593         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L594
L595         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L596         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L597         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L598         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L599         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L600         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L601         import scorer
L602         dw_eff = scorer.D_WEIGHTS_EFF
L603         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L604                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L605         if near_D:
L606             add = [t for t in near_D if t not in set(D_UNI)][:10]
L607             if add:
L608                 d_disp2 = pd.DataFrame(index=add)
L609                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L610                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L611                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L612         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L613
L614         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L615         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L616         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L617
L618         self.io_table = pd.DataFrame({
L619             'IN': pd.Series(in_list),
L620             '/ OUT': pd.Series(out_list)
L621         })
L622         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L623         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L624         self.io_table['GSC'] = pd.Series(g_list)
L625         self.io_table['DSC'] = pd.Series(d_list)
L626
L627         print("Changes:")
L628         print(self.io_table.to_string(index=False))
L629
L630         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L631         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L632         for name,ticks in portfolios.items():
L633             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L634             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L635             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L636             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L637             if len(ticks)>=2:
L638                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L639                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L640                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L641             else: RAW_rho = RESID_rho = np.nan
L642             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L643         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L644         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L645         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L646         def _fmt_row(s):
L647             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L648         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L649         if self.debug:
L650             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L651             print("Debug Data:"); print(self.debug_table.to_string())
L652
L653         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L654         try:
L655             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L656             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L657             all_scores = all_scores.dropna(subset=['G_plus_D'])
L658             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L659             print("Low Score Candidates (GSC+DSC bottom 10):")
L660             print(self.low10_table.to_string())
L661         except Exception as e:
L662             print(f"[warn] low-score ranking failed: {e}")
L663             self.low10_table = None
L664
L665     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L666     def notify_slack(self):
L667         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L668         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L669         def _filter_suffix_from(spec: dict, group: str) -> str:
L670             g = spec.get(group, {})
L671             parts = [str(m) for m in g.get("pre_mask", [])]
L672             for k, v in (g.get("pre_filter", {}) or {}).items():
L673                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L674                 name = {"beta": "Î²"}.get(base, base)
L675                 try: val = f"{float(v):g}"
L676                 except: val = str(v)
L677                 parts.append(f"{name}{op}{val}")
L678             return "" if not parts else " / filter:" + " & ".join(parts)
L679         def _inject_filter_suffix(title: str, group: str) -> str:
L680             suf = _filter_suffix_from(FILTER_SPEC, group)
L681             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L682         def _blk(title, tbl, fmt=None, drop=()):
L683             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(é¸å®šãªã—)\n"
L684             if drop and hasattr(tbl,'columns'):
L685                 keep = [c for c in tbl.columns if c not in drop]
L686                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L687             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L688
L689         g_title = _inject_filter_suffix(self.g_title, "G")
L690         d_title = _inject_filter_suffix(self.d_title, "D")
L691         message  = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L692         if self.miss_df is not None and not self.miss_df.empty:
L693             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L694         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L695         message += _blk(d_title, self.d_table, self.d_formatters)
L696         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L697         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L698         if self.debug and self.debug_table is not None:
L699             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L700         payload = {"text": message}
L701         try:
L702             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L703         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L704
L705
L706 def _infer_g_universe(feature_df, selected12=None, near5=None):
L707     try:
L708         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L709         if out: return out
L710     except Exception:
L711         pass
L712     base = set()
L713     for lst in (selected12 or []), (near5 or []):
L714         for x in (lst or []): base.add(x)
L715     return list(base) if base else list(feature_df.index)
L716
L717
L718 def _fmt_with_fire_mark(tickers, feature_df):
L719     out = []
L720     for t in tickers or []:
L721         try:
L722             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L723             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L724             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L725         except Exception:
L726             out.append(t)
L727     return out
L728
L729
L730 def _label_recent_event(t, feature_df):
L731     try:
L732         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L733         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L734         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L735         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L736         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L737     except Exception:
L738         pass
L739     return t
L740
L741
L742 # ===== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ==============================
L743
L744 def io_build_input_bundle() -> InputBundle:
L745     """
L746     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L747     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L748     """
L749     inp = Input(cand=cand, exist=exist, bench=bench,
L750                 price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY)
L751     state = inp.prepare_data()
L752     return InputBundle(
L753         cand=state["cand"], tickers=state["tickers"], bench=bench,
L754         data=state["data"], px=state["px"], spx=state["spx"],
L755         tickers_bulk=state["tickers_bulk"], info=state["info"],
L756         eps_df=state["eps_df"], fcf_df=state["fcf_df"],
L757         returns=state["returns"]
L758     )
L759
L760 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L761               n_target: int) -> tuple[list, float, float, float]:
L762     """
L763     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L764     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L765     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L766     """
L767     sc.cfg = cfg
L768
L769     if hasattr(sc, "score_build_features"):
L770         feat = sc.score_build_features(inb)
L771         if not hasattr(sc, "_feat_logged"):
L772             T.log("features built (scorer)")
L773             sc._feat_logged = True
L774         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L775     else:
L776         fb = sc.aggregate_scores(inb, cfg)
L777         if not hasattr(sc, "_feat_logged"):
L778             T.log("features built (scorer)")
L779             sc._feat_logged = True
L780         sc._feat = fb
L781         agg = fb.g_score if group == "G" else fb.d_score_all
L782         if group == "D" and hasattr(fb, "df"):
L783             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L784
L785     if hasattr(sc, "filter_candidates"):
L786         mask = sc.filter_candidates(inb, agg, group, cfg)
L787         agg = agg[mask]
L788
L789     selector = Selector()
L790     if hasattr(sc, "select_diversified"):
L791         pick, avg_r, sum_sc, obj = sc.select_diversified(
L792             agg, group, cfg, n_target,
L793             selector=selector, prev_tickers=None,
L794             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L795             cross_mu=cfg.drrs.cross_mu_gd
L796         )
L797     else:
L798         if group == "G":
L799             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L800             res = selector.select_bucket_drrs(
L801                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L802                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L803                 lam=cfg.drrs.G.get("lam", 0.68),
L804                 lookback=cfg.drrs.G.get("lookback", 252),
L805                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0
L806             )
L807         else:
L808             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L809             g_fixed = getattr(sc, "_top_G", None)
L810             res = selector.select_bucket_drrs(
L811                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L812                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L813                 lam=cfg.drrs.D.get("lam", 0.85),
L814                 lookback=cfg.drrs.D.get("lookback", 504),
L815                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L816                 mu=cfg.drrs.cross_mu_gd
L817             )
L818         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L819         sum_sc = res["sum_score"]; obj = res["objective"]
L820         if group == "D":
L821             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L822             T.log("selection finalized (G/D)")
L823     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L824     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L825     try:
L826         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L827         near10 = list(pool.sort_values(ascending=False).head(10).index)
L828         setattr(sc, f"_near_{group}", near10)
L829         setattr(sc, f"_agg_{group}", agg)
L830     except Exception:
L831         pass
L832
L833     if group == "D":
L834         T.log("save done")
L835     if group == "G":
L836         sc._top_G = pick
L837     return pick, avg_r, sum_sc, obj
L838
L839 def run_pipeline() -> SelectionBundle:
L840     """
L841     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L842     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L843     """
L844     inb = io_build_input_bundle()
L845     cfg = PipelineConfig(
L846         weights=WeightsConfig(g=g_weights, d=D_weights),
L847         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L848                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L849         price_max=CAND_PRICE_MAX
L850     )
L851     sc = Scorer()
L852     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L853     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L854     alpha = Scorer.spx_to_alpha(inb.spx)
L855     sectors = {t: (inb.info.get(t, {}).get("sector") or "U") for t in poolG}
L856     scores = {t: Scorer.g_score.get(t, 0.0) for t in poolG}
L857     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L858     sc._top_G = top_G
L859     try:
L860         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L861         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L862     except Exception:
L863         pass
L864     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L865     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L866     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L867     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L868     fb = getattr(sc, "_feat", None)
L869     near_G = getattr(sc, "_near_G", [])
L870     selected12 = list(top_G)
L871     df = fb.df if fb is not None else pd.DataFrame()
L872     guni = _infer_g_universe(df, selected12, near_G)
L873     try:
L874         fire_recent = [t for t in guni
L875                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L876                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L877     except Exception:
L878         fire_recent = []
L879
L880     # === å…ˆé ­ãƒ˜ãƒƒãƒ€ï¼ˆãƒ¢ãƒ¼ãƒ‰ãƒ»ã—ãã„å€¤ãƒ»åˆ†ä½ï¼‰ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯åŒ–ã—ã¦å·®ã—è¾¼ã¿ ===
L881     try:
L882         lead_lines, _mode = _build_breadth_lead_lines(inb)  # æ—¢å­˜ã®é–¢æ•°ï¼ˆä»¥å‰ã®æ”¹ä¿®ã§è¿½åŠ æ¸ˆã¿ï¼‰
L883         head_block = "```" + "\n".join(lead_lines) + "```"
L884     except Exception:
L885         head_block = ""  # ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ï¼ˆãƒ˜ãƒƒãƒ€ãªã—ã§ã‚‚å¾Œç¶šã¯ç¶™ç¶šï¼‰
L886
L887     lines = [
L888         head_block,
L889         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L890         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L891         f"é¸å®š12: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else "é¸å®š12: ãªã—",
L892         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",
L893     ]
L894
L895     if fire_recent:
L896         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L897         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L898     else:
L899         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L900
L901     try:
L902         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L903         if webhook:
L904             # å…ˆé ­ã® head_block ã‚’å«ã‚€è¤‡æ•°è¡Œã‚’ãã®ã¾ã¾é€ä¿¡ï¼ˆSlackå´ã§```ãŒã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æç”»ï¼‰
L905             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""] )}, timeout=10)
L906     except Exception:
L907         pass
L908
L909     out = Output(debug=debug_mode)
L910     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L911     try: out._sc = sc
L912     except Exception: pass
L913     if hasattr(sc, "_feat"):
L914         try:
L915             out.miss_df = sc._feat.missing_logs
L916             out.display_results(
L917                 exist=exist, bench=bench, df_z=sc._feat.df_z,
L918                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L919                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D
L920             )
L921         except Exception:
L922             pass
L923     out.notify_slack()
L924     sb = SelectionBundle(
L925         resG={"tickers": top_G, "avg_res_corr": avgG,
L926               "sum_score": sumG, "objective": objG},
L927         resD={"tickers": top_D, "avg_res_corr": avgD,
L928               "sum_score": sumD, "objective": objD},
L929         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D
L930     )
L931
L932     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L933     try:
L934         _low_df = (
L935             pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L936               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L937               .sort_values("G_plus_D")
L938               .head(10)
L939               .round(3)
L940         )
L941         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L942                "```"
L943                + _low_df.to_string(index=True, index_names=False)
L944                + "\n```")
L945     except Exception as _e:
L946         _slack(f"Low Score Candidates: ä½œæˆå¤±æ•—: {_e}")
L947
L948     if debug_mode:
L949         try:
L950             _slack_debug(_compact_debug(fb, sb, [], []))
L951         except Exception as e:
L952             print(f"[debug skipped] {e}")
L953
L954     return sb
L955
L956 if __name__ == "__main__":
L957     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py 
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None:
L43         return float(c)
L44     try:
L45         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L46         return float(h.iloc[-1]) if len(h) else np.nan
L47     except Exception:
L48         return np.nan
L49
L50 def _ttm_div_sum(t, lookback_days=400):
L51     try:
L52         div = yf.Ticker(t).dividends
L53         if div is None or len(div) == 0:
L54             return 0.0
L55         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L56         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L57         return ttm if ttm > 0 else float(div.tail(4).sum())
L58     except Exception:
L59         return 0.0
L60
L61 def ttm_div_yield_portfolio(tickers, price_map=None):
L62     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L63     return float(np.mean(ys)) if ys else 0.0
L64
L65 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L66 def winsorize_s(s: pd.Series, p=0.02):
L67     if s is None or s.dropna().empty: return s
L68     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L69
L70 def robust_z(s: pd.Series, p=0.02):
L71     s2 = winsorize_s(s, p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L72
L73 def _safe_div(a, b):
L74     try:
L75         if b is None or float(b)==0 or pd.isna(b): return np.nan
L76         return float(a)/float(b)
L77     except Exception: return np.nan
L78
L79 def _safe_last(series: pd.Series, default=np.nan):
L80     try: return float(series.iloc[-1])
L81     except Exception: return default
L82
L83 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L84
L85 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L86 class Scorer:
L87     """
L88     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L89     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L90     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L91     """
L92
L93     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L94     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L95     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L96
L97     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L98     @staticmethod
L99     def _validate_ib_for_scorer(ib: Any):
L100         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L101         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L102         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L103         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L104         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L105         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L106         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L107
L108     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L109     @staticmethod
L110     def trend(s: pd.Series):
L111         if len(s)<200: return np.nan
L112         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L113         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L114         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L115         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L116         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L117         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L118         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L119         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L120         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L121         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L122         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L123         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L124
L125     @staticmethod
L126     def rs(s, b):
L127         n, nb = len(s), len(b)
L128         if n<60 or nb<60: return np.nan
L129         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L130         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L131         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L132
L133     @staticmethod
L134     def tr_str(s):
L135         if len(s)<50: return np.nan
L136         return s.iloc[-1]/s.rolling(50).mean().iloc[-1] - 1
L137
L138     @staticmethod
L139     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L140         r = (s/b).dropna()
L141         if len(r) < win: return np.nan
L142         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L143         try: return float(np.polyfit(x, y, 1)[0])
L144         except Exception: return np.nan
L145
L146     @staticmethod
L147     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L148         ev = info_t.get('enterpriseValue', np.nan)
L149         if pd.notna(ev) and ev>0: return float(ev)
L150         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L151         try:
L152             bs = tk.quarterly_balance_sheet
L153             if bs is not None and not bs.empty:
L154                 c = bs.columns[0]
L155                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L156                     if k in bs.index: debt = float(bs.loc[k,c]); break
L157                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L158                     if k in bs.index: cash = float(bs.loc[k,c]); break
L159         except Exception: pass
L160         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L161         return np.nan
L162
L163     @staticmethod
L164     def dividend_status(ticker: str) -> str:
L165         t = yf.Ticker(ticker)
L166         try:
L167             if not t.dividends.empty: return "has"
L168         except Exception: return "unknown"
L169         try:
L170             a = t.actions
L171             if (a is not None and not a.empty and "Stock Splits" in a.columns and a["Stock Splits"].abs().sum()>0): return "none_confident"
L172         except Exception: pass
L173         try:
L174             fi = t.fast_info
L175             if any(getattr(fi,k,None) for k in ("last_dividend_date","dividend_rate","dividend_yield")): return "maybe_missing"
L176         except Exception: pass
L177         return "unknown"
L178
L179     @staticmethod
L180     def div_streak(t):
L181         try:
L182             divs = yf.Ticker(t).dividends.dropna(); ann = divs.groupby(divs.index.year).sum(); ann = ann[ann.index<pd.Timestamp.today().year]
L183             years, streak = sorted(ann.index), 0
L184             for i in range(len(years)-1,0,-1):
L185                 if ann[years[i]] > ann[years[i-1]]: streak += 1
L186                 else: break
L187             return streak
L188         except Exception: return 0
L189
L190     @staticmethod
L191     def fetch_finnhub_metrics(symbol):
L192         api_key = os.environ.get("FINNHUB_API_KEY")
L193         if not api_key: return {}
L194         url, params = "https://finnhub.io/api/v1/stock/metric", {"symbol":symbol,"metric":"all","token":api_key}
L195         try:
L196             r = requests.get(url, params=params, timeout=10); r.raise_for_status(); m = r.json().get("metric",{})
L197             return {'EPS':m.get('epsGrowthTTMYoy'),'REV':m.get('revenueGrowthTTMYoy'),'ROE':m.get('roeTTM'),'BETA':m.get('beta'),'DIV':m.get('dividendYieldIndicatedAnnual'),'FCF':(m.get('freeCashFlowTTM')/m.get('enterpriseValue')) if m.get('freeCashFlowTTM') and m.get('enterpriseValue') else None}
L198         except Exception: return {}
L199
L200     @staticmethod
L201     def calc_beta(series: pd.Series, market: pd.Series, lookback=252):
L202         r, m = series.pct_change().dropna(), market.pct_change().dropna()
L203         n = min(len(r), len(m), lookback)
L204         if n<60: return np.nan
L205         r, m = r.iloc[-n:], m.iloc[-n:]; cov, var = np.cov(r, m)[0,1], np.var(m)
L206         return np.nan if var==0 else cov/var
L207
L208     @staticmethod
L209     def spx_to_alpha(spx: pd.Series, bands=(0.03,0.10), w=(0.6,0.4),
L210                      span=5, q=(0.20,0.40), alphas=(0.05,0.08,0.10)) -> float:
L211         """
L212         S&P500æŒ‡æ•°ã®ã¿ã‹ã‚‰æ“¬ä¼¼breadthã‚’ä½œã‚Šã€å±¥æ­´åˆ†ä½ã§Î±ã‚’æ®µéšæ±ºå®šã€‚
L213         bands=(Â±3%, Â±10%), w=(50DMA,200DMA), åˆ†ä½q=(20%,40%), alphas=(ä½,ä¸­,é«˜)
L214         """
L215         ma50, ma200 = spx.rolling(50).mean(), spx.rolling(200).mean()
L216         b50  = ((spx/ma50 - 1) + bands[0])/(2*bands[0])
L217         b200 = ((spx/ma200 - 1) + bands[1])/(2*bands[1])
L218         hist = (w[0]*b50 + w[1]*b200).clip(0,1).ewm(span=span).mean()
L219         b = float(hist.iloc[-1])
L220         lo, mid = float(hist.quantile(q[0])), float(hist.quantile(q[1]))
L221         return alphas[0] if b < lo else alphas[1] if b < mid else alphas[2]
L222
L223     @staticmethod
L224     def soft_cap_effective_scores(scores: pd.Series|dict, sectors: dict, cap=2, alpha=0.08) -> pd.Series:
L225         """
L226         åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼capè¶…éï¼ˆ3æœ¬ç›®ä»¥é™ï¼‰ã« Î±Ã—æ®µéšæ¸›ç‚¹ã‚’èª²ã—ãŸâ€œæœ‰åŠ¹ã‚¹ã‚³ã‚¢â€Seriesã‚’è¿”ã™ã€‚
L227         æˆ»ã‚Šå€¤ã¯é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã€‚
L228         """
L229         s = pd.Series(scores, dtype=float); order = s.sort_values(ascending=False).index
L230         cnt, pen = {}, {}
L231         for t in order:
L232             sec = sectors.get(t, "U")
L233             k = cnt.get(sec, 0) + 1
L234             pen[t] = alpha * max(0, k - cap)
L235             cnt[sec] = k
L236         return (s - pd.Series(pen)).sort_values(ascending=False)
L237
L238     @staticmethod
L239     def pick_top_softcap(scores: pd.Series|dict, sectors: dict, N: int, cap=2, alpha=0.08, hard: int|None=5) -> list[str]:
L240         """
L241         soft-capé©ç”¨å¾Œã®ä¸Šä½Nãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚hard>0ãªã‚‰éå¸¸ç”¨ãƒãƒ¼ãƒ‰ä¸Šé™ã§åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼è¶…éã‚’é–“å¼•ãï¼ˆæ—¢å®š=5ï¼‰ã€‚
L242         """
L243         eff = Scorer.soft_cap_effective_scores(scores, sectors, cap, alpha)
L244         if not hard:
L245             return list(eff.head(N).index)
L246         pick, used = [], {}
L247         for t in eff.index:
L248             s = sectors.get(t, "U")
L249             if used.get(s, 0) < hard:
L250                 pick.append(t)
L251                 used[s] = used.get(s, 0) + 1
L252             if len(pick) == N:
L253                 break
L254         return pick
L255
L256     @staticmethod
L257     def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L258         """
L259         å„å–¶æ¥­æ—¥ã® trend_template åˆæ ¼æœ¬æ•°ï¼ˆåˆæ ¼â€œæœ¬æ•°â€=Cï¼‰ã‚’è¿”ã™ã€‚
L260         - px: åˆ—=tickerï¼ˆãƒ™ãƒ³ãƒã¯å«ã‚ãªã„ï¼‰
L261         - spx: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Seriesï¼ˆpx.index ã«æ•´åˆ—ï¼‰
L262         - win_days: æœ«å°¾ã®è¨ˆç®—å¯¾è±¡å–¶æ¥­æ—¥æ•°ï¼ˆNoneâ†’å…¨ä½“ã€æ—¢å®š600ã¯å‘¼ã³å‡ºã—å´æŒ‡å®šï¼‰
L263         ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼†rollingã®ã¿ã§è»½é‡ã€‚æ¬ æã¯ False æ‰±ã„ã€‚
L264         """
L265         import numpy as np, pandas as pd
L266         if px is None or px.empty:
L267             return pd.Series(dtype=int)
L268         px = px.dropna(how="all", axis=1)
L269         if win_days and win_days > 0:
L270             px = px.tail(win_days)
L271         if px.empty:
L272             return pd.Series(dtype=int)
L273         spx = spx.reindex(px.index).ffill()
L274
L275         ma50  = px.rolling(50).mean()
L276         ma150 = px.rolling(150).mean()
L277         ma200 = px.rolling(200).mean()
L278
L279         tt = (px > ma150)
L280         tt &= (px > ma200)
L281         tt &= (ma150 > ma200)
L282         tt &= (ma200 - ma200.shift(21) > 0)
L283         tt &= (ma50  > ma150)
L284         tt &= (ma50  > ma200)
L285         tt &= (px    > ma50)
L286
L287         lo252 = px.rolling(252).min()
L288         hi252 = px.rolling(252).max()
L289         tt &= (px.divide(lo252).sub(1.0) >= 0.30)   # P_OVER_LOW52 >= 0.30
L290         tt &= (px >= (0.75 * hi252))                # NEAR_52W_HIGH >= -0.25
L291
L292         r12  = px.divide(px.shift(252)).sub(1.0)
L293         br12 = spx.divide(spx.shift(252)).sub(1.0)
L294         r1   = px.divide(px.shift(22)).sub(1.0)
L295         br1  = spx.divide(spx.shift(22)).sub(1.0)
L296         rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L297         tt &= (rs >= 0.10)
L298
L299         return tt.fillna(False).sum(axis=1).astype(int)
L300
L301     # ---- ã‚¹ã‚³ã‚¢é›†è¨ˆï¼ˆDTO/Configã‚’å—ã‘å–ã‚Šã€FeatureBundleã‚’è¿”ã™ï¼‰ ----
L302     def aggregate_scores(self, ib: Any, cfg):
L303         if cfg is None:
L304             raise ValueError("cfg is required; pass factor.PipelineConfig")
L305         self._validate_ib_for_scorer(ib)
L306
L307         px, spx, tickers = ib.px, ib.spx, ib.tickers
L308         tickers_bulk, info, eps_df, fcf_df = ib.tickers_bulk, ib.info, ib.eps_df, ib.fcf_df
L309
L310         df, missing_logs = pd.DataFrame(index=tickers), []
L311         for t in tickers:
L312             d, s = info[t], px[t]; ev = self.ev_fallback(d, tickers_bulk.tickers[t])
L313             # --- åŸºæœ¬ç‰¹å¾´ ---
L314             df.loc[t,'TR']   = self.trend(s)
L315             df.loc[t,'EPS']  = eps_df.loc[t,'EPS_TTM'] if t in eps_df.index else np.nan
L316             df.loc[t,'REV']  = d.get('revenueGrowth',np.nan)
L317             df.loc[t,'ROE']  = d.get('returnOnEquity',np.nan)
L318             df.loc[t,'BETA'] = self.calc_beta(s, spx, lookback=252)
L319
L320             # --- é…å½“ï¼ˆæ¬ æè£œå®Œå«ã‚€ï¼‰ ---
L321             div = d.get('dividendYield') if d.get('dividendYield') is not None else d.get('trailingAnnualDividendYield')
L322             if div is None or pd.isna(div):
L323                 try:
L324                     divs = yf.Ticker(t).dividends
L325                     if divs is not None and not divs.empty:
L326                         last_close = s.iloc[-1]; div_1y = divs[divs.index >= (divs.index.max() - pd.Timedelta(days=365))].sum()
L327                         if last_close and last_close>0: div = float(div_1y/last_close)
L328                 except Exception: pass
L329             df.loc[t,'DIV'] = 0.0 if (div is None or pd.isna(div)) else float(div)
L330
L331             # --- FCF/EV ---
L332             fcf_val = fcf_df.loc[t,'FCF_TTM'] if t in fcf_df.index else np.nan
L333             df.loc[t,'FCF'] = (fcf_val/ev) if (pd.notna(fcf_val) and pd.notna(ev) and ev>0) else np.nan
L334
L335             # --- ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ»ãƒœãƒ©é–¢é€£ ---
L336             df.loc[t,'RS'], df.loc[t,'TR_str'] = self.rs(s, spx), self.tr_str(s)
L337             r, rm = s.pct_change().dropna(), spx.pct_change().dropna()
L338             n = int(min(len(r), len(rm)))
L339
L340             DOWNSIDE_DEV = np.nan
L341             if n>=60:
L342                 r6 = r.iloc[-min(len(r),126):]; neg = r6[r6<0]
L343                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L344             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L345
L346             MDD_1Y = np.nan
L347             try:
L348                 w = s.iloc[-min(len(s),252):].dropna()
L349                 if len(w)>=30:
L350                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L351             except Exception: pass
L352             df.loc[t,'MDD_1Y'] = MDD_1Y
L353
L354             RESID_VOL = np.nan
L355             if n>=120:
L356                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L357                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L358                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L359                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L360             df.loc[t,'RESID_VOL'] = RESID_VOL
L361
L362             DOWN_OUTPERF = np.nan
L363             if n>=60:
L364                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L365                 if mask.sum()>=10:
L366                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L367                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L368             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L369
L370             # --- é•·æœŸç§»å‹•å¹³å‡/ä½ç½® ---
L371             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L372             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L373
L374             # --- é…å½“ã®è©³ç´°ç³» ---
L375             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L376             try:
L377                 divs = yf.Ticker(t).dividends.dropna()
L378                 if not divs.empty:
L379                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L380                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L381                     ann = divs.groupby(divs.index.year).sum()
L382                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L383                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L384                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L385                 so = d.get('sharesOutstanding',None)
L386                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L387                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L388             except Exception: pass
L389             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L390
L391             # --- è²¡å‹™å®‰å®šæ€§ ---
L392             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L393
L394             # --- EPS å¤‰å‹• ---
L395             EPS_VAR_8Q = np.nan
L396             try:
L397                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L398                 if qe is not None and not qe.empty and so:
L399                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L400                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L401             except Exception: pass
L402             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L403
L404             # --- ã‚µã‚¤ã‚º/æµå‹•æ€§ ---
L405             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L406             try:
L407                 vol_series = ib.data['Volume'][t].dropna()
L408                 if len(vol_series)>=5 and len(s)==len(vol_series):
L409                     dv = (vol_series*s).rolling(60).mean(); adv60 = float(dv.iloc[-1])
L410             except Exception: pass
L411             df.loc[t,'ADV60_USD'] = adv60
L412
L413             # --- å£²ä¸Š/åˆ©ç›Šã®åŠ é€Ÿåº¦ç­‰ ---
L414             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L415             REV_ANNUAL_STREAK = np.nan
L416             try:
L417                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L418                 if qe is not None and not qe.empty:
L419                     if 'Revenue' in qe.columns:
L420                         rev = qe['Revenue'].dropna().astype(float)
L421                         if len(rev)>=5: REV_Q_YOY = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5])
L422                         if len(rev)>=6:
L423                             yoy_now = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5]); yoy_prev = _safe_div(rev.iloc[-2]-rev.iloc[-6], rev.iloc[-6])
L424                             if pd.notna(yoy_now) and pd.notna(yoy_prev): REV_YOY_ACC = yoy_now - yoy_prev
L425                         yoy_list=[]
L426                         for k in range(1,5):
L427                             if len(rev)>=4+k:
L428                                 y = _safe_div(rev.iloc[-k]-rev.iloc[-(k+4)], rev.iloc[-(k+4)])
L429                                 if pd.notna(y): yoy_list.append(y)
L430                         if len(yoy_list)>=2: REV_YOY_VAR = float(np.std(yoy_list, ddof=1))
L431                         # NEW: å¹´æ¬¡ã®æŒç¶šæ€§ï¼ˆç›´è¿‘ã‹ã‚‰é¡ã£ã¦å‰å¹´æ¯”ãƒ—ãƒ©ã‚¹ãŒä½•å¹´é€£ç¶šã‹ã€å››åŠæœŸ4æœ¬æƒã†å®Œå…¨å¹´ã®ã¿ï¼‰
L432                         try:
L433                             g = rev.groupby(rev.index.year)
L434                             ann_sum, cnt = g.sum(), g.count()
L435                             ann_sum = ann_sum[cnt >= 4]
L436                             if len(ann_sum) >= 3:
L437                                 yoy = ann_sum.pct_change().dropna()
L438                                 streak = 0
L439                                 for v in yoy.iloc[::-1]:
L440                                     if pd.isna(v) or v <= 0:
L441                                         break
L442                                     streak += 1
L443                                 REV_ANNUAL_STREAK = float(streak)
L444                         except Exception:
L445                             pass
L446                     if 'Earnings' in qe.columns and so:
L447                         eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L448                         if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L449                             EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L450             except Exception: pass
L451             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'], df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_Q_YOY, EPS_Q_YOY, REV_YOY_ACC, REV_YOY_VAR
L452             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L453
L454             # --- Rule of 40 ã‚„å‘¨è¾º ---
L455             total_rev_ttm = d.get('totalRevenue',np.nan)
L456             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L457             df.loc[t,'FCF_MGN'] = FCF_MGN
L458             rule40 = np.nan
L459             try:
L460                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L461             except Exception: pass
L462             df.loc[t,'RULE40'] = rule40
L463
L464             # --- ãƒˆãƒ¬ãƒ³ãƒ‰è£œåŠ© ---
L465             sma50  = s.rolling(50).mean()
L466             sma150 = s.rolling(150).mean()
L467             sma200 = s.rolling(200).mean()
L468             p = _safe_last(s)
L469
L470             df.loc[t,'MA50_OVER_150'] = (
L471                 _safe_last(sma50)/_safe_last(sma150) - 1
L472                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L473             )
L474             df.loc[t,'MA150_OVER_200'] = (
L475                 _safe_last(sma150)/_safe_last(sma200) - 1
L476                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L477             )
L478
L479             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L480             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L481
L482             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L483             if len(sma200.dropna()) >= 21:
L484                 cur200 = _safe_last(sma200)
L485                 old2001 = float(sma200.iloc[-21])
L486                 if old2001:
L487                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L488
L489             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L490             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L491             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L492             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L493             if len(sma200.dropna())>=105:
L494                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L495                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L496             # NEW: 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ãã®ã€Œæ—¥æ•°ã€
L497             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L498             try:
L499                 s200 = sma200.dropna()
L500                 if len(s200) >= 2:
L501                     diff200 = s200.diff()
L502                     up = 0
L503                     for v in diff200.iloc[::-1]:
L504                         if pd.isna(v) or v <= 0:
L505                             break
L506                         up += 1
L507                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L508             except Exception:
L509                 pass
L510             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L511             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L512             if hi52 and hi52>0 and pd.notna(p):
L513                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L514             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L515             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L516
L517             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L518
L519             # --- æ¬ æãƒ¡ãƒ¢ ---
L520             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L521             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L522             if need_finnhub:
L523                 fin_data = self.fetch_finnhub_metrics(t)
L524                 for col in need_finnhub:
L525                     val = fin_data.get(col)
L526                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L527             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L528                 if pd.isna(df.loc[t,col]):
L529                     if col=='DIV':
L530                         status = self.dividend_status(t)
L531                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L532                     else:
L533                         missing_logs.append({'Ticker':t,'Column':col})
L534
L535         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L536             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L537             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L538             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L539             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L540             c5 = (row.get('TR_str', np.nan) > 0)
L541             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L542             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L543             c8 = (row.get('RS', np.nan) >= 0.10)
L544             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L545
L546         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L547         assert 'trend_template' in df.columns
L548
L549         # === ZåŒ–ã¨åˆæˆ ===
L550         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L551
L552         df_z = pd.DataFrame(index=df.index)
L553         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L554         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L555         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L556         for col in ['REV_Q_YOY','EPS_Q_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']: df_z[col] = robust_z(df[col])
L557         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L558
L559         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L560         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L561         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L562         df_z['GROWTH_F']  = robust_z(
L563               0.25*df_z['REV']          # â†“0.30â†’0.25
L564             + 0.20*df_z['EPS_Q_YOY']
L565             + 0.15*df_z['REV_Q_YOY']
L566             + 0.15*df_z['REV_YOY_ACC']
L567             + 0.10*df_z['RULE40']
L568             + 0.10*df_z['FCF_MGN']
L569             + 0.10*df_z['EPS']          # â˜…è¿½åŠ ï¼šé»’å­—å„ªé‡ï¼èµ¤å­—æ¸›ç‚¹
L570             + 0.05*df_z['REV_ANN_STREAK']
L571             - 0.05*df_z['REV_YOY_VAR']
L572         ).clip(-3.0,3.0)
L573         df_z['MOM_F'] = robust_z(
L574               0.40*df_z['RS']
L575             + 0.15*df_z['TR_str']
L576             + 0.15*df_z['RS_SLOPE_6W']
L577             + 0.15*df_z['RS_SLOPE_13W']
L578             + 0.10*df_z['MA200_SLOPE_5M']
L579             + 0.10*df_z['MA200_UP_STREAK_D']
L580         ).clip(-3.0,3.0)
L581         df_z['VOL'] = robust_z(df['BETA'])
L582         df_z.rename(columns={'GROWTH_F':'GRW','MOM_F':'MOM','QUALITY_F':'QAL','YIELD_F':'YLD'}, inplace=True)
L583
L584         # === begin: BIO LOSS PENALTY =====================================
L585         try:
L586             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L587         except Exception:
L588             penalty_z = 0.8
L589
L590         def _is_bio_like(t: str) -> bool:
L591             inf = info.get(t, {}) if isinstance(info, dict) else {}
L592             sec = str(inf.get("sector", "")).lower()
L593             ind = str(inf.get("industry", "")).lower()
L594             if "health" not in sec:
L595                 return False
L596             keys = ("biotech", "biopharma", "pharma")
L597             return any(k in ind for k in keys)
L598
L599         tickers_s = pd.Index(df_z.index)
L600         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L601         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L602         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L603
L604         if bool(mask_bio_loss.any()) and penalty_z > 0:
L605             df_z.loc[mask_bio_loss, "GRW"] = df_z.loc[mask_bio_loss, "GRW"] - penalty_z
L606             df_z["GRW"] = df_z["GRW"].clip(-3.0, 3.0)
L607         # === end: BIO LOSS PENALTY =======================================
L608
L609         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L610         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L611
L612         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L613         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L614         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L615         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L616
L617         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L618         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L619         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L620
L621         d_comp = pd.concat({
L622             'QAL': df_z['D_QAL'],
L623             'YLD': df_z['D_YLD'],
L624             'VOL': df_z['D_VOL_RAW'],
L625             'TRD': df_z['D_TRD']
L626         }, axis=1)
L627         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L628         globals()['D_WEIGHTS_EFF'] = dw.copy()
L629         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L630
L631         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L632         mask = df['trend_template']
L633         if not bool(mask.any()):
L634             mask = (
L635                 (df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L636                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L637                 (df.get('RS', np.nan) >= 0.08) &
L638                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L639                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L640                 (df.get('MA150_OVER_200', np.nan) > 0) &
L641                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L642                 (df.get('TR_str', np.nan) > 0)
L643             ).fillna(False)
L644             df['trend_template'] = mask
L645
L646         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L647         g_score = g_score_all.loc[mask]
L648         Scorer.g_score = g_score
L649         df_z['GSC'] = g_score_all
L650         df_z['DSC'] = d_score_all
L651
L652         try:
L653             current = (
L654                 pd.read_csv("current_tickers.csv")
L655                   .iloc[:, 0]
L656                   .str.upper()
L657                   .tolist()
L658             )
L659         except FileNotFoundError:
L660             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L661             current = []
L662
L663         mask_bonus = g_score.index.isin(current)
L664         if mask_bonus.any():
L665             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L666             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L667             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L668             sigma_g = g_score.std()
L669             if pd.isna(sigma_g):
L670                 sigma_g = 0.0
L671             bonus_g = round(k * sigma_g, 3)
L672             g_score.loc[mask_bonus] += bonus_g
L673             Scorer.g_score = g_score
L674             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L675             sigma_d = d_score_all.std()
L676             if pd.isna(sigma_d):
L677                 sigma_d = 0.0
L678             bonus_d = round(k * sigma_d, 3)
L679             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L680
L681         try:
L682             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L683         except Exception:
L684             pass
L685
L686         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L687         return FeatureBundle(
L688             df=df,
L689             df_z=df_z,
L690             g_score=g_score,
L691             d_score_all=d_score_all,
L692             missing_logs=pd.DataFrame(missing_logs)
L693         )
L694
L695
L696 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L697     """
L698     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L699     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L700       - G_BREAKOUT_recent_5d : bool
L701       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L702       - G_PULLBACK_recent_5d : bool
L703       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L704       - G_PIVOT_price        : float
L705     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L706     """
L707     try:
L708         px   = bundle.px                      # çµ‚å€¤ DataFrame
L709         hi   = bundle.data['High']
L710         lo   = bundle.data['Low']
L711         vol  = bundle.data['Volume']
L712         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L713
L714         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L715         g_universe = getattr(self_obj, "g_universe", None)
L716         if g_universe is None:
L717             try:
L718                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L719             except Exception:
L720                 g_universe = list(feature_df.index)
L721         if not g_universe:
L722             return feature_df
L723
L724         # æŒ‡æ¨™
L725         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L726         ma50  = px[g_universe].rolling(50).mean()
L727         ma150 = px[g_universe].rolling(150).mean()
L728         ma200 = px[g_universe].rolling(200).mean()
L729         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L730         vol20 = vol[g_universe].rolling(20).mean()
L731         vol50 = vol[g_universe].rolling(50).mean()
L732
L733         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L734         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L735                             & (ma150 > ma200) & (ma200.diff() > 0)
L736
L737         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L738         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L739
L740         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L741         bench_aligned = bench.reindex(px.index).ffill()
L742         rs = px[g_universe].div(bench_aligned, axis=0)
L743         rs_high = rs.rolling(252).max().shift(1)
L744
L745         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L746         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L747                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L748         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L749
L750         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L751         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L752         volume_dryup = (vol20 / vol50) <= 1.0
L753         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L754         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L755         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L756
L757         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L758         rows = []
L759         for t in g_universe:
L760             def _recent_and_date(s, win):
L761                 sw = s[t].iloc[-win:]
L762                 if sw.any():
L763                     d = sw[sw].index[-1]
L764                     return True, d.strftime("%Y-%m-%d")
L765                 return False, ""
L766             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L767             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L768             rows.append((t, {
L769                 "G_BREAKOUT_recent_5d": br_recent,
L770                 "G_BREAKOUT_last_date": br_date,
L771                 "G_PULLBACK_recent_5d": pb_recent,
L772                 "G_PULLBACK_last_date": pb_date,
L773                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L774             }))
L775         flags = pd.DataFrame({k: v for k, v in rows}).T
L776
L777         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L778         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L779         for c in cols:
L780             if c not in feature_df.columns:
L781                 feature_df[c] = np.nan
L782         feature_df.loc[flags.index, flags.columns] = flags
L783
L784     except Exception:
L785         pass
L786     return feature_df
L787
L788
L789
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v3
L24
L25       - name: Setup Python
L26         uses: actions/setup-python@v5
L27         with:
L28           python-version: '3.x'
L29           cache: 'pip'
L30           cache-dependency-path: requirements.txt
L31
L32       - name: Install dependencies
L33         run: pip install -r requirements.txt
L34
L35       - name: Prepare results directory
L36         run: mkdir -p results
L37
L38       - name: Run factor & scoring
L39         env:
L40           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L41           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L42           FIN_THREADS: "8"
L43         run: python factor.py
L44       - name: Persist breadth mode (if changed)
L45         run: |
L46           git config user.name "github-actions[bot]"
L47           git config user.email "github-actions[bot]@users.noreply.github.com"
L48           git add results/breadth_state.json || true
L49           if ! git diff --cached --quiet; then
L50             git commit -m "chore: update breadth_state.json [skip ci]" || true
L51             git push || true
L52           else
L53             echo "No breadth_state.json changes."
L54           fi
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 25éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š4%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6
L7 ## Barbell Growth-Defenseæ–¹é‡
L8 - Growthæ 12éŠ˜æŸ„ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L9 - Defenseæ 13éŠ˜æŸ„ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L10 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L11
L12 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L13 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**
L14 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L15   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L16   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= 1.5Ã—N_Gï¼‰
L17   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L18 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯18æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯36æœ¬ä»¥ä¸Šï¼‰
L19
L20 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L21 - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **10%**
L22 - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23 - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ25Ã—4%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L24
L25 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ï¼ˆçµ±ä¸€ï¼‰
L26 - G/D å…±é€šã® **åŸºæœ¬TS=15%**
L27 - å«ã¿ç›ŠãŒ **+20% / +40% / +60%** åˆ°é”ã§ TS ã‚’ **12% / 9% / 7%** ã«æ®µéšå¼•ãä¸Šã’
L28 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L29
L30 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L31 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L32 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L33
L34 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L35 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L36
L37 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L38 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L39 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/factor_design.md>
```text
L1 # factor.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®éŠ˜æŸ„ã¨æ¤œè¨ä¸­ã®éŠ˜æŸ„ç¾¤ã‚’åŒæ™‚ã«æ‰±ã†éŠ˜æŸ„é¸å®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
L5 - ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨DRRSé¸å®šã‚’è¡Œã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚
L6   - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚æ¼ã‚ŒãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L7   - IN/OUTã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨OUTå´ã®ä½ã‚¹ã‚³ã‚¢éŠ˜æŸ„
L8   - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨
L9   - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ•´ç†ç”¨ï¼‰
L10
L11 ## å…¨ä½“ãƒ•ãƒ­ãƒ¼
L12 1. **Input** â€“ `current_tickers.csv`ã¨`candidate_tickers.csv`ã‚’èª­ã¿è¾¼ã¿ã€yfinanceã‚„Finnhubã®APIã‹ã‚‰ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦`InputBundle`ã‚’æ•´å‚™ã€‚
L13 2. **Score Calculation** â€“ ScorerãŒç‰¹å¾´é‡ã‚’è¨ˆç®—ã—å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã—ã¦`FeatureBundle`ã‚’ç”Ÿæˆã€‚
L14 3. **Correlation Reduction & Selection** â€“ SelectorãŒDRRSãƒ­ã‚¸ãƒƒã‚¯ã§ç›¸é–¢ã‚’æŠ‘ãˆã¤ã¤G/DéŠ˜æŸ„ã‚’é¸å®šã—`SelectionBundle`ã‚’å¾—ã‚‹ã€‚
L15 4. **Output** â€“ æ¡ç”¨çµæœã¨å‘¨è¾ºæƒ…å ±ã‚’è¡¨ãƒ»Slacké€šçŸ¥ã¨ã—ã¦å‡ºåŠ›ã€‚
L16
L17 ```mermaid
L18 flowchart LR
L19   A[Input\nAPI & å‰å‡¦ç†] --> B[Score Calculation\nç‰¹å¾´é‡ãƒ»å› å­åˆæˆ]
L20   B --> C[Correlation Reduction\nDRRSé¸å®š]
L21   C --> D[Output\nSlacké€šçŸ¥]
L22 ```
L23
L24 ## å®šæ•°ãƒ»è¨­å®š
L25 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L26 | --- | --- | --- |
L27 | `exist` / `cand` | ç¾è¡Œãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æ¤œè¨ä¸­éŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ | ã‚¹ã‚³ã‚¢å¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã®æ§‹æˆã€å€™è£œæ•´ç† |
L28 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L29 | `CAND_PRICE_MAX` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | é«˜é¡éŠ˜æŸ„ã®äº‹å‰é™¤å¤– |
L30 | `N_G` / `N_D` | G/Dæ¡ç”¨æ ã®ä»¶æ•° | æœ€çµ‚çš„ã«é¸ã¶éŠ˜æŸ„æ•°ã®åˆ¶ç´„ |
L31 | `g_weights` / `D_weights` | å„å› å­ã®é‡ã¿dict | G/Dã‚¹ã‚³ã‚¢åˆæˆ |
L32 | `D_BETA_MAX` | Dãƒã‚±ãƒƒãƒˆã®è¨±å®¹Î²ä¸Šé™ | é«˜Î²éŠ˜æŸ„ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ |
L33 | `FILTER_SPEC` | G/Dã”ã¨ã®å‰å‡¦ç†ãƒ•ã‚£ãƒ«ã‚¿ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¹ã‚¯ã‚„Î²ä¸Šé™è¨­å®š |
L34 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L35 | `DRRS_G` / `DRRS_D` | DRRSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç›¸é–¢ä½æ¸›è¨­å®š |
L36 | `DRRS_SHRINK` | æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å®‰å®šåŒ– |
L37 | `CROSS_MU_GD` | G-Dé–“ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ | 2ãƒã‚±ãƒƒãƒˆåŒæ™‚æœ€é©åŒ–ã§ç›¸é–¢æŠ‘åˆ¶ |
L38 | `RESULTS_DIR` | é¸å®šçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `_save_sel`/`_load_prev`ã®å…¥å‡ºåŠ› |
L39
L40 é¸å®šçµæœã¯`results/`é…ä¸‹ã«JSONã¨ã—ã¦ä¿å­˜ã—ã€æ¬¡å›å®Ÿè¡Œæ™‚ã«`_load_prev`ã§èª­ã¿è¾¼ã‚“ã§é¸å®šæ¡ä»¶ã«åæ˜ ã€‚
L41
L42 ## DTO/Config
L43 å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨è¨­å®šå€¤ã€‚å¤‰æ•°ã®æ„å‘³åˆã„ã¨åˆ©ç”¨ç®‡æ‰€ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚
L44
L45 ### InputBundleï¼ˆInput â†’ Scorerï¼‰
L46 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L47 | --- | --- | --- |
L48 | `cand` | å€™è£œéŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆ | OUTãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æ¯é›†å›£ |
L49 | `tickers` | ç¾è¡Œ+å€™è£œã‚’åˆã‚ã›ãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ | ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®— |
L50 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L51 | `data` | yfinanceã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœï¼ˆéšå±¤åˆ—ï¼‰ | `px`/`spx`/ãƒªã‚¿ãƒ¼ãƒ³ç­‰ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿ |
L52 | `px` | `data['Close']`ã ã‘ã‚’æŠœãå‡ºã—ãŸä¾¡æ ¼ç³»åˆ— | æŒ‡æ¨™è¨ˆç®—ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ç”Ÿæˆ |
L53 | `spx` | `data['Close'][bench]` ã®Series | `rs`ã‚„`calc_beta`ã®åŸºæº–æŒ‡æ•° |
L54 | `tickers_bulk` | `yf.Tickers`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | `info`ç­‰ã®ä¸€æ‹¬å–å¾— |
L55 | `info` | ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã®yfinanceæƒ…å ±dict | ã‚»ã‚¯ã‚¿ãƒ¼åˆ¤å®šã‚„EPSè£œå®Œ |
L56 | `eps_df` | EPS TTM/ç›´è¿‘EPSç­‰ã‚’ã¾ã¨ã‚ãŸè¡¨ | æˆé•·æŒ‡æ¨™ã®ç®—å‡º |
L57 | `fcf_df` | CFOãƒ»CapExãƒ»FCF TTMã¨æƒ…å ±æºãƒ•ãƒ©ã‚° | FCF/EVã‚„é…å½“ã‚«ãƒãƒ¬ãƒƒã‚¸ |
L58 | `returns` | `px.pct_change()`ã®ãƒªã‚¿ãƒ¼ãƒ³è¡¨ | ç›¸é–¢è¡Œåˆ—ãƒ»DRRSè¨ˆç®— |
L59
L60 ### FeatureBundleï¼ˆScorer â†’ Selectorï¼‰
L61 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L62 | --- | --- | --- |
L63 | `df` | è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™ã®ç”Ÿå€¤ãƒ†ãƒ¼ãƒ–ãƒ« | ãƒ‡ãƒãƒƒã‚°ãƒ»å‡ºåŠ›è¡¨ç¤º |
L64 | `df_z` | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å¾ŒZã‚¹ã‚³ã‚¢åŒ–ã—ãŸæŒ‡æ¨™è¡¨ | å› å­ã‚¹ã‚³ã‚¢åˆæˆã€é¸å®šåŸºæº– |
L65 | `g_score` | Gãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ | Gé¸å®šã€IN/OUTæ¯”è¼ƒ |
L66 | `d_score_all` | Dãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ï¼ˆå…¨éŠ˜æŸ„ï¼‰ | Dé¸å®šã€ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
L67 | `missing_logs` | æ¬ ææŒ‡æ¨™ã¨è£œå®ŒçŠ¶æ³ã®ãƒ­ã‚° | ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ |
L68
L69 ### SelectionBundleï¼ˆSelector â†’ Outputï¼‰
L70 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L71 | --- | --- | --- |
L72 | `resG` | Gé¸å®šçµæœã®è©³ç´°dictï¼ˆ`tickers`ã€ç›®çš„å€¤ç­‰ï¼‰ | çµæœä¿å­˜ãƒ»å¹³å‡ç›¸é–¢ãªã©ã®æŒ‡æ¨™è¡¨ç¤º |
L73 | `resD` | Dé¸å®šçµæœã®è©³ç´°dict | åŒä¸Š |
L74 | `top_G` | æœ€çµ‚æ¡ç”¨Gãƒ†ã‚£ãƒƒã‚«ãƒ¼ | æ–°ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ |
L75 | `top_D` | æœ€çµ‚æ¡ç”¨Dãƒ†ã‚£ãƒƒã‚«ãƒ¼ | åŒä¸Š |
L76 | `init_G` | DRRSå‰ã®GåˆæœŸå€™è£œ | æƒœã—ãã‚‚å¤–ã‚ŒãŸéŠ˜æŸ„è¡¨ç¤º |
L77 | `init_D` | DRRSå‰ã®DåˆæœŸå€™è£œ | åŒä¸Š |
L78
L79 ### WeightsConfig
L80 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L81 | --- | --- | --- |
L82 | `g` | Gå› å­ï¼ˆGRW/MOM/VOLï¼‰ã®é‡ã¿dict | `g_score`åˆæˆ |
L83 | `d` | Då› å­ï¼ˆD_QAL/D_YLD/D_VOL_RAW/D_TRDï¼‰ã®é‡ã¿dict | `d_score_all`åˆæˆ |
L84
L85 ### DRRSParams
L86 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L87 | --- | --- | --- |
L88 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L89 | `shrink` | æ®‹å·®ç›¸é–¢ã®ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å¯¾è§’å¼·èª¿ |
L90 | `G` | Gãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dictï¼ˆ`lookback`ç­‰ï¼‰ | `select_bucket_drrs`è¨­å®š |
L91 | `D` | Dãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | åŒä¸Š |
L92 | `cross_mu_gd` | G-Dã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°Î¼ | `select_buckets`ã®ç›®çš„é–¢æ•° |
L93
L94 ### PipelineConfig
L95 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L96 | --- | --- | --- |
L97 | `weights` | `WeightsConfig`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | ã‚¹ã‚³ã‚¢åˆæˆã®é‡ã¿å‚ç…§ |
L98 | `drrs` | `DRRSParams`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | é¸å®šã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šå€¤ |
L99 | `price_max` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | Inputæ®µéšã§ã®ãƒ•ã‚£ãƒ«ã‚¿ |
L100
L101 ## å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
L102 - `winsorize_s` / `robust_z` : å¤–ã‚Œå€¤å‡¦ç†ã¨Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L103 - `_safe_div` / `_safe_last` : ä¾‹å¤–ã‚’æ½°ã—ãŸåˆ†å‰²ãƒ»æœ«å°¾å–å¾—ã€‚
L104 - `_load_prev` / `_save_sel` : é¸å®šçµæœã®èª­ã¿æ›¸ãã€‚
L105
L106 ## ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
L107 ### Step1: Input
L108 `current_tickers.csv`ã®ç¾è¡ŒéŠ˜æŸ„ã¨`candidate_tickers.csv`ã®æ¤œè¨ä¸­éŠ˜æŸ„ã‚’èµ·ç‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã™ã‚‹ã€‚å¤–éƒ¨I/Oã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€`prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¯**yfinanceã‚’å„ªå…ˆã—ã€æ¬ æãŒã‚ã‚‹æŒ‡æ¨™ã®ã¿Finnhub APIã§è£œå®Œ**ã™ã‚‹ã€‚
L109 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L110 - `impute_eps_ttm` : å››åŠæœŸEPSÃ—4ã§TTMã‚’æ¨å®šã—æ¬ ææ™‚ã®ã¿å·®ã—æ›¿ãˆã€‚
L111 - `fetch_cfo_capex_ttm_yf` : yfinanceã®å››åŠæœŸ/å¹´æ¬¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‹ã‚‰CFOãƒ»CapExãƒ»FCF TTMã‚’ç®—å‡ºã€‚
L112 - `fetch_cfo_capex_ttm_finnhub` : yfinanceã§æ¬ ã‘ãŸéŠ˜æŸ„ã®ã¿Finnhub APIã§è£œå®Œã€‚
L113 - `compute_fcf_with_fallback` : yfinanceå€¤ã‚’åŸºæº–ã«Finnhubå€¤ã§ç©´åŸ‹ã‚ã—ã€CFO/CapEx/FCFã¨æƒ…å ±æºãƒ•ãƒ©ã‚°ã‚’è¿”ã™ã€‚
L114 - `_build_eps_df` : `info`ã‚„`quarterly_earnings`ã‹ã‚‰EPS TTMã¨ç›´è¿‘EPSã‚’è¨ˆç®—ã—ã€`impute_eps_ttm`ã§è£œå®Œã€‚
L115 - `prepare_data` :
L116     0. CSVã‹ã‚‰ç¾è¡ŒéŠ˜æŸ„ã¨å€™è£œéŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
L117     1. å€™è£œéŠ˜æŸ„ã®ç¾åœ¨å€¤ã‚’å–å¾—ã—ä¾¡æ ¼ä¸Šé™ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
L118     2. æ—¢å­˜+å€™è£œã‹ã‚‰å¯¾è±¡ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’æ±ºå®šã—ã€ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆyfinanceï¼‰ã€‚
L119     3. yfinanceå€¤ã‚’åŸºã«EPS/FCFãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç³»åˆ—ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ¬ æã‚»ãƒ«ã¯Finnhubå‘¼ã³å‡ºã—ã§ç©´åŸ‹ã‚ã€‚
L120     4. ä¸Šè¨˜ã‚’`InputBundle`ã«æ ¼ç´ã—ã¦è¿”ã™ã€‚
L121
L122 ### Step2: Score Calculation (Scorer)
L123 ç‰¹å¾´é‡è¨ˆç®—ã¨ã‚¹ã‚³ã‚¢åˆæˆã‚’æ‹…å½“ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L124
L125 #### è£œåŠ©é–¢æ•°
L126 - `trend(s)` : 50/150/200æ—¥ç§»å‹•å¹³å‡ã‚„52é€±ãƒ¬ãƒ³ã‚¸ã‹ã‚‰-0.5ã€œ0.5ã§æ§‹æˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ã€‚
L127 - `rs(s,b)` / `tr_str(s)` / `rs_line_slope(s,b,win)` : ç›¸å¯¾å¼·ã•ã‚„çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã€RSå›å¸°å‚¾ãã‚’ç®—å‡ºã€‚
L128 - `ev_fallback` : `enterpriseValue`æ¬ ææ™‚ã«è² å‚µãƒ»ç¾é‡‘ã‹ã‚‰EVã‚’æ¨å®šã€‚
L129 - `dividend_status` / `div_streak` : é…å½“æœªè¨­å®šçŠ¶æ³ã®åˆ¤å®šã¨å¢—é…å¹´æ•°ã‚«ã‚¦ãƒ³ãƒˆã€‚
L130 - `fetch_finnhub_metrics` : Finnhub APIã‹ã‚‰EPSæˆé•·ãƒ»ROEãƒ»Î²ãªã©ä¸è¶³æŒ‡æ¨™ã‚’å–å¾—ã€‚
L131 - `calc_beta` : ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å…±åˆ†æ•£ã‹ã‚‰Î²ã‚’ç®—å‡ºã€‚
L132 - `spx_to_alpha` : S&P500ã®ä½ç½®æƒ…å ±ã‹ã‚‰DRRSã§ç”¨ã„ã‚‹Î±ã‚’æ¨å®šã€‚
L133 - `soft_cap_effective_scores` / `pick_top_softcap` : ã‚»ã‚¯ã‚¿ãƒ¼ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ—ä»˜ãã‚¹ã‚³ã‚¢èª¿æ•´ã¨ä¸Šä½æŠ½å‡ºã€‚
L134
L135 **è£œåŠ©é–¢æ•°ã¨ç”ŸæˆæŒ‡æ¨™**
L136
L137 | è£œåŠ©é–¢æ•° | ç”ŸæˆæŒ‡æ¨™ | ç•¥ç§° |
L138 | --- | --- | --- |
L139 | `trend` | ãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ | `TR` |
L140 | `rs` | ç›¸å¯¾å¼·ã• | `RS` |
L141 | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç·šã®ä¹–é›¢ | `TR_str` |
L142 | `rs_line_slope` | RSç·šã®å›å¸°å‚¾ã | `RS_SLOPE_*` |
L143 | `calc_beta` | Î² | `BETA` |
L144 | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° | `DIV_STREAK` |
L145
L146 #### `aggregate_scores` è©³ç´°
L147 1. å„éŠ˜æŸ„ã®ä¾¡æ ¼ç³»åˆ—ã‚„`info`ã‚’åŸºã«ä»¥ä¸‹ã‚’ç®—å‡ºã€‚
L148    - **ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ **: `TR`ã€`RS`ã€`TR_str`ã€å¤šæ§˜ãªç§»å‹•å¹³å‡æ¯”ã€`RS_SLOPE_*`ãªã©ã€‚
L149    - **ãƒªã‚¹ã‚¯**: `BETA`ã€`DOWNSIDE_DEV`ã€`MDD_1Y`ã€`RESID_VOL`ã€`DOWN_OUTPERF`ã€`EXT_200`ç­‰ã€‚
L150    - **é…å½“**: `DIV`ã€`DIV_TTM_PS`ã€`DIV_VAR5`ã€`DIV_YOY`ã€`DIV_FCF_COVER`ã€`DIV_STREAK`ã€‚
L151    - **è²¡å‹™ãƒ»æˆé•·**: `EPS`ã€`REV`ã€`ROE`ã€`FCF/EV`ã€`REV_Q_YOY`ã€`EPS_Q_YOY`ã€`REV_YOY_ACC`ã€`REV_YOY_VAR`ã€`REV_ANN_STREAK`ã€`RULE40`ã€`FCF_MGN` ç­‰ã€‚
L152    - **å®‰å®šæ€§/ã‚µã‚¤ã‚º**: `DEBT2EQ`ã€`CURR_RATIO`ã€`MARKET_CAP`ã€`ADV60_USD`ã€`EPS_VAR_8Q`ãªã©ã€‚
L153 2. æŒ‡æ¨™æ¬ æã¯Finnhub APIç­‰ã§è£œå®Œã—ã€æœªå–å¾—é …ç›®ã‚’`missing_logs`ã«è¨˜éŒ²ã€‚
L154 3. `winsorize_s`â†’`robust_z`ã§æ¨™æº–åŒ–ã—`df_z`ã¸ä¿å­˜ã€‚ã‚µã‚¤ã‚ºãƒ»æµå‹•æ€§ã¯å¯¾æ•°å¤‰æ›ã€‚
L155 4. æ­£è¦åŒ–æ¸ˆæŒ‡æ¨™ã‹ã‚‰å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã€‚
L156    - å„å› å­ã®æ§‹æˆã¨é‡ã¿ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
L157      - **GRW**: 0.30Ã—`REV` + 0.20Ã—`EPS_Q_YOY` + 0.15Ã—`REV_Q_YOY` + 0.15Ã—`REV_YOY_ACC` + 0.10Ã—`RULE40` + 0.10Ã—`FCF_MGN` + 0.10Ã—`REV_ANN_STREAK` âˆ’ 0.05Ã—`REV_YOY_VAR`ã€‚
L158      - **MOM**: 0.40Ã—`RS` + 0.15Ã—`TR_str` + 0.15Ã—`RS_SLOPE_6W` + 0.15Ã—`RS_SLOPE_13W` + 0.10Ã—`MA200_SLOPE_5M` + 0.10Ã—`MA200_UP_STREAK_D`ã€‚
L159      - **VOL**: `BETA`å˜ä½“ã‚’ä½¿ç”¨ã€‚
L160      - **QAL**: 0.60Ã—`FCF_W` + 0.40Ã—`ROE_W`ã§ä½œæˆã€‚
L161      - **YLD**: 0.30Ã—`DIV` + 0.70Ã—`DIV_STREAK`ã€‚
L162      - **D_QAL**: 0.35Ã—`QAL` + 0.20Ã—`FCF` + 0.15Ã—`CURR_RATIO` âˆ’ 0.15Ã—`DEBT2EQ` âˆ’ 0.15Ã—`EPS_VAR_8Q`ã€‚
L163      - **D_YLD**: 0.45Ã—`DIV` + 0.25Ã—`DIV_STREAK` + 0.20Ã—`DIV_FCF_COVER` âˆ’ 0.10Ã—`DIV_VAR5`ã€‚
L164      - **D_VOL_RAW**: 0.40Ã—`DOWNSIDE_DEV` + 0.22Ã—`RESID_VOL` + 0.18Ã—`MDD_1Y` âˆ’ 0.10Ã—`DOWN_OUTPERF` âˆ’ 0.05Ã—`EXT_200` âˆ’ 0.08Ã—`SIZE` âˆ’ 0.10Ã—`LIQ` + 0.10Ã—`BETA`ã€‚
L165      - **D_TRD**: 0.40Ã—`MA200_SLOPE_5M` âˆ’ 0.30Ã—`EXT_200` + 0.15Ã—`NEAR_52W_HIGH` + 0.15Ã—`TR`ã€‚
L166     - ä¸»ãªæŒ‡æ¨™ã®ç•¥ç§°ã¨æ„å‘³:
L167
L168       | ç•¥ç§° | è£œåŠ©é–¢æ•° | æ¦‚è¦ |
L169       | --- | --- | --- |
L170       | TR | `trend` | 50/150/200æ—¥ç§»å‹•å¹³å‡ã¨52é€±ãƒ¬ãƒ³ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ |
L171       | RS | `rs` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹ç›¸å¯¾å¼·ã•ï¼ˆ12M/1Mãƒªã‚¿ãƒ¼ãƒ³å·®ï¼‰ |
L172       | TR_str | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ |
L173       | RS_SLOPE_6W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®6é€±å›å¸°å‚¾ã |
L174       | RS_SLOPE_13W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®13é€±å›å¸°å‚¾ã |
L175       | MA200_SLOPE_5M | - | 200æ—¥ç§»å‹•å¹³å‡ã®5ã‹æœˆé¨°è½ç‡ |
L176       | MA200_UP_STREAK_D | - | 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ã„ãŸæ—¥æ•° |
L177       | BETA | `calc_beta` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹Î² |
L178       | DOWNSIDE_DEV | - | ä¸‹æ–¹ãƒªã‚¿ãƒ¼ãƒ³ã®ã¿ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L179       | RESID_VOL | - | Î²ã§èª¿æ•´ã—ãŸæ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L180       | MDD_1Y | - | éå»1å¹´ã®æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ |
L181       | DOWN_OUTPERF | - | å¸‚å ´ä¸‹è½æ—¥ã«å¯¾ã™ã‚‹å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ |
L182       | EXT_200 | - | 200æ—¥ç§»å‹•å¹³å‡ã‹ã‚‰ã®çµ¶å¯¾ä¹–é›¢ç‡ |
L183       | NEAR_52W_HIGH | - | 52é€±é«˜å€¤ã¾ã§ã®ä¸‹æ–¹è·é›¢ï¼ˆ0=é«˜å€¤ï¼‰ |
L184       | FCF_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®FCF/EV |
L185       | ROE_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®ROE |
L186       | FCF | - | FCF/EV |
L187       | QAL | - | FCF_Wã¨ROE_Wã‚’çµ„ã¿åˆã‚ã›ãŸå“è³ªã‚¹ã‚³ã‚¢ |
L188       | CURR_RATIO | - | æµå‹•æ¯”ç‡ |
L189       | DEBT2EQ | - | è² å‚µè³‡æœ¬å€ç‡ |
L190       | EPS_VAR_8Q | - | EPSã®8å››åŠæœŸæ¨™æº–åå·® |
L191       | DIV | - | å¹´ç‡æ›ç®—é…å½“åˆ©å›ã‚Š |
L192       | DIV_STREAK | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° |
L193       | DIV_FCF_COVER | - | é…å½“ã®FCFã‚«ãƒãƒ¬ãƒƒã‚¸ |
L194       | DIV_VAR5 | - | 5å¹´é…å½“å¤‰å‹•ç‡ |
L195       | DIV_TTM_PS | - | 1æ ªå½“ãŸã‚ŠTTMé…å½“ |
L196       | DIV_YOY | - | å‰å¹´æ¯”é…å½“æˆé•·ç‡ |
L197       | REV | - | å£²ä¸Šæˆé•·ç‡TTM |
L198       | EPS_Q_YOY | - | å››åŠæœŸEPSã®å‰å¹´åŒæœŸæ¯” |
L199       | REV_Q_YOY | - | å››åŠæœŸå£²ä¸Šã®å‰å¹´åŒæœŸæ¯” |
L200       | REV_YOY_ACC | - | å£²ä¸Šæˆé•·ç‡ã®åŠ é€Ÿåˆ† |
L201       | RULE40 | - | å£²ä¸Šæˆé•·ç‡ã¨FCFãƒãƒ¼ã‚¸ãƒ³ã®åˆè¨ˆ |
L202       | FCF_MGN | - | FCFãƒãƒ¼ã‚¸ãƒ³ |
L203       | REV_ANN_STREAK | - | å¹´æ¬¡å£²ä¸Šæˆé•·ã®é€£ç¶šå¹´æ•° |
L204       | REV_YOY_VAR | - | å¹´æ¬¡å£²ä¸Šæˆé•·ç‡ã®å¤‰å‹•æ€§ |
L205       | SIZE | - | æ™‚ä¾¡ç·é¡ã®å¯¾æ•°å€¤ |
L206       | LIQ | - | 60æ—¥å¹³å‡å‡ºæ¥é«˜ãƒ‰ãƒ«ã®å¯¾æ•°å€¤ |
L207    - Gãƒã‚±ãƒƒãƒˆ: `GRW`ã€`MOM`ã€`VOL`ã‚’`cfg.weights.g`ï¼ˆ0.40/0.45/-0.15ï¼‰ã§åŠ é‡ã—`g_score`ã‚’å¾—ã‚‹ã€‚
L208    - Dãƒã‚±ãƒƒãƒˆ: `D_QAL`ã€`D_YLD`ã€`D_VOL_RAW`ã€`D_TRD`ã‚’`cfg.weights.d`ï¼ˆ0.15/0.15/-0.45/0.25ï¼‰ã§åŠ é‡ã—`d_score_all`ã‚’ç®—å‡ºã€‚
L209    - ã‚»ã‚¯ã‚¿ãƒ¼capã«ã‚ˆã‚‹`soft_cap_effective_scores`ã‚’é©ç”¨ã—ã€Gæ¡ç”¨éŠ˜æŸ„ã«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€‚
L210 5. `_apply_growth_entry_flags`ã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®ç™ºç«çŠ¶æ³ã‚’ä»˜åŠ ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L211
L212 ### Step3: Correlation Reduction & Selection (Selector)
L213 DRRSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç›¸é–¢ã‚’æŠ‘ãˆãŸéŠ˜æŸ„é¸å®šã‚’è¡Œã„ã€`SelectionBundle`ã‚’è¿”ã™ã€‚`results/`ã«ä¿å­˜ã•ã‚ŒãŸå‰å›é¸å®šï¼ˆ`G_selection.json` / `D_selection.json`ï¼‰ã‚’`_load_prev`ã§èª­ã¿è¾¼ã¿ã€ç›®çš„å€¤ãŒå¤§ããæ‚ªåŒ–ã—ãªã„é™ã‚Šç¶­æŒã™ã‚‹ã€‚æ–°ã—ã„æ¡ç”¨é›†åˆã¯`_save_sel`ã§JSONã«æ›¸ãå‡ºã—æ¬¡å›ä»¥é™ã®å…¥åŠ›ã«å‚™ãˆã‚‹ã€‚
L214 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L215 - `residual_corr` : åç›Šç‡è¡Œåˆ—ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã—ã€ä¸Šä½ä¸»æˆåˆ†ã‚’é™¤å»ã—ãŸæ®‹å·®ã‹ã‚‰ç›¸é–¢è¡Œåˆ—ã‚’æ±‚ã‚ã€å¹³å‡ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯ã€‚
L216 - `rrqr_like_det` : ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘ã—ãŸQRåˆ†è§£é¢¨ã®æ‰‹é †ã§åˆæœŸå€™è£œã‚’kä»¶æŠ½å‡ºã—ã€ã‚¹ã‚³ã‚¢ã®é«˜ã„éç›¸é–¢ãªé›†åˆã‚’å¾—ã‚‹ã€‚
L217 - `swap_local_det` / `swap_local_det_cross` : `sum(score) - Î»*within_corr - Î¼*cross_corr`ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ã€å…¥ã‚Œæ›¿ãˆæ¢ç´¢ã§å±€æ‰€çš„ã«æœ€é©åŒ–ã€‚
L218 - `select_bucket_drrs` : ãƒ—ãƒ¼ãƒ«éŠ˜æŸ„ã¨ã‚¹ã‚³ã‚¢ã‹ã‚‰æ®‹å·®ç›¸é–¢ã‚’è¨ˆç®—ã—ã€ä¸Šè¨˜2æ®µéš(åˆæœŸé¸æŠâ†’å…¥ã‚Œæ›¿ãˆ)ã§kéŠ˜æŸ„ã‚’æ±ºå®šã€‚éå»æ¡ç”¨éŠ˜æŸ„ã¨ã®æ¯”è¼ƒã§ç›®çš„å€¤ãŒåŠ£åŒ–ã—ãªã‘ã‚Œã°ç¶­æŒã™ã‚‹ã€‚
L219 - `select_buckets` : Gãƒã‚±ãƒƒãƒˆã‚’é¸å®šå¾Œã€ãã®çµæœã‚’é™¤ã„ãŸå€™è£œã‹ã‚‰Dãƒã‚±ãƒƒãƒˆã‚’é¸ã¶ã€‚Dé¸å®šæ™‚ã¯Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ã‚’ä»˜ä¸ã—ã€ä¸¡ãƒã‚±ãƒƒãƒˆã®åˆ†æ•£ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
L220
L221 #### ç›¸é–¢ä½æ¸›ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°
L222 1. **æ®‹å·®ç›¸é–¢è¡Œåˆ—ã®æ§‹ç¯‰ (`residual_corr`)**
L223    - ãƒªã‚¿ãƒ¼ãƒ³è¡Œåˆ—`R`ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L224    - SVDã§ä¸Šä½`n_pc`ä¸»æˆåˆ†`F`ã‚’æ±‚ã‚ã€æœ€å°äºŒä¹—ã§ä¿‚æ•°`B`ã‚’ç®—å‡ºã—æ®‹å·®`E = Z - F@B`ã‚’å¾—ã‚‹ã€‚
L225    - `E`ã®ç›¸é–¢è¡Œåˆ—`C`ã‚’è¨ˆç®—ã—ã€å¹³å‡çµ¶å¯¾ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯é‡`shrink_eff`ã‚’è£œæ­£ã—ã¦å¯¾è§’ã‚’å¼·èª¿ã€‚
L226 2. **åˆæœŸå€™è£œã®æŠ½å‡º (`rrqr_like_det`)**
L227    - ã‚¹ã‚³ã‚¢ã‚’0-1æ­£è¦åŒ–ã—ãŸé‡ã¿`w`ã¨ã—ã€`Z*(1+Î³w)`ã§åˆ—ãƒãƒ«ãƒ ã‚’å¼·èª¿ã€‚
L228    - æ®‹å·®ãƒãƒ«ãƒ æœ€å¤§ã®åˆ—ã‚’é€æ¬¡é¸ã³ã€QRãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã£ã¦éç›¸é–¢ã‹ã¤é«˜ã‚¹ã‚³ã‚¢ãª`k`éŠ˜æŸ„é›†åˆ`S0`ã‚’å¾—ã‚‹ã€‚
L229 3. **å±€æ‰€æ¢ç´¢ (`swap_local_det` / `swap_local_det_cross`)**
L230    - ç›®çš„é–¢æ•°`Î£z_score âˆ’ Î»Â·within_corr âˆ’ Î¼Â·cross_corr`ã‚’æœ€å¤§åŒ–ã€‚
L231    - é¸æŠé›†åˆã®å„éŠ˜æŸ„ã‚’ä»–å€™è£œã¨å…¥ã‚Œæ›¿ãˆã€æ”¹å–„ãŒãªããªã‚‹ã¾ã§ã¾ãŸã¯`max_pass`å›ã¾ã§æ¢ç´¢ã€‚
L232    - `swap_local_det_cross`ã¯Gãƒã‚±ãƒƒãƒˆã¨ã®ã‚¯ãƒ­ã‚¹ç›¸é–¢è¡Œåˆ—`C_cross`ã‚’ä½¿ç”¨ã—ã€ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’ä»˜ä¸ã€‚
L233 4. **éå»æ¡ç”¨ã®ç¶­æŒã¨ã‚¯ãƒ­ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ (`select_bucket_drrs` / `select_buckets`)**
L234    - å±€æ‰€æ¢ç´¢çµæœ`S`ã¨éå»é›†åˆ`P`ã®ç›®çš„å€¤ã‚’æ¯”è¼ƒã—ã€`S`ãŒ`P`ã‚ˆã‚Š`Î·`æœªæº€ã®æ”¹å–„ãªã‚‰`P`ã‚’ç¶­æŒã€‚
L235    - `select_buckets`ã§ã¯Gã‚’å…ˆã«æ±ºå®šã—ã€Dé¸å®šæ™‚ã«Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’åŠ ãˆã¦ã‚¯ãƒ­ã‚¹åˆ†æ•£ã‚’æŠ‘åˆ¶ã€‚
L236
L237 ### Step4: Output
L238 é¸å®šçµæœã‚’å¯è¦–åŒ–ã—å…±æœ‰ã™ã‚‹å·¥ç¨‹ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦æ¨™æº–å‡ºåŠ›ã¨Slackã¸é€ã‚‹ã€‚
L239 - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚é¸å¤–ã¨ãªã£ãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L240 - IN/OUTãƒªã‚¹ãƒˆã¨OUTéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ï¼ˆä½å¾—ç‚¹éŠ˜æŸ„ã‚’ç¢ºèªã—ã‚„ã™ãï¼‰
L241 - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨ï¼ˆçµ„å…¥ã‚Œãƒ»é™¤å¤–ã€ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼‰
L242 - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
L243
L244 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L245 - `display_results` : ä¸Šè¨˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŠ ãˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚„åˆ†æ•£åŒ–æŒ‡æ¨™ã‚’è¡¨ç¤ºã€‚
L246 - `notify_slack` : Slack Webhookã¸åŒå†…å®¹ã‚’é€ä¿¡ã€‚
L247 - è£œåŠ©:`_avg_offdiag`ã€`_resid_avg_rho`ã€`_raw_avg_rho`ã€`_cross_block_raw_rho`ã€‚
L248
L249 ## ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
L250 1. `PipelineConfig`ã‚’æ§‹ç¯‰ã€‚
L251 2. **Step1** `Input.prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚
L252 3. **Step2** `Scorer.aggregate_scores`ã§`FeatureBundle`ã‚’å–å¾—ã€‚
L253 4. **Step3** `Selector.select_buckets`ã§`SelectionBundle`ã‚’ç®—å‡ºã€‚
L254 5. **Step4** `Output.display_results`ã¨`notify_slack`ã§çµæœã‚’å‡ºåŠ›ã€‚
```
