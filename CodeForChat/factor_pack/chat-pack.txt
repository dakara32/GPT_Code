# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰, è¨ˆç®—ã¯ scorer.py'''
L2 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L3 BONUS_COEFF = 0.55  # æ¨å¥¨: æ”»ã‚=0.45 / ä¸­åº¸=0.55 / å®ˆã‚Š=0.65
L4 SWAP_DELTA_Z = 0.15   # åƒ…å·®åˆ¤å®š: Ïƒã®15%ã€‚(ç·©ã‚=0.10 / æ¨™æº–=0.15 / å›ºã‚=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+ã“ã®é †ä½ä»¥å†…ã®ç¾è¡Œã¯ä¿æŒã€‚(ç²˜ã‚Šå¼±=2 / æ¨™æº–=3 / ç²˜ã‚Šå¼·=4ã€œ5)
L6 import os, time, requests
L7 from time import perf_counter
L8 from dataclasses import dataclass, replace
L9 from typing import Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 class T:
L19     t = perf_counter()
L20     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L21
L22 T.log("start")
L23
L24 # === ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ ===
L25 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L26 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L27 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L28 N_G, N_D = config.N_G, config.N_D  # G/Dæ ã‚µã‚¤ã‚ºï¼ˆNORMALåŸºæº–: G12/D8ï¼‰
L29 g_weights = {'GRW':0.30,'MOM':0.55,'VOL':-0.15}
L30 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.7"))
L31 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L32 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L33 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L34
L35 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L36 corrM = 45
L37 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L38 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L39
L40 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L41 try: CROSS_MU_GD
L42 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L43
L44 # å‡ºåŠ›é–¢é€£
L45 RESULTS_DIR = "results"
L46 os.makedirs(RESULTS_DIR, exist_ok=True)
L47
L48 # ãã®ä»–
L49 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L50 _API = (FINNHUB_API_KEY or "").strip()
L51
L52 def _fetch_eps_non_gaap_ttm_metric(sym: str, token: str) -> float:
L53     """
L54     Finnhub /stock/metric ã‹ã‚‰ Non-GAAPã«ç›¸å½“ã™ã‚‹TTMã‚’å–å¾—ã€‚
L55     ç¬¬ä¸€å€™è£œ: epsExclExtraItemsTTMï¼ˆèª¿æ•´å¾ŒEPSã«ç›¸å½“ï¼‰
L56     ä»£æ›¿å€™è£œ: epsNormalizedAnnualï¼ˆå¹´æ¬¡ã ãŒNon-GAAPã«è¿‘ã„ï¼‰
L57     æœ€çµ‚å€™è£œ: epsTTMï¼ˆGAAPã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
L58     ã„ãšã‚Œã‚‚æ¬ æãªã‚‰ NaN ã‚’è¿”ã™ï¼ˆ0.0ã¯è¿”ã•ãªã„ï¼‰ã€‚
L59     """
L60     try:
L61         r = requests.get(
L62             "https://finnhub.io/api/v1/stock/metric",
L63             params={"symbol": sym, "metric": "all", "token": token},
L64             timeout=12,
L65         )
L66         j = r.json() if r.ok else {}
L67         m = (j or {}).get("metric", {}) or {}
L68         for k in ("epsExclExtraItemsTTM", "epsNormalizedAnnual", "epsTTM"):
L69             v = m.get(k, None)
L70             if v is not None:
L71                 try:
L72                     fv = float(v)
L73                     return fv
L74                 except Exception:
L75                     pass
L76         return np.nan
L77     except Exception:
L78         return np.nan
L79
L80 # === å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config ===
L81 @dataclass(frozen=True)
L82 class InputBundle:
L83     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L84     cand: List[str]
L85     tickers: List[str]
L86     bench: str
L87     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L88     px: pd.DataFrame                # data['Close']
L89     spx: pd.Series                  # data['Close'][bench]
L90     tickers_bulk: object            # yfinance.Tickers
L91     info: Dict[str, dict]           # yfinance info per ticker
L92     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L93     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L94     returns: pd.DataFrame           # px[tickers].pct_change()
L95
L96 @dataclass(frozen=True)
L97 class FeatureBundle:
L98     df: pd.DataFrame
L99     df_z: pd.DataFrame
L100     g_score: pd.Series
L101     d_score_all: pd.Series
L102     missing_logs: pd.DataFrame
L103
L104 @dataclass(frozen=True)
L105 class SelectionBundle:
L106     resG: dict
L107     resD: dict
L108     top_G: List[str]
L109     top_D: List[str]
L110     init_G: List[str]
L111     init_D: List[str]
L112
L113 @dataclass(frozen=True)
L114 class WeightsConfig:
L115     g: Dict[str,float]
L116     d: Dict[str,float]
L117
L118 @dataclass(frozen=True)
L119 class DRRSParams:
L120     corrM: int
L121     shrink: float
L122     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L123     D: Dict[str,float]
L124     cross_mu_gd: float
L125
L126 @dataclass(frozen=True)
L127 class PipelineConfig:
L128     weights: WeightsConfig
L129     drrs: DRRSParams
L130     price_max: float
L131
L132 # === å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ ===
L133 # (unused local utils removed â€“ use scorer.py versions if needed)
L134
L135 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L136
L137 def _post_slack(payload: dict):
L138     url = os.getenv("SLACK_WEBHOOK_URL")
L139     if not url: print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L140     try:
L141         requests.post(url, json=payload).raise_for_status()
L142     except Exception as e:
L143         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L144
L145 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L146
L147 def _slack_debug(text: str, chunk=2800):
L148     i = 0
L149     while i < len(text):
L150         j = min(len(text), i + chunk)
L151         k = text.rfind("\n", i, j)
L152         j = k if k > i + 100 else j
L153         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L154         i = j
L155
L156 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L157     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC","eps_ttm","nEPS_ttm","eps_imputed","fcf_ttm","fcf_imputed"]
L158     all_cols = _env_true("DEBUG_ALL_COLS", False)
L159     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L160
L161     Gp, Dp = set(prevG or []), set(prevD or [])
L162     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L163     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L164
L165     show_near = _env_true("DEBUG_NEAR5", True)
L166     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L167     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L168     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L169     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L170     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L171     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L172
L173     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L174     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L175
L176     def _fmt_near(lbl, ser, lst):
L177         if ser is None: return f"{lbl}: off"
L178         g = ser.get
L179         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L180         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L181
L182     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L183           _fmt_near("G near10", gs, g_miss),
L184           _fmt_near("D near10", ds, d_miss),
L185           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L186           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L187
L188     tbl="(df_z or columns not available)"
L189     if not fb.df_z.empty and cols:
L190         idx=[t for t in focus if t in fb.df_z.index]
L191         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L192
L193     miss_txt=""
L194     if _env_true("DEBUG_MISSING_LOGS", False):
L195         miss=getattr(fb,"missing_logs",None)
L196         if miss is not None and not miss.empty:
L197             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L198
L199     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L200
L201 def _disjoint_keepG(top_G, top_D, poolD):
L202     """Gé‡è¤‡ã‚’Dã‹ã‚‰é™¤å»ã—ã€poolDã§é †æ¬¡è£œå……ï¼ˆæ¯æ¸‡æ™‚ã¯å…ƒéŠ˜æŸ„ç¶­æŒï¼‰ã€‚"""
L203     used, D, i = set(top_G), list(top_D), 0
L204     for j, t in enumerate(D):
L205         if t in used:
L206             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L207                 i += 1
L208             if i < len(poolD):
L209                 D[j] = poolD[i]; used.add(D[j]); i += 1
L210     return top_G, D
L211
L212
L213 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L214                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L215     import pandas as pd, numpy as np
L216     sel = list(pick)
L217     if not sel: return sel
L218     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L219     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L220     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L221     thresh = kth - delta_z * sigma
L222     ranked_all = agg.sort_values(ascending=False)
L223     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L224     for t in cand:
L225         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L226         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L227         if within_score or within_rank:
L228             non_inc = [x for x in sel if x not in incumbents]
L229             if not non_inc: break
L230             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L231             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L232                 sel.remove(weakest); sel.append(t)
L233     if len(sel) > n_target:
L234         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L235     return sel
L236
L237
L238 # === Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ ===
L239 class Input:
L240     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L241         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L242         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L243
L244     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L245     @staticmethod
L246     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L247         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L248         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L249         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L250
L251     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L252
L253     @staticmethod
L254     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L255         if df is None or df.empty: return None
L256         idx_lower={str(i).lower():i for i in df.index}
L257         for n in names:
L258             k=n.lower()
L259             if k in idx_lower: return df.loc[idx_lower[k]]
L260         return None
L261
L262     @staticmethod
L263     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L264         if s is None or s.empty: return None
L265         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L266
L267     @staticmethod
L268     def _latest(s: pd.Series|None) -> float|None:
L269         if s is None or s.empty: return None
L270         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L271
L272     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L273         from concurrent.futures import ThreadPoolExecutor, as_completed
L274         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L275
L276         def one(t: str):
L277             try:
L278                 tk = yf.Ticker(t)  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯æ¸¡ã•ãªã„ï¼ˆYFãŒcurl_cffiã§ç®¡ç†ï¼‰
L279                 qcf = tk.quarterly_cashflow
L280                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L281                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L282                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L283                 if any(v is None for v in (cfo, capex, fcf)):
L284                     acf = tk.cashflow
L285                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L286                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L287                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L288             except Exception as e:
L289                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L290             n=np.nan
L291             return {"ticker":t,
L292                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L293                     "capex_ttm_yf": n if capex is None else capex,
L294                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L295
L296         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L297         with ThreadPoolExecutor(max_workers=mw) as ex:
L298             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L299         return pd.DataFrame(rows).set_index("ticker")
L300
L301     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L302     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L303
L304     @staticmethod
L305     def _first_key(d: dict, keys: list[str]):
L306         for k in keys:
L307             if k in d and d[k] is not None: return d[k]
L308         return None
L309
L310     @staticmethod
L311     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L312         for i in range(retries):
L313             r = session.get(url, params=params, timeout=15)
L314             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L315             r.raise_for_status(); return r.json()
L316         r.raise_for_status()
L317
L318     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L319         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L320         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L321         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L322         for sym in tickers:
L323             cfo_ttm = capex_ttm = None
L324             try:
L325                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L326                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L327                 for item in arr[:4]:
L328                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L329                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L330                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L331             except Exception: pass
L332             if cfo_ttm is None or capex_ttm is None:
L333                 try:
L334                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L335                     arr = j.get("cashFlow") or []
L336                     if arr:
L337                         item0 = arr[0]
L338                         if cfo_ttm is None:
L339                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L340                             if v is not None: cfo_ttm = float(v)
L341                         if capex_ttm is None:
L342                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L343                             if v is not None: capex_ttm = float(v)
L344                 except Exception: pass
L345             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L346         return pd.DataFrame(rows).set_index("ticker")
L347
L348     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L349         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L350         T.log("financials (yf) done")
L351         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L352         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L353         if need:
L354             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L355             df = yf_df.join(fh_df, how="left")
L356             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L357                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L358             print("[T] financials (finnhub) done (fallback only)")
L359         else:
L360             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L361             print("[T] financials (finnhub) skipped (no missing)")
L362         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L363         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L364         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L365         fcf_calc = cfo - capex
L366         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L367         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L368         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L369         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L370         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L371         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L372         return df[cols].sort_index()
L373
L374     def _build_eps_df(self, tickers, tickers_bulk, info):
L375         eps_rows=[]
L376         for t in tickers:
L377             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L378             try:
L379                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L380                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L381                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L382                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L383                     eps_q = qearn["Earnings"].iloc[-1]/so
L384             except Exception: pass
L385             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L386         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L387
L388     def prepare_data(self):
L389         """Fetch price and fundamental data for all tickers."""
L390         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L391         for t in self.cand:
L392             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L393             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L394         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L395         T.log("price cap filter done (CAND_PRICE_MAX)")
L396         tickers = sorted(set(self.exist + cand_f))
L397         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L398         data = yf.download(tickers + [self.bench], period="600d", auto_adjust=True, progress=False)
L399         T.log("yf.download done")
L400         px, spx = data["Close"], data["Close"][self.bench]
L401         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0ãªã‚‰ç„¡åŠ¹ï¼ˆæ—¢å®šï¼‰
L402         if clip_days > 0:
L403             px  = px.tail(clip_days + 1)
L404             spx = spx.tail(clip_days + 1)
L405             print(f"[T] price window clipped by env: {len(px)} rows (PRICE_CLIP_DAYS={clip_days})")
L406         else:
L407             print(f"[T] price window clip skipped; rows={len(px)}")
L408         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L409         for t in tickers:
L410             try: info[t] = tickers_bulk.tickers[t].info
L411             except Exception as e: print(f"{t}: info fetch failed ({e})"); info[t] = {}
L412         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L413         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L414         T.log("eps/fcf prep done")
L415         returns = px[tickers].pct_change()
L416         T.log("price prep/returns done")
L417         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L418
L419 # === Selectorï¼šç›¸é–¢ä½æ¸›ãƒ»é¸å®šï¼ˆã‚¹ã‚³ã‚¢ï¼†ãƒªã‚¿ãƒ¼ãƒ³ã ã‘èª­ã‚€ï¼‰ ===
L420 class Selector:
L421     # ---- DRRS helpersï¼ˆSelectorå°‚ç”¨ï¼‰ ----
L422     @staticmethod
L423     def _z_np(X: np.ndarray) -> np.ndarray:
L424         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L425         return (np.nan_to_num(X)-m)/s
L426
L427     @classmethod
L428     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L429         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L430         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L431         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L432         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L433         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L434
L435     @classmethod
L436     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L437         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L438         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L439         if k==0: return []
L440         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L441         for _ in range(k):
L442             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L443             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L444             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L445         return sorted(S)
L446
L447     @staticmethod
L448     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L449         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L450         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L451
L452     @classmethod
L453     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L454         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L455         while improved and passes<max_pass:
L456             improved, passes = False, passes+1
L457             for i,out in enumerate(list(S)):
L458                 for inn in range(len(score)):
L459                     if inn in S: continue
L460                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L461                     if v>best+1e-10: S, best, improved = cand, v, True; break
L462                 if improved: break
L463         return S, best
L464
L465     @staticmethod
L466     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L467         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L468         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L469         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L470         return float(s[idx].sum() - lam*within - mu*cross)
L471
L472     @classmethod
L473     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L474         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L475         while improved and passes<max_pass:
L476             improved, passes = False, passes+1
L477             for i,out in enumerate(list(S)):
L478                 for inn in range(N):
L479                     if inn in S: continue
L480                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L481                     if v>best+1e-10: S, best, improved = cand, v, True; break
L482                 if improved: break
L483         return S, best
L484
L485     @staticmethod
L486     def avg_corr(C: np.ndarray, idx) -> float:
L487         k = len(idx); P = C[np.ix_(idx, idx)]
L488         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L489
L490     @classmethod
L491     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L492         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L493         union = [t for t in pool_tickers if t in returns_df.columns]
L494         for t in g_fixed:
L495             if t not in union: union.append(t)
L496         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L497         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L498         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L499         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L500         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L501         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L502         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L503         if len(g_eff)>0 and mu>0.0:
L504             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L505         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L506         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L507         selected_tickers = [pool_eff[i] for i in S]
L508         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L509
L510     # ---- é¸å®šï¼ˆã‚¹ã‚³ã‚¢ Series / returns ã ã‘ã‚’å—ã‘ã‚‹ï¼‰----
L511 # === Outputï¼šå‡ºåŠ›æ•´å½¢ã¨é€ä¿¡ï¼ˆè¡¨ç¤ºãƒ»Slackï¼‰ ===
L512 class Output:
L513
L514     def __init__(self, debug=False):
L515         self.debug = debug
L516         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = self.debug_table = None
L517         self.g_title = self.d_title = ""
L518         self.g_formatters = self.d_formatters = {}
L519         # ä½ã‚¹ã‚³ã‚¢ï¼ˆGSC+DSCï¼‰Top10 è¡¨ç¤º/é€ä¿¡ç”¨
L520         self.low10_table = None
L521
L522     # --- è¡¨ç¤ºï¼ˆå…ƒ display_results ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L523     def display_results(self, *, exist, bench, df_z, g_score, d_score_all,
L524                         init_G, init_D, top_G, top_D, **kwargs):
L525         pd.set_option('display.float_format','{:.3f}'.format)
L526         print("ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ")
L527         if self.miss_df is not None and not self.miss_df.empty:
L528             print("Missing Data:")
L529             print(self.miss_df.to_string(index=False))
L530
L531         # ---- è¡¨ç¤ºç”¨ï¼šChanges/Near-Miss ã®ã‚¹ã‚³ã‚¢æºã‚’â€œæœ€çµ‚é›†è¨ˆâ€ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚· ----
L532         try:
L533             sc = getattr(self, "_sc", None)
L534             agg_G = getattr(sc, "_agg_G", None)
L535             agg_D = getattr(sc, "_agg_D", None)
L536         except Exception:
L537             sc = agg_G = agg_D = None
L538         class _SeriesProxy:
L539             __slots__ = ("primary", "fallback")
L540             def __init__(self, primary, fallback): self.primary, self.fallback = primary, fallback
L541             def get(self, key, default=None):
L542                 try:
L543                     v = self.primary.get(key) if hasattr(self.primary, "get") else None
L544                     if v is not None and not (isinstance(v, float) and v != v):
L545                         return v
L546                 except Exception:
L547                     pass
L548                 try:
L549                     return self.fallback.get(key) if hasattr(self.fallback, "get") else default
L550                 except Exception:
L551                     return default
L552         g_score = _SeriesProxy(agg_G, g_score)
L553         d_score_all = _SeriesProxy(agg_D, d_score_all)
L554         near_G = getattr(sc, "_near_G", []) if sc else []
L555         near_D = getattr(sc, "_near_D", []) if sc else []
L556
L557         extra_G = [t for t in init_G if t not in top_G][:5]; G_UNI = top_G + extra_G
L558         gsc_series = pd.Series({t: g_score.get(t) for t in G_UNI}, name='GSC')
L559         self.g_table = pd.concat([df_z.loc[G_UNI,['GRW','MOM','TRD','VOL']], gsc_series], axis=1)
L560         self.g_table.index = [t + ("â­ï¸" if t in top_G else "") for t in G_UNI]
L561         self.g_formatters = {col:"{:.2f}".format for col in ['GRW','MOM','TRD','VOL']}; self.g_formatters['GSC'] = "{:.3f}".format
L562         self.g_title = (f"[Gæ  / {N_G} / {_fmt_w(g_weights)} / corrM={corrM} / "
L563                         f"LB={DRRS_G['lookback']} nPC={DRRS_G['n_pc']} Î³={DRRS_G['gamma']} Î»={DRRS_G['lam']} Î·={DRRS_G['eta']} shrink={DRRS_SHRINK}]")
L564         if near_G:
L565             add = [t for t in near_G if t not in set(G_UNI)][:10]
L566             if len(add) < 10:
L567                 try:
L568                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L569                     out_now = sorted(set(exist) - set(top_G + top_D))  # ä»Šå› OUT
L570                     used = set(G_UNI + add)
L571                     def _push(lst):
L572                         nonlocal add, used
L573                         for t in lst:
L574                             if len(add) == 10: break
L575                             if t in aggG.index and t not in used:
L576                                 add.append(t); used.add(t)
L577                     _push(out_now)           # â‘  ä»Šå› OUT ã‚’å„ªå…ˆ
L578                     _push(list(aggG.index))  # â‘¡ ã¾ã è¶³ã‚Šãªã‘ã‚Œã°ä¸Šä½ã§å……å¡«
L579                 except Exception:
L580                     pass
L581             if add:
L582                 near_tbl = pd.concat([df_z.loc[add,['GRW','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L583                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L584         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L585
L586         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L587         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L588         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L589         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L590         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L591         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L592         import scorer
L593         dw_eff = scorer.D_WEIGHTS_EFF
L594         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L595                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L596         if near_D:
L597             add = [t for t in near_D if t not in set(D_UNI)][:10]
L598             if add:
L599                 d_disp2 = pd.DataFrame(index=add)
L600                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L601                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L602                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L603         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L604
L605         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L606         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L607         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L608
L609         self.io_table = pd.DataFrame({
L610             'IN': pd.Series(in_list),
L611             '/ OUT': pd.Series(out_list)
L612         })
L613         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L614         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L615         self.io_table['GSC'] = pd.Series(g_list)
L616         self.io_table['DSC'] = pd.Series(d_list)
L617
L618         print("Changes:")
L619         print(self.io_table.to_string(index=False))
L620
L621         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L622         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L623         for name,ticks in portfolios.items():
L624             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L625             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L626             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L627             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L628             if len(ticks)>=2:
L629                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L630                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L631                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L632             else: RAW_rho = RESID_rho = np.nan
L633             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L634         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L635         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L636         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L637         def _fmt_row(s):
L638             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L639         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L640         if self.debug:
L641             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L642             print("Debug Data:"); print(self.debug_table.to_string())
L643
L644         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L645         try:
L646             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L647             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L648             all_scores = all_scores.dropna(subset=['G_plus_D'])
L649             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L650             print("Low Score Candidates (GSC+DSC bottom 10):")
L651             print(self.low10_table.to_string())
L652         except Exception as e:
L653             print(f"[warn] low-score ranking failed: {e}")
L654             self.low10_table = None
L655
L656     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L657     def notify_slack(self):
L658         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L659         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L660         def _filter_suffix_from(spec: dict, group: str) -> str:
L661             g = spec.get(group, {})
L662             parts = [str(m) for m in g.get("pre_mask", [])]
L663             for k, v in (g.get("pre_filter", {}) or {}).items():
L664                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L665                 name = {"beta": "Î²"}.get(base, base)
L666                 try: val = f"{float(v):g}"
L667                 except: val = str(v)
L668                 parts.append(f"{name}{op}{val}")
L669             return "" if not parts else " / filter:" + " & ".join(parts)
L670         def _inject_filter_suffix(title: str, group: str) -> str:
L671             suf = _filter_suffix_from(FILTER_SPEC, group)
L672             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L673         def _blk(title, tbl, fmt=None, drop=()):
L674             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(é¸å®šãªã—)\n"
L675             if drop and hasattr(tbl,'columns'):
L676                 keep = [c for c in tbl.columns if c not in drop]
L677                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L678             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L679
L680         g_title = _inject_filter_suffix(self.g_title, "G")
L681         d_title = _inject_filter_suffix(self.d_title, "D")
L682         message  = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L683         if self.miss_df is not None and not self.miss_df.empty:
L684             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L685         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L686         message += _blk(d_title, self.d_table, self.d_formatters)
L687         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L688         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L689         if self.debug and self.debug_table is not None:
L690             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L691         payload = {"text": message}
L692         try:
L693             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L694         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L695
L696 def _infer_g_universe(feature_df, selected12=None, near5=None):
L697     try:
L698         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L699         if out: return out
L700     except Exception:
L701         pass
L702     base = set()
L703     for lst in (selected12 or []), (near5 or []):
L704         for x in (lst or []): base.add(x)
L705     return list(base) if base else list(feature_df.index)
L706
L707 def _fmt_with_fire_mark(tickers, feature_df):
L708     out = []
L709     for t in tickers or []:
L710         try:
L711             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L712             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L713             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L714         except Exception:
L715             out.append(t)
L716     return out
L717
L718 def _label_recent_event(t, feature_df):
L719     try:
L720         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L721         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L722         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L723         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L724         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L725     except Exception:
L726         pass
L727     return t
L728
L729 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L730
L731 def io_build_input_bundle() -> InputBundle:
L732     """
L733     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L734     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L735     """
L736     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L737     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L738
L739 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L740               n_target: int) -> tuple[list, float, float, float]:
L741     """
L742     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L743     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L744     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L745     """
L746     sc.cfg = cfg
L747
L748     if hasattr(sc, "score_build_features"):
L749         feat = sc.score_build_features(inb)
L750         if not hasattr(sc, "_feat_logged"):
L751             T.log("features built (scorer)")
L752             sc._feat_logged = True
L753         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L754     else:
L755         fb = sc.aggregate_scores(inb, cfg)
L756         if not hasattr(sc, "_feat_logged"):
L757             T.log("features built (scorer)")
L758             sc._feat_logged = True
L759         sc._feat = fb
L760         agg = fb.g_score if group == "G" else fb.d_score_all
L761         if group == "D" and hasattr(fb, "df"):
L762             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L763
L764     if hasattr(sc, "filter_candidates"):
L765         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L766
L767     selector = Selector()
L768     if hasattr(sc, "select_diversified"):
L769         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L770             selector=selector, prev_tickers=None,
L771             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L772             cross_mu=cfg.drrs.cross_mu_gd)
L773     else:
L774         if group == "G":
L775             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L776             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L777                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L778                 lam=cfg.drrs.G.get("lam", 0.68),
L779                 lookback=cfg.drrs.G.get("lookback", 252),
L780                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L781         else:
L782             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L783             g_fixed = getattr(sc, "_top_G", None)
L784             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L785                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L786                 lam=cfg.drrs.D.get("lam", 0.85),
L787                 lookback=cfg.drrs.D.get("lookback", 504),
L788                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L789                 mu=cfg.drrs.cross_mu_gd)
L790         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L791         sum_sc = res["sum_score"]; obj = res["objective"]
L792         if group == "D":
L793             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L794             T.log("selection finalized (G/D)")
L795     try:
L796         inc = [t for t in exist if t in agg.index]
L797         pick = _sticky_keep_current(
L798             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L799             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L800         )
L801     except Exception as _e:
L802         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L803     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L804     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L805     try:
L806         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L807         near10 = list(pool.sort_values(ascending=False).head(10).index)
L808         setattr(sc, f"_near_{group}", near10)
L809         setattr(sc, f"_agg_{group}", agg)
L810     except Exception:
L811         pass
L812
L813     if group == "D":
L814         T.log("save done")
L815     if group == "G":
L816         sc._top_G = pick
L817     return pick, avg_r, sum_sc, obj
L818
L819 def run_pipeline() -> SelectionBundle:
L820     """
L821     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L822     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L823     """
L824     inb = io_build_input_bundle()
L825     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L826         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L827                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L828         price_max=CAND_PRICE_MAX)
L829
L830     # --- Pass-1: æš«å®šé¸å®šï¼ˆGAAPã®ã¿ï¼‰ ---
L831     sc_p1 = Scorer()
L832     top_G1, _, _, _ = run_group(sc_p1, "G", inb, cfg, N_G)
L833     poolG1 = list(getattr(sc_p1, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L834     alpha1 = Scorer.spx_to_alpha(inb.spx)
L835     sectors1 = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG1}; scores1 = {t:Scorer.g_score.get(t,0.0) for t in poolG1}
L836     top_G1 = Scorer.pick_top_softcap(scores1, sectors1, N=N_G, cap=2, alpha=alpha1, hard=5)
L837     sc_p1._top_G = top_G1
L838     try:
L839         aggG1 = getattr(sc_p1, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L840         sc_p1._near_G = [t for t in aggG1.index if t not in set(top_G1)][:10]
L841     except Exception:
L842         pass
L843     top_D1, _, _, _ = run_group(sc_p1, "D", inb, cfg, N_D)
L844     hopeful = sorted(set(top_G1 + top_D1 + getattr(sc_p1, "_near_G", []) + getattr(sc_p1, "_near_D", [])))
L845
L846     # --- hopeful only: Non-GAAP EPS å–å¾— ---
L847     eps_df2 = inb.eps_df.copy()
L848     if "nEPS_ttm" not in eps_df2.columns:
L849         eps_df2["nEPS_ttm"] = np.nan
L850     if _API and hopeful:
L851         n_map = {t: _fetch_eps_non_gaap_ttm_metric(t, _API) for t in hopeful}
L852         for t, v in n_map.items():
L853             if t in eps_df2.index:
L854                 eps_df2.at[t, "nEPS_ttm"] = v
L855         print(f"[nEPS] fetched={sum(np.isfinite(list(n_map.values())))}  sample: "
L856               f"{[(k, round(v,3)) for k,v in list(n_map.items())[:5]]}")
L857     else:
L858         pass  # APIã‚­ãƒ¼ç„¡ã—ã®å ´åˆã§ã‚‚åˆ—ã¯å¿…ãšä¿æŒï¼ˆå¾Œæ®µã®KeyErroré˜²æ­¢ï¼‰
L859
L860     # Frozen å›é¿: InputBundle ã‚’ replace ã§å†ç”Ÿæˆ
L861     inb2 = replace(inb, eps_df=eps_df2)
L862
L863     # --- Pass-2: æœ€çµ‚é¸å®šï¼ˆnEPS åæ˜ å¾Œï¼‰ ---
L864     sc = Scorer()
L865     top_G, avgG, sumG, objG = run_group(sc, "G", inb2, cfg, N_G)
L866     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L867     alpha = Scorer.spx_to_alpha(inb2.spx)
L868     sectors = {t:(inb2.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L869     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L870     sc._top_G = top_G
L871     try:
L872         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L873         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L874     except Exception:
L875         pass
L876     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L877     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L878     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L879     top_D, avgD, sumD, objD = run_group(sc, "D", inb2, cfg, N_D)
L880     fb = getattr(sc, "_feat", None)
L881     if fb is not None:
L882         try:
L883             fb.df_z["nEPS_ttm"] = inb2.eps_df["nEPS_ttm"]
L884         except Exception:
L885             pass
L886     near_G = getattr(sc, "_near_G", [])
L887     selected12 = list(top_G)
L888     df = fb.df if fb is not None else pd.DataFrame()
L889     guni = _infer_g_universe(df, selected12, near_G)
L890     try:
L891         fire_recent = [t for t in guni
L892                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L893                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L894     except Exception: fire_recent = []
L895
L896     lines = [
L897         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L898         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L899         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L900         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L901
L902     if fire_recent:
L903         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L904         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L905     else:
L906         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L907
L908     try:
L909         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L910         if webhook:
L911             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L912     except Exception:
L913         pass
L914
L915     out = Output(debug=debug_mode)
L916     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L917     try: out._sc = sc
L918     except Exception: pass
L919     if hasattr(sc, "_feat"):
L920         try:
L921             out.miss_df = sc._feat.missing_logs
L922             out.display_results(exist=exist, bench=bench, df_z=sc._feat.df_z,
L923                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L924                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D)
L925         except Exception:
L926             pass
L927     out.notify_slack()
L928     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L929               "sum_score": sumG, "objective": objG},
L930         resD={"tickers": top_D, "avg_res_corr": avgD,
L931               "sum_score": sumD, "objective": objD},
L932         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L933
L934     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L935     try:
L936         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L937               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L938               .sort_values("G_plus_D")
L939               .head(10)
L940               .round(3))
L941         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L942                "```"
L943                + _low_df.to_string(index=True, index_names=False)
L944                + "\n```")
L945     except Exception as _e:
L946         _slack(f"Low Score Candidates: ä½œæˆå¤±æ•—: {_e}")
L947
L948     if debug_mode:
L949         try:
L950             _slack_debug(_compact_debug(fb, sb, [], []))
L951         except Exception as e:
L952             print(f"[debug skipped] {e}")
L953
L954     return sb
L955
L956 if __name__ == "__main__":
L957     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None: return float(c)
L43     try:
L44         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L45         return float(h.iloc[-1]) if len(h) else np.nan
L46     except Exception:
L47         return np.nan
L48
L49 def _ttm_div_sum(t, lookback_days=400):
L50     try:
L51         div = yf.Ticker(t).dividends
L52         if div is None or len(div) == 0: return 0.0
L53         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L54         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L55         return ttm if ttm > 0 else float(div.tail(4).sum())
L56     except Exception:
L57         return 0.0
L58
L59 def ttm_div_yield_portfolio(tickers, price_map=None):
L60     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L61     return float(np.mean(ys)) if ys else 0.0
L62
L63 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L64 def winsorize_s(s: pd.Series, p=0.02):
L65     if s is None or s.dropna().empty: return s
L66     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L67
L68 def robust_z(s: pd.Series, p=0.02):
L69     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L70
L71 def _safe_div(a, b):
L72     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L73     except Exception: return np.nan
L74
L75 def _safe_last(series: pd.Series, default=np.nan):
L76     try: return float(series.iloc[-1])
L77     except Exception: return default
L78
L79 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L80
L81 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L82 class Scorer:
L83     """
L84     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L85     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L86     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L87     """
L88
L89     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L90     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L91     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L92
L93     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L94     @staticmethod
L95     def _validate_ib_for_scorer(ib: Any):
L96         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L97         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L98         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L99         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L100         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L101         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L102         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L103
L104     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L105     @staticmethod
L106     def trend(s: pd.Series):
L107         if len(s)<200: return np.nan
L108         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L109         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L110         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L111         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L112         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L113         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L114         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L115         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L116         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L117         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L118         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L119         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L120
L121     @staticmethod
L122     def rs(s, b):
L123         n, nb = len(s), len(b)
L124         if n<60 or nb<60: return np.nan
L125         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L126         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L127         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L128
L129     @staticmethod
L130     def tr_str(s):
L131         if len(s)<50: return np.nan
L132         return s.iloc[-1]/s.rolling(50).mean().iloc[-1] - 1
L133
L134     @staticmethod
L135     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L136         r = (s/b).dropna()
L137         if len(r) < win: return np.nan
L138         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L139         try: return float(np.polyfit(x, y, 1)[0])
L140         except Exception: return np.nan
L141
L142     @staticmethod
L143     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L144         ev = info_t.get('enterpriseValue', np.nan)
L145         if pd.notna(ev) and ev>0: return float(ev)
L146         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L147         try:
L148             bs = tk.quarterly_balance_sheet
L149             if bs is not None and not bs.empty:
L150                 c = bs.columns[0]
L151                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L152                     if k in bs.index: debt = float(bs.loc[k,c]); break
L153                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L154                     if k in bs.index: cash = float(bs.loc[k,c]); break
L155         except Exception: pass
L156         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L157         return np.nan
L158
L159     @staticmethod
L160     def dividend_status(ticker: str) -> str:
L161         t = yf.Ticker(ticker)
L162         try:
L163             if not t.dividends.empty: return "has"
L164         except Exception: return "unknown"
L165         try:
L166             a = t.actions
L167             if (a is not None and not a.empty and "Stock Splits" in a.columns and a["Stock Splits"].abs().sum()>0): return "none_confident"
L168         except Exception: pass
L169         try:
L170             fi = t.fast_info
L171             if any(getattr(fi,k,None) for k in ("last_dividend_date","dividend_rate","dividend_yield")): return "maybe_missing"
L172         except Exception: pass
L173         return "unknown"
L174
L175     @staticmethod
L176     def div_streak(t):
L177         try:
L178             divs = yf.Ticker(t).dividends.dropna(); ann = divs.groupby(divs.index.year).sum(); ann = ann[ann.index<pd.Timestamp.today().year]
L179             years, streak = sorted(ann.index), 0
L180             for i in range(len(years)-1,0,-1):
L181                 if ann[years[i]] > ann[years[i-1]]: streak += 1
L182                 else: break
L183             return streak
L184         except Exception: return 0
L185
L186     @staticmethod
L187     def fetch_finnhub_metrics(symbol):
L188         api_key = os.environ.get("FINNHUB_API_KEY")
L189         if not api_key: return {}
L190         url, params = "https://finnhub.io/api/v1/stock/metric", {"symbol":symbol,"metric":"all","token":api_key}
L191         try:
L192             r = requests.get(url, params=params, timeout=10); r.raise_for_status(); m = r.json().get("metric",{})
L193             return {'EPS':m.get('epsGrowthTTMYoy'),'REV':m.get('revenueGrowthTTMYoy'),'ROE':m.get('roeTTM'),'BETA':m.get('beta'),'DIV':m.get('dividendYieldIndicatedAnnual'),'FCF':(m.get('freeCashFlowTTM')/m.get('enterpriseValue')) if m.get('freeCashFlowTTM') and m.get('enterpriseValue') else None}
L194         except Exception: return {}
L195
L196     @staticmethod
L197     def calc_beta(series: pd.Series, market: pd.Series, lookback=252):
L198         r, m = series.pct_change().dropna(), market.pct_change().dropna()
L199         n = min(len(r), len(m), lookback)
L200         if n<60: return np.nan
L201         r, m = r.iloc[-n:], m.iloc[-n:]; cov, var = np.cov(r, m)[0,1], np.var(m)
L202         return np.nan if var==0 else cov/var
L203
L204     @staticmethod
L205     def spx_to_alpha(spx: pd.Series, bands=(0.03,0.10), w=(0.6,0.4),
L206                      span=5, q=(0.20,0.40), alphas=(0.05,0.08,0.10)) -> float:
L207         """
L208         S&P500æŒ‡æ•°ã®ã¿ã‹ã‚‰æ“¬ä¼¼breadthã‚’ä½œã‚Šã€å±¥æ­´åˆ†ä½ã§Î±ã‚’æ®µéšæ±ºå®šã€‚
L209         bands=(Â±3%, Â±10%), w=(50DMA,200DMA), åˆ†ä½q=(20%,40%), alphas=(ä½,ä¸­,é«˜)
L210         """
L211         ma50, ma200 = spx.rolling(50).mean(), spx.rolling(200).mean()
L212         b50, b200 = ((spx/ma50 - 1)+bands[0])/(2*bands[0]), ((spx/ma200 - 1)+bands[1])/(2*bands[1])
L213         hist = (w[0]*b50 + w[1]*b200).clip(0,1).ewm(span=span).mean()
L214         b, (lo, mid) = float(hist.iloc[-1]), (float(hist.quantile(q[0])), float(hist.quantile(q[1])))
L215         return alphas[0] if b < lo else alphas[1] if b < mid else alphas[2]
L216
L217     @staticmethod
L218     def soft_cap_effective_scores(scores: pd.Series|dict, sectors: dict, cap=2, alpha=0.08) -> pd.Series:
L219         """
L220         åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼capè¶…éï¼ˆ3æœ¬ç›®ä»¥é™ï¼‰ã« Î±Ã—æ®µéšæ¸›ç‚¹ã‚’èª²ã—ãŸâ€œæœ‰åŠ¹ã‚¹ã‚³ã‚¢â€Seriesã‚’è¿”ã™ã€‚
L221         æˆ»ã‚Šå€¤ã¯é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã€‚
L222         """
L223         s = pd.Series(scores, dtype=float); order = s.sort_values(ascending=False).index
L224         cnt, pen = {}, {}
L225         for t in order:
L226             sec = sectors.get(t, "U"); cnt[sec] = cnt.get(sec,0) + 1; pen[t] = alpha*max(0, cnt[sec]-cap)
L227         return (s - pd.Series(pen)).sort_values(ascending=False)
L228
L229     @staticmethod
L230     def pick_top_softcap(scores: pd.Series|dict, sectors: dict, N: int, cap=2, alpha=0.08, hard: int|None=5) -> list[str]:
L231         """
L232         soft-capé©ç”¨å¾Œã®ä¸Šä½Nãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚hard>0ãªã‚‰éå¸¸ç”¨ãƒãƒ¼ãƒ‰ä¸Šé™ã§åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼è¶…éã‚’é–“å¼•ãï¼ˆæ—¢å®š=5ï¼‰ã€‚
L233         """
L234         eff = Scorer.soft_cap_effective_scores(scores, sectors, cap, alpha)
L235         if not hard:
L236             return list(eff.head(N).index)
L237         pick, used = [], {}
L238         for t in eff.index:
L239             s = sectors.get(t, "U")
L240             if used.get(s,0) < hard:
L241                 pick.append(t); used[s] = used.get(s,0) + 1
L242             if len(pick) == N: break
L243         return pick
L244
L245     @staticmethod
L246     def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L247         """
L248         å„å–¶æ¥­æ—¥ã® trend_template åˆæ ¼æœ¬æ•°ï¼ˆåˆæ ¼â€œæœ¬æ•°â€=Cï¼‰ã‚’è¿”ã™ã€‚
L249         - px: åˆ—=tickerï¼ˆãƒ™ãƒ³ãƒã¯å«ã‚ãªã„ï¼‰
L250         - spx: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Seriesï¼ˆpx.index ã«æ•´åˆ—ï¼‰
L251         - win_days: æœ«å°¾ã®è¨ˆç®—å¯¾è±¡å–¶æ¥­æ—¥æ•°ï¼ˆNoneâ†’å…¨ä½“ã€æ—¢å®š600ã¯å‘¼ã³å‡ºã—å´æŒ‡å®šï¼‰
L252         ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼†rollingã®ã¿ã§è»½é‡ã€‚æ¬ æã¯ False æ‰±ã„ã€‚
L253         """
L254         import numpy as np, pandas as pd
L255         if px is None or px.empty:
L256             return pd.Series(dtype=int)
L257         px = px.dropna(how="all", axis=1)
L258         if win_days and win_days > 0:
L259             px = px.tail(win_days)
L260         if px.empty:
L261             return pd.Series(dtype=int)
L262         spx = spx.reindex(px.index).ffill()
L263
L264         ma50  = px.rolling(50).mean()
L265         ma150 = px.rolling(150).mean()
L266         ma200 = px.rolling(200).mean()
L267
L268         tt = (px > ma150)
L269         tt &= (px > ma200)
L270         tt &= (ma150 > ma200)
L271         tt &= (ma200 - ma200.shift(21) > 0)
L272         tt &= (ma50  > ma150)
L273         tt &= (ma50  > ma200)
L274         tt &= (px    > ma50)
L275
L276         lo252 = px.rolling(252).min()
L277         hi252 = px.rolling(252).max()
L278         tt &= (px.divide(lo252).sub(1.0) >= 0.30)   # P_OVER_LOW52 >= 0.30
L279         tt &= (px >= (0.75 * hi252))                # NEAR_52W_HIGH >= -0.25
L280
L281         r12  = px.divide(px.shift(252)).sub(1.0)
L282         br12 = spx.divide(spx.shift(252)).sub(1.0)
L283         r1   = px.divide(px.shift(22)).sub(1.0)
L284         br1  = spx.divide(spx.shift(22)).sub(1.0)
L285         rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L286         tt &= (rs >= 0.10)
L287
L288         return tt.fillna(False).sum(axis=1).astype(int)
L289
L290     def filter_candidates(self, ib, agg, group, cfg):
L291         df = ib.eps_df.join(ib.fcf_df, how="outer")
L292         eps_any = (df.get("EPS_TTM", 0) > 0) | (df.get("nEPS_ttm", 0) > 0)
L293         profitable = eps_any & (df.get("FCF_TTM", 0) > 0)
L294         return profitable.reindex(agg.index).fillna(False)
L295
L296     # ---- ã‚¹ã‚³ã‚¢é›†è¨ˆï¼ˆDTO/Configã‚’å—ã‘å–ã‚Šã€FeatureBundleã‚’è¿”ã™ï¼‰ ----
L297     def aggregate_scores(self, ib: Any, cfg):
L298         if cfg is None:
L299             raise ValueError("cfg is required; pass factor.PipelineConfig")
L300         self._validate_ib_for_scorer(ib)
L301
L302         px, spx, tickers = ib.px, ib.spx, ib.tickers
L303         tickers_bulk, info, eps_df, fcf_df = ib.tickers_bulk, ib.info, ib.eps_df, ib.fcf_df
L304
L305         df, missing_logs = pd.DataFrame(index=tickers), []
L306         for t in tickers:
L307             d, s = info[t], px[t]; ev = self.ev_fallback(d, tickers_bulk.tickers[t])
L308             # --- åŸºæœ¬ç‰¹å¾´ ---
L309             df.loc[t,'TR']   = self.trend(s)
L310             df.loc[t,'EPS']  = eps_df.loc[t,'EPS_TTM'] if t in eps_df.index else np.nan
L311             if 'nEPS_ttm' in eps_df.columns:
L312                 df.loc[t,'nEPS_ttm'] = eps_df.loc[t,'nEPS_ttm'] if t in eps_df.index else np.nan
L313             else:
L314                 df.loc[t,'nEPS_ttm'] = np.nan
L315             df.loc[t,'REV']  = d.get('revenueGrowth',np.nan)
L316             df.loc[t,'ROE']  = d.get('returnOnEquity',np.nan)
L317             df.loc[t,'BETA'] = self.calc_beta(s, spx, lookback=252)
L318
L319             # --- é…å½“ï¼ˆç›´è¿‘1å¹´ç„¡é…ã¯ DIV=0 æ‰±ã„ï¼‰ ---
L320             div = 0.0
L321             try:
L322                 divs = yf.Ticker(t).dividends
L323                 if divs is not None and not divs.empty:
L324                     last_close = s.iloc[-1]
L325                     cutoff = divs.index.max() - pd.Timedelta(days=365)
L326                     ttm_sum = float(divs[divs.index >= cutoff].sum())
L327                     # ç›´è¿‘1å¹´ã®ç¾é‡‘é…å½“åˆè¨ˆãŒæ­£ãªã‚‰ã®ã¿æ¡ç”¨ï¼ˆç‰¹åˆ¥é…ã®éå»åˆ†ã¯ç„¡è¦–ï¼‰
L328                     if last_close and last_close > 0 and ttm_sum > 0:
L329                         div = ttm_sum / float(last_close)
L330             except Exception:
L331                 pass
L332
L333             # dividends æ™‚ç³»åˆ—ãŒå–ã‚Œãªã‹ã£ãŸã¨ãã ã‘ã€infoå´ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
L334             if div == 0.0:
L335                 yi = d.get('dividendYield', None)
L336                 if yi is None:
L337                     yi = d.get('trailingAnnualDividendYield', None)
L338                 try:
L339                     if yi is not None and not pd.isna(yi):
L340                         div = float(yi)
L341                 except Exception:
L342                     pass
L343
L344             df.loc[t, 'DIV'] = float(div)  # æœ€çµ‚ç¢ºå®šã€‚ç›´è¿‘1å¹´ã‚¼ãƒ­ãªã‚‰å¿…ãš 0.0
L345
L346             # --- FCF/EV ---
L347             fcf_val = fcf_df.loc[t,'FCF_TTM'] if t in fcf_df.index else np.nan
L348             df.loc[t,'FCF_TTM'] = fcf_val
L349             df.loc[t,'FCF'] = (fcf_val/ev) if (pd.notna(fcf_val) and pd.notna(ev) and ev>0) else np.nan
L350
L351             # --- ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ»ãƒœãƒ©é–¢é€£ ---
L352             df.loc[t,'RS'], df.loc[t,'TR_str'] = self.rs(s, spx), self.tr_str(s)
L353             r, rm = s.pct_change().dropna(), spx.pct_change().dropna()
L354             n = int(min(len(r), len(rm)))
L355
L356             DOWNSIDE_DEV = np.nan
L357             if n>=60:
L358                 r6 = r.iloc[-min(len(r),126):]; neg = r6[r6<0]
L359                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L360             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L361
L362             MDD_1Y = np.nan
L363             try:
L364                 w = s.iloc[-min(len(s),252):].dropna()
L365                 if len(w)>=30:
L366                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L367             except Exception: pass
L368             df.loc[t,'MDD_1Y'] = MDD_1Y
L369
L370             RESID_VOL = np.nan
L371             if n>=120:
L372                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L373                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L374                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L375                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L376             df.loc[t,'RESID_VOL'] = RESID_VOL
L377
L378             DOWN_OUTPERF = np.nan
L379             if n>=60:
L380                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L381                 if mask.sum()>=10:
L382                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L383                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L384             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L385
L386             # --- é•·æœŸç§»å‹•å¹³å‡/ä½ç½® ---
L387             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L388             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L389
L390             # --- é…å½“ã®è©³ç´°ç³» ---
L391             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L392             try:
L393                 divs = yf.Ticker(t).dividends.dropna()
L394                 if not divs.empty:
L395                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L396                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L397                     ann = divs.groupby(divs.index.year).sum()
L398                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L399                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L400                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L401                 so = d.get('sharesOutstanding',None)
L402                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L403                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L404             except Exception: pass
L405             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L406
L407             # --- è²¡å‹™å®‰å®šæ€§ ---
L408             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L409
L410             # --- EPS å¤‰å‹• ---
L411             EPS_VAR_8Q = np.nan
L412             try:
L413                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L414                 if qe is not None and not qe.empty and so:
L415                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L416                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L417             except Exception: pass
L418             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L419
L420             # --- ã‚µã‚¤ã‚º/æµå‹•æ€§ ---
L421             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L422             try:
L423                 vol_series = ib.data['Volume'][t].dropna()
L424                 if len(vol_series)>=5 and len(s)==len(vol_series):
L425                     dv = (vol_series*s).rolling(60).mean(); adv60 = float(dv.iloc[-1])
L426             except Exception: pass
L427             df.loc[t,'ADV60_USD'] = adv60
L428
L429             # --- å£²ä¸Š/åˆ©ç›Šã®åŠ é€Ÿåº¦ç­‰ ---
L430             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L431             REV_ANNUAL_STREAK = np.nan
L432             try:
L433                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L434                 if qe is not None and not qe.empty:
L435                     if 'Revenue' in qe.columns:
L436                         rev = qe['Revenue'].dropna().astype(float)
L437                         if len(rev)>=5: REV_Q_YOY = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5])
L438                         if len(rev)>=6:
L439                             yoy_now = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5]); yoy_prev = _safe_div(rev.iloc[-2]-rev.iloc[-6], rev.iloc[-6])
L440                             if pd.notna(yoy_now) and pd.notna(yoy_prev): REV_YOY_ACC = yoy_now - yoy_prev
L441                         yoy_list=[]
L442                         for k in range(1,5):
L443                             if len(rev)>=4+k:
L444                                 y = _safe_div(rev.iloc[-k]-rev.iloc[-(k+4)], rev.iloc[-(k+4)])
L445                                 if pd.notna(y): yoy_list.append(y)
L446                         if len(yoy_list)>=2: REV_YOY_VAR = float(np.std(yoy_list, ddof=1))
L447                         # NEW: å¹´æ¬¡ã®æŒç¶šæ€§ï¼ˆç›´è¿‘ã‹ã‚‰é¡ã£ã¦å‰å¹´æ¯”ãƒ—ãƒ©ã‚¹ãŒä½•å¹´é€£ç¶šã‹ã€å››åŠæœŸ4æœ¬æƒã†å®Œå…¨å¹´ã®ã¿ï¼‰
L448                         try:
L449                             g = rev.groupby(rev.index.year)
L450                             ann_sum, cnt = g.sum(), g.count()
L451                             ann_sum = ann_sum[cnt >= 4]
L452                             if len(ann_sum) >= 3:
L453                                 yoy = ann_sum.pct_change().dropna()
L454                                 streak = 0
L455                                 for v in yoy.iloc[::-1]:
L456                                     if pd.isna(v) or v <= 0:
L457                                         break
L458                                     streak += 1
L459                                 REV_ANNUAL_STREAK = float(streak)
L460                         except Exception:
L461                             pass
L462                     if 'Earnings' in qe.columns and so:
L463                         eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L464                         if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L465                             EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L466             except Exception: pass
L467             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'], df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_Q_YOY, EPS_Q_YOY, REV_YOY_ACC, REV_YOY_VAR
L468             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L469
L470             # --- Rule of 40 ã‚„å‘¨è¾º ---
L471             total_rev_ttm = d.get('totalRevenue',np.nan)
L472             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L473             df.loc[t,'FCF_MGN'] = FCF_MGN
L474             rule40 = np.nan
L475             try:
L476                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L477             except Exception: pass
L478             df.loc[t,'RULE40'] = rule40
L479
L480             # --- ãƒˆãƒ¬ãƒ³ãƒ‰è£œåŠ© ---
L481             sma50  = s.rolling(50).mean()
L482             sma150 = s.rolling(150).mean()
L483             sma200 = s.rolling(200).mean()
L484             p = _safe_last(s)
L485
L486             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L487                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L488             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L489                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L490
L491             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L492             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L493
L494             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L495             if len(sma200.dropna()) >= 21:
L496                 cur200 = _safe_last(sma200)
L497                 old2001 = float(sma200.iloc[-21])
L498                 if old2001:
L499                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L500
L501             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L502             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L503             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L504             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L505             if len(sma200.dropna())>=105:
L506                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L507                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L508             # NEW: 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ãã®ã€Œæ—¥æ•°ã€
L509             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L510             try:
L511                 s200 = sma200.dropna()
L512                 if len(s200) >= 2:
L513                     diff200 = s200.diff()
L514                     up = 0
L515                     for v in diff200.iloc[::-1]:
L516                         if pd.isna(v) or v <= 0:
L517                             break
L518                         up += 1
L519                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L520             except Exception:
L521                 pass
L522             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L523             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L524             if hi52 and hi52>0 and pd.notna(p):
L525                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L526             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L527             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L528
L529             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L530
L531             # --- æ¬ æãƒ¡ãƒ¢ ---
L532             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L533             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L534             if need_finnhub:
L535                 fin_data = self.fetch_finnhub_metrics(t)
L536                 for col in need_finnhub:
L537                     val = fin_data.get(col)
L538                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L539             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L540                 if pd.isna(df.loc[t,col]):
L541                     if col=='DIV':
L542                         status = self.dividend_status(t)
L543                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L544                     else:
L545                         missing_logs.append({'Ticker':t,'Column':col})
L546
L547         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L548             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L549             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L550             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L551             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L552             c5 = (row.get('TR_str', np.nan) > 0)
L553             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L554             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L555             c8 = (row.get('RS', np.nan) >= 0.10)
L556             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L557
L558         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L559         assert 'trend_template' in df.columns
L560
L561         # === ZåŒ–ã¨åˆæˆ ===
L562         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L563
L564         for _c in ('DIV_TTM_PS', 'DIV_FCF_COVER'):
L565             if _c in df.columns:
L566                 df[_c] = df[_c].fillna(0.0)
L567
L568         df_z = pd.DataFrame(index=df.index)
L569         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']:
L570             df_z[col] = robust_z(df[col])
L571         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L572         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L573         for col in ['REV_Q_YOY','EPS_Q_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']: df_z[col] = robust_z(df[col])
L574         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L575
L576         # --- Dividend handling: penalize non-payers ---
L577         df['HAS_DIV'] = (df['DIV_TTM_PS'] > 0).astype(int)
L578         y = df['DIV_TTM_PS'].where(df['HAS_DIV'] == 1, np.nan)
L579         y_non = y.dropna()
L580         z_yld = pd.Series(robust_z(y_non), index=y_non.index).reindex(df.index)
L581         penalty = (np.nanmin(z_yld) - 1.0) if len(z_yld.dropna()) else -1.0
L582         z_yld = z_yld.fillna(penalty)
L583         z_streak = pd.Series(robust_z(df['DIV_STREAK'].where(df['HAS_DIV'] == 1, 0)), index=df.index)
L584         z_cover = pd.Series(robust_z(df['DIV_FCF_COVER'].where(df['HAS_DIV'] == 1, 0)), index=df.index)
L585         z_var = pd.Series(robust_z(df['DIV_VAR5'].where(df['HAS_DIV'] == 1, df['DIV_VAR5'].max())), index=df.index)
L586         df['YLD'] = (
L587             0.30*z_yld +
L588             0.30*z_streak +
L589             0.25*z_cover -
L590             0.15*z_var
L591         )
L592         df_z['DIV'] = z_yld
L593         df_z['DIV_STREAK'] = z_streak
L594         df_z['DIV_FCF_COVER'] = z_cover
L595         df_z['DIV_VAR5'] = z_var
L596
L597         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L598         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L599         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L600         df_z['GROWTH_F']  = robust_z(0.25*df_z['REV']          # â†“0.30â†’0.25
L601             + 0.20*df_z['EPS_Q_YOY']
L602             + 0.15*df_z['REV_Q_YOY']
L603             + 0.15*df_z['REV_YOY_ACC']
L604             + 0.10*df_z['RULE40']
L605             + 0.10*df_z['FCF_MGN']
L606             + 0.10*df_z['EPS']          # â˜…è¿½åŠ ï¼šé»’å­—å„ªé‡ï¼èµ¤å­—æ¸›ç‚¹
L607             + 0.05*df_z['REV_ANN_STREAK']
L608             - 0.05*df_z['REV_YOY_VAR']).clip(-3.0,3.0)
L609         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L610             + 0.15*df_z['TR_str']
L611             + 0.15*df_z['RS_SLOPE_6W']
L612             + 0.15*df_z['RS_SLOPE_13W']
L613             + 0.10*df_z['MA200_SLOPE_5M']
L614             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L615         df_z['VOL'] = robust_z(df['BETA'])
L616         df_z.rename(columns={'GROWTH_F':'GRW','MOM_F':'MOM','QUALITY_F':'QAL','YIELD_F':'YLD'}, inplace=True)
L617
L618         # --- EPS-only penalty: punish negative EPS (GAAP or nEPS) ---
L619         eps_any = (df.get('EPS', 0) > 0) | (df.get('nEPS_ttm', 0) > 0)
L620         PEN_EPS = float(os.getenv("PEN_EPS_FOR_GRW", "0.8"))
L621         if 'GRW' in df_z.columns:
L622             red_eps = (~eps_any).astype(float)
L623             # Adjust displayed GRW directly based on EPS penalty only (no FCF)
L624             df_z['GRW'] = (df_z['GRW'] - PEN_EPS * red_eps).clip(-3.0, 3.0)
L625
L626         # === begin: BIO LOSS PENALTY =====================================
L627         try:
L628             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L629         except Exception:
L630             penalty_z = 0.8
L631
L632         def _is_bio_like(t: str) -> bool:
L633             inf = info.get(t, {}) if isinstance(info, dict) else {}
L634             sec = str(inf.get("sector", "")).lower()
L635             ind = str(inf.get("industry", "")).lower()
L636             if "health" not in sec:
L637                 return False
L638             keys = ("biotech", "biopharma", "pharma")
L639             return any(k in ind for k in keys)
L640
L641         tickers_s = pd.Index(df_z.index)
L642         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L643         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L644         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L645
L646         if bool(mask_bio_loss.any()) and penalty_z > 0:
L647             df_z.loc[mask_bio_loss, "GRW"] = df_z.loc[mask_bio_loss, "GRW"] - penalty_z
L648             df_z["GRW"] = df_z["GRW"].clip(-3.0, 3.0)
L649         # === end: BIO LOSS PENALTY =======================================
L650
L651         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L652         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L653
L654         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L655         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L656         df_z['D_YLD']     = df['YLD']
L657         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L658
L659         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L660         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L661         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L662
L663         d_comp = pd.concat({
L664             'QAL': df_z['D_QAL'],
L665             'YLD': df_z['D_YLD'],
L666             'VOL': df_z['D_VOL_RAW'],
L667             'TRD': df_z['D_TRD']
L668         }, axis=1)
L669         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L670         globals()['D_WEIGHTS_EFF'] = dw.copy()
L671         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L672
L673         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L674         mask = df['trend_template']
L675         if not bool(mask.any()):
L676             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L677                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L678                 (df.get('RS', np.nan) >= 0.08) &
L679                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L680                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L681                 (df.get('MA150_OVER_200', np.nan) > 0) &
L682                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L683                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L684             df['trend_template'] = mask
L685
L686         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L687         g_score = g_score_all.loc[mask]
L688         Scorer.g_score = g_score
L689         df_z['GSC'] = g_score_all
L690         df_z['DSC'] = d_score_all
L691
L692         try:
L693             current = (pd.read_csv("current_tickers.csv")
L694                   .iloc[:, 0]
L695                   .str.upper()
L696                   .tolist())
L697         except FileNotFoundError:
L698             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L699             current = []
L700
L701         mask_bonus = g_score.index.isin(current)
L702         if mask_bonus.any():
L703             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L704             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L705             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L706             sigma_g = g_score.std()
L707             if pd.isna(sigma_g):
L708                 sigma_g = 0.0
L709             bonus_g = round(k * sigma_g, 3)
L710             g_score.loc[mask_bonus] += bonus_g
L711             Scorer.g_score = g_score
L712             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L713             sigma_d = d_score_all.std()
L714             if pd.isna(sigma_d):
L715                 sigma_d = 0.0
L716             bonus_d = round(k * sigma_d, 3)
L717             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L718
L719         try:
L720             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L721         except Exception:
L722             pass
L723
L724         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L725         return FeatureBundle(df=df,
L726             df_z=df_z,
L727             g_score=g_score,
L728             d_score_all=d_score_all,
L729             missing_logs=pd.DataFrame(missing_logs))
L730
L731 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L732     """
L733     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L734     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L735       - G_BREAKOUT_recent_5d : bool
L736       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L737       - G_PULLBACK_recent_5d : bool
L738       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L739       - G_PIVOT_price        : float
L740     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L741     """
L742     try:
L743         px   = bundle.px                      # çµ‚å€¤ DataFrame
L744         hi   = bundle.data['High']
L745         lo   = bundle.data['Low']
L746         vol  = bundle.data['Volume']
L747         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L748
L749         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L750         g_universe = getattr(self_obj, "g_universe", None)
L751         if g_universe is None:
L752             try:
L753                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L754             except Exception:
L755                 g_universe = list(feature_df.index)
L756         if not g_universe:
L757             return feature_df
L758
L759         # æŒ‡æ¨™
L760         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L761         ma50  = px[g_universe].rolling(50).mean()
L762         ma150 = px[g_universe].rolling(150).mean()
L763         ma200 = px[g_universe].rolling(200).mean()
L764         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L765         vol20 = vol[g_universe].rolling(20).mean()
L766         vol50 = vol[g_universe].rolling(50).mean()
L767
L768         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L769         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L770                             & (ma150 > ma200) & (ma200.diff() > 0)
L771
L772         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L773         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L774
L775         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L776         bench_aligned = bench.reindex(px.index).ffill()
L777         rs = px[g_universe].div(bench_aligned, axis=0)
L778         rs_high = rs.rolling(252).max().shift(1)
L779
L780         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L781         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L782                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L783         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L784
L785         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L786         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L787         volume_dryup = (vol20 / vol50) <= 1.0
L788         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L789         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L790         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L791
L792         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L793         rows = []
L794         for t in g_universe:
L795             def _recent_and_date(s, win):
L796                 sw = s[t].iloc[-win:]
L797                 if sw.any():
L798                     d = sw[sw].index[-1]
L799                     return True, d.strftime("%Y-%m-%d")
L800                 return False, ""
L801             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L802             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L803             rows.append((t, {
L804                 "G_BREAKOUT_recent_5d": br_recent,
L805                 "G_BREAKOUT_last_date": br_date,
L806                 "G_PULLBACK_recent_5d": pb_recent,
L807                 "G_PULLBACK_last_date": pb_date,
L808                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L809             }))
L810         flags = pd.DataFrame({k: v for k, v in rows}).T
L811
L812         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L813         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L814         for c in cols:
L815             if c not in feature_df.columns:
L816                 feature_df[c] = np.nan
L817         feature_df.loc[flags.index, flags.columns] = flags
L818
L819     except Exception:
L820         pass
L821     return feature_df
L822
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v3
L24
L25       - name: Setup Python
L26         uses: actions/setup-python@v5
L27         with:
L28           python-version: '3.x'
L29           cache: 'pip'
L30           cache-dependency-path: requirements.txt
L31
L32       - name: Install dependencies
L33         run: pip install -r requirements.txt
L34
L35       - name: Prepare results directory
L36         run: mkdir -p results
L37
L38       - name: Run factor & scoring
L39         env:
L40           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L41           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L42           FIN_THREADS: "8"
L43         run: python factor.py
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**ï¼ˆNORMAL åŸºæº–ï¼‰
L7
L8 ## Barbell Growth-Defenseæ–¹é‡
L9 - Growthæ  **12éŠ˜æŸ„**ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L10 - Defenseæ  **8éŠ˜æŸ„**ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L11 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L12
L13 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L14 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**ï¼ˆåŸºæº– N_G=12ï¼‰
L15 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L16   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L17   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= ceil(1.5Ã—12)ï¼‰
L18   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L19 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L20
L21 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L22  - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23  - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **14%**
L24  - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ20Ã—5%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L25
L26 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨â€œä¿æœ‰éŠ˜æŸ„æ•°â€ï¼ˆMMFâ‰’ç¾é‡‘ï¼‰
L27 *å„æ =5%ï¼ˆ20éŠ˜æŸ„å‡ç­‰ï¼‰ã€‚ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œæ™‚ã¯**Gã®æ æ•°ã®ã¿**èª¿æ•´ã—ã€å¤–ã—ãŸæ ã¯ç¾é‡‘ã¨ã—ã¦ä¿æŒã€‚*
L28
L29 - **NORMAL:** G **12** / D **8** / ç¾é‡‘åŒ–æ  **0**  
L30 - **CAUTION:** G **10** / D **8** / ç¾é‡‘åŒ–æ  **2**ï¼ˆ= 10%ï¼‰  
L31 - **EMERG:** G **8**  / D **8** / ç¾é‡‘åŒ–æ  **4**ï¼ˆ= 20%ï¼‰  
L32
L33 > å®Ÿé‹ç”¨ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚è§£é™¤æ™‚ã¯factorä¸Šä½ã‹ã‚‰è£œå……ã€‚
L34
L35 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
L36 - **åŸºæœ¬TS (ãƒ¢ãƒ¼ãƒ‰åˆ¥):** NORMAL **15%** / CAUTION **13%** / EMERG **10%**
L37 - å«ã¿ç›ŠãŒ **+30% / +60% / +100%** åˆ°é”ã§ã€åŸºæœ¬ã‹ã‚‰ **-3pt / -6pt / -8pt** å¼•ãä¸Šã’
L38 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L39
L40 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰æ‰‹é †
L41 ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã§**ã‚¢ãƒ©ãƒ¼ãƒˆ**ãŒå‡ºãŸå ´åˆï¼ˆåˆè¨ˆ|drift| ãŒãƒ¢ãƒ¼ãƒ‰é–¾å€¤ã‚’è¶…éã€EMERGé™¤ãï¼‰ã€ç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãã§ä¸‹è¨˜ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
L42
L43 1. **å£²å´ï¼ˆå¿…é ˆï¼‰**  
L44    Slackãƒ†ãƒ¼ãƒ–ãƒ«ã® **Î”qty ãŒãƒã‚¤ãƒŠã‚¹ã®éŠ˜æŸ„ã‚’å£²å´** ã™ã‚‹ï¼ˆå¯„ä»˜ãæˆè¡Œæ¨å¥¨ï¼‰ã€‚  
L45    ã“ã‚Œã¯ã€ŒåŠæˆ»ã—ã€è¨ˆç®—ã«åŸºã¥ãéé‡é‡ã®å‰Šæ¸›ã‚’æ„å‘³ã™ã‚‹ã€‚
L46
L47 2. **è³¼å…¥ï¼ˆä»»æ„ãƒ»åŠæˆ»ã—ç›®å®‰ï¼‰**  
L48    åŠæˆ»ã—å¾Œã®åˆè¨ˆ|drift|ã‚’**ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ï¼ˆSlackãƒ˜ãƒƒãƒ€ã«è¡¨ç¤ºï¼‰**ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ã‚’ç›®å®‰ã«ã€  
L49    **ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—**ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ï¼ˆÎ”qtyãŒãƒ—ãƒ©ã‚¹ã®éŠ˜æŸ„ã‚’å„ªå…ˆã—ã¦ã‚‚ã‚ˆã„ï¼‰ã€‚
L50
L51 3. **ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã®å†è¨­å®šï¼ˆå¿…é ˆï¼‰**  
L52    ã™ã¹ã¦ã®ä¿æœ‰éŠ˜æŸ„ã«ã¤ã„ã¦ã€æœ€æ–°ã®è©•ä¾¡é¡ã«åˆã‚ã›ã¦TSã‚’**å†ç™ºæ³¨ï¼æ›´æ–°**ã™ã‚‹ã€‚  
L53    ãƒ«ãƒ¼ãƒ«ã¯ä¸‹è¨˜ï¼ˆåˆ©ç›Šåˆ°é”ã§æ®µéšçš„ã«ã‚¿ã‚¤ãƒˆåŒ–ï¼‰ï¼š  
L54    - **åŸºæœ¬TS:** -15%  
L55    - **+30% åˆ°é” â†’ TS -12%**  
L56    - **+60% åˆ°é” â†’ TS -9%**  
L57    - **+100% åˆ°é” â†’ TS -7%**  
L58    â€»ã‚¹ãƒˆãƒƒãƒ—ä¾¡æ ¼ã®å¼•ãä¸Šã’ã¯è¨±å¯ã€**å¼•ãä¸‹ã’ã¯ä¸å¯**ï¼ˆåˆ©ç›Šä¿å…¨ã®åŸå‰‡ï¼‰ã€‚
L59
L60 4. **ä¾‹å¤–ï¼ˆEMERGãƒ¢ãƒ¼ãƒ‰ï¼‰**  
L61    ç·Šæ€¥(EMERG)ã§ã¯**ãƒ‰ãƒªãƒ•ãƒˆç”±æ¥ã®å£²è²·ã¯åœæ­¢ï¼ˆâˆï¼‰**ã€‚20éŠ˜æŸ„Ã—å„5%ã¸ã®**å…¨æˆ»ã—**ã®ã¿è¨±å®¹ã€‚
L62
L63 5. **å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°**
L64    - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L65    - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
L66
L67 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †ï¼ˆè¶…ã‚·ãƒ³ãƒ—ãƒ«ï¼‰
L68 ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€**Gã®æ æ•°ã ã‘**ã‚’èª¿æ•´ã™ã‚‹ï¼š
L69 1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰  
L70    - â­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚  
L71    - **`current_tickers.csv` ã‹ã‚‰å¤–ã™GéŠ˜æŸ„ã®è¡Œã‚’å‰Šé™¤**ï¼ˆï¼ãã®æ ã¯ç¾é‡‘åŒ–ï¼‰ã€‚
L72 2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**  
L73    - å¤–ã—ãŸæ ã¯ç¾é‡‘ï¼ˆã¾ãŸã¯MMFç›¸å½“ï¼‰ã§ãƒ—ãƒ¼ãƒ«ã€‚  
L74 3. **å¾©å¸°æ™‚ã®è£œå……**ï¼ˆNORMALã¸ï¼‰  
L75    - **`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ **ï¼ˆfactorä¸Šä½ã‹ã‚‰ï¼‰ã€‚  
L76    - ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚
L77
L78 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦è‡ªå‹•ã§å‡ç­‰æ¯”ç‡ãŒå†è¨ˆç®—ã•ã‚Œã‚‹ã€‚
L79
L80 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L81 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L82 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L83
L84 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L85 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L86
L87 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L88 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L89 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/factor_design.md>
```text
L1 # factor.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®éŠ˜æŸ„ã¨æ¤œè¨ä¸­ã®éŠ˜æŸ„ç¾¤ã‚’åŒæ™‚ã«æ‰±ã†éŠ˜æŸ„é¸å®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
L5 - ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨DRRSé¸å®šã‚’è¡Œã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚
L6   - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚æ¼ã‚ŒãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L7   - IN/OUTã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨OUTå´ã®ä½ã‚¹ã‚³ã‚¢éŠ˜æŸ„
L8   - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨
L9   - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ•´ç†ç”¨ï¼‰
L10
L11 ## å…¨ä½“ãƒ•ãƒ­ãƒ¼
L12 1. **Input** â€“ `current_tickers.csv`ã¨`candidate_tickers.csv`ã‚’èª­ã¿è¾¼ã¿ã€yfinanceã‚„Finnhubã®APIã‹ã‚‰ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦`InputBundle`ã‚’æ•´å‚™ã€‚
L13 2. **Score Calculation** â€“ ScorerãŒç‰¹å¾´é‡ã‚’è¨ˆç®—ã—å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã—ã¦`FeatureBundle`ã‚’ç”Ÿæˆã€‚
L14 3. **Correlation Reduction & Selection** â€“ SelectorãŒDRRSãƒ­ã‚¸ãƒƒã‚¯ã§ç›¸é–¢ã‚’æŠ‘ãˆã¤ã¤G/DéŠ˜æŸ„ã‚’é¸å®šã—`SelectionBundle`ã‚’å¾—ã‚‹ã€‚
L15 4. **Output** â€“ æ¡ç”¨çµæœã¨å‘¨è¾ºæƒ…å ±ã‚’è¡¨ãƒ»Slacké€šçŸ¥ã¨ã—ã¦å‡ºåŠ›ã€‚
L16
L17 ```mermaid
L18 flowchart LR
L19   A[Input\nAPI & å‰å‡¦ç†] --> B[Score Calculation\nç‰¹å¾´é‡ãƒ»å› å­åˆæˆ]
L20   B --> C[Correlation Reduction\nDRRSé¸å®š]
L21   C --> D[Output\nSlacké€šçŸ¥]
L22 ```
L23
L24 ## å®šæ•°ãƒ»è¨­å®š
L25 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L26 | --- | --- | --- |
L27 | `exist` / `cand` | ç¾è¡Œãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æ¤œè¨ä¸­éŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ | ã‚¹ã‚³ã‚¢å¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã®æ§‹æˆã€å€™è£œæ•´ç† |
L28 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L29 | `CAND_PRICE_MAX` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | é«˜é¡éŠ˜æŸ„ã®äº‹å‰é™¤å¤– |
L30 | `N_G` / `N_D` | G/Dæ¡ç”¨æ ã®ä»¶æ•°ï¼ˆ**æ—¢å®š: 12 / 8**ï¼‰ | æœ€çµ‚çš„ã«é¸ã¶éŠ˜æŸ„æ•°ã®åˆ¶ç´„ |
L31 | `g_weights` / `D_weights` | å„å› å­ã®é‡ã¿dict | G/Dã‚¹ã‚³ã‚¢åˆæˆ |
L32 | `D_BETA_MAX` | Dãƒã‚±ãƒƒãƒˆã®è¨±å®¹Î²ä¸Šé™ | é«˜Î²éŠ˜æŸ„ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ |
L33 | `FILTER_SPEC` | G/Dã”ã¨ã®å‰å‡¦ç†ãƒ•ã‚£ãƒ«ã‚¿ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¹ã‚¯ã‚„Î²ä¸Šé™è¨­å®š |
L34 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L35 | `DRRS_G` / `DRRS_D` | DRRSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç›¸é–¢ä½æ¸›è¨­å®š |
L36 | `DRRS_SHRINK` | æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å®‰å®šåŒ– |
L37 | `CROSS_MU_GD` | G-Dé–“ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ | 2ãƒã‚±ãƒƒãƒˆåŒæ™‚æœ€é©åŒ–ã§ç›¸é–¢æŠ‘åˆ¶ |
L38 | `RESULTS_DIR` | é¸å®šçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `_save_sel`/`_load_prev`ã®å…¥å‡ºåŠ› |
L39
L40 é¸å®šçµæœã¯`results/`é…ä¸‹ã«JSONã¨ã—ã¦ä¿å­˜ã—ã€æ¬¡å›å®Ÿè¡Œæ™‚ã«`_load_prev`ã§èª­ã¿è¾¼ã‚“ã§é¸å®šæ¡ä»¶ã«åæ˜ ã€‚
L41
L42 ## DTO/Config
L43 å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨è¨­å®šå€¤ã€‚å¤‰æ•°ã®æ„å‘³åˆã„ã¨åˆ©ç”¨ç®‡æ‰€ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚
L44
L45 ### InputBundleï¼ˆInput â†’ Scorerï¼‰
L46 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L47 | --- | --- | --- |
L48 | `cand` | å€™è£œéŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆ | OUTãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æ¯é›†å›£ |
L49 | `tickers` | ç¾è¡Œ+å€™è£œã‚’åˆã‚ã›ãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ | ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®— |
L50 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L51 | `data` | yfinanceã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœï¼ˆéšå±¤åˆ—ï¼‰ | `px`/`spx`/ãƒªã‚¿ãƒ¼ãƒ³ç­‰ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿ |
L52 | `px` | `data['Close']`ã ã‘ã‚’æŠœãå‡ºã—ãŸä¾¡æ ¼ç³»åˆ— | æŒ‡æ¨™è¨ˆç®—ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ç”Ÿæˆ |
L53 | `spx` | `data['Close'][bench]` ã®Series | `rs`ã‚„`calc_beta`ã®åŸºæº–æŒ‡æ•° |
L54 | `tickers_bulk` | `yf.Tickers`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | `info`ç­‰ã®ä¸€æ‹¬å–å¾— |
L55 | `info` | ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã®yfinanceæƒ…å ±dict | ã‚»ã‚¯ã‚¿ãƒ¼åˆ¤å®šã‚„EPSè£œå®Œ |
L56 | `eps_df` | EPS TTM/ç›´è¿‘EPSç­‰ã‚’ã¾ã¨ã‚ãŸè¡¨ | æˆé•·æŒ‡æ¨™ã®ç®—å‡º |
L57 | `fcf_df` | CFOãƒ»CapExãƒ»FCF TTMã¨æƒ…å ±æºãƒ•ãƒ©ã‚° | FCF/EVã‚„é…å½“ã‚«ãƒãƒ¬ãƒƒã‚¸ |
L58 | `returns` | `px.pct_change()`ã®ãƒªã‚¿ãƒ¼ãƒ³è¡¨ | ç›¸é–¢è¡Œåˆ—ãƒ»DRRSè¨ˆç®— |
L59
L60 ### FeatureBundleï¼ˆScorer â†’ Selectorï¼‰
L61 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L62 | --- | --- | --- |
L63 | `df` | è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™ã®ç”Ÿå€¤ãƒ†ãƒ¼ãƒ–ãƒ« | ãƒ‡ãƒãƒƒã‚°ãƒ»å‡ºåŠ›è¡¨ç¤º |
L64 | `df_z` | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å¾ŒZã‚¹ã‚³ã‚¢åŒ–ã—ãŸæŒ‡æ¨™è¡¨ | å› å­ã‚¹ã‚³ã‚¢åˆæˆã€é¸å®šåŸºæº– |
L65 | `g_score` | Gãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ | Gé¸å®šã€IN/OUTæ¯”è¼ƒ |
L66 | `d_score_all` | Dãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ï¼ˆå…¨éŠ˜æŸ„ï¼‰ | Dé¸å®šã€ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
L67 | `missing_logs` | æ¬ ææŒ‡æ¨™ã¨è£œå®ŒçŠ¶æ³ã®ãƒ­ã‚° | ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ |
L68
L69 ### SelectionBundleï¼ˆSelector â†’ Outputï¼‰
L70 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L71 | --- | --- | --- |
L72 | `resG` | Gé¸å®šçµæœã®è©³ç´°dictï¼ˆ`tickers`ã€ç›®çš„å€¤ç­‰ï¼‰ | çµæœä¿å­˜ãƒ»å¹³å‡ç›¸é–¢ãªã©ã®æŒ‡æ¨™è¡¨ç¤º |
L73 | `resD` | Dé¸å®šçµæœã®è©³ç´°dict | åŒä¸Š |
L74 | `top_G` | æœ€çµ‚æ¡ç”¨Gãƒ†ã‚£ãƒƒã‚«ãƒ¼ | æ–°ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ |
L75 | `top_D` | æœ€çµ‚æ¡ç”¨Dãƒ†ã‚£ãƒƒã‚«ãƒ¼ | åŒä¸Š |
L76 | `init_G` | DRRSå‰ã®GåˆæœŸå€™è£œ | æƒœã—ãã‚‚å¤–ã‚ŒãŸéŠ˜æŸ„è¡¨ç¤º |
L77 | `init_D` | DRRSå‰ã®DåˆæœŸå€™è£œ | åŒä¸Š |
L78
L79 ### WeightsConfig
L80 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L81 | --- | --- | --- |
L82 | `g` | Gå› å­ï¼ˆGRW/MOM/VOLï¼‰ã®é‡ã¿dict | `g_score`åˆæˆ |
L83 | `d` | Då› å­ï¼ˆD_QAL/D_YLD/D_VOL_RAW/D_TRDï¼‰ã®é‡ã¿dict | `d_score_all`åˆæˆ |
L84
L85 ### DRRSParams
L86 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L87 | --- | --- | --- |
L88 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L89 | `shrink` | æ®‹å·®ç›¸é–¢ã®ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å¯¾è§’å¼·èª¿ |
L90 | `G` | Gãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dictï¼ˆ`lookback`ç­‰ï¼‰ | `select_bucket_drrs`è¨­å®š |
L91 | `D` | Dãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | åŒä¸Š |
L92 | `cross_mu_gd` | G-Dã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°Î¼ | `select_buckets`ã®ç›®çš„é–¢æ•° |
L93
L94 ### PipelineConfig
L95 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L96 | --- | --- | --- |
L97 | `weights` | `WeightsConfig`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | ã‚¹ã‚³ã‚¢åˆæˆã®é‡ã¿å‚ç…§ |
L98 | `drrs` | `DRRSParams`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | é¸å®šã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šå€¤ |
L99 | `price_max` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | Inputæ®µéšã§ã®ãƒ•ã‚£ãƒ«ã‚¿ |
L100
L101 ## å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
L102 - `winsorize_s` / `robust_z` : å¤–ã‚Œå€¤å‡¦ç†ã¨Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L103 - `_safe_div` / `_safe_last` : ä¾‹å¤–ã‚’æ½°ã—ãŸåˆ†å‰²ãƒ»æœ«å°¾å–å¾—ã€‚
L104 - `_load_prev` / `_save_sel` : é¸å®šçµæœã®èª­ã¿æ›¸ãã€‚
L105
L106 ## ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
L107 ### Step1: Input
L108 `current_tickers.csv`ã®ç¾è¡ŒéŠ˜æŸ„ã¨`candidate_tickers.csv`ã®æ¤œè¨ä¸­éŠ˜æŸ„ã‚’èµ·ç‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã™ã‚‹ã€‚å¤–éƒ¨I/Oã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€`prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¯**yfinanceã‚’å„ªå…ˆã—ã€æ¬ æãŒã‚ã‚‹æŒ‡æ¨™ã®ã¿Finnhub APIã§è£œå®Œ**ã™ã‚‹ã€‚
L109 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L110 - `impute_eps_ttm` : å››åŠæœŸEPSÃ—4ã§TTMã‚’æ¨å®šã—æ¬ ææ™‚ã®ã¿å·®ã—æ›¿ãˆã€‚
L111 - `fetch_cfo_capex_ttm_yf` : yfinanceã®å››åŠæœŸ/å¹´æ¬¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‹ã‚‰CFOãƒ»CapExãƒ»FCF TTMã‚’ç®—å‡ºã€‚
L112 - `fetch_cfo_capex_ttm_finnhub` : yfinanceã§æ¬ ã‘ãŸéŠ˜æŸ„ã®ã¿Finnhub APIã§è£œå®Œã€‚
L113 - `compute_fcf_with_fallback` : yfinanceå€¤ã‚’åŸºæº–ã«Finnhubå€¤ã§ç©´åŸ‹ã‚ã—ã€CFO/CapEx/FCFã¨æƒ…å ±æºãƒ•ãƒ©ã‚°ã‚’è¿”ã™ã€‚
L114 - `_build_eps_df` : `info`ã‚„`quarterly_earnings`ã‹ã‚‰EPS TTMã¨ç›´è¿‘EPSã‚’è¨ˆç®—ã—ã€`impute_eps_ttm`ã§è£œå®Œã€‚
L115 - `prepare_data` :
L116     0. CSVã‹ã‚‰ç¾è¡ŒéŠ˜æŸ„ã¨å€™è£œéŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
L117     1. å€™è£œéŠ˜æŸ„ã®ç¾åœ¨å€¤ã‚’å–å¾—ã—ä¾¡æ ¼ä¸Šé™ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
L118     2. æ—¢å­˜+å€™è£œã‹ã‚‰å¯¾è±¡ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’æ±ºå®šã—ã€ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆyfinanceï¼‰ã€‚
L119     3. yfinanceå€¤ã‚’åŸºã«EPS/FCFãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç³»åˆ—ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ¬ æã‚»ãƒ«ã¯Finnhubå‘¼ã³å‡ºã—ã§ç©´åŸ‹ã‚ã€‚
L120     4. ä¸Šè¨˜ã‚’`InputBundle`ã«æ ¼ç´ã—ã¦è¿”ã™ã€‚
L121
L122 ### Step2: Score Calculation (Scorer)
L123 ç‰¹å¾´é‡è¨ˆç®—ã¨ã‚¹ã‚³ã‚¢åˆæˆã‚’æ‹…å½“ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L124
L125 #### è£œåŠ©é–¢æ•°
L126 - `trend(s)` : 50/150/200æ—¥ç§»å‹•å¹³å‡ã‚„52é€±ãƒ¬ãƒ³ã‚¸ã‹ã‚‰-0.5ã€œ0.5ã§æ§‹æˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ã€‚
L127 - `rs(s,b)` / `tr_str(s)` / `rs_line_slope(s,b,win)` : ç›¸å¯¾å¼·ã•ã‚„çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã€RSå›å¸°å‚¾ãã‚’ç®—å‡ºã€‚
L128 - `ev_fallback` : `enterpriseValue`æ¬ ææ™‚ã«è² å‚µãƒ»ç¾é‡‘ã‹ã‚‰EVã‚’æ¨å®šã€‚
L129 - `dividend_status` / `div_streak` : é…å½“æœªè¨­å®šçŠ¶æ³ã®åˆ¤å®šã¨å¢—é…å¹´æ•°ã‚«ã‚¦ãƒ³ãƒˆã€‚
L130 - `fetch_finnhub_metrics` : Finnhub APIã‹ã‚‰EPSæˆé•·ãƒ»ROEãƒ»Î²ãªã©ä¸è¶³æŒ‡æ¨™ã‚’å–å¾—ã€‚
L131 - `calc_beta` : ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å…±åˆ†æ•£ã‹ã‚‰Î²ã‚’ç®—å‡ºã€‚
L132 - `spx_to_alpha` : S&P500ã®ä½ç½®æƒ…å ±ã‹ã‚‰DRRSã§ç”¨ã„ã‚‹Î±ã‚’æ¨å®šã€‚
L133 - `soft_cap_effective_scores` / `pick_top_softcap` : ã‚»ã‚¯ã‚¿ãƒ¼ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ—ä»˜ãã‚¹ã‚³ã‚¢èª¿æ•´ã¨ä¸Šä½æŠ½å‡ºã€‚
L134
L135 **è£œåŠ©é–¢æ•°ã¨ç”ŸæˆæŒ‡æ¨™**
L136
L137 | è£œåŠ©é–¢æ•° | ç”ŸæˆæŒ‡æ¨™ | ç•¥ç§° |
L138 | --- | --- | --- |
L139 | `trend` | ãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ | `TR` |
L140 | `rs` | ç›¸å¯¾å¼·ã• | `RS` |
L141 | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç·šã®ä¹–é›¢ | `TR_str` |
L142 | `rs_line_slope` | RSç·šã®å›å¸°å‚¾ã | `RS_SLOPE_*` |
L143 | `calc_beta` | Î² | `BETA` |
L144 | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° | `DIV_STREAK` |
L145
L146 #### `aggregate_scores` è©³ç´°
L147 1. å„éŠ˜æŸ„ã®ä¾¡æ ¼ç³»åˆ—ã‚„`info`ã‚’åŸºã«ä»¥ä¸‹ã‚’ç®—å‡ºã€‚
L148    - **ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ **: `TR`ã€`RS`ã€`TR_str`ã€å¤šæ§˜ãªç§»å‹•å¹³å‡æ¯”ã€`RS_SLOPE_*`ãªã©ã€‚
L149    - **ãƒªã‚¹ã‚¯**: `BETA`ã€`DOWNSIDE_DEV`ã€`MDD_1Y`ã€`RESID_VOL`ã€`DOWN_OUTPERF`ã€`EXT_200`ç­‰ã€‚
L150    - **é…å½“**: `DIV`ã€`DIV_TTM_PS`ã€`DIV_VAR5`ã€`DIV_YOY`ã€`DIV_FCF_COVER`ã€`DIV_STREAK`ã€‚
L151    - **è²¡å‹™ãƒ»æˆé•·**: `EPS`ã€`REV`ã€`ROE`ã€`FCF/EV`ã€`REV_Q_YOY`ã€`EPS_Q_YOY`ã€`REV_YOY_ACC`ã€`REV_YOY_VAR`ã€`REV_ANN_STREAK`ã€`RULE40`ã€`FCF_MGN` ç­‰ã€‚
L152    - **å®‰å®šæ€§/ã‚µã‚¤ã‚º**: `DEBT2EQ`ã€`CURR_RATIO`ã€`MARKET_CAP`ã€`ADV60_USD`ã€`EPS_VAR_8Q`ãªã©ã€‚
L153 2. æŒ‡æ¨™æ¬ æã¯Finnhub APIç­‰ã§è£œå®Œã—ã€æœªå–å¾—é …ç›®ã‚’`missing_logs`ã«è¨˜éŒ²ã€‚
L154 3. `winsorize_s`â†’`robust_z`ã§æ¨™æº–åŒ–ã—`df_z`ã¸ä¿å­˜ã€‚ã‚µã‚¤ã‚ºãƒ»æµå‹•æ€§ã¯å¯¾æ•°å¤‰æ›ã€‚
L155 4. æ­£è¦åŒ–æ¸ˆæŒ‡æ¨™ã‹ã‚‰å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã€‚
L156    - å„å› å­ã®æ§‹æˆã¨é‡ã¿ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
L157      - **GRW**: 0.30Ã—`REV` + 0.20Ã—`EPS_Q_YOY` + 0.15Ã—`REV_Q_YOY` + 0.15Ã—`REV_YOY_ACC` + 0.10Ã—`RULE40` + 0.10Ã—`FCF_MGN` + 0.10Ã—`REV_ANN_STREAK` âˆ’ 0.05Ã—`REV_YOY_VAR`ã€‚
L158      - **MOM**: 0.40Ã—`RS` + 0.15Ã—`TR_str` + 0.15Ã—`RS_SLOPE_6W` + 0.15Ã—`RS_SLOPE_13W` + 0.10Ã—`MA200_SLOPE_5M` + 0.10Ã—`MA200_UP_STREAK_D`ã€‚
L159      - **VOL**: `BETA`å˜ä½“ã‚’ä½¿ç”¨ã€‚
L160      - **QAL**: 0.60Ã—`FCF_W` + 0.40Ã—`ROE_W`ã§ä½œæˆã€‚
L161      - **YLD**: 0.30Ã—`DIV` + 0.70Ã—`DIV_STREAK`ã€‚
L162      - **D_QAL**: 0.35Ã—`QAL` + 0.20Ã—`FCF` + 0.15Ã—`CURR_RATIO` âˆ’ 0.15Ã—`DEBT2EQ` âˆ’ 0.15Ã—`EPS_VAR_8Q`ã€‚
L163      - **D_YLD**: 0.45Ã—`DIV` + 0.25Ã—`DIV_STREAK` + 0.20Ã—`DIV_FCF_COVER` âˆ’ 0.10Ã—`DIV_VAR5`ã€‚
L164      - **D_VOL_RAW**: 0.40Ã—`DOWNSIDE_DEV` + 0.22Ã—`RESID_VOL` + 0.18Ã—`MDD_1Y` âˆ’ 0.10Ã—`DOWN_OUTPERF` âˆ’ 0.05Ã—`EXT_200` âˆ’ 0.08Ã—`SIZE` âˆ’ 0.10Ã—`LIQ` + 0.10Ã—`BETA`ã€‚
L165      - **D_TRD**: 0.40Ã—`MA200_SLOPE_5M` âˆ’ 0.30Ã—`EXT_200` + 0.15Ã—`NEAR_52W_HIGH` + 0.15Ã—`TR`ã€‚
L166     - ä¸»ãªæŒ‡æ¨™ã®ç•¥ç§°ã¨æ„å‘³:
L167
L168       | ç•¥ç§° | è£œåŠ©é–¢æ•° | æ¦‚è¦ |
L169       | --- | --- | --- |
L170       | TR | `trend` | 50/150/200æ—¥ç§»å‹•å¹³å‡ã¨52é€±ãƒ¬ãƒ³ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ |
L171       | RS | `rs` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹ç›¸å¯¾å¼·ã•ï¼ˆ12M/1Mãƒªã‚¿ãƒ¼ãƒ³å·®ï¼‰ |
L172       | TR_str | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ |
L173       | RS_SLOPE_6W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®6é€±å›å¸°å‚¾ã |
L174       | RS_SLOPE_13W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®13é€±å›å¸°å‚¾ã |
L175       | MA200_SLOPE_5M | - | 200æ—¥ç§»å‹•å¹³å‡ã®5ã‹æœˆé¨°è½ç‡ |
L176       | MA200_UP_STREAK_D | - | 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ã„ãŸæ—¥æ•° |
L177       | BETA | `calc_beta` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹Î² |
L178       | DOWNSIDE_DEV | - | ä¸‹æ–¹ãƒªã‚¿ãƒ¼ãƒ³ã®ã¿ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L179       | RESID_VOL | - | Î²ã§èª¿æ•´ã—ãŸæ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L180       | MDD_1Y | - | éå»1å¹´ã®æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ |
L181       | DOWN_OUTPERF | - | å¸‚å ´ä¸‹è½æ—¥ã«å¯¾ã™ã‚‹å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ |
L182       | EXT_200 | - | 200æ—¥ç§»å‹•å¹³å‡ã‹ã‚‰ã®çµ¶å¯¾ä¹–é›¢ç‡ |
L183       | NEAR_52W_HIGH | - | 52é€±é«˜å€¤ã¾ã§ã®ä¸‹æ–¹è·é›¢ï¼ˆ0=é«˜å€¤ï¼‰ |
L184       | FCF_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®FCF/EV |
L185       | ROE_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®ROE |
L186       | FCF | - | FCF/EV |
L187       | QAL | - | FCF_Wã¨ROE_Wã‚’çµ„ã¿åˆã‚ã›ãŸå“è³ªã‚¹ã‚³ã‚¢ |
L188       | CURR_RATIO | - | æµå‹•æ¯”ç‡ |
L189       | DEBT2EQ | - | è² å‚µè³‡æœ¬å€ç‡ |
L190       | EPS_VAR_8Q | - | EPSã®8å››åŠæœŸæ¨™æº–åå·® |
L191       | DIV | - | å¹´ç‡æ›ç®—é…å½“åˆ©å›ã‚Š |
L192       | DIV_STREAK | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° |
L193       | DIV_FCF_COVER | - | é…å½“ã®FCFã‚«ãƒãƒ¬ãƒƒã‚¸ |
L194       | DIV_VAR5 | - | 5å¹´é…å½“å¤‰å‹•ç‡ |
L195       | DIV_TTM_PS | - | 1æ ªå½“ãŸã‚ŠTTMé…å½“ |
L196       | DIV_YOY | - | å‰å¹´æ¯”é…å½“æˆé•·ç‡ |
L197       | REV | - | å£²ä¸Šæˆé•·ç‡TTM |
L198       | EPS_Q_YOY | - | å››åŠæœŸEPSã®å‰å¹´åŒæœŸæ¯” |
L199       | REV_Q_YOY | - | å››åŠæœŸå£²ä¸Šã®å‰å¹´åŒæœŸæ¯” |
L200       | REV_YOY_ACC | - | å£²ä¸Šæˆé•·ç‡ã®åŠ é€Ÿåˆ† |
L201       | RULE40 | - | å£²ä¸Šæˆé•·ç‡ã¨FCFãƒãƒ¼ã‚¸ãƒ³ã®åˆè¨ˆ |
L202       | FCF_MGN | - | FCFãƒãƒ¼ã‚¸ãƒ³ |
L203       | REV_ANN_STREAK | - | å¹´æ¬¡å£²ä¸Šæˆé•·ã®é€£ç¶šå¹´æ•° |
L204       | REV_YOY_VAR | - | å¹´æ¬¡å£²ä¸Šæˆé•·ç‡ã®å¤‰å‹•æ€§ |
L205       | SIZE | - | æ™‚ä¾¡ç·é¡ã®å¯¾æ•°å€¤ |
L206       | LIQ | - | 60æ—¥å¹³å‡å‡ºæ¥é«˜ãƒ‰ãƒ«ã®å¯¾æ•°å€¤ |
L207    - Gãƒã‚±ãƒƒãƒˆ: `GRW`ã€`MOM`ã€`VOL`ã‚’`cfg.weights.g`ï¼ˆ0.40/0.45/-0.15ï¼‰ã§åŠ é‡ã—`g_score`ã‚’å¾—ã‚‹ã€‚
L208    - Dãƒã‚±ãƒƒãƒˆ: `D_QAL`ã€`D_YLD`ã€`D_VOL_RAW`ã€`D_TRD`ã‚’`cfg.weights.d`ï¼ˆ0.15/0.15/-0.45/0.25ï¼‰ã§åŠ é‡ã—`d_score_all`ã‚’ç®—å‡ºã€‚
L209    - ã‚»ã‚¯ã‚¿ãƒ¼capã«ã‚ˆã‚‹`soft_cap_effective_scores`ã‚’é©ç”¨ã—ã€Gæ¡ç”¨éŠ˜æŸ„ã«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€‚
L210 5. `_apply_growth_entry_flags`ã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®ç™ºç«çŠ¶æ³ã‚’ä»˜åŠ ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L211
L212 ### Step3: Correlation Reduction & Selection (Selector)
L213 DRRSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç›¸é–¢ã‚’æŠ‘ãˆãŸéŠ˜æŸ„é¸å®šã‚’è¡Œã„ã€`SelectionBundle`ã‚’è¿”ã™ã€‚`results/`ã«ä¿å­˜ã•ã‚ŒãŸå‰å›é¸å®šï¼ˆ`G_selection.json` / `D_selection.json`ï¼‰ã‚’`_load_prev`ã§èª­ã¿è¾¼ã¿ã€ç›®çš„å€¤ãŒå¤§ããæ‚ªåŒ–ã—ãªã„é™ã‚Šç¶­æŒã™ã‚‹ã€‚æ–°ã—ã„æ¡ç”¨é›†åˆã¯`_save_sel`ã§JSONã«æ›¸ãå‡ºã—æ¬¡å›ä»¥é™ã®å…¥åŠ›ã«å‚™ãˆã‚‹ã€‚
L214 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L215 - `residual_corr` : åç›Šç‡è¡Œåˆ—ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã—ã€ä¸Šä½ä¸»æˆåˆ†ã‚’é™¤å»ã—ãŸæ®‹å·®ã‹ã‚‰ç›¸é–¢è¡Œåˆ—ã‚’æ±‚ã‚ã€å¹³å‡ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯ã€‚
L216 - `rrqr_like_det` : ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘ã—ãŸQRåˆ†è§£é¢¨ã®æ‰‹é †ã§åˆæœŸå€™è£œã‚’kä»¶æŠ½å‡ºã—ã€ã‚¹ã‚³ã‚¢ã®é«˜ã„éç›¸é–¢ãªé›†åˆã‚’å¾—ã‚‹ã€‚
L217 - `swap_local_det` / `swap_local_det_cross` : `sum(score) - Î»*within_corr - Î¼*cross_corr`ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ã€å…¥ã‚Œæ›¿ãˆæ¢ç´¢ã§å±€æ‰€çš„ã«æœ€é©åŒ–ã€‚
L218 - `select_bucket_drrs` : ãƒ—ãƒ¼ãƒ«éŠ˜æŸ„ã¨ã‚¹ã‚³ã‚¢ã‹ã‚‰æ®‹å·®ç›¸é–¢ã‚’è¨ˆç®—ã—ã€ä¸Šè¨˜2æ®µéš(åˆæœŸé¸æŠâ†’å…¥ã‚Œæ›¿ãˆ)ã§kéŠ˜æŸ„ã‚’æ±ºå®šã€‚éå»æ¡ç”¨éŠ˜æŸ„ã¨ã®æ¯”è¼ƒã§ç›®çš„å€¤ãŒåŠ£åŒ–ã—ãªã‘ã‚Œã°ç¶­æŒã™ã‚‹ã€‚
L219 - `select_buckets` : Gãƒã‚±ãƒƒãƒˆã‚’é¸å®šå¾Œã€ãã®çµæœã‚’é™¤ã„ãŸå€™è£œã‹ã‚‰Dãƒã‚±ãƒƒãƒˆã‚’é¸ã¶ã€‚Dé¸å®šæ™‚ã¯Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ã‚’ä»˜ä¸ã—ã€ä¸¡ãƒã‚±ãƒƒãƒˆã®åˆ†æ•£ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
L220
L221 #### ç›¸é–¢ä½æ¸›ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°
L222 1. **æ®‹å·®ç›¸é–¢è¡Œåˆ—ã®æ§‹ç¯‰ (`residual_corr`)**
L223    - ãƒªã‚¿ãƒ¼ãƒ³è¡Œåˆ—`R`ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L224    - SVDã§ä¸Šä½`n_pc`ä¸»æˆåˆ†`F`ã‚’æ±‚ã‚ã€æœ€å°äºŒä¹—ã§ä¿‚æ•°`B`ã‚’ç®—å‡ºã—æ®‹å·®`E = Z - F@B`ã‚’å¾—ã‚‹ã€‚
L225    - `E`ã®ç›¸é–¢è¡Œåˆ—`C`ã‚’è¨ˆç®—ã—ã€å¹³å‡çµ¶å¯¾ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯é‡`shrink_eff`ã‚’è£œæ­£ã—ã¦å¯¾è§’ã‚’å¼·èª¿ã€‚
L226 2. **åˆæœŸå€™è£œã®æŠ½å‡º (`rrqr_like_det`)**
L227    - ã‚¹ã‚³ã‚¢ã‚’0-1æ­£è¦åŒ–ã—ãŸé‡ã¿`w`ã¨ã—ã€`Z*(1+Î³w)`ã§åˆ—ãƒãƒ«ãƒ ã‚’å¼·èª¿ã€‚
L228    - æ®‹å·®ãƒãƒ«ãƒ æœ€å¤§ã®åˆ—ã‚’é€æ¬¡é¸ã³ã€QRãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã£ã¦éç›¸é–¢ã‹ã¤é«˜ã‚¹ã‚³ã‚¢ãª`k`éŠ˜æŸ„é›†åˆ`S0`ã‚’å¾—ã‚‹ã€‚
L229 3. **å±€æ‰€æ¢ç´¢ (`swap_local_det` / `swap_local_det_cross`)**
L230    - ç›®çš„é–¢æ•°`Î£z_score âˆ’ Î»Â·within_corr âˆ’ Î¼Â·cross_corr`ã‚’æœ€å¤§åŒ–ã€‚
L231    - é¸æŠé›†åˆã®å„éŠ˜æŸ„ã‚’ä»–å€™è£œã¨å…¥ã‚Œæ›¿ãˆã€æ”¹å–„ãŒãªããªã‚‹ã¾ã§ã¾ãŸã¯`max_pass`å›ã¾ã§æ¢ç´¢ã€‚
L232    - `swap_local_det_cross`ã¯Gãƒã‚±ãƒƒãƒˆã¨ã®ã‚¯ãƒ­ã‚¹ç›¸é–¢è¡Œåˆ—`C_cross`ã‚’ä½¿ç”¨ã—ã€ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’ä»˜ä¸ã€‚
L233 4. **éå»æ¡ç”¨ã®ç¶­æŒã¨ã‚¯ãƒ­ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ (`select_bucket_drrs` / `select_buckets`)**
L234    - å±€æ‰€æ¢ç´¢çµæœ`S`ã¨éå»é›†åˆ`P`ã®ç›®çš„å€¤ã‚’æ¯”è¼ƒã—ã€`S`ãŒ`P`ã‚ˆã‚Š`Î·`æœªæº€ã®æ”¹å–„ãªã‚‰`P`ã‚’ç¶­æŒã€‚
L235    - `select_buckets`ã§ã¯Gã‚’å…ˆã«æ±ºå®šã—ã€Dé¸å®šæ™‚ã«Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’åŠ ãˆã¦ã‚¯ãƒ­ã‚¹åˆ†æ•£ã‚’æŠ‘åˆ¶ã€‚
L236
L237 ### Step4: Output
L238 é¸å®šçµæœã‚’å¯è¦–åŒ–ã—å…±æœ‰ã™ã‚‹å·¥ç¨‹ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦æ¨™æº–å‡ºåŠ›ã¨Slackã¸é€ã‚‹ã€‚
L239 - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚é¸å¤–ã¨ãªã£ãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L240 - IN/OUTãƒªã‚¹ãƒˆã¨OUTéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ï¼ˆä½å¾—ç‚¹éŠ˜æŸ„ã‚’ç¢ºèªã—ã‚„ã™ãï¼‰
L241 - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨ï¼ˆçµ„å…¥ã‚Œãƒ»é™¤å¤–ã€ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼‰
L242 - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
L243
L244 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L245 - `display_results` : ä¸Šè¨˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŠ ãˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚„åˆ†æ•£åŒ–æŒ‡æ¨™ã‚’è¡¨ç¤ºã€‚
L246 - `notify_slack` : Slack Webhookã¸åŒå†…å®¹ã‚’é€ä¿¡ã€‚
L247 - è£œåŠ©:`_avg_offdiag`ã€`_resid_avg_rho`ã€`_raw_avg_rho`ã€`_cross_block_raw_rho`ã€‚
L248
L249 ## ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
L250 1. `PipelineConfig`ã‚’æ§‹ç¯‰ã€‚
L251 2. **Step1** `Input.prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚
L252 3. **Step2** `Scorer.aggregate_scores`ã§`FeatureBundle`ã‚’å–å¾—ã€‚
L253 4. **Step3** `Selector.select_buckets`ã§`SelectionBundle`ã‚’ç®—å‡ºã€‚
L254 5. **Step4** `Output.display_results`ã¨`notify_slack`ã§çµæœã‚’å‡ºåŠ›ã€‚
```
