# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <factor.py>
```text
L1 """
L2 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
L3 â”ƒ ROLE of factor.py                                     â”ƒ
L4 â”ƒ  - Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰     â”ƒ
L5 â”ƒ  - è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¡ç‚¹/ãƒ•ã‚£ãƒ«ã‚¿/ç›¸é–¢ä½æ¸›ï¼‰ã¯ scorer.py â”ƒ
L6 â”ƒ  - ã“ã“ã§ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…/å¤‰æ›´ã—ãªã„                   â”ƒ
L7 â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
L8 """
L9 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L10 BONUS_COEFF = 0.4   # æ”»ã‚=0.3 / ä¸­åº¸=0.4 / å®ˆã‚Š=0.5
L11 import yfinance as yf, pandas as pd, numpy as np, os, requests, time
L12 from scipy.stats import zscore
L13 from dataclasses import dataclass
L14 from typing import Dict, List
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 from time import perf_counter
L17
L18
L19 class T:
L20     t = perf_counter()
L21
L22     @staticmethod
L23     def log(tag: str):
L24         now = perf_counter()
L25         print(f"[T] {tag}: {now - T.t:.2f}s")
L26         T.t = now
L27
L28
L29 T.log("start")
L30
L31 # ===== ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ =====
L32 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L33 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L34 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L35 N_G, N_D = 12, 13  # G/Dæ ã‚µã‚¤ã‚º
L36 g_weights = {'GRW':0.40,'MOM':0.45,'VOL':-0.15}
L37 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L38 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L39 D_weights = {'QAL':0.15,'YLD':0.15,'VOL':-0.45,'TRD':0.25}
L40 def _fmt_w(w): return " ".join(f"{k}{int(v*100)}" for k,v in w.items())
L41
L42 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L43 corrM = 45
L44 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L45 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L46
L47 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L48 try: CROSS_MU_GD
L49 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L50
L51 # å‡ºåŠ›é–¢é€£
L52 RESULTS_DIR = "results"
L53 os.makedirs(RESULTS_DIR, exist_ok=True)
L54
L55 # ãã®ä»–
L56 debug_mode, FINNHUB_API_KEY = False, os.environ.get("FINNHUB_API_KEY")
L57
L58
L59 # ===== å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config =====
L60 @dataclass(frozen=True)
L61 class InputBundle:
L62     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L63     cand: List[str]
L64     tickers: List[str]
L65     bench: str
L66     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L67     px: pd.DataFrame                # data['Close']
L68     spx: pd.Series                  # data['Close'][bench]
L69     tickers_bulk: object            # yfinance.Tickers
L70     info: Dict[str, dict]           # yfinance info per ticker
L71     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L72     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L73     returns: pd.DataFrame           # px[tickers].pct_change()
L74
L75 @dataclass(frozen=True)
L76 class FeatureBundle:
L77     df: pd.DataFrame
L78     df_z: pd.DataFrame
L79     g_score: pd.Series
L80     d_score_all: pd.Series
L81     missing_logs: pd.DataFrame
L82
L83 @dataclass(frozen=True)
L84 class SelectionBundle:
L85     resG: dict
L86     resD: dict
L87     top_G: List[str]
L88     top_D: List[str]
L89     init_G: List[str]
L90     init_D: List[str]
L91
L92 @dataclass(frozen=True)
L93 class WeightsConfig:
L94     g: Dict[str,float]
L95     d: Dict[str,float]
L96
L97 @dataclass(frozen=True)
L98 class DRRSParams:
L99     corrM: int
L100     shrink: float
L101     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L102     D: Dict[str,float]
L103     cross_mu_gd: float
L104
L105 @dataclass(frozen=True)
L106 class PipelineConfig:
L107     weights: WeightsConfig
L108     drrs: DRRSParams
L109     price_max: float
L110
L111
L112 # ===== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ =====
L113 # (unused local utils removed â€“ use scorer.py versions if needed)
L114
L115 def _env_true(name: str, default=False):
L116     v = os.getenv(name)
L117     return default if v is None else v.strip().lower() == "true"
L118
L119 def _slack(message, code=False):
L120     url = os.getenv("SLACK_WEBHOOK_URL")
L121     if not url:
L122         print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L123     try:
L124         requests.post(url, json={"text": f"```{message}```" if code else message}).raise_for_status()
L125     except Exception as e:
L126         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L127
L128 def _slack_debug(text: str, chunk=2800):
L129     url=os.getenv("SLACK_WEBHOOK_URL")
L130     if not url: print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L131     i=0
L132     while i<len(text):
L133         j=min(len(text), i+chunk); k=text.rfind("\n", i, j); j=k if k>i+100 else j
L134         blk={"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}
L135         try: requests.post(url, json={"blocks":[blk]}).raise_for_status()
L136         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L137         i=j
L138
L139 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L140     # ---- åˆ—é¸æŠï¼šæ—¢å®šã¯æœ€å°åˆ—ã€DEBUG_ALL_COLS=True ã§å…¨åˆ—ã« ----
L141     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC"]
L142     all_cols = _env_true("DEBUG_ALL_COLS", False)
L143     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L144
L145     # ---- å·®åˆ†ï¼ˆå…¥æ›¿ï¼‰----
L146     Gp, Dp = set(prevG or []), set(prevD or [])
L147     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L148     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L149
L150     # ---- æ¬¡ç‚¹10ï¼ˆãƒ•ãƒ©ã‚°ã§æœ‰ç„¡åˆ‡æ›¿ï¼‰----
L151     show_near = _env_true("DEBUG_NEAR5", True)
L152     gs = getattr(fb,"g_score",None); ds = getattr(fb,"d_score_all",None)
L153     gs = gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None
L154     ds = ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None
L155     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L156     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L157     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L158
L159     # ---- è¡Œé¸æŠï¼šæ—¢å®šã¯å…¥æ›¿+æ¡ç”¨+æ¬¡ç‚¹ã€DEBUG_ALL_ROWS=True ã§å…¨éŠ˜æŸ„ ----
L160     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L161     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))
L162     focus = focus[:max_rows]
L163
L164     # ---- ãƒ˜ãƒƒãƒ€ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã‚’æ˜ç¤ºï¼‰----
L165     def _fmt_near(lbl, ser, lst):
L166         if ser is None: return f"{lbl}: off"
L167         parts=[]
L168         for t in lst:
L169             x=ser.get(t, float("nan"))
L170             parts.append(f"{t}:{x:.3f}" if pd.notna(x) else f"{t}:nan")
L171         return f"{lbl}: "+(", ".join(parts) if parts else "-")
L172     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L173           _fmt_near("G near10", gs, g_miss),
L174           _fmt_near("D near10", ds, d_miss),
L175           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L176           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L177
L178     # ---- ãƒ†ãƒ¼ãƒ–ãƒ« ----
L179     if fb.df_z.empty or not cols:
L180         tbl="(df_z or columns not available)"
L181     else:
L182         idx=[t for t in focus if t in fb.df_z.index]
L183         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L184
L185     # ---- æ¬ æãƒ­ã‚°ï¼ˆãƒ•ãƒ©ã‚°ã§æœ‰ç„¡åˆ‡æ›¿ï¼‰----
L186     miss_txt=""
L187     if _env_true("DEBUG_MISSING_LOGS", False):
L188         miss=getattr(fb,"missing_logs",None)
L189         if miss is not None and not miss.empty:
L190             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L191
L192     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L193
L194 def _disjoint_keepG(top_G, top_D, poolD):
L195     """
L196     Gã«å«ã¾ã‚Œã‚‹éŠ˜æŸ„ã‚’Dã‹ã‚‰é™¤å»ã—ã€Dã¯poolDï¼ˆæ¬¡ç‚¹ï¼‰ã§è£œå……ã™ã‚‹ã€‚
L197     - å¼•æ•°:
L198         top_G: List[str]  â€¦ Gæœ€çµ‚12éŠ˜æŸ„
L199         top_D: List[str]  â€¦ Dæœ€çµ‚13éŠ˜æŸ„ï¼ˆé‡è¤‡ã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰
L200         poolD: List[str]  â€¦ Då€™è£œã®é †ä½ãƒªã‚¹ãƒˆï¼ˆtop_Dã‚’å«ã‚€ä¸Šä½æ‹¡å¼µï¼‰
L201     - æˆ»ã‚Šå€¤: (top_G, top_D_disjoint)
L202     - æŒ™å‹•:
L203         1) Dã«Gé‡è¤‡ãŒã‚ã‚Œã°é †ã«ç½®æ›
L204         2) ç½®æ›å€™è£œã¯ poolD ã‹ã‚‰ã€æ—¢ä½¿ç”¨(GâˆªD)ã‚’é¿ã‘ã¦å‰ã‹ã‚‰æ¡ç”¨
L205         3) è£œå……åˆ†ãŒå°½ããŸå ´åˆã¯å…ƒã®éŠ˜æŸ„ã‚’æ®‹ã™ï¼ˆå®‰å…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
L206     """
L207     used, D = set(top_G), list(top_D)
L208     i = 0
L209     for j, t in enumerate(D):
L210         if t in used:
L211             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L212                 i += 1
L213             if i < len(poolD):
L214                 D[j] = poolD[i]; used.add(D[j]); i += 1
L215     return top_G, D
L216
L217
L218 # ===== Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ =====
L219 class Input:
L220     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L221         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L222         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L223
L224     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L225     @staticmethod
L226     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L227         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L228         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L229         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L230
L231     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L232
L233     @staticmethod
L234     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L235         if df is None or df.empty: return None
L236         idx_lower = {str(i).lower(): i for i in df.index}
L237         for name in names:
L238             key = name.lower()
L239             if key in idx_lower: return df.loc[idx_lower[key]]
L240         return None
L241
L242     @staticmethod
L243     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L244         if s is None or s.empty: return None
L245         vals = s.dropna().astype(float); return None if vals.empty else vals.iloc[:n].sum()
L246
L247     @staticmethod
L248     def _latest(s: pd.Series|None) -> float|None:
L249         if s is None or s.empty: return None
L250         vals = s.dropna().astype(float); return vals.iloc[0] if not vals.empty else None
L251
L252     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L253         from concurrent.futures import ThreadPoolExecutor, as_completed
L254         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L255
L256         def one(t: str):
L257             try:
L258                 tk = yf.Ticker(t)  # â˜… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯æ¸¡ã•ãªã„ï¼ˆYFãŒcurl_cffiã§ç®¡ç†ï¼‰
L259                 qcf = tk.quarterly_cashflow
L260                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L261                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L262                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L263                 if any(v is None for v in (cfo, capex, fcf)):
L264                     acf = tk.cashflow
L265                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L266                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L267                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L268             except Exception as e:
L269                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L270             n=np.nan
L271             return {"ticker":t,
L272                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L273                     "capex_ttm_yf": n if capex is None else capex,
L274                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L275
L276         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L277         with ThreadPoolExecutor(max_workers=mw) as ex:
L278             for f in as_completed(ex.submit(one,t) for t in tickers): rows.append(f.result())
L279         return pd.DataFrame(rows).set_index("ticker")
L280
L281     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L282     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L283
L284     @staticmethod
L285     def _first_key(d: dict, keys: list[str]):
L286         for k in keys:
L287             if k in d and d[k] is not None: return d[k]
L288         return None
L289
L290     @staticmethod
L291     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L292         for i in range(retries):
L293             r = session.get(url, params=params, timeout=15)
L294             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L295             r.raise_for_status(); return r.json()
L296         r.raise_for_status()
L297
L298     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L299         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L300         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L301         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L302         for sym in tickers:
L303             cfo_ttm = capex_ttm = None
L304             try:
L305                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L306                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L307                 for item in arr[:4]:
L308                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L309                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L310                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L311             except Exception: pass
L312             if cfo_ttm is None or capex_ttm is None:
L313                 try:
L314                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L315                     arr = j.get("cashFlow") or []
L316                     if arr:
L317                         item0 = arr[0]
L318                         if cfo_ttm is None:
L319                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L320                             if v is not None: cfo_ttm = float(v)
L321                         if capex_ttm is None:
L322                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L323                             if v is not None: capex_ttm = float(v)
L324                 except Exception: pass
L325             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L326         return pd.DataFrame(rows).set_index("ticker")
L327
L328     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L329         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L330         T.log("financials (yf) done")
L331         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L332         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L333         if need:
L334             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L335             df = yf_df.join(fh_df, how="left")
L336             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L337                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L338             print("[T] financials (finnhub) done (fallback only)")
L339         else:
L340             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L341             print("[T] financials (finnhub) skipped (no missing)")
L342         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L343         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L344         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L345         fcf_calc = cfo - capex
L346         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L347         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L348         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L349         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L350         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L351         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L352         return df[cols].sort_index()
L353
L354     def _build_eps_df(self, tickers, tickers_bulk, info):
L355         eps_rows=[]
L356         for t in tickers:
L357             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L358             try:
L359                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L360                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L361                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L362                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L363                     eps_q = qearn["Earnings"].iloc[-1]/so
L364             except Exception: pass
L365             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L366         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L367
L368     def prepare_data(self):
L369         """Fetch price and fundamental data for all tickers."""
L370         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L371         for t in self.cand:
L372             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L373             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L374         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L375         T.log("price cap filter done (CAND_PRICE_MAX)")
L376         tickers = sorted(set(self.exist + cand_f))
L377         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L378         data = yf.download(tickers + [self.bench], period="600d", auto_adjust=True, progress=False)
L379         T.log("yf.download done")
L380         px, spx = data["Close"], data["Close"][self.bench]
L381         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0ãªã‚‰ç„¡åŠ¹ï¼ˆæ—¢å®šï¼‰
L382         if clip_days > 0:
L383             px  = px.tail(clip_days + 1)
L384             spx = spx.tail(clip_days + 1)
L385             print(f"[T] price window clipped by env: {len(px)} rows (PRICE_CLIP_DAYS={clip_days})")
L386         else:
L387             print(f"[T] price window clip skipped; rows={len(px)}")
L388         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L389         for t in tickers:
L390             try: info[t] = tickers_bulk.tickers[t].info
L391             except Exception as e: print(f"{t}: info fetch failed ({e})"); info[t] = {}
L392         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L393         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L394         T.log("eps/fcf prep done")
L395         returns = px[tickers].pct_change()
L396         T.log("price prep/returns done")
L397         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L398
L399
L400 # ===== Selectorï¼šç›¸é–¢ä½æ¸›ãƒ»é¸å®šï¼ˆã‚¹ã‚³ã‚¢ï¼†ãƒªã‚¿ãƒ¼ãƒ³ã ã‘èª­ã‚€ï¼‰ =====
L401 class Selector:
L402     # ---- DRRS helpersï¼ˆSelectorå°‚ç”¨ï¼‰ ----
L403     @staticmethod
L404     def _z_np(X: np.ndarray) -> np.ndarray:
L405         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L406         return (np.nan_to_num(X)-m)/s
L407
L408     @classmethod
L409     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L410         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L411         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L412         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L413         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L414         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L415
L416     @classmethod
L417     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L418         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L419         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L420         if k==0: return []
L421         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L422         for _ in range(k):
L423             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L424             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L425             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L426         return sorted(S)
L427
L428     @staticmethod
L429     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L430         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L431         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L432
L433     @classmethod
L434     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L435         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L436         while improved and passes<max_pass:
L437             improved, passes = False, passes+1
L438             for i,out in enumerate(list(S)):
L439                 for inn in range(len(score)):
L440                     if inn in S: continue
L441                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L442                     if v>best+1e-10: S, best, improved = cand, v, True; break
L443                 if improved: break
L444         return S, best
L445
L446     @staticmethod
L447     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L448         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L449         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L450         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L451         return float(s[idx].sum() - lam*within - mu*cross)
L452
L453     @classmethod
L454     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L455         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L456         while improved and passes<max_pass:
L457             improved, passes = False, passes+1
L458             for i,out in enumerate(list(S)):
L459                 for inn in range(N):
L460                     if inn in S: continue
L461                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L462                     if v>best+1e-10: S, best, improved = cand, v, True; break
L463                 if improved: break
L464         return S, best
L465
L466     @staticmethod
L467     def avg_corr(C: np.ndarray, idx) -> float:
L468         k = len(idx); P = C[np.ix_(idx, idx)]
L469         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L470
L471     @classmethod
L472     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L473         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L474         union = [t for t in pool_tickers if t in returns_df.columns]
L475         for t in g_fixed:
L476             if t not in union: union.append(t)
L477         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L478         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L479         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L480         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L481         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L482         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L483         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L484         if len(g_eff)>0 and mu>0.0:
L485             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L486         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L487         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L488         selected_tickers = [pool_eff[i] for i in S]
L489         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L490
L491     # ---- é¸å®šï¼ˆã‚¹ã‚³ã‚¢ Series / returns ã ã‘ã‚’å—ã‘ã‚‹ï¼‰----
L492 # ===== Outputï¼šå‡ºåŠ›æ•´å½¢ã¨é€ä¿¡ï¼ˆè¡¨ç¤ºãƒ»Slackï¼‰ =====
L493 class Output:
L494
L495     def __init__(self, debug=False):
L496         self.debug = debug
L497         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = self.debug_table = None
L498         self.g_title = self.d_title = ""
L499         self.g_formatters = self.d_formatters = {}
L500         # ä½ã‚¹ã‚³ã‚¢ï¼ˆGSC+DSCï¼‰Top10 è¡¨ç¤º/é€ä¿¡ç”¨
L501         self.low10_table = None
L502
L503     # --- è¡¨ç¤ºï¼ˆå…ƒ display_results ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L504     def display_results(self, *, exist, bench, df_z, g_score, d_score_all,
L505                         init_G, init_D, top_G, top_D, **kwargs):
L506         pd.set_option('display.float_format','{:.3f}'.format)
L507         print("ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ")
L508         if self.miss_df is not None and not self.miss_df.empty:
L509             print("Missing Data:")
L510             print(self.miss_df.to_string(index=False))
L511
L512         # ---- è¡¨ç¤ºç”¨ï¼šChanges/Near-Miss ã®ã‚¹ã‚³ã‚¢æºã‚’â€œæœ€çµ‚é›†è¨ˆâ€ã«çµ±ä¸€ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚· ----
L513         try:
L514             sc = getattr(self, "_sc", None)
L515             agg_G = getattr(sc, "_agg_G", None)
L516             agg_D = getattr(sc, "_agg_D", None)
L517         except Exception:
L518             sc = agg_G = agg_D = None
L519         class _SeriesProxy:
L520             __slots__ = ("primary", "fallback")
L521             def __init__(self, primary, fallback): self.primary, self.fallback = primary, fallback
L522             def get(self, key, default=None):
L523                 try:
L524                     v = self.primary.get(key) if hasattr(self.primary, "get") else None
L525                     if v is not None and not (isinstance(v, float) and v != v):
L526                         return v
L527                 except Exception:
L528                     pass
L529                 try:
L530                     return self.fallback.get(key) if hasattr(self.fallback, "get") else default
L531                 except Exception:
L532                     return default
L533         g_score = _SeriesProxy(agg_G, g_score)
L534         d_score_all = _SeriesProxy(agg_D, d_score_all)
L535         near_G = getattr(sc, "_near_G", []) if sc else []
L536         near_D = getattr(sc, "_near_D", []) if sc else []
L537
L538         extra_G = [t for t in init_G if t not in top_G][:5]; G_UNI = top_G + extra_G
L539         gsc_series = pd.Series({t: g_score.get(t) for t in G_UNI}, name='GSC')
L540         self.g_table = pd.concat([df_z.loc[G_UNI,['GRW','MOM','TRD','VOL']], gsc_series], axis=1)
L541         self.g_table.index = [t + ("â­ï¸" if t in top_G else "") for t in G_UNI]
L542         self.g_formatters = {col:"{:.2f}".format for col in ['GRW','MOM','TRD','VOL']}; self.g_formatters['GSC'] = "{:.3f}".format
L543         self.g_title = (f"[Gæ  / {N_G} / {_fmt_w(g_weights)} / corrM={corrM} / "
L544                         f"LB={DRRS_G['lookback']} nPC={DRRS_G['n_pc']} Î³={DRRS_G['gamma']} Î»={DRRS_G['lam']} Î·={DRRS_G['eta']} shrink={DRRS_SHRINK}]")
L545         if near_G:
L546             add = [t for t in near_G if t not in set(G_UNI)][:10]
L547             if len(add) < 10:
L548                 try:
L549                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L550                     out_now = sorted(set(exist) - set(top_G + top_D))  # ä»Šå› OUT
L551                     used = set(G_UNI + add)
L552                     def _push(lst):
L553                         nonlocal add, used
L554                         for t in lst:
L555                             if len(add) == 10: break
L556                             if t in aggG.index and t not in used:
L557                                 add.append(t); used.add(t)
L558                     _push(out_now)           # â‘  ä»Šå› OUT ã‚’å„ªå…ˆ
L559                     _push(list(aggG.index))  # â‘¡ ã¾ã è¶³ã‚Šãªã‘ã‚Œã°ä¸Šä½ã§å……å¡«
L560                 except Exception:
L561                     pass
L562             if add:
L563                 near_tbl = pd.concat([df_z.loc[add,['GRW','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L564                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L565         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L566
L567         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L568         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L569         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L570         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L571         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L572         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L573         import scorer
L574         dw_eff = scorer.D_WEIGHTS_EFF
L575         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L576                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L577         if near_D:
L578             add = [t for t in near_D if t not in set(D_UNI)][:10]
L579             if add:
L580                 d_disp2 = pd.DataFrame(index=add)
L581                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L582                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L583                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L584         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L585
L586         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L587         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L588         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L589
L590         self.io_table = pd.DataFrame({
L591             'IN': pd.Series(in_list),
L592             '/ OUT': pd.Series(out_list)
L593         })
L594         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L595         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L596         self.io_table['GSC'] = pd.Series(g_list)
L597         self.io_table['DSC'] = pd.Series(d_list)
L598
L599         print("Changes:")
L600         print(self.io_table.to_string(index=False))
L601
L602         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L603         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L604         for name,ticks in portfolios.items():
L605             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L606             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L607             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L608             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L609             if len(ticks)>=2:
L610                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L611                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L612                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L613             else: RAW_rho = RESID_rho = np.nan
L614             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L615         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L616         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L617         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L618         def _fmt_row(s):
L619             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L620         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L621         if self.debug:
L622             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L623             print("Debug Data:"); print(self.debug_table.to_string())
L624
L625         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L626         try:
L627             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L628             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L629             all_scores = all_scores.dropna(subset=['G_plus_D'])
L630             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L631             print("Low Score Candidates (GSC+DSC bottom 10):")
L632             print(self.low10_table.to_string())
L633         except Exception as e:
L634             print(f"[warn] low-score ranking failed: {e}")
L635             self.low10_table = None
L636
L637     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L638     def notify_slack(self):
L639         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L640         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L641         def _filter_suffix_from(spec: dict, group: str) -> str:
L642             g = spec.get(group, {})
L643             parts = [str(m) for m in g.get("pre_mask", [])]
L644             for k, v in (g.get("pre_filter", {}) or {}).items():
L645                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L646                 name = {"beta": "Î²"}.get(base, base)
L647                 try: val = f"{float(v):g}"
L648                 except: val = str(v)
L649                 parts.append(f"{name}{op}{val}")
L650             return "" if not parts else " / filter:" + " & ".join(parts)
L651         def _inject_filter_suffix(title: str, group: str) -> str:
L652             suf = _filter_suffix_from(FILTER_SPEC, group)
L653             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L654         def _blk(title, tbl, fmt=None, drop=()):
L655             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(é¸å®šãªã—)\n"
L656             if drop and hasattr(tbl,'columns'):
L657                 keep = [c for c in tbl.columns if c not in drop]
L658                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L659             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L660
L661         g_title = _inject_filter_suffix(self.g_title, "G")
L662         d_title = _inject_filter_suffix(self.d_title, "D")
L663         message  = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L664         if self.miss_df is not None and not self.miss_df.empty:
L665             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L666         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L667         message += _blk(d_title, self.d_table, self.d_formatters)
L668         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L669         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L670         if self.debug and self.debug_table is not None:
L671             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L672         payload = {"text": message}
L673         try:
L674             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L675         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L676
L677
L678 def _infer_g_universe(feature_df, selected12=None, near5=None):
L679     try:
L680         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L681         if out: return out
L682     except Exception:
L683         pass
L684     base = set()
L685     for lst in (selected12 or []), (near5 or []):
L686         for x in (lst or []): base.add(x)
L687     return list(base) if base else list(feature_df.index)
L688
L689
L690 def _fmt_with_fire_mark(tickers, feature_df):
L691     out = []
L692     for t in tickers or []:
L693         try:
L694             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L695             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L696             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L697         except Exception:
L698             out.append(t)
L699     return out
L700
L701
L702 def _label_recent_event(t, feature_df):
L703     try:
L704         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L705         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L706         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L707         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L708         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L709     except Exception:
L710         pass
L711     return t
L712
L713
L714 # ===== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ==============================
L715
L716 def io_build_input_bundle() -> InputBundle:
L717     """
L718     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L719     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L720     """
L721     inp = Input(cand=cand, exist=exist, bench=bench,
L722                 price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY)
L723     state = inp.prepare_data()
L724     return InputBundle(
L725         cand=state["cand"], tickers=state["tickers"], bench=bench,
L726         data=state["data"], px=state["px"], spx=state["spx"],
L727         tickers_bulk=state["tickers_bulk"], info=state["info"],
L728         eps_df=state["eps_df"], fcf_df=state["fcf_df"],
L729         returns=state["returns"]
L730     )
L731
L732 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L733               n_target: int) -> tuple[list, float, float, float]:
L734     """
L735     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L736     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L737     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L738     """
L739     sc.cfg = cfg
L740
L741     if hasattr(sc, "score_build_features"):
L742         feat = sc.score_build_features(inb)
L743         if not hasattr(sc, "_feat_logged"):
L744             T.log("features built (scorer)")
L745             sc._feat_logged = True
L746         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L747     else:
L748         fb = sc.aggregate_scores(inb, cfg)
L749         if not hasattr(sc, "_feat_logged"):
L750             T.log("features built (scorer)")
L751             sc._feat_logged = True
L752         sc._feat = fb
L753         agg = fb.g_score if group == "G" else fb.d_score_all
L754         if group == "D" and hasattr(fb, "df"):
L755             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L756
L757     if hasattr(sc, "filter_candidates"):
L758         mask = sc.filter_candidates(inb, agg, group, cfg)
L759         agg = agg[mask]
L760
L761     selector = Selector()
L762     if hasattr(sc, "select_diversified"):
L763         pick, avg_r, sum_sc, obj = sc.select_diversified(
L764             agg, group, cfg, n_target,
L765             selector=selector, prev_tickers=None,
L766             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L767             cross_mu=cfg.drrs.cross_mu_gd
L768         )
L769     else:
L770         if group == "G":
L771             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L772             res = selector.select_bucket_drrs(
L773                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L774                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L775                 lam=cfg.drrs.G.get("lam", 0.68),
L776                 lookback=cfg.drrs.G.get("lookback", 252),
L777                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0
L778             )
L779         else:
L780             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L781             g_fixed = getattr(sc, "_top_G", None)
L782             res = selector.select_bucket_drrs(
L783                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L784                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L785                 lam=cfg.drrs.D.get("lam", 0.85),
L786                 lookback=cfg.drrs.D.get("lookback", 504),
L787                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L788                 mu=cfg.drrs.cross_mu_gd
L789             )
L790         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L791         sum_sc = res["sum_score"]; obj = res["objective"]
L792         if group == "D":
L793             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L794             T.log("selection finalized (G/D)")
L795     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L796     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L797     try:
L798         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L799         near10 = list(pool.sort_values(ascending=False).head(10).index)
L800         setattr(sc, f"_near_{group}", near10)
L801         setattr(sc, f"_agg_{group}", agg)
L802     except Exception:
L803         pass
L804
L805     if group == "D":
L806         T.log("save done")
L807     if group == "G":
L808         sc._top_G = pick
L809     return pick, avg_r, sum_sc, obj
L810
L811 def run_pipeline() -> SelectionBundle:
L812     """
L813     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L814     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L815     """
L816     inb = io_build_input_bundle()
L817     cfg = PipelineConfig(
L818         weights=WeightsConfig(g=g_weights, d=D_weights),
L819         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L820                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L821         price_max=CAND_PRICE_MAX
L822     )
L823     sc = Scorer()
L824     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L825     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L826     alpha = Scorer.spx_to_alpha(inb.spx)
L827     sectors = {t: (inb.info.get(t, {}).get("sector") or "U") for t in poolG}
L828     scores = {t: Scorer.g_score.get(t, 0.0) for t in poolG}
L829     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L830     sc._top_G = top_G
L831     try:
L832         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L833         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L834     except Exception:
L835         pass
L836     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L837     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L838     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L839     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L840     fb = getattr(sc, "_feat", None)
L841     near_G = getattr(sc, "_near_G", [])
L842     selected12 = list(top_G)
L843     df = fb.df if fb is not None else pd.DataFrame()
L844     guni = _infer_g_universe(df, selected12, near_G)
L845     try:
L846         fire_recent = [t for t in guni
L847                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L848                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L849     except Exception:
L850         fire_recent = []
L851     lines = [
L852         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L853         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L854         f"é¸å®š12: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else "é¸å®š12: ãªã—",
L855         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",
L856     ]
L857     if fire_recent:
L858         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L859         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L860     else:
L861         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L862     try:
L863         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L864         if webhook:
L865             requests.post(webhook, json={"text": "\n".join(lines)}, timeout=10)
L866     except Exception:
L867         pass
L868
L869     out = Output(debug=debug_mode)
L870     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L871     try: out._sc = sc
L872     except Exception: pass
L873     if hasattr(sc, "_feat"):
L874         try:
L875             out.miss_df = sc._feat.missing_logs
L876             out.display_results(
L877                 exist=exist, bench=bench, df_z=sc._feat.df_z,
L878                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L879                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D
L880             )
L881         except Exception:
L882             pass
L883     out.notify_slack()
L884     sb = SelectionBundle(
L885         resG={"tickers": top_G, "avg_res_corr": avgG,
L886               "sum_score": sumG, "objective": objG},
L887         resD={"tickers": top_D, "avg_res_corr": avgD,
L888               "sum_score": sumD, "objective": objD},
L889         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D
L890     )
L891
L892     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L893     try:
L894         _low_df = (
L895             pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L896               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L897               .sort_values("G_plus_D")
L898               .head(10)
L899               .round(3)
L900         )
L901         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L902                "```"
L903                + _low_df.to_string(index=True, index_names=False)
L904                + "\n```")
L905     except Exception as _e:
L906         _slack(f"Low Score Candidates: ä½œæˆå¤±æ•—: {_e}")
L907
L908     if debug_mode:
L909         try:
L910             _slack_debug(_compact_debug(fb, sb, [], []))
L911         except Exception as e:
L912             print(f"[debug skipped] {e}")
L913
L914     return sb
L915
L916 if __name__ == "__main__":
L917     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py 
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None:
L43         return float(c)
L44     try:
L45         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L46         return float(h.iloc[-1]) if len(h) else np.nan
L47     except Exception:
L48         return np.nan
L49
L50 def _ttm_div_sum(t, lookback_days=400):
L51     try:
L52         div = yf.Ticker(t).dividends
L53         if div is None or len(div) == 0:
L54             return 0.0
L55         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L56         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L57         return ttm if ttm > 0 else float(div.tail(4).sum())
L58     except Exception:
L59         return 0.0
L60
L61 def ttm_div_yield_portfolio(tickers, price_map=None):
L62     ys = []
L63     for t in tickers:
L64         c = _last_close(t, price_map)
L65         if not np.isfinite(c) or c <= 0:
L66             ys.append(0.0)
L67             continue
L68         s = _ttm_div_sum(t)
L69         ys.append(s / c if s > 0 else 0.0)
L70     return float(np.mean(ys)) if ys else 0.0
L71
L72 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L73 def winsorize_s(s: pd.Series, p=0.02):
L74     if s is None or s.dropna().empty: return s
L75     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L76
L77 def robust_z(s: pd.Series, p=0.02):
L78     s2 = winsorize_s(s, p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L79
L80 def _safe_div(a, b):
L81     try:
L82         if b is None or float(b)==0 or pd.isna(b): return np.nan
L83         return float(a)/float(b)
L84     except Exception: return np.nan
L85
L86 def _safe_last(series: pd.Series, default=np.nan):
L87     try: return float(series.iloc[-1])
L88     except Exception: return default
L89
L90 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L91
L92 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L93 class Scorer:
L94     """
L95     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L96     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L97     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L98     """
L99
L100     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L101     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L102     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L103
L104     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L105     @staticmethod
L106     def _validate_ib_for_scorer(ib: Any):
L107         must_attrs = ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"]
L108         miss = [a for a in must_attrs if not hasattr(ib, a) or getattr(ib, a) is None]
L109         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L110
L111         # å¾Œæ–¹äº’æ›ã®ãŸã‚ã€ã¾ãš rename ã‚’è©¦ã¿ã‚‹
L112         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME.keys()):
L113             ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L114         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME.keys()):
L115             ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L116
L117         # å¿…é ˆåˆ—ã®å­˜åœ¨ç¢ºèª
L118         need_eps = {"EPS_TTM","EPS_Q_LastQ"}
L119         need_fcf = {"FCF_TTM"}
L120         if not need_eps.issubset(set(ib.eps_df.columns)):
L121             raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L122         if not need_fcf.issubset(set(ib.fcf_df.columns)):
L123             raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L124
L125     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L126     @staticmethod
L127     def trend(s: pd.Series):
L128         if len(s)<200: return np.nan
L129         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L130         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L131         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L132         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L133         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L134         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L135         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L136         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L137         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L138         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L139         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L140         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L141
L142     @staticmethod
L143     def rs(s, b):
L144         n, nb = len(s), len(b)
L145         if n<60 or nb<60: return np.nan
L146         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L147         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L148         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L149
L150     @staticmethod
L151     def tr_str(s):
L152         if len(s)<50: return np.nan
L153         return s.iloc[-1]/s.rolling(50).mean().iloc[-1] - 1
L154
L155     @staticmethod
L156     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L157         r = (s/b).dropna()
L158         if len(r)<win: return np.nan
L159         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L160         try: return float(np.polyfit(x, y, 1)[0])
L161         except Exception: return np.nan
L162
L163     @staticmethod
L164     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L165         ev = info_t.get('enterpriseValue', np.nan)
L166         if pd.notna(ev) and ev>0: return float(ev)
L167         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L168         try:
L169             bs = tk.quarterly_balance_sheet
L170             if bs is not None and not bs.empty:
L171                 c = bs.columns[0]
L172                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L173                     if k in bs.index: debt = float(bs.loc[k,c]); break
L174                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L175                     if k in bs.index: cash = float(bs.loc[k,c]); break
L176         except Exception: pass
L177         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L178         return np.nan
L179
L180     @staticmethod
L181     def dividend_status(ticker: str) -> str:
L182         t = yf.Ticker(ticker)
L183         try:
L184             if not t.dividends.empty: return "has"
L185         except Exception: return "unknown"
L186         try:
L187             a = t.actions
L188             if a is not None and not a.empty and "Stock Splits" in a.columns and a["Stock Splits"].abs().sum()>0: return "none_confident"
L189         except Exception: pass
L190         try:
L191             fi = t.fast_info
L192             if any(getattr(fi,k,None) for k in ("last_dividend_date","dividend_rate","dividend_yield")): return "maybe_missing"
L193         except Exception: pass
L194         return "unknown"
L195
L196     @staticmethod
L197     def div_streak(t):
L198         try:
L199             divs = yf.Ticker(t).dividends.dropna(); ann = divs.groupby(divs.index.year).sum(); ann = ann[ann.index<pd.Timestamp.today().year]
L200             years, streak = sorted(ann.index), 0
L201             for i in range(len(years)-1,0,-1):
L202                 if ann[years[i]] > ann[years[i-1]]: streak += 1
L203                 else: break
L204             return streak
L205         except Exception: return 0
L206
L207     @staticmethod
L208     def fetch_finnhub_metrics(symbol):
L209         api_key = os.environ.get("FINNHUB_API_KEY")
L210         if not api_key: return {}
L211         url, params = "https://finnhub.io/api/v1/stock/metric", {"symbol":symbol,"metric":"all","token":api_key}
L212         try:
L213             r = requests.get(url, params=params, timeout=10); r.raise_for_status(); m = r.json().get("metric",{})
L214             return {'EPS':m.get('epsGrowthTTMYoy'),'REV':m.get('revenueGrowthTTMYoy'),'ROE':m.get('roeTTM'),'BETA':m.get('beta'),'DIV':m.get('dividendYieldIndicatedAnnual'),'FCF':(m.get('freeCashFlowTTM')/m.get('enterpriseValue')) if m.get('freeCashFlowTTM') and m.get('enterpriseValue') else None}
L215         except Exception: return {}
L216
L217     @staticmethod
L218     def calc_beta(series: pd.Series, market: pd.Series, lookback=252):
L219         r, m = series.pct_change().dropna(), market.pct_change().dropna()
L220         n = min(len(r), len(m), lookback)
L221         if n<60: return np.nan
L222         r, m = r.iloc[-n:], m.iloc[-n:]; cov, var = np.cov(r, m)[0,1], np.var(m)
L223         return np.nan if var==0 else cov/var
L224
L225     @staticmethod
L226     def spx_to_alpha(spx: pd.Series, bands=(0.03,0.10), w=(0.6,0.4),
L227                      span=5, q=(0.20,0.40), alphas=(0.05,0.08,0.10)) -> float:
L228         """
L229         S&P500æŒ‡æ•°ã®ã¿ã‹ã‚‰æ“¬ä¼¼breadthã‚’ä½œã‚Šã€å±¥æ­´åˆ†ä½ã§Î±ã‚’æ®µéšæ±ºå®šã€‚
L230         bands=(Â±3%, Â±10%), w=(50DMA,200DMA), åˆ†ä½q=(20%,40%), alphas=(ä½,ä¸­,é«˜)
L231         """
L232         ma50, ma200 = spx.rolling(50).mean(), spx.rolling(200).mean()
L233         b50  = ((spx/ma50 - 1) + bands[0])/(2*bands[0])
L234         b200 = ((spx/ma200 - 1) + bands[1])/(2*bands[1])
L235         hist = (w[0]*b50 + w[1]*b200).clip(0,1).ewm(span=span).mean()
L236         b = float(hist.iloc[-1])
L237         lo, mid = float(hist.quantile(q[0])), float(hist.quantile(q[1]))
L238         return alphas[0] if b < lo else alphas[1] if b < mid else alphas[2]
L239
L240     @staticmethod
L241     def soft_cap_effective_scores(scores: pd.Series|dict, sectors: dict, cap=2, alpha=0.08) -> pd.Series:
L242         """
L243         åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼capè¶…éï¼ˆ3æœ¬ç›®ä»¥é™ï¼‰ã« Î±Ã—æ®µéšæ¸›ç‚¹ã‚’èª²ã—ãŸâ€œæœ‰åŠ¹ã‚¹ã‚³ã‚¢â€Seriesã‚’è¿”ã™ã€‚
L244         æˆ»ã‚Šå€¤ã¯é™é †ã‚½ãƒ¼ãƒˆæ¸ˆã¿ã€‚
L245         """
L246         s = pd.Series(scores, dtype=float); order = s.sort_values(ascending=False).index
L247         cnt, pen = {}, {}
L248         for t in order:
L249             sec = sectors.get(t, "U")
L250             k = cnt.get(sec, 0) + 1
L251             pen[t] = alpha * max(0, k - cap)
L252             cnt[sec] = k
L253         return (s - pd.Series(pen)).sort_values(ascending=False)
L254
L255     @staticmethod
L256     def pick_top_softcap(scores: pd.Series|dict, sectors: dict, N: int, cap=2, alpha=0.08, hard: int|None=5) -> list[str]:
L257         """
L258         soft-capé©ç”¨å¾Œã®ä¸Šä½Nãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’è¿”ã™ã€‚hard>0ãªã‚‰éå¸¸ç”¨ãƒãƒ¼ãƒ‰ä¸Šé™ã§åŒä¸€ã‚»ã‚¯ã‚¿ãƒ¼è¶…éã‚’é–“å¼•ãï¼ˆæ—¢å®š=5ï¼‰ã€‚
L259         """
L260         eff = Scorer.soft_cap_effective_scores(scores, sectors, cap, alpha)
L261         if not hard:
L262             return list(eff.head(N).index)
L263         pick, used = [], {}
L264         for t in eff.index:
L265             s = sectors.get(t, "U")
L266             if used.get(s, 0) < hard:
L267                 pick.append(t)
L268                 used[s] = used.get(s, 0) + 1
L269             if len(pick) == N:
L270                 break
L271         return pick
L272
L273     # ---- ã‚¹ã‚³ã‚¢é›†è¨ˆï¼ˆDTO/Configã‚’å—ã‘å–ã‚Šã€FeatureBundleã‚’è¿”ã™ï¼‰ ----
L274     def aggregate_scores(self, ib: Any, cfg):
L275         if cfg is None:
L276             raise ValueError("cfg is required; pass factor.PipelineConfig")
L277         self._validate_ib_for_scorer(ib)
L278
L279         px, spx, tickers = ib.px, ib.spx, ib.tickers
L280         tickers_bulk, info, eps_df, fcf_df = ib.tickers_bulk, ib.info, ib.eps_df, ib.fcf_df
L281
L282         df, missing_logs = pd.DataFrame(index=tickers), []
L283         for t in tickers:
L284             d, s = info[t], px[t]; ev = self.ev_fallback(d, tickers_bulk.tickers[t])
L285             # --- åŸºæœ¬ç‰¹å¾´ ---
L286             df.loc[t,'TR']   = self.trend(s)
L287             df.loc[t,'EPS']  = eps_df.loc[t,'EPS_TTM'] if t in eps_df.index else np.nan
L288             df.loc[t,'REV']  = d.get('revenueGrowth',np.nan)
L289             df.loc[t,'ROE']  = d.get('returnOnEquity',np.nan)
L290             df.loc[t,'BETA'] = self.calc_beta(s, spx, lookback=252)
L291
L292             # --- é…å½“ï¼ˆæ¬ æè£œå®Œå«ã‚€ï¼‰ ---
L293             div = d.get('dividendYield') if d.get('dividendYield') is not None else d.get('trailingAnnualDividendYield')
L294             if div is None or pd.isna(div):
L295                 try:
L296                     divs = yf.Ticker(t).dividends
L297                     if divs is not None and not divs.empty:
L298                         last_close = s.iloc[-1]; div_1y = divs[divs.index >= (divs.index.max() - pd.Timedelta(days=365))].sum()
L299                         if last_close and last_close>0: div = float(div_1y/last_close)
L300                 except Exception: pass
L301             df.loc[t,'DIV'] = 0.0 if (div is None or pd.isna(div)) else float(div)
L302
L303             # --- FCF/EV ---
L304             fcf_val = fcf_df.loc[t,'FCF_TTM'] if t in fcf_df.index else np.nan
L305             df.loc[t,'FCF'] = (fcf_val/ev) if (pd.notna(fcf_val) and pd.notna(ev) and ev>0) else np.nan
L306
L307             # --- ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ãƒ»ãƒœãƒ©é–¢é€£ ---
L308             df.loc[t,'RS'], df.loc[t,'TR_str'] = self.rs(s, spx), self.tr_str(s)
L309             r, rm = s.pct_change().dropna(), spx.pct_change().dropna()
L310             n = int(min(len(r), len(rm)))
L311
L312             DOWNSIDE_DEV = np.nan
L313             if n>=60:
L314                 r6 = r.iloc[-min(len(r),126):]; neg = r6[r6<0]
L315                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L316             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L317
L318             MDD_1Y = np.nan
L319             try:
L320                 w = s.iloc[-min(len(s),252):].dropna()
L321                 if len(w)>=30:
L322                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L323             except Exception: pass
L324             df.loc[t,'MDD_1Y'] = MDD_1Y
L325
L326             RESID_VOL = np.nan
L327             if n>=120:
L328                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L329                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L330                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L331                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L332             df.loc[t,'RESID_VOL'] = RESID_VOL
L333
L334             DOWN_OUTPERF = np.nan
L335             if n>=60:
L336                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L337                 if mask.sum()>=10:
L338                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L339                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L340             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L341
L342             # --- é•·æœŸç§»å‹•å¹³å‡/ä½ç½® ---
L343             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L344             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L345
L346             # --- é…å½“ã®è©³ç´°ç³» ---
L347             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L348             try:
L349                 divs = yf.Ticker(t).dividends.dropna()
L350                 if not divs.empty:
L351                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L352                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L353                     ann = divs.groupby(divs.index.year).sum()
L354                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L355                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L356                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L357                 so = d.get('sharesOutstanding',None)
L358                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L359                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L360             except Exception: pass
L361             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L362
L363             # --- è²¡å‹™å®‰å®šæ€§ ---
L364             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L365
L366             # --- EPS å¤‰å‹• ---
L367             EPS_VAR_8Q = np.nan
L368             try:
L369                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L370                 if qe is not None and not qe.empty and so:
L371                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L372                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L373             except Exception: pass
L374             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L375
L376             # --- ã‚µã‚¤ã‚º/æµå‹•æ€§ ---
L377             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L378             try:
L379                 vol_series = ib.data['Volume'][t].dropna()
L380                 if len(vol_series)>=5 and len(s)==len(vol_series):
L381                     dv = (vol_series*s).rolling(60).mean(); adv60 = float(dv.iloc[-1])
L382             except Exception: pass
L383             df.loc[t,'ADV60_USD'] = adv60
L384
L385             # --- å£²ä¸Š/åˆ©ç›Šã®åŠ é€Ÿåº¦ç­‰ ---
L386             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L387             REV_ANNUAL_STREAK = np.nan
L388             try:
L389                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L390                 if qe is not None and not qe.empty:
L391                     if 'Revenue' in qe.columns:
L392                         rev = qe['Revenue'].dropna().astype(float)
L393                         if len(rev)>=5: REV_Q_YOY = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5])
L394                         if len(rev)>=6:
L395                             yoy_now = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5]); yoy_prev = _safe_div(rev.iloc[-2]-rev.iloc[-6], rev.iloc[-6])
L396                             if pd.notna(yoy_now) and pd.notna(yoy_prev): REV_YOY_ACC = yoy_now - yoy_prev
L397                         yoy_list=[]
L398                         for k in range(1,5):
L399                             if len(rev)>=4+k:
L400                                 y = _safe_div(rev.iloc[-k]-rev.iloc[-(k+4)], rev.iloc[-(k+4)])
L401                                 if pd.notna(y): yoy_list.append(y)
L402                         if len(yoy_list)>=2: REV_YOY_VAR = float(np.std(yoy_list, ddof=1))
L403                         # NEW: å¹´æ¬¡ã®æŒç¶šæ€§ï¼ˆç›´è¿‘ã‹ã‚‰é¡ã£ã¦å‰å¹´æ¯”ãƒ—ãƒ©ã‚¹ãŒä½•å¹´é€£ç¶šã‹ã€å››åŠæœŸ4æœ¬æƒã†å®Œå…¨å¹´ã®ã¿ï¼‰
L404                         try:
L405                             g = rev.groupby(rev.index.year)
L406                             ann_sum, cnt = g.sum(), g.count()
L407                             ann_sum = ann_sum[cnt >= 4]
L408                             if len(ann_sum) >= 3:
L409                                 yoy = ann_sum.pct_change().dropna()
L410                                 streak = 0
L411                                 for v in yoy.iloc[::-1]:
L412                                     if pd.isna(v) or v <= 0:
L413                                         break
L414                                     streak += 1
L415                                 REV_ANNUAL_STREAK = float(streak)
L416                         except Exception:
L417                             pass
L418                     if 'Earnings' in qe.columns and so:
L419                         eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L420                         if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L421                             EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L422             except Exception: pass
L423             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'], df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_Q_YOY, EPS_Q_YOY, REV_YOY_ACC, REV_YOY_VAR
L424             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L425
L426             # --- Rule of 40 ã‚„å‘¨è¾º ---
L427             total_rev_ttm = d.get('totalRevenue',np.nan)
L428             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L429             df.loc[t,'FCF_MGN'] = FCF_MGN
L430             rule40 = np.nan
L431             try:
L432                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L433             except Exception: pass
L434             df.loc[t,'RULE40'] = rule40
L435
L436             # --- ãƒˆãƒ¬ãƒ³ãƒ‰è£œåŠ© ---
L437             sma50  = s.rolling(50).mean()
L438             sma150 = s.rolling(150).mean()
L439             sma200 = s.rolling(200).mean()
L440             p = _safe_last(s)
L441
L442             df.loc[t,'MA50_OVER_150'] = (
L443                 _safe_last(sma50)/_safe_last(sma150) - 1
L444                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L445             )
L446             df.loc[t,'MA150_OVER_200'] = (
L447                 _safe_last(sma150)/_safe_last(sma200) - 1
L448                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L449             )
L450
L451             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L452             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L453
L454             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L455             if len(sma200.dropna()) >= 21:
L456                 cur200 = _safe_last(sma200)
L457                 old2001 = float(sma200.iloc[-21])
L458                 if old2001:
L459                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L460
L461             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L462             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L463             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L464             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L465             if len(sma200.dropna())>=105:
L466                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L467                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L468             # NEW: 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ãã®ã€Œæ—¥æ•°ã€
L469             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L470             try:
L471                 s200 = sma200.dropna()
L472                 if len(s200) >= 2:
L473                     diff200 = s200.diff()
L474                     up = 0
L475                     for v in diff200.iloc[::-1]:
L476                         if pd.isna(v) or v <= 0:
L477                             break
L478                         up += 1
L479                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L480             except Exception:
L481                 pass
L482             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L483             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L484             if hi52 and hi52>0 and pd.notna(p):
L485                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L486             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L487             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L488
L489             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L490
L491             # --- æ¬ æãƒ¡ãƒ¢ ---
L492             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L493             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L494             if need_finnhub:
L495                 fin_data = self.fetch_finnhub_metrics(t)
L496                 for col in need_finnhub:
L497                     val = fin_data.get(col)
L498                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L499             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L500                 if pd.isna(df.loc[t,col]):
L501                     if col=='DIV':
L502                         status = self.dividend_status(t)
L503                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L504                     else:
L505                         missing_logs.append({'Ticker':t,'Column':col})
L506
L507         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L508             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L509             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L510             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L511             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L512             c5 = (row.get('TR_str', np.nan) > 0)
L513             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L514             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L515             c8 = (row.get('RS', np.nan) >= 0.10)
L516             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L517
L518         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L519         assert 'trend_template' in df.columns
L520
L521         # === ZåŒ–ã¨åˆæˆ ===
L522         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L523
L524         df_z = pd.DataFrame(index=df.index)
L525         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L526         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L527         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L528         for col in ['REV_Q_YOY','EPS_Q_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']: df_z[col] = robust_z(df[col])
L529         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L530
L531         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L532         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L533         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L534         df_z['GROWTH_F']  = robust_z(
L535               0.25*df_z['REV']          # â†“0.30â†’0.25
L536             + 0.20*df_z['EPS_Q_YOY']
L537             + 0.15*df_z['REV_Q_YOY']
L538             + 0.15*df_z['REV_YOY_ACC']
L539             + 0.10*df_z['RULE40']
L540             + 0.10*df_z['FCF_MGN']
L541             + 0.10*df_z['EPS']          # â˜…è¿½åŠ ï¼šé»’å­—å„ªé‡ï¼èµ¤å­—æ¸›ç‚¹
L542             + 0.05*df_z['REV_ANN_STREAK']
L543             - 0.05*df_z['REV_YOY_VAR']
L544         ).clip(-3.0,3.0)
L545         df_z['MOM_F'] = robust_z(
L546               0.40*df_z['RS']
L547             + 0.15*df_z['TR_str']
L548             + 0.15*df_z['RS_SLOPE_6W']
L549             + 0.15*df_z['RS_SLOPE_13W']
L550             + 0.10*df_z['MA200_SLOPE_5M']
L551             + 0.10*df_z['MA200_UP_STREAK_D']
L552         ).clip(-3.0,3.0)
L553         df_z['VOL'] = robust_z(df['BETA'])
L554         df_z.rename(columns={'GROWTH_F':'GRW','MOM_F':'MOM','QUALITY_F':'QAL','YIELD_F':'YLD'}, inplace=True)
L555         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L556         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L557
L558         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L559         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L560         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L561         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L562
L563         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L564         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L565         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L566
L567         d_comp = pd.concat({
L568             'QAL': df_z['D_QAL'],
L569             'YLD': df_z['D_YLD'],
L570             'VOL': df_z['D_VOL_RAW'],
L571             'TRD': df_z['D_TRD']
L572         }, axis=1)
L573         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L574         globals()['D_WEIGHTS_EFF'] = dw.copy()
L575         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L576
L577         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L578         mask = df['trend_template']
L579         if not bool(mask.any()):
L580             mask = (
L581                 (df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L582                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L583                 (df.get('RS', np.nan) >= 0.08) &
L584                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L585                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L586                 (df.get('MA150_OVER_200', np.nan) > 0) &
L587                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L588                 (df.get('TR_str', np.nan) > 0)
L589             ).fillna(False)
L590             df['trend_template'] = mask
L591
L592         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L593         g_score = g_score_all.loc[mask]
L594         Scorer.g_score = g_score
L595         df_z['GSC'] = g_score_all
L596         df_z['DSC'] = d_score_all
L597
L598         try:
L599             current = (
L600                 pd.read_csv("current_tickers.csv")
L601                   .iloc[:, 0]
L602                   .str.upper()
L603                   .tolist()
L604             )
L605         except FileNotFoundError:
L606             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L607             current = []
L608
L609         mask_bonus = g_score.index.isin(current)
L610         if mask_bonus.any():
L611             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L612             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L613             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L614             sigma_g = g_score.std()
L615             if pd.isna(sigma_g):
L616                 sigma_g = 0.0
L617             bonus_g = round(k * sigma_g, 3)
L618             g_score.loc[mask_bonus] += bonus_g
L619             Scorer.g_score = g_score
L620             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L621             sigma_d = d_score_all.std()
L622             if pd.isna(sigma_d):
L623                 sigma_d = 0.0
L624             bonus_d = round(k * sigma_d, 3)
L625             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L626
L627         try:
L628             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L629         except Exception:
L630             pass
L631
L632         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L633         return FeatureBundle(
L634             df=df,
L635             df_z=df_z,
L636             g_score=g_score,
L637             d_score_all=d_score_all,
L638             missing_logs=pd.DataFrame(missing_logs)
L639         )
L640
L641
L642 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L643     """
L644     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L645     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L646       - G_BREAKOUT_recent_5d : bool
L647       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L648       - G_PULLBACK_recent_5d : bool
L649       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L650       - G_PIVOT_price        : float
L651     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L652     """
L653     try:
L654         px   = bundle.px                      # çµ‚å€¤ DataFrame
L655         hi   = bundle.data['High']
L656         lo   = bundle.data['Low']
L657         vol  = bundle.data['Volume']
L658         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L659
L660         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L661         g_universe = getattr(self_obj, "g_universe", None)
L662         if g_universe is None:
L663             try:
L664                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L665             except Exception:
L666                 g_universe = list(feature_df.index)
L667         if not g_universe:
L668             return feature_df
L669
L670         # æŒ‡æ¨™
L671         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L672         ma50  = px[g_universe].rolling(50).mean()
L673         ma150 = px[g_universe].rolling(150).mean()
L674         ma200 = px[g_universe].rolling(200).mean()
L675         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L676         vol20 = vol[g_universe].rolling(20).mean()
L677         vol50 = vol[g_universe].rolling(50).mean()
L678
L679         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L680         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L681                             & (ma150 > ma200) & (ma200.diff() > 0)
L682
L683         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L684         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L685
L686         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L687         bench_aligned = bench.reindex(px.index).ffill()
L688         rs = px[g_universe].div(bench_aligned, axis=0)
L689         rs_high = rs.rolling(252).max().shift(1)
L690
L691         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L692         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L693                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L694         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L695
L696         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L697         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L698         volume_dryup = (vol20 / vol50) <= 1.0
L699         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L700         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L701         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L702
L703         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L704         rows = []
L705         for t in g_universe:
L706             def _recent_and_date(s, win):
L707                 sw = s[t].iloc[-win:]
L708                 if sw.any():
L709                     d = sw[sw].index[-1]
L710                     return True, d.strftime("%Y-%m-%d")
L711                 return False, ""
L712             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L713             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L714             rows.append((t, {
L715                 "G_BREAKOUT_recent_5d": br_recent,
L716                 "G_BREAKOUT_last_date": br_date,
L717                 "G_PULLBACK_recent_5d": pb_recent,
L718                 "G_PULLBACK_last_date": pb_date,
L719                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L720             }))
L721         flags = pd.DataFrame({k: v for k, v in rows}).T
L722
L723         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L724         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L725         for c in cols:
L726             if c not in feature_df.columns:
L727                 feature_df[c] = np.nan
L728         feature_df.loc[flags.index, flags.columns] = flags
L729
L730     except Exception:
L731         pass
L732     return feature_df
L733
L734
L735
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v5
L25         with:
L26           python-version: '3.x'                # ï¼ˆå¿…è¦æœ€å°é™ã®ã¾ã¾ã€‚å›ºå®šã—ãŸã‘ã‚Œã° '3.13'ï¼‰
L27           cache: 'pip'                         # â˜… pipã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹åŒ–
L28           cache-dependency-path: requirements.txt  # â˜… ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã«
L29
L30       - name: Install dependencies
L31         run: pip install -r requirements.txt
L32
L33       - name: Prepare results directory
L34         run: mkdir -p results
L35
L36       - name: Run factor & scoring
L37         env:
L38           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L39           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L40           FIN_THREADS: "8"
L41         run: python factor.py
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 25éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š4%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6
L7 ## Barbell Growth-Defenseæ–¹é‡
L8 - Growthæ 12éŠ˜æŸ„ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L9 - Defenseæ 13éŠ˜æŸ„ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L10 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L11
L12 ## ç¾é‡‘æ¯”ç‡ï¼ˆVIX 5æ—¥ç§»å‹•å¹³å‡ã§åˆ¤å®šï¼‰
L13 - VIX MA5 < 20: 5%
L14 - 20 â‰¤ VIX MA5 < 26: 7.5%
L15 - VIX MA5 â‰¥ 27: 12%ï¼ˆé«˜VIXç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ï¼‰
L16
L17 ## ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤
L18 - VIX MA5 < 20: 10%
L19 - 20 â‰¤ VIX MA5 < 26: 12%
L20 - VIX MA5 â‰¥ 27: é«˜VIXç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ã¸ç§»è¡Œ
L21
L22 ## é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®é‹ç”¨
L23 - æ¯å–¶æ¥­æ—¥ã€â‘ 90æ—¥çµŒé or â‘¡ãƒ‰ãƒªãƒ•ãƒˆãŒé–¾å€¤è¶…éã§åŠæˆ»ã—
L24 - åŠæˆ»ã—ï¼šä¹–é›¢ã®50%ã‚’ä¸­å¤®ã¸å¯„ã›ã€ç¾é‡‘æ¯”ç‡ã‚’ä¸Šè¡¨ã©ãŠã‚Šã«èª¿æ•´
L25 - å…¨éŠ˜æŸ„ã®ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—(TS)ã‚’å†è¨­å®š
L26 - ãƒ‰ãƒªãƒ•ãƒˆï¼Î£|ç¾åœ¨æ¯”ç‡âˆ’4%|ï¼ˆç«¯æ•°åˆ‡ã‚Šæ¨ã¦ï¼‰
L27
L28 ## é«˜VIXç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ï¼ˆMA5 > 27ã§ç™ºå‹•ï¼‰
L29 1. å…¨25éŠ˜æŸ„ã‚’å„4%ã¸å…¨æˆ»ã—
L30 2. ç¾é‡‘æ¯”ç‡12%ã¸å¼•ä¸Šã’
L31 3. å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã—ä»¥é™ã®å£²è²·ã¨ãƒ‰ãƒªãƒ•ãƒˆè¨ˆç®—ã‚’åœæ­¢
L32
L33 ## é«˜VIXç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ã®è§£é™¤
L34 - MA5 < 23 ã¾ãŸã¯30å–¶æ¥­æ—¥çµŒéã§è§£é™¤
L35 - ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã«TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã‚’è£œå……ã—25éŠ˜æŸ„Ã—4%ã«ãƒªãƒãƒ©ãƒ³ã‚¹
L36 - é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®æ—¥æ¬¡ãƒã‚§ãƒƒã‚¯ã‚’å†é–‹
L37
L38 ## æ®µéšçš„ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
L39 - Growth: åŸºæœ¬25%
L40 - Defense: åŸºæœ¬20%
L41 - å«ã¿ç›ŠãŒ40/60/80%ã«é”ã—ãŸã‚‰TSã‚’3/5/8ãƒã‚¤ãƒ³ãƒˆãšã¤å¼•ãä¸Šã’
L42 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L43
L44 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L45 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L46 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L47
L48 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L49 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L50 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
L51
L52 ## VIXæ—©è¦‹è¡¨
L53 | VIX MA5 | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ | ç¾é‡‘æ¯”ç‡ | ãƒ¢ãƒ¼ãƒ‰ |
L54 |--------|--------------|---------|-------|
L55 | <20    | 10           | 5%      | é€šå¸¸ |
L56 | 20â€“26  | 12           | 7.5%    | é€šå¸¸ |
L57 | â‰¥27    | â€“            | 12%     | é«˜VIXç·Šæ€¥ |
```

## <documents/factor_design.md>
```text
L1 # factor.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - æ—¢å­˜ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®éŠ˜æŸ„ã¨æ¤œè¨ä¸­ã®éŠ˜æŸ„ç¾¤ã‚’åŒæ™‚ã«æ‰±ã†éŠ˜æŸ„é¸å®šãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚
L5 - ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¿ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨DRRSé¸å®šã‚’è¡Œã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’å¾—ã‚‹ã€‚
L6   - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚æ¼ã‚ŒãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L7   - IN/OUTã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆã¨OUTå´ã®ä½ã‚¹ã‚³ã‚¢éŠ˜æŸ„
L8   - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨
L9   - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆæ•´ç†ç”¨ï¼‰
L10
L11 ## å…¨ä½“ãƒ•ãƒ­ãƒ¼
L12 1. **Input** â€“ `current_tickers.csv`ã¨`candidate_tickers.csv`ã‚’èª­ã¿è¾¼ã¿ã€yfinanceã‚„Finnhubã®APIã‹ã‚‰ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦`InputBundle`ã‚’æ•´å‚™ã€‚
L13 2. **Score Calculation** â€“ ScorerãŒç‰¹å¾´é‡ã‚’è¨ˆç®—ã—å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã—ã¦`FeatureBundle`ã‚’ç”Ÿæˆã€‚
L14 3. **Correlation Reduction & Selection** â€“ SelectorãŒDRRSãƒ­ã‚¸ãƒƒã‚¯ã§ç›¸é–¢ã‚’æŠ‘ãˆã¤ã¤G/DéŠ˜æŸ„ã‚’é¸å®šã—`SelectionBundle`ã‚’å¾—ã‚‹ã€‚
L15 4. **Output** â€“ æ¡ç”¨çµæœã¨å‘¨è¾ºæƒ…å ±ã‚’è¡¨ãƒ»Slacké€šçŸ¥ã¨ã—ã¦å‡ºåŠ›ã€‚
L16
L17 ```mermaid
L18 flowchart LR
L19   A[Input\nAPI & å‰å‡¦ç†] --> B[Score Calculation\nç‰¹å¾´é‡ãƒ»å› å­åˆæˆ]
L20   B --> C[Correlation Reduction\nDRRSé¸å®š]
L21   C --> D[Output\nSlacké€šçŸ¥]
L22 ```
L23
L24 ## å®šæ•°ãƒ»è¨­å®š
L25 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L26 | --- | --- | --- |
L27 | `exist` / `cand` | ç¾è¡Œãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æ¤œè¨ä¸­éŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒªã‚¹ãƒˆ | ã‚¹ã‚³ã‚¢å¯¾è±¡ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã®æ§‹æˆã€å€™è£œæ•´ç† |
L28 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L29 | `CAND_PRICE_MAX` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | é«˜é¡éŠ˜æŸ„ã®äº‹å‰é™¤å¤– |
L30 | `N_G` / `N_D` | G/Dæ¡ç”¨æ ã®ä»¶æ•° | æœ€çµ‚çš„ã«é¸ã¶éŠ˜æŸ„æ•°ã®åˆ¶ç´„ |
L31 | `g_weights` / `D_weights` | å„å› å­ã®é‡ã¿dict | G/Dã‚¹ã‚³ã‚¢åˆæˆ |
L32 | `D_BETA_MAX` | Dãƒã‚±ãƒƒãƒˆã®è¨±å®¹Î²ä¸Šé™ | é«˜Î²éŠ˜æŸ„ã®é™¤å¤–ãƒ•ã‚£ãƒ«ã‚¿ |
L33 | `FILTER_SPEC` | G/Dã”ã¨ã®å‰å‡¦ç†ãƒ•ã‚£ãƒ«ã‚¿ | ãƒˆãƒ¬ãƒ³ãƒ‰ãƒã‚¹ã‚¯ã‚„Î²ä¸Šé™è¨­å®š |
L34 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L35 | `DRRS_G` / `DRRS_D` | DRRSãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | ãƒã‚±ãƒƒãƒˆåˆ¥ã®ç›¸é–¢ä½æ¸›è¨­å®š |
L36 | `DRRS_SHRINK` | æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å®‰å®šåŒ– |
L37 | `CROSS_MU_GD` | G-Dé–“ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ | 2ãƒã‚±ãƒƒãƒˆåŒæ™‚æœ€é©åŒ–ã§ç›¸é–¢æŠ‘åˆ¶ |
L38 | `RESULTS_DIR` | é¸å®šçµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `_save_sel`/`_load_prev`ã®å…¥å‡ºåŠ› |
L39
L40 é¸å®šçµæœã¯`results/`é…ä¸‹ã«JSONã¨ã—ã¦ä¿å­˜ã—ã€æ¬¡å›å®Ÿè¡Œæ™‚ã«`_load_prev`ã§èª­ã¿è¾¼ã‚“ã§é¸å®šæ¡ä»¶ã«åæ˜ ã€‚
L41
L42 ## DTO/Config
L43 å„ã‚¹ãƒ†ãƒƒãƒ—é–“ã§å—ã‘æ¸¡ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨è¨­å®šå€¤ã€‚å¤‰æ•°ã®æ„å‘³åˆã„ã¨åˆ©ç”¨ç®‡æ‰€ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚
L44
L45 ### InputBundleï¼ˆInput â†’ Scorerï¼‰
L46 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L47 | --- | --- | --- |
L48 | `cand` | å€™è£œéŠ˜æŸ„ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒªã‚¹ãƒˆ | OUTãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯¾è±¡ã®æ¯é›†å›£ |
L49 | `tickers` | ç¾è¡Œ+å€™è£œã‚’åˆã‚ã›ãŸãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ | ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®— |
L50 | `bench` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ | ç›¸å¯¾å¼·ã•ãƒ»Î²ç®—å‡ºã€ãƒãƒ¼ãƒˆæ¯”è¼ƒ |
L51 | `data` | yfinanceã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœï¼ˆéšå±¤åˆ—ï¼‰ | `px`/`spx`/ãƒªã‚¿ãƒ¼ãƒ³ç­‰ã®åŸºç¤ãƒ‡ãƒ¼ã‚¿ |
L52 | `px` | `data['Close']`ã ã‘ã‚’æŠœãå‡ºã—ãŸä¾¡æ ¼ç³»åˆ— | æŒ‡æ¨™è¨ˆç®—ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ç”Ÿæˆ |
L53 | `spx` | `data['Close'][bench]` ã®Series | `rs`ã‚„`calc_beta`ã®åŸºæº–æŒ‡æ•° |
L54 | `tickers_bulk` | `yf.Tickers`ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | `info`ç­‰ã®ä¸€æ‹¬å–å¾— |
L55 | `info` | ãƒ†ã‚£ãƒƒã‚«ãƒ¼åˆ¥ã®yfinanceæƒ…å ±dict | ã‚»ã‚¯ã‚¿ãƒ¼åˆ¤å®šã‚„EPSè£œå®Œ |
L56 | `eps_df` | EPS TTM/ç›´è¿‘EPSç­‰ã‚’ã¾ã¨ã‚ãŸè¡¨ | æˆé•·æŒ‡æ¨™ã®ç®—å‡º |
L57 | `fcf_df` | CFOãƒ»CapExãƒ»FCF TTMã¨æƒ…å ±æºãƒ•ãƒ©ã‚° | FCF/EVã‚„é…å½“ã‚«ãƒãƒ¬ãƒƒã‚¸ |
L58 | `returns` | `px.pct_change()`ã®ãƒªã‚¿ãƒ¼ãƒ³è¡¨ | ç›¸é–¢è¡Œåˆ—ãƒ»DRRSè¨ˆç®— |
L59
L60 ### FeatureBundleï¼ˆScorer â†’ Selectorï¼‰
L61 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L62 | --- | --- | --- |
L63 | `df` | è¨ˆç®—æ¸ˆã¿æŒ‡æ¨™ã®ç”Ÿå€¤ãƒ†ãƒ¼ãƒ–ãƒ« | ãƒ‡ãƒãƒƒã‚°ãƒ»å‡ºåŠ›è¡¨ç¤º |
L64 | `df_z` | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å¾ŒZã‚¹ã‚³ã‚¢åŒ–ã—ãŸæŒ‡æ¨™è¡¨ | å› å­ã‚¹ã‚³ã‚¢åˆæˆã€é¸å®šåŸºæº– |
L65 | `g_score` | Gãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ | Gé¸å®šã€IN/OUTæ¯”è¼ƒ |
L66 | `d_score_all` | Dãƒã‚±ãƒƒãƒˆç·åˆã‚¹ã‚³ã‚¢ï¼ˆå…¨éŠ˜æŸ„ï¼‰ | Dé¸å®šã€ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚° |
L67 | `missing_logs` | æ¬ ææŒ‡æ¨™ã¨è£œå®ŒçŠ¶æ³ã®ãƒ­ã‚° | ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ |
L68
L69 ### SelectionBundleï¼ˆSelector â†’ Outputï¼‰
L70 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L71 | --- | --- | --- |
L72 | `resG` | Gé¸å®šçµæœã®è©³ç´°dictï¼ˆ`tickers`ã€ç›®çš„å€¤ç­‰ï¼‰ | çµæœä¿å­˜ãƒ»å¹³å‡ç›¸é–¢ãªã©ã®æŒ‡æ¨™è¡¨ç¤º |
L73 | `resD` | Dé¸å®šçµæœã®è©³ç´°dict | åŒä¸Š |
L74 | `top_G` | æœ€çµ‚æ¡ç”¨Gãƒ†ã‚£ãƒƒã‚«ãƒ¼ | æ–°ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ |
L75 | `top_D` | æœ€çµ‚æ¡ç”¨Dãƒ†ã‚£ãƒƒã‚«ãƒ¼ | åŒä¸Š |
L76 | `init_G` | DRRSå‰ã®GåˆæœŸå€™è£œ | æƒœã—ãã‚‚å¤–ã‚ŒãŸéŠ˜æŸ„è¡¨ç¤º |
L77 | `init_D` | DRRSå‰ã®DåˆæœŸå€™è£œ | åŒä¸Š |
L78
L79 ### WeightsConfig
L80 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L81 | --- | --- | --- |
L82 | `g` | Gå› å­ï¼ˆGRW/MOM/VOLï¼‰ã®é‡ã¿dict | `g_score`åˆæˆ |
L83 | `d` | Då› å­ï¼ˆD_QAL/D_YLD/D_VOL_RAW/D_TRDï¼‰ã®é‡ã¿dict | `d_score_all`åˆæˆ |
L84
L85 ### DRRSParams
L86 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L87 | --- | --- | --- |
L88 | `corrM` | DRRSåˆæœŸãƒ—ãƒ¼ãƒ«ã®æœ€å¤§ä»¶æ•° | ç›¸é–¢è¡Œåˆ—ã‚µã‚¤ã‚ºåˆ¶å¾¡ |
L89 | `shrink` | æ®‹å·®ç›¸é–¢ã®ã‚·ãƒ¥ãƒªãƒ³ã‚¯ç‡ | `residual_corr`ã®å¯¾è§’å¼·èª¿ |
L90 | `G` | Gãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dictï¼ˆ`lookback`ç­‰ï¼‰ | `select_bucket_drrs`è¨­å®š |
L91 | `D` | Dãƒã‚±ãƒƒãƒˆç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿dict | åŒä¸Š |
L92 | `cross_mu_gd` | G-Dã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°Î¼ | `select_buckets`ã®ç›®çš„é–¢æ•° |
L93
L94 ### PipelineConfig
L95 | å¤‰æ•° | å†…å®¹ | ä¸»ãªç”¨é€” |
L96 | --- | --- | --- |
L97 | `weights` | `WeightsConfig`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | ã‚¹ã‚³ã‚¢åˆæˆã®é‡ã¿å‚ç…§ |
L98 | `drrs` | `DRRSParams`ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ | é¸å®šã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šå€¤ |
L99 | `price_max` | å€™è£œéŠ˜æŸ„ã®è¨±å®¹ä¾¡æ ¼ä¸Šé™ | Inputæ®µéšã§ã®ãƒ•ã‚£ãƒ«ã‚¿ |
L100
L101 ## å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
L102 - `winsorize_s` / `robust_z` : å¤–ã‚Œå€¤å‡¦ç†ã¨Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L103 - `_safe_div` / `_safe_last` : ä¾‹å¤–ã‚’æ½°ã—ãŸåˆ†å‰²ãƒ»æœ«å°¾å–å¾—ã€‚
L104 - `_load_prev` / `_save_sel` : é¸å®šçµæœã®èª­ã¿æ›¸ãã€‚
L105
L106 ## ã‚¯ãƒ©ã‚¹è¨­è¨ˆ
L107 ### Step1: Input
L108 `current_tickers.csv`ã®ç¾è¡ŒéŠ˜æŸ„ã¨`candidate_tickers.csv`ã®æ¤œè¨ä¸­éŠ˜æŸ„ã‚’èµ·ç‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã™ã‚‹ã€‚å¤–éƒ¨I/Oã¨å‰å‡¦ç†ã‚’æ‹…å½“ã—ã€`prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚ä¾¡æ ¼ãƒ»è²¡å‹™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¯**yfinanceã‚’å„ªå…ˆã—ã€æ¬ æãŒã‚ã‚‹æŒ‡æ¨™ã®ã¿Finnhub APIã§è£œå®Œ**ã™ã‚‹ã€‚
L109 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L110 - `impute_eps_ttm` : å››åŠæœŸEPSÃ—4ã§TTMã‚’æ¨å®šã—æ¬ ææ™‚ã®ã¿å·®ã—æ›¿ãˆã€‚
L111 - `fetch_cfo_capex_ttm_yf` : yfinanceã®å››åŠæœŸ/å¹´æ¬¡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã‹ã‚‰CFOãƒ»CapExãƒ»FCF TTMã‚’ç®—å‡ºã€‚
L112 - `fetch_cfo_capex_ttm_finnhub` : yfinanceã§æ¬ ã‘ãŸéŠ˜æŸ„ã®ã¿Finnhub APIã§è£œå®Œã€‚
L113 - `compute_fcf_with_fallback` : yfinanceå€¤ã‚’åŸºæº–ã«Finnhubå€¤ã§ç©´åŸ‹ã‚ã—ã€CFO/CapEx/FCFã¨æƒ…å ±æºãƒ•ãƒ©ã‚°ã‚’è¿”ã™ã€‚
L114 - `_build_eps_df` : `info`ã‚„`quarterly_earnings`ã‹ã‚‰EPS TTMã¨ç›´è¿‘EPSã‚’è¨ˆç®—ã—ã€`impute_eps_ttm`ã§è£œå®Œã€‚
L115 - `prepare_data` :
L116     0. CSVã‹ã‚‰ç¾è¡ŒéŠ˜æŸ„ã¨å€™è£œéŠ˜æŸ„ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
L117     1. å€™è£œéŠ˜æŸ„ã®ç¾åœ¨å€¤ã‚’å–å¾—ã—ä¾¡æ ¼ä¸Šé™ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
L118     2. æ—¢å­˜+å€™è£œã‹ã‚‰å¯¾è±¡ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’æ±ºå®šã—ã€ä¾¡æ ¼ãƒ»å‡ºæ¥é«˜ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆyfinanceï¼‰ã€‚
L119     3. yfinanceå€¤ã‚’åŸºã«EPS/FCFãƒ†ãƒ¼ãƒ–ãƒ«ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç³»åˆ—ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ¬ æã‚»ãƒ«ã¯Finnhubå‘¼ã³å‡ºã—ã§ç©´åŸ‹ã‚ã€‚
L120     4. ä¸Šè¨˜ã‚’`InputBundle`ã«æ ¼ç´ã—ã¦è¿”ã™ã€‚
L121
L122 ### Step2: Score Calculation (Scorer)
L123 ç‰¹å¾´é‡è¨ˆç®—ã¨ã‚¹ã‚³ã‚¢åˆæˆã‚’æ‹…å½“ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L124
L125 #### è£œåŠ©é–¢æ•°
L126 - `trend(s)` : 50/150/200æ—¥ç§»å‹•å¹³å‡ã‚„52é€±ãƒ¬ãƒ³ã‚¸ã‹ã‚‰-0.5ã€œ0.5ã§æ§‹æˆã•ã‚ŒãŸãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ã€‚
L127 - `rs(s,b)` / `tr_str(s)` / `rs_line_slope(s,b,win)` : ç›¸å¯¾å¼·ã•ã‚„çŸ­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã€RSå›å¸°å‚¾ãã‚’ç®—å‡ºã€‚
L128 - `ev_fallback` : `enterpriseValue`æ¬ ææ™‚ã«è² å‚µãƒ»ç¾é‡‘ã‹ã‚‰EVã‚’æ¨å®šã€‚
L129 - `dividend_status` / `div_streak` : é…å½“æœªè¨­å®šçŠ¶æ³ã®åˆ¤å®šã¨å¢—é…å¹´æ•°ã‚«ã‚¦ãƒ³ãƒˆã€‚
L130 - `fetch_finnhub_metrics` : Finnhub APIã‹ã‚‰EPSæˆé•·ãƒ»ROEãƒ»Î²ãªã©ä¸è¶³æŒ‡æ¨™ã‚’å–å¾—ã€‚
L131 - `calc_beta` : ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®å…±åˆ†æ•£ã‹ã‚‰Î²ã‚’ç®—å‡ºã€‚
L132 - `spx_to_alpha` : S&P500ã®ä½ç½®æƒ…å ±ã‹ã‚‰DRRSã§ç”¨ã„ã‚‹Î±ã‚’æ¨å®šã€‚
L133 - `soft_cap_effective_scores` / `pick_top_softcap` : ã‚»ã‚¯ã‚¿ãƒ¼ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ—ä»˜ãã‚¹ã‚³ã‚¢èª¿æ•´ã¨ä¸Šä½æŠ½å‡ºã€‚
L134
L135 **è£œåŠ©é–¢æ•°ã¨ç”ŸæˆæŒ‡æ¨™**
L136
L137 | è£œåŠ©é–¢æ•° | ç”ŸæˆæŒ‡æ¨™ | ç•¥ç§° |
L138 | --- | --- | --- |
L139 | `trend` | ãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ | `TR` |
L140 | `rs` | ç›¸å¯¾å¼·ã• | `RS` |
L141 | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç·šã®ä¹–é›¢ | `TR_str` |
L142 | `rs_line_slope` | RSç·šã®å›å¸°å‚¾ã | `RS_SLOPE_*` |
L143 | `calc_beta` | Î² | `BETA` |
L144 | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° | `DIV_STREAK` |
L145
L146 #### `aggregate_scores` è©³ç´°
L147 1. å„éŠ˜æŸ„ã®ä¾¡æ ¼ç³»åˆ—ã‚„`info`ã‚’åŸºã«ä»¥ä¸‹ã‚’ç®—å‡ºã€‚
L148    - **ãƒˆãƒ¬ãƒ³ãƒ‰/ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ **: `TR`ã€`RS`ã€`TR_str`ã€å¤šæ§˜ãªç§»å‹•å¹³å‡æ¯”ã€`RS_SLOPE_*`ãªã©ã€‚
L149    - **ãƒªã‚¹ã‚¯**: `BETA`ã€`DOWNSIDE_DEV`ã€`MDD_1Y`ã€`RESID_VOL`ã€`DOWN_OUTPERF`ã€`EXT_200`ç­‰ã€‚
L150    - **é…å½“**: `DIV`ã€`DIV_TTM_PS`ã€`DIV_VAR5`ã€`DIV_YOY`ã€`DIV_FCF_COVER`ã€`DIV_STREAK`ã€‚
L151    - **è²¡å‹™ãƒ»æˆé•·**: `EPS`ã€`REV`ã€`ROE`ã€`FCF/EV`ã€`REV_Q_YOY`ã€`EPS_Q_YOY`ã€`REV_YOY_ACC`ã€`REV_YOY_VAR`ã€`REV_ANN_STREAK`ã€`RULE40`ã€`FCF_MGN` ç­‰ã€‚
L152    - **å®‰å®šæ€§/ã‚µã‚¤ã‚º**: `DEBT2EQ`ã€`CURR_RATIO`ã€`MARKET_CAP`ã€`ADV60_USD`ã€`EPS_VAR_8Q`ãªã©ã€‚
L153 2. æŒ‡æ¨™æ¬ æã¯Finnhub APIç­‰ã§è£œå®Œã—ã€æœªå–å¾—é …ç›®ã‚’`missing_logs`ã«è¨˜éŒ²ã€‚
L154 3. `winsorize_s`â†’`robust_z`ã§æ¨™æº–åŒ–ã—`df_z`ã¸ä¿å­˜ã€‚ã‚µã‚¤ã‚ºãƒ»æµå‹•æ€§ã¯å¯¾æ•°å¤‰æ›ã€‚
L155 4. æ­£è¦åŒ–æ¸ˆæŒ‡æ¨™ã‹ã‚‰å› å­ã‚¹ã‚³ã‚¢ã‚’åˆæˆã€‚
L156    - å„å› å­ã®æ§‹æˆã¨é‡ã¿ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚
L157      - **GRW**: 0.30Ã—`REV` + 0.20Ã—`EPS_Q_YOY` + 0.15Ã—`REV_Q_YOY` + 0.15Ã—`REV_YOY_ACC` + 0.10Ã—`RULE40` + 0.10Ã—`FCF_MGN` + 0.10Ã—`REV_ANN_STREAK` âˆ’ 0.05Ã—`REV_YOY_VAR`ã€‚
L158      - **MOM**: 0.40Ã—`RS` + 0.15Ã—`TR_str` + 0.15Ã—`RS_SLOPE_6W` + 0.15Ã—`RS_SLOPE_13W` + 0.10Ã—`MA200_SLOPE_5M` + 0.10Ã—`MA200_UP_STREAK_D`ã€‚
L159      - **VOL**: `BETA`å˜ä½“ã‚’ä½¿ç”¨ã€‚
L160      - **QAL**: 0.60Ã—`FCF_W` + 0.40Ã—`ROE_W`ã§ä½œæˆã€‚
L161      - **YLD**: 0.30Ã—`DIV` + 0.70Ã—`DIV_STREAK`ã€‚
L162      - **D_QAL**: 0.35Ã—`QAL` + 0.20Ã—`FCF` + 0.15Ã—`CURR_RATIO` âˆ’ 0.15Ã—`DEBT2EQ` âˆ’ 0.15Ã—`EPS_VAR_8Q`ã€‚
L163      - **D_YLD**: 0.45Ã—`DIV` + 0.25Ã—`DIV_STREAK` + 0.20Ã—`DIV_FCF_COVER` âˆ’ 0.10Ã—`DIV_VAR5`ã€‚
L164      - **D_VOL_RAW**: 0.40Ã—`DOWNSIDE_DEV` + 0.22Ã—`RESID_VOL` + 0.18Ã—`MDD_1Y` âˆ’ 0.10Ã—`DOWN_OUTPERF` âˆ’ 0.05Ã—`EXT_200` âˆ’ 0.08Ã—`SIZE` âˆ’ 0.10Ã—`LIQ` + 0.10Ã—`BETA`ã€‚
L165      - **D_TRD**: 0.40Ã—`MA200_SLOPE_5M` âˆ’ 0.30Ã—`EXT_200` + 0.15Ã—`NEAR_52W_HIGH` + 0.15Ã—`TR`ã€‚
L166     - ä¸»ãªæŒ‡æ¨™ã®ç•¥ç§°ã¨æ„å‘³:
L167
L168       | ç•¥ç§° | è£œåŠ©é–¢æ•° | æ¦‚è¦ |
L169       | --- | --- | --- |
L170       | TR | `trend` | 50/150/200æ—¥ç§»å‹•å¹³å‡ã¨52é€±ãƒ¬ãƒ³ã‚¸ã‚’çµ„ã¿åˆã‚ã›ãŸãƒˆãƒ¬ãƒ³ãƒ‰ç·åˆå€¤ |
L171       | RS | `rs` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹ç›¸å¯¾å¼·ã•ï¼ˆ12M/1Mãƒªã‚¿ãƒ¼ãƒ³å·®ï¼‰ |
L172       | TR_str | `tr_str` | ä¾¡æ ¼ã¨50æ—¥ç§»å‹•å¹³å‡ã®ä¹–é›¢ |
L173       | RS_SLOPE_6W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®6é€±å›å¸°å‚¾ã |
L174       | RS_SLOPE_13W | `rs_line_slope` | ç›¸å¯¾å¼·ã•ç·šã®13é€±å›å¸°å‚¾ã |
L175       | MA200_SLOPE_5M | - | 200æ—¥ç§»å‹•å¹³å‡ã®5ã‹æœˆé¨°è½ç‡ |
L176       | MA200_UP_STREAK_D | - | 200æ—¥ç·šãŒé€£ç¶šã§ä¸Šå‘ã„ãŸæ—¥æ•° |
L177       | BETA | `calc_beta` | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹Î² |
L178       | DOWNSIDE_DEV | - | ä¸‹æ–¹ãƒªã‚¿ãƒ¼ãƒ³ã®ã¿ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L179       | RESID_VOL | - | Î²ã§èª¿æ•´ã—ãŸæ®‹å·®ãƒªã‚¿ãƒ¼ãƒ³ã®å¹´ç‡åŒ–æ¨™æº–åå·® |
L180       | MDD_1Y | - | éå»1å¹´ã®æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ |
L181       | DOWN_OUTPERF | - | å¸‚å ´ä¸‹è½æ—¥ã«å¯¾ã™ã‚‹å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ |
L182       | EXT_200 | - | 200æ—¥ç§»å‹•å¹³å‡ã‹ã‚‰ã®çµ¶å¯¾ä¹–é›¢ç‡ |
L183       | NEAR_52W_HIGH | - | 52é€±é«˜å€¤ã¾ã§ã®ä¸‹æ–¹è·é›¢ï¼ˆ0=é«˜å€¤ï¼‰ |
L184       | FCF_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®FCF/EV |
L185       | ROE_W | - | ã‚¦ã‚£ãƒ³ã‚¶ãƒ¼å‡¦ç†å¾Œã®ROE |
L186       | FCF | - | FCF/EV |
L187       | QAL | - | FCF_Wã¨ROE_Wã‚’çµ„ã¿åˆã‚ã›ãŸå“è³ªã‚¹ã‚³ã‚¢ |
L188       | CURR_RATIO | - | æµå‹•æ¯”ç‡ |
L189       | DEBT2EQ | - | è² å‚µè³‡æœ¬å€ç‡ |
L190       | EPS_VAR_8Q | - | EPSã®8å››åŠæœŸæ¨™æº–åå·® |
L191       | DIV | - | å¹´ç‡æ›ç®—é…å½“åˆ©å›ã‚Š |
L192       | DIV_STREAK | `div_streak` | é€£ç¶šå¢—é…å¹´æ•° |
L193       | DIV_FCF_COVER | - | é…å½“ã®FCFã‚«ãƒãƒ¬ãƒƒã‚¸ |
L194       | DIV_VAR5 | - | 5å¹´é…å½“å¤‰å‹•ç‡ |
L195       | DIV_TTM_PS | - | 1æ ªå½“ãŸã‚ŠTTMé…å½“ |
L196       | DIV_YOY | - | å‰å¹´æ¯”é…å½“æˆé•·ç‡ |
L197       | REV | - | å£²ä¸Šæˆé•·ç‡TTM |
L198       | EPS_Q_YOY | - | å››åŠæœŸEPSã®å‰å¹´åŒæœŸæ¯” |
L199       | REV_Q_YOY | - | å››åŠæœŸå£²ä¸Šã®å‰å¹´åŒæœŸæ¯” |
L200       | REV_YOY_ACC | - | å£²ä¸Šæˆé•·ç‡ã®åŠ é€Ÿåˆ† |
L201       | RULE40 | - | å£²ä¸Šæˆé•·ç‡ã¨FCFãƒãƒ¼ã‚¸ãƒ³ã®åˆè¨ˆ |
L202       | FCF_MGN | - | FCFãƒãƒ¼ã‚¸ãƒ³ |
L203       | REV_ANN_STREAK | - | å¹´æ¬¡å£²ä¸Šæˆé•·ã®é€£ç¶šå¹´æ•° |
L204       | REV_YOY_VAR | - | å¹´æ¬¡å£²ä¸Šæˆé•·ç‡ã®å¤‰å‹•æ€§ |
L205       | SIZE | - | æ™‚ä¾¡ç·é¡ã®å¯¾æ•°å€¤ |
L206       | LIQ | - | 60æ—¥å¹³å‡å‡ºæ¥é«˜ãƒ‰ãƒ«ã®å¯¾æ•°å€¤ |
L207    - Gãƒã‚±ãƒƒãƒˆ: `GRW`ã€`MOM`ã€`VOL`ã‚’`cfg.weights.g`ï¼ˆ0.40/0.45/-0.15ï¼‰ã§åŠ é‡ã—`g_score`ã‚’å¾—ã‚‹ã€‚
L208    - Dãƒã‚±ãƒƒãƒˆ: `D_QAL`ã€`D_YLD`ã€`D_VOL_RAW`ã€`D_TRD`ã‚’`cfg.weights.d`ï¼ˆ0.15/0.15/-0.45/0.25ï¼‰ã§åŠ é‡ã—`d_score_all`ã‚’ç®—å‡ºã€‚
L209    - ã‚»ã‚¯ã‚¿ãƒ¼capã«ã‚ˆã‚‹`soft_cap_effective_scores`ã‚’é©ç”¨ã—ã€Gæ¡ç”¨éŠ˜æŸ„ã«ã¯ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã€‚
L210 5. `_apply_growth_entry_flags`ã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®ç™ºç«çŠ¶æ³ã‚’ä»˜åŠ ã—ã€`FeatureBundle`ã‚’è¿”ã™ã€‚
L211
L212 ### Step3: Correlation Reduction & Selection (Selector)
L213 DRRSã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ç›¸é–¢ã‚’æŠ‘ãˆãŸéŠ˜æŸ„é¸å®šã‚’è¡Œã„ã€`SelectionBundle`ã‚’è¿”ã™ã€‚`results/`ã«ä¿å­˜ã•ã‚ŒãŸå‰å›é¸å®šï¼ˆ`G_selection.json` / `D_selection.json`ï¼‰ã‚’`_load_prev`ã§èª­ã¿è¾¼ã¿ã€ç›®çš„å€¤ãŒå¤§ããæ‚ªåŒ–ã—ãªã„é™ã‚Šç¶­æŒã™ã‚‹ã€‚æ–°ã—ã„æ¡ç”¨é›†åˆã¯`_save_sel`ã§JSONã«æ›¸ãå‡ºã—æ¬¡å›ä»¥é™ã®å…¥åŠ›ã«å‚™ãˆã‚‹ã€‚
L214 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L215 - `residual_corr` : åç›Šç‡è¡Œåˆ—ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã—ã€ä¸Šä½ä¸»æˆåˆ†ã‚’é™¤å»ã—ãŸæ®‹å·®ã‹ã‚‰ç›¸é–¢è¡Œåˆ—ã‚’æ±‚ã‚ã€å¹³å‡ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯ã€‚
L216 - `rrqr_like_det` : ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ã‘ã—ãŸQRåˆ†è§£é¢¨ã®æ‰‹é †ã§åˆæœŸå€™è£œã‚’kä»¶æŠ½å‡ºã—ã€ã‚¹ã‚³ã‚¢ã®é«˜ã„éç›¸é–¢ãªé›†åˆã‚’å¾—ã‚‹ã€‚
L217 - `swap_local_det` / `swap_local_det_cross` : `sum(score) - Î»*within_corr - Î¼*cross_corr`ã‚’ç›®çš„é–¢æ•°ã¨ã—ã¦ã€å…¥ã‚Œæ›¿ãˆæ¢ç´¢ã§å±€æ‰€çš„ã«æœ€é©åŒ–ã€‚
L218 - `select_bucket_drrs` : ãƒ—ãƒ¼ãƒ«éŠ˜æŸ„ã¨ã‚¹ã‚³ã‚¢ã‹ã‚‰æ®‹å·®ç›¸é–¢ã‚’è¨ˆç®—ã—ã€ä¸Šè¨˜2æ®µéš(åˆæœŸé¸æŠâ†’å…¥ã‚Œæ›¿ãˆ)ã§kéŠ˜æŸ„ã‚’æ±ºå®šã€‚éå»æ¡ç”¨éŠ˜æŸ„ã¨ã®æ¯”è¼ƒã§ç›®çš„å€¤ãŒåŠ£åŒ–ã—ãªã‘ã‚Œã°ç¶­æŒã™ã‚‹ã€‚
L219 - `select_buckets` : Gãƒã‚±ãƒƒãƒˆã‚’é¸å®šå¾Œã€ãã®çµæœã‚’é™¤ã„ãŸå€™è£œã‹ã‚‰Dãƒã‚±ãƒƒãƒˆã‚’é¸ã¶ã€‚Dé¸å®šæ™‚ã¯Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£Î¼ã‚’ä»˜ä¸ã—ã€ä¸¡ãƒã‚±ãƒƒãƒˆã®åˆ†æ•£ã‚’åˆ¶å¾¡ã™ã‚‹ã€‚
L220
L221 #### ç›¸é–¢ä½æ¸›ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°
L222 1. **æ®‹å·®ç›¸é–¢è¡Œåˆ—ã®æ§‹ç¯‰ (`residual_corr`)**
L223    - ãƒªã‚¿ãƒ¼ãƒ³è¡Œåˆ—`R`ã‚’Zã‚¹ã‚³ã‚¢åŒ–ã€‚
L224    - SVDã§ä¸Šä½`n_pc`ä¸»æˆåˆ†`F`ã‚’æ±‚ã‚ã€æœ€å°äºŒä¹—ã§ä¿‚æ•°`B`ã‚’ç®—å‡ºã—æ®‹å·®`E = Z - F@B`ã‚’å¾—ã‚‹ã€‚
L225    - `E`ã®ç›¸é–¢è¡Œåˆ—`C`ã‚’è¨ˆç®—ã—ã€å¹³å‡çµ¶å¯¾ç›¸é–¢ã«å¿œã˜ã¦ã‚·ãƒ¥ãƒªãƒ³ã‚¯é‡`shrink_eff`ã‚’è£œæ­£ã—ã¦å¯¾è§’ã‚’å¼·èª¿ã€‚
L226 2. **åˆæœŸå€™è£œã®æŠ½å‡º (`rrqr_like_det`)**
L227    - ã‚¹ã‚³ã‚¢ã‚’0-1æ­£è¦åŒ–ã—ãŸé‡ã¿`w`ã¨ã—ã€`Z*(1+Î³w)`ã§åˆ—ãƒãƒ«ãƒ ã‚’å¼·èª¿ã€‚
L228    - æ®‹å·®ãƒãƒ«ãƒ æœ€å¤§ã®åˆ—ã‚’é€æ¬¡é¸ã³ã€QRãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã£ã¦éç›¸é–¢ã‹ã¤é«˜ã‚¹ã‚³ã‚¢ãª`k`éŠ˜æŸ„é›†åˆ`S0`ã‚’å¾—ã‚‹ã€‚
L229 3. **å±€æ‰€æ¢ç´¢ (`swap_local_det` / `swap_local_det_cross`)**
L230    - ç›®çš„é–¢æ•°`Î£z_score âˆ’ Î»Â·within_corr âˆ’ Î¼Â·cross_corr`ã‚’æœ€å¤§åŒ–ã€‚
L231    - é¸æŠé›†åˆã®å„éŠ˜æŸ„ã‚’ä»–å€™è£œã¨å…¥ã‚Œæ›¿ãˆã€æ”¹å–„ãŒãªããªã‚‹ã¾ã§ã¾ãŸã¯`max_pass`å›ã¾ã§æ¢ç´¢ã€‚
L232    - `swap_local_det_cross`ã¯Gãƒã‚±ãƒƒãƒˆã¨ã®ã‚¯ãƒ­ã‚¹ç›¸é–¢è¡Œåˆ—`C_cross`ã‚’ä½¿ç”¨ã—ã€ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’ä»˜ä¸ã€‚
L233 4. **éå»æ¡ç”¨ã®ç¶­æŒã¨ã‚¯ãƒ­ã‚¹ãƒšãƒŠãƒ«ãƒ†ã‚£ (`select_bucket_drrs` / `select_buckets`)**
L234    - å±€æ‰€æ¢ç´¢çµæœ`S`ã¨éå»é›†åˆ`P`ã®ç›®çš„å€¤ã‚’æ¯”è¼ƒã—ã€`S`ãŒ`P`ã‚ˆã‚Š`Î·`æœªæº€ã®æ”¹å–„ãªã‚‰`P`ã‚’ç¶­æŒã€‚
L235    - `select_buckets`ã§ã¯Gã‚’å…ˆã«æ±ºå®šã—ã€Dé¸å®šæ™‚ã«Gã¨ã®ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£`Î¼`ã‚’åŠ ãˆã¦ã‚¯ãƒ­ã‚¹åˆ†æ•£ã‚’æŠ‘åˆ¶ã€‚
L236
L237 ### Step4: Output
L238 é¸å®šçµæœã‚’å¯è¦–åŒ–ã—å…±æœ‰ã™ã‚‹å·¥ç¨‹ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«åŒ–ã—ã¦æ¨™æº–å‡ºåŠ›ã¨Slackã¸é€ã‚‹ã€‚
L239 - æ¡ç”¨éŠ˜æŸ„ã¨æƒœã—ãã‚‚é¸å¤–ã¨ãªã£ãŸéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ä¸€è¦§
L240 - IN/OUTãƒªã‚¹ãƒˆã¨OUTéŠ˜æŸ„ã®ã‚¹ã‚³ã‚¢ï¼ˆä½å¾—ç‚¹éŠ˜æŸ„ã‚’ç¢ºèªã—ã‚„ã™ãï¼‰
L241 - æ–°æ—§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æ¯”è¼ƒè¡¨ï¼ˆçµ„å…¥ã‚Œãƒ»é™¤å¤–ã€ã‚¹ã‚³ã‚¢å¤‰åŒ–ï¼‰
L242 - æ¤œè¨ä¸­éŠ˜æŸ„ã®ä½ã‚¹ã‚³ã‚¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
L243
L244 ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰:
L245 - `display_results` : ä¸Šè¨˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«åŠ ãˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚„åˆ†æ•£åŒ–æŒ‡æ¨™ã‚’è¡¨ç¤ºã€‚
L246 - `notify_slack` : Slack Webhookã¸åŒå†…å®¹ã‚’é€ä¿¡ã€‚
L247 - è£œåŠ©:`_avg_offdiag`ã€`_resid_avg_rho`ã€`_raw_avg_rho`ã€`_cross_block_raw_rho`ã€‚
L248
L249 ## ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
L250 1. `PipelineConfig`ã‚’æ§‹ç¯‰ã€‚
L251 2. **Step1** `Input.prepare_data`ã§`InputBundle`ã‚’ç”Ÿæˆã€‚
L252 3. **Step2** `Scorer.aggregate_scores`ã§`FeatureBundle`ã‚’å–å¾—ã€‚
L253 4. **Step3** `Selector.select_buckets`ã§`SelectionBundle`ã‚’ç®—å‡ºã€‚
L254 5. **Step4** `Output.display_results`ã¨`notify_slack`ã§çµæœã‚’å‡ºåŠ›ã€‚
```
