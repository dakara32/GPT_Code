```text
1016         df_z['TREND_SLOPE_EPS_RAW'] = slope_eps
L1017         df_z['TREND_SLOPE_EPS'] = slope_eps.clip(-3.0, 3.0)
L1018
L1019         # 年次トレンド（サブ）
L1020         slope_rev_yr = zpos(df_z['REV_YOY'])
L1021         slope_eps_yr = zpos(df_z.get('EPS_YOY', pd.Series(0.0, index=df.index)))
L1022         streak_base = df['REV_ANN_STREAK'].clip(lower=0).fillna(0)
L1023         streak_yr = streak_base / (streak_base.abs() + 1.0)
L1024         slope_rev_yr_combo = 0.7*slope_rev_yr + 0.3*streak_yr
L1025         df_z['TREND_SLOPE_REV_YR_RAW'] = slope_rev_yr_combo
L1026         df_z['TREND_SLOPE_REV_YR'] = slope_rev_yr_combo.clip(-3.0, 3.0)
L1027         df_z['TREND_SLOPE_EPS_YR_RAW'] = slope_eps_yr
L1028         df_z['TREND_SLOPE_EPS_YR'] = slope_eps_yr.clip(-3.0, 3.0)
L1029
L1030         # ===== GRW flexible score (variable data paths) =====
L1031         grw_raw = pd.to_numeric(df.get('GRW_FLEX_SCORE'), errors="coerce")
L1032         df_z['GRW_FLEX_SCORE_RAW'] = grw_raw
L1033         df_z['GROWTH_F_RAW'] = grw_raw
L1034         df_z['GROWTH_F'] = robust_z_keepnan(grw_raw).clip(-3.0, 3.0)
L1035         df_z['GRW_FLEX_WEIGHT'] = pd.to_numeric(df.get('GRW_FLEX_WEIGHT'), errors="coerce")
L1036         df_z['GRW_FLEX_CORE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_CORE'), errors="coerce")
L1037         df_z['GRW_FLEX_PRICE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_PRICE'), errors="coerce")
L1038
L1039         # Debug dump for GRW composition (console OFF by default; enable only with env)
L1040         if bool(os.getenv("GRW_CONSOLE_DEBUG")):
L1041             try:
L1042                 cols = ['GROWTH_F', 'GROWTH_F_RAW', 'GRW_FLEX_WEIGHT']
L1043                 use_cols = [c for c in cols if c in df_z.columns]
L1044                 i = df_z[use_cols].copy() if use_cols else pd.DataFrame(index=df_z.index)
L1045                 i.sort_values('GROWTH_F', ascending=False, inplace=True)
L1046                 limit = max(0, min(40, len(i)))
L1047                 print("[DEBUG: GRW]")
L1048                 for t in i.index[:limit]:
L1049                     row = i.loc[t]
L1050                     parts = []
L1051                     if pd.notna(row.get('GROWTH_F')):
L1052                         parts.append(f"GROWTH_F={row.get('GROWTH_F'):.3f}")
L1053                     raw_val = row.get('GROWTH_F_RAW')
L1054                     if pd.notna(raw_val):
L1055                         parts.append(f"GROWTH_F_RAW={raw_val:.3f}")
L1056                     weight_val = row.get('GRW_FLEX_WEIGHT')
L1057                     if pd.notna(weight_val):
L1058                         parts.append(f"w={weight_val:.2f}")
L1059                     path_val = None
L1060                     try:
L1061                         path_val = info.get(t, {}).get('DEBUG_GRW_PATH')
L1062                     except Exception:
L1063                         path_val = None
L1064                     if not path_val and 'DEBUG_GRW_PATH' in df.columns:
L1065                         path_val = df.at[t, 'DEBUG_GRW_PATH']
L1066                     if path_val:
L1067                         parts.append(f"PATH={path_val}")
L1068                     parts_json = None
L1069                     try:
L1070                         parts_json = info.get(t, {}).get('DEBUG_GRW_PARTS')
L1071                     except Exception:
L1072                         parts_json = None
L1073                     if not parts_json and 'DEBUG_GRW_PARTS' in df.columns:
L1074                         parts_json = df.at[t, 'DEBUG_GRW_PARTS']
L1075                     if parts_json:
L1076                         parts.append(f"PARTS={parts_json}")
L1077                     if not parts:
L1078                         parts.append('no-data')
L1079                     print(f"Ticker: {t} | " + " ".join(parts))
L1080                 print()
L1081             except Exception as exc:
L1082                 print(f"[ERR] GRW debug dump failed: {exc}")
L1083
L1084         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L1085             + 0.15*df_z['TR_str']
L1086             + 0.15*df_z['RS_SLOPE_6W']
L1087             + 0.15*df_z['RS_SLOPE_13W']
L1088             + 0.10*df_z['MA200_SLOPE_5M']
L1089             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L1090         df_z['VOL'] = robust_z(df['BETA'])
L1091         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L1092         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L1093
L1094         # df_z 全明細をページングしてログ出力（最小版）
L1095         if getattr(cfg, "debug_mode", False):
L1096             pd.set_option("display.max_columns", None)
L1097             pd.set_option("display.max_colwidth", None)
L1098             pd.set_option("display.width", None)
L1099             page = int(getattr(cfg, "debug_dfz_page", 50))  # デフォルト50行単位
L1100             n = len(df_z)
L1101             logger.info("=== df_z FULL DUMP start === rows=%d cols=%d page=%d", n, df_z.shape[1], page)
L1102             for i in range(0, n, page):
L1103                 j = min(i + page, n)
L1104                 try:
L1105                     chunk_str = df_z.iloc[i:j].to_string()
L1106                 except Exception:
L1107                     chunk_str = df_z.iloc[i:j].astype(str).to_string()
L1108                 logger.info("--- df_z rows %d..%d ---\n%s", i, j-1, chunk_str)
L1109             logger.info("=== df_z FULL DUMP end ===")
L1110
L1111         # === begin: BIO LOSS PENALTY =====================================
L1112         try:
L1113             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L1114         except Exception:
L1115             penalty_z = 0.8
L1116
L1117         def _is_bio_like(t: str) -> bool:
L1118             inf = info.get(t, {}) if isinstance(info, dict) else {}
L1119             sec = str(inf.get("sector", "")).lower()
L1120             ind = str(inf.get("industry", "")).lower()
L1121             if "health" not in sec:
L1122                 return False
L1123             keys = ("biotech", "biopharma", "pharma")
L1124             return any(k in ind for k in keys)
L1125
L1126         tickers_s = pd.Index(df_z.index)
L1127         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L1128         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L1129         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L1130
L1131         if bool(mask_bio_loss.any()) and penalty_z > 0:
L1132             df_z.loc[mask_bio_loss, "GROWTH_F"] = df_z.loc[mask_bio_loss, "GROWTH_F"] - penalty_z
L1133             df_z["GROWTH_F"] = df_z["GROWTH_F"].clip(-3.0, 3.0)
L1134         # === end: BIO LOSS PENALTY =======================================
L1135
L1136         df_z['TRD'] = 0.0  # TRDはスコア寄与から外し、テンプレ判定はフィルタで行う（列は表示互換のため残す）
L1137         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L1138
L1139         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L1140         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L1141         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L1142         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L1143
L1144         # --- 重みは cfg を優先（外部があればそれを使用） ---
L1145         # ① 全銘柄で G/D スコアを算出（unmasked）
L1146         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L1147
L1148         d_comp = pd.concat({
L1149             'QAL': df_z['D_QAL'],
L1150             'YLD': df_z['D_YLD'],
L1151             'VOL': df_z['D_VOL_RAW'],
L1152             'TRD': df_z['D_TRD']
L1153         }, axis=1)
L1154         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L1155         globals()['D_WEIGHTS_EFF'] = dw.copy()
L1156         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L1157
L1158         # ② テンプレ判定（既存ロジックそのまま）
L1159         mask = df['trend_template']
L1160         if not bool(mask.any()):
L1161             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L1162                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L1163                 (df.get('RS', np.nan) >= 0.08) &
L1164                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L1165                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L1166                 (df.get('MA150_OVER_200', np.nan) > 0) &
L1167                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L1168                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L1169             df['trend_template'] = mask
L1170
L1171         # ③ 採用用は mask、表示/分析用は列で全銘柄保存
L1172         g_score = g_score_all.loc[mask]
L1173         Scorer.g_score = g_score
L1174         df_z['GSC'] = g_score_all
L1175         df_z['DSC'] = d_score_all
L1176
L1177         try:
L1178             current = (pd.read_csv("current_tickers.csv")
L1179                   .iloc[:, 0]
L1180                   .str.upper()
L1181                   .tolist())
L1182         except FileNotFoundError:
L1183             warnings.warn("current_tickers.csv not found — bonus skipped")
L1184             current = []
L1185
L1186         mask_bonus = g_score.index.isin(current)
L1187         if mask_bonus.any():
L1188             # 1) factor.BONUS_COEFF から k を決め、無ければ 0.4
L1189             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L1190             # 2) g 側の σ を取り、NaN なら 0 に丸める
L1191             sigma_g = g_score.std()
L1192             if pd.isna(sigma_g):
L1193                 sigma_g = 0.0
L1194             bonus_g = round(k * sigma_g, 3)
L1195             g_score.loc[mask_bonus] += bonus_g
L1196             Scorer.g_score = g_score
L1197             # 3) D 側も同様に σ の NaN をケア
L1198             sigma_d = d_score_all.std()
L1199             if pd.isna(sigma_d):
L1200                 sigma_d = 0.0
L1201             bonus_d = round(k * sigma_d, 3)
L1202             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L1203
L1204         try:
L1205             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L1206         except Exception:
L1207             pass
L1208
L1209         df_full = df.copy()
L1210         df_full_z = df_z.copy()
L1211
L1212         from factor import FeatureBundle  # type: ignore  # 実行時importなし（循環回避）
L1213         return FeatureBundle(df=df,
L1214             df_z=df_z,
L1215             g_score=g_score,
L1216             d_score_all=d_score_all,
L1217             missing_logs=pd.DataFrame(missing_logs),
L1218             df_full=df_full,
L1219             df_full_z=df_full_z,
L1220             scaler=None)
L1221
L1222 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L1223     """
L1224     G枠ユニバースに対し、ブレイクアウト確定/押し目反発の「直近N営業日内の発火」を判定し、
L1225     次の列を feature_df に追加する（index=ticker）。
L1226       - G_BREAKOUT_recent_5d : bool
L1227       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L1228       - G_PULLBACK_recent_5d : bool
L1229       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L1230       - G_PIVOT_price        : float
L1231     失敗しても例外は握り潰し、既存処理を阻害しない。
L1232     """
L1233     try:
L1234         px   = bundle.px                      # 終値 DataFrame
L1235         hi   = bundle.data['High']
L1236         lo   = bundle.data['Low']
L1237         vol  = bundle.data['Volume']
L1238         bench= bundle.spx                     # ベンチマーク Series
L1239
L1240         # Gユニバース推定：self.g_universe 優先 → feature_df['group']=='G' → 全銘柄
L1241         g_universe = getattr(self_obj, "g_universe", None)
L1242         if g_uni
```