```text
UP_STREAK_D']).clip(-3.0,3.0)
L878         df_z['VOL'] = robust_z(df['BETA'])
L879         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L880         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L881
L882         # df_z 全明細をページングしてログ出力（最小版）
L883         if getattr(cfg, "debug_mode", False):
L884             pd.set_option("display.max_columns", None)
L885             pd.set_option("display.max_colwidth", None)
L886             pd.set_option("display.width", None)
L887             page = int(getattr(cfg, "debug_dfz_page", 50))  # デフォルト50行単位
L888             n = len(df_z)
L889             logger.info("=== df_z FULL DUMP start === rows=%d cols=%d page=%d", n, df_z.shape[1], page)
L890             for i in range(0, n, page):
L891                 j = min(i + page, n)
L892                 try:
L893                     chunk_str = df_z.iloc[i:j].to_string()
L894                 except Exception:
L895                     chunk_str = df_z.iloc[i:j].astype(str).to_string()
L896                 logger.info("--- df_z rows %d..%d ---\n%s", i, j-1, chunk_str)
L897             logger.info("=== df_z FULL DUMP end ===")
L898
L899         # === begin: BIO LOSS PENALTY =====================================
L900         try:
L901             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L902         except Exception:
L903             penalty_z = 0.8
L904
L905         def _is_bio_like(t: str) -> bool:
L906             inf = info.get(t, {}) if isinstance(info, dict) else {}
L907             sec = str(inf.get("sector", "")).lower()
L908             ind = str(inf.get("industry", "")).lower()
L909             if "health" not in sec:
L910                 return False
L911             keys = ("biotech", "biopharma", "pharma")
L912             return any(k in ind for k in keys)
L913
L914         tickers_s = pd.Index(df_z.index)
L915         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L916         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L917         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L918
L919         if bool(mask_bio_loss.any()) and penalty_z > 0:
L920             df_z.loc[mask_bio_loss, "GROWTH_F"] = df_z.loc[mask_bio_loss, "GROWTH_F"] - penalty_z
L921             df_z["GROWTH_F"] = df_z["GROWTH_F"].clip(-3.0, 3.0)
L922         # === end: BIO LOSS PENALTY =======================================
L923
L924         assert not any(c.endswith("_RAW") for c in df_z.columns)
L925         for c in ["DIV_TTM_PS","DIV_YOY","LOW52PCT25_EXCESS","MA50_OVER_200"]:
L926             assert c not in df_z.columns
L927
L928         df_z['TRD'] = 0.0  # TRDはスコア寄与から外し、テンプレ判定はフィルタで行う（列は表示互換のため残す）
L929         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L930
L931         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L932         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L933         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L934         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L935
L936         # --- 重みは cfg を優先（外部があればそれを使用） ---
L937         # ① 全銘柄で G/D スコアを算出（unmasked）
L938         g_score_all = _as_numeric_series(df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1))
L939
L940         d_comp = pd.concat({
L941             'QAL': df_z['D_QAL'],
L942             'YLD': df_z['D_YLD'],
L943             'VOL': df_z['D_VOL_RAW'],
L944             'TRD': df_z['D_TRD']
L945         }, axis=1)
L946         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L947         globals()['D_WEIGHTS_EFF'] = dw.copy()
L948         d_score_all = _as_numeric_series(d_comp.mul(dw, axis=1).sum(axis=1))
L949
L950         # ② テンプレ判定（既存ロジックそのまま）
L951         mask = df['trend_template']
L952         if not bool(mask.any()):
L953             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L954                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L955                 (df.get('RS', np.nan) >= 0.08) &
L956                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L957                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L958                 (df.get('MA150_OVER_200', np.nan) > 0) &
L959                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L960                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L961             df['trend_template'] = mask
L962
L963         # ③ 採用用は mask、表示/分析用は列で全銘柄保存
L964         g_score = _as_numeric_series(g_score_all.loc[mask])
L965         Scorer.g_score = g_score
L966         df_z['GSC'] = g_score_all
L967         df_z['DSC'] = d_score_all
L968
L969         try:
L970             current = (pd.read_csv("current_tickers.csv")
L971                   .iloc[:, 0]
L972                   .str.upper()
L973                   .tolist())
L974         except FileNotFoundError:
L975             warnings.warn("current_tickers.csv not found — bonus skipped")
L976             current = []
L977
L978         mask_bonus = g_score.index.isin(current)
L979         if mask_bonus.any():
L980             # 1) factor.BONUS_COEFF から k を決め、無ければ 0.4
L981             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L982             # 2) g 側の σ を取り、NaN なら 0 に丸める
L983             sigma_g = g_score.std()
L984             if pd.isna(sigma_g):
L985                 sigma_g = 0.0
L986             bonus_g = round(k * sigma_g, 3)
L987             g_score.loc[mask_bonus] += bonus_g
L988             Scorer.g_score = g_score
L989             # 3) D 側も同様に σ の NaN をケア
L990             sigma_d = d_score_all.std()
L991             if pd.isna(sigma_d):
L992                 sigma_d = 0.0
L993             bonus_d = round(k * sigma_d, 3)
L994             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L995
L996         try:
L997             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L998         except Exception:
L999             pass
L1000
L1001         df_full = df.copy()
L1002         df_full_z = df_z.copy()
L1003
L1004         from factor import FeatureBundle  # type: ignore  # 実行時importなし（循環回避）
L1005         return FeatureBundle(df=df,
L1006             df_z=df_z,
L1007             g_score=g_score,
L1008             d_score_all=d_score_all,
L1009             missing_logs=pd.DataFrame(missing_logs),
L1010             df_full=df_full,
L1011             df_full_z=df_full_z,
L1012             scaler=None)
L1013
L1014 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L1015     """
L1016     G枠ユニバースに対し、ブレイクアウト確定/押し目反発の「直近N営業日内の発火」を判定し、
L1017     次の列を feature_df に追加する（index=ticker）。
L1018       - G_BREAKOUT_recent_5d : bool
L1019       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L1020       - G_PULLBACK_recent_5d : bool
L1021       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L1022       - G_PIVOT_price        : float
L1023     失敗しても例外は握り潰し、既存処理を阻害しない。
L1024     """
L1025     try:
L1026         px   = bundle.px                      # 終値 DataFrame
L1027         hi   = bundle.data['High']
L1028         lo   = bundle.data['Low']
L1029         vol  = bundle.data['Volume']
L1030         bench= bundle.spx                     # ベンチマーク Series
L1031
L1032         # Gユニバース推定：self.g_universe 優先 → feature_df['group']=='G' → 全銘柄
L1033         g_universe = getattr(self_obj, "g_universe", None)
L1034         if g_universe is None:
L1035             try:
L1036                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L1037             except Exception:
L1038                 g_universe = list(feature_df.index)
L1039         if not g_universe:
L1040             return feature_df
L1041
L1042         # 指標
L1043         px = px.ffill(limit=2)
L1044         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L1045         ma50  = px[g_universe].rolling(50).mean()
L1046         ma150 = px[g_universe].rolling(150).mean()
L1047         ma200 = px[g_universe].rolling(200).mean()
L1048         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L1049         vol20 = vol[g_universe].rolling(20).mean()
L1050         vol50 = vol[g_universe].rolling(50).mean()
L1051
L1052         # トレンドテンプレート合格
L1053         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L1054                             & (ma150 > ma200) & (ma200.diff() > 0)
L1055
L1056         # 汎用ピボット：直近65営業日の高値（当日除外）
L1057         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L1058
L1059         # 相対力：年内高値更新
L1060         bench_aligned = bench.reindex(px.index).ffill()
L1061         rs = px[g_universe].div(bench_aligned, axis=0)
L1062         rs_high = rs.rolling(252).max().shift(1)
L1063
L1064         # ブレイクアウト「発生日」：条件立ち上がり
L1065         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L1066                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L1067         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L1068
L1069         # 押し目反発「発生日」：EMA21帯×出来高ドライアップ×前日高値越え×終値EMA21上
L1070         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L1071         volume_dryup = (vol20 / vol50) <= 1.0
L1072         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L1073         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L1074         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L1075
L1076         # 直近N営業日内の発火 / 最終発生日
L1077         rows = []
L1078         for t in g_universe:
L1079             def _recent_and_date(s, win):
L1080                 sw = s[t].iloc[-win:]
L1081                 if sw.any():
L1082                     d = sw[sw].index[-1]
L1083                     return True, d.strftime("%Y-%m-%d")
L1084                 return False, ""
L1085             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L1086             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L1087             rows.append((t, {
L1088                 "G_BREAKOUT_recent_5d": br_recent,
L1089                 "G_BREAKOUT_last_date": br_date,
L1090                 "G_PULLBACK_recent_5d": pb_recent,
L1091                 "G_PULLBACK_last_date": pb_date,
L1092                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L1093             }))
L1094         flags = pd.DataFrame({k: v for k, v in rows}).T
L1095
L1096         # 列を作成・上書き
L1097         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L1098         for c in cols:
L1099             if c not in feature_df.columns:
L1100                 feature_df[c] = np.nan
L1101         feature_df.loc[flags.index, flags.columns] = flags
L1102
L1103     except Exception:
L1104         pass
L1105     return feature_df
L1106
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 → JST 09:00（土）
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20       
```