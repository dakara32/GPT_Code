```text
Exception:
L558                 pass
L559             df.loc[t,'ADV60_USD'] = adv60
L560
L561             # --- Rule of 40 や周辺 ---
L562             total_rev_ttm = d.get('totalRevenue',np.nan)
L563             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L564             df.loc[t,'FCF_MGN'] = FCF_MGN
L565             rule40 = np.nan
L566             try:
L567                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L568             except Exception: pass
L569             df.loc[t,'RULE40'] = rule40
L570
L571             # --- トレンド補助 ---
L572             sma50  = s.rolling(50).mean()
L573             sma150 = s.rolling(150).mean()
L574             sma200 = s.rolling(200).mean()
L575             p = _safe_last(s)
L576
L577             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L578                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L579             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L580                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L581
L582             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L583             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L584
L585             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L586             if len(sma200.dropna()) >= 21:
L587                 cur200 = _safe_last(sma200)
L588                 old2001 = float(sma200.iloc[-21])
L589                 if old2001:
L590                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L591
L592             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L593             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L594             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L595             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L596             if len(sma200.dropna())>=105:
L597                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L598                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L599             # NEW: 200日線が連続で上向きの「日数」
L600             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L601             try:
L602                 s200 = sma200.dropna()
L603                 if len(s200) >= 2:
L604                     diff200 = s200.diff()
L605                     up = 0
L606                     for v in diff200.iloc[::-1]:
L607                         if pd.isna(v) or v <= 0:
L608                             break
L609                         up += 1
L610                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L611             except Exception:
L612                 pass
L613             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L614             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L615             if hi52 and hi52>0 and pd.notna(p):
L616                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L617             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L618             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L619
L620             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L621
L622             # --- 欠損メモ ---
L623             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L624             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L625             if need_finnhub:
L626                 fin_data = self.fetch_finnhub_metrics(t)
L627                 for col in need_finnhub:
L628                     val = fin_data.get(col)
L629                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L630             # 欠損ログは factor 側で補完後に集約する（ここでは検知のみ）
L631
L632         def _pick_series(entry: dict, keys: list[str]):
L633             for k in keys:
L634                 val = entry.get(k) if isinstance(entry, dict) else None
L635                 if val is None:
L636                     continue
L637                 try:
L638                     if hasattr(val, "empty") and getattr(val, "empty"):
L639                         continue
L640                 except Exception:
L641                     pass
L642                 if isinstance(val, (list, tuple)) and len(val) == 0:
L643                     continue
L644                 return val
L645             return None
L646
L647         def _has_sec_series(val) -> bool:
L648             try:
L649                 if isinstance(val, pd.Series):
L650                     return not val.dropna().empty
L651                 if isinstance(val, (list, tuple)):
L652                     return any(pd.notna(v) for v in val)
L653                 return bool(val)
L654             except Exception:
L655                 return False
L656
L657         def _series_len(val) -> int:
L658             try:
L659                 if isinstance(val, pd.Series):
L660                     return int(val.dropna().size)
L661                 if isinstance(val, (list, tuple)):
L662                     return len(val)
L663                 return int(bool(val))
L664             except Exception:
L665                 return 0
L666
L667         for t in tickers:
L668             try:
L669                 d = info.get(t, {}) or {}
L670                 rev_series = d.get("SEC_REV_Q_SERIES")
L671                 eps_series = d.get("SEC_EPS_Q_SERIES")
L672                 fallback_qearn = False
L673                 try:
L674                     qe = tickers_bulk.tickers[t].quarterly_earnings
L675                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L676                 except Exception:
L677                     qe = None
L678
L679                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L680                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L681                 r_raw = _ensure_series(r_src)
L682                 e_raw = _ensure_series(e_src)
L683
L684                 r_q = _to_quarterly(r_raw)
L685                 e_q = _to_quarterly(e_raw)
L686
L687                 df.at[t, "EPS_SERIES"] = e_q
L688
L689                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L690                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L691
L692                 def _q_yoy(qs):
L693                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L694
L695                 rev_q_yoy = _q_yoy(r_q)
L696                 eps_q_yoy = _q_yoy(e_q)
L697
L698                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L699                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L700                         ann = qs.groupby(qs.index.year).last().pct_change()
L701                         ann_dn = ann.dropna()
L702                         if not ann_dn.empty:
L703                             y = float(ann_dn.iloc[-1])
L704                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L705                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L706                             return y, acc, var
L707                     yoy_dn = yoy_ttm.dropna()
L708                     if yoy_dn.empty:
L709                         return np.nan, np.nan, np.nan
L710                     return (
L711                         float(yoy_dn.iloc[-1]),
L712                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L713                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L714                     )
L715
L716                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L717                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L718
L719                 def _pos_streak(s: pd.Series):
L720                     s = s.dropna()
L721                     if s.empty:
L722                         return np.nan
L723                     b = (s > 0).astype(int).to_numpy()[::-1]
L724                     k = 0
L725                     for v in b:
L726                         if v == 1:
L727                             k += 1
L728                         else:
L729                             break
L730                     return float(k)
L731
L732                 rev_ann_streak = _pos_streak(r_yoy_ttm)
L733
L734                 df.loc[t, "REV_Q_YOY"] = rev_q_yoy
L735                 df.loc[t, "EPS_Q_YOY"] = eps_q_yoy
L736                 df.loc[t, "REV_YOY"] = rev_yoy
L737                 df.loc[t, "EPS_YOY"] = eps_yoy
L738                 df.loc[t, "REV_YOY_ACC"] = rev_acc
L739                 df.loc[t, "REV_YOY_VAR"] = rev_var
L740                 df.loc[t, "REV_ANN_STREAK"] = rev_ann_streak
L741
L742             except Exception as e:
L743                 logger.warning("growth-derivatives failed: %s: %s", t, e)
L744
L745         def _pct_change(new, old):
L746             try:
L747                 if np.isfinite(new) and np.isfinite(old) and float(old) != 0:
L748                     return float((new - old) / abs(old))
L749             except Exception:
L750                 pass
L751             return np.nan
L752
L753         def _pct_series(a: pd.Series, b: pd.Series) -> list[float]:
L754             a_vals = pd.to_numeric(a, errors="coerce") if a is not None else pd.Series(np.nan, index=df.index)
L755             b_vals = pd.to_numeric(b, errors="coerce") if b is not None else pd.Series(np.nan, index=df.index)
L756             return [_pct_change(x, y) for x, y in zip(a_vals.reindex(df.index), b_vals.reindex(df.index))]
L757
L758         def _mean_valid(vals: list[float]) -> float:
L759             arr = [float(v) for v in vals if np.isfinite(v)]
L760             return float(np.mean(arr)) if arr else np.nan
L761
L762         grw_q_eps_last = _pct_series(df['EPS_Q'], df.get('EPS_Q_PREV', pd.Series(np.nan, index=df.index)))
L763         grw_q_rev_last = _pct_series(df['REV_Q'], df.get('REV_Q_PREV', pd.Series(np.nan, index=df.index)))
L764         grw_q_eps_ttm = _pct_series(df['EPS'], df.get('EPS_TTM_PREV', pd.Series(np.nan, index=df.index)))
L765         grw_q_rev_ttm = _pct_series(df['REV_TTM'], df.get('REV_TTM_PREV', pd.Series(np.nan, index=df.index)))
L766
L767         grw_a_eps_yoy = _pct_series(df.get('EPS_A_LATEST', pd.Series(np.nan, index=df.index)), df.get('EPS_A_PREV', pd.Series(np.nan, index=df.index)))
L768         grw_a_rev_yoy = _pct_series(df.get('REV_A_LATEST', pd.Series(np.nan, index=df.index)), df.get('REV_A_PREV', pd.Series(np.nan, index=df.index)))
L769         grw_a_eps_cagr = pd.to_numeric(df.get('EPS_A_CAGR3', pd.Series(np.nan, index=df.index)), errors="coerce").reindex(df.index).tolist()
L770         grw_a_rev_cagr = pd.to_numeric(df.get('REV_A_CAGR3', pd.Series(np.nan, index=df.index)), errors="coerce").reindex(df.index).tolist()
L771
L772         grw_q_combined = [
L773             _mean_valid([a, b, c, d])
L774             for a, b, c, d in zip(grw_q_eps_last, grw_q_rev_last, grw_q_eps_ttm, grw_q_rev_ttm)
L775         ]
L776         grw_a_combined = [
L777             _mean_valid([a, b, c, d])
L778             for a, b, c, d in zip(grw_a_eps_yoy, grw_a_rev_yoy, grw_a_eps_cagr, grw_a_rev_cagr)
L779         ]
L780
L781         df['GRW_Q_RAW'] = pd.Series(grw_q_combined, index=df.index, dtype=float)
L782         df['GRW_A_RAW'] = pd.Series(grw_a_combined, index=df.index, dtype=float)
L783
L784         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L785             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np
```