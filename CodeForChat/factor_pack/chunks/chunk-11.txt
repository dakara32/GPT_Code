```text
sma200)) and _safe_last(sma200)!=0 else np.nan
L598             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L599             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L600             if len(sma200.dropna())>=105:
L601                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L602                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L603             # NEW: 200日線が連続で上向きの「日数」
L604             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L605             try:
L606                 s200 = sma200.dropna()
L607                 if len(s200) >= 2:
L608                     diff200 = s200.diff()
L609                     up = 0
L610                     for v in diff200.iloc[::-1]:
L611                         if pd.isna(v) or v <= 0:
L612                             break
L613                         up += 1
L614                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L615             except Exception:
L616                 pass
L617             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L618             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L619             if hi52 and hi52>0 and pd.notna(p):
L620                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L621             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L622             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L623
L624             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L625
L626             # --- 欠損メモ ---
L627             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L628             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L629             if need_finnhub:
L630                 fin_data = self.fetch_finnhub_metrics(t)
L631                 for col in need_finnhub:
L632                     val = fin_data.get(col)
L633                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L634             # 欠損ログは factor 側で補完後に集約する（ここでは検知のみ）
L635
L636         def _pick_series(entry: dict, keys: list[str]):
L637             for k in keys:
L638                 val = entry.get(k) if isinstance(entry, dict) else None
L639                 if val is None:
L640                     continue
L641                 try:
L642                     if hasattr(val, "empty") and getattr(val, "empty"):
L643                         continue
L644                 except Exception:
L645                     pass
L646                 if isinstance(val, (list, tuple)) and len(val) == 0:
L647                     continue
L648                 return val
L649             return None
L650
L651         def _has_sec_series(val) -> bool:
L652             try:
L653                 if isinstance(val, pd.Series):
L654                     return not val.dropna().empty
L655                 if isinstance(val, (list, tuple)):
L656                     return any(pd.notna(v) for v in val)
L657                 return bool(val)
L658             except Exception:
L659                 return False
L660
L661         def _series_len(val) -> int:
L662             try:
L663                 if isinstance(val, pd.Series):
L664                     return int(val.dropna().size)
L665                 if isinstance(val, (list, tuple)):
L666                     return len(val)
L667                 return int(bool(val))
L668             except Exception:
L669                 return 0
L670
L671         for t in tickers:
L672             try:
L673                 d = info.get(t, {}) or {}
L674                 rev_series = d.get("SEC_REV_Q_SERIES")
L675                 eps_series = d.get("SEC_EPS_Q_SERIES")
L676                 fallback_qearn = False
L677                 try:
L678                     qe = tickers_bulk.tickers[t].quarterly_earnings
L679                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L680                 except Exception:
L681                     qe = None
L682
L683                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L684                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L685                 r_raw = _ensure_series(r_src)
L686                 e_raw = _ensure_series(e_src)
L687
L688                 r_q = _to_quarterly(r_raw)
L689                 e_q = _to_quarterly(e_raw)
L690
L691                 df.at[t, "EPS_SERIES"] = e_q
L692
L693                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L694                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L695
L696                 def _q_yoy(qs):
L697                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L698
L699                 rev_q_yoy = _q_yoy(r_q)
L700                 eps_q_yoy = _q_yoy(e_q)
L701
L702                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L703                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L704                         ann = qs.groupby(qs.index.year).last().pct_change()
L705                         ann_dn = ann.dropna()
L706                         if not ann_dn.empty:
L707                             y = float(ann_dn.iloc[-1])
L708                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L709                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L710                             return y, acc, var
L711                     yoy_dn = yoy_ttm.dropna()
L712                     if yoy_dn.empty:
L713                         return np.nan, np.nan, np.nan
L714                     return (
L715                         float(yoy_dn.iloc[-1]),
L716                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L717                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L718                     )
L719
L720                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L721                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L722
L723                 def _pos_streak(s: pd.Series):
L724                     s = s.dropna()
L725                     if s.empty:
L726                         return np.nan
L727                     b = (s > 0).astype(int).to_numpy()[::-1]
L728                     k = 0
L729                     for v in b:
L730                         if v == 1:
L731                             k += 1
L732                         else:
L733                             break
L734                     return float(k)
L735
L736                 rev_ann_streak = _pos_streak(r_yoy_ttm)
L737
L738                 df.loc[t, "REV_Q_YOY"] = rev_q_yoy
L739                 df.loc[t, "EPS_Q_YOY"] = eps_q_yoy
L740                 df.loc[t, "REV_YOY"] = rev_yoy
L741                 df.loc[t, "EPS_YOY"] = eps_yoy
L742                 df.loc[t, "REV_YOY_ACC"] = rev_acc
L743                 df.loc[t, "REV_YOY_VAR"] = rev_var
L744                 df.loc[t, "REV_ANN_STREAK"] = rev_ann_streak
L745
L746             except Exception as e:
L747                 logger.warning("growth-derivatives failed: %s: %s", t, e)
L748
L749         def _pct_change(new, old):
L750             try:
L751                 if np.isfinite(new) and np.isfinite(old) and float(old) != 0:
L752                     return float((new - old) / abs(old))
L753             except Exception:
L754                 pass
L755             return np.nan
L756
L757         def _pct_series(a: pd.Series, b: pd.Series) -> list[float]:
L758             a_vals = pd.to_numeric(a, errors="coerce") if a is not None else pd.Series(np.nan, index=df.index)
L759             b_vals = pd.to_numeric(b, errors="coerce") if b is not None else pd.Series(np.nan, index=df.index)
L760             return [_pct_change(x, y) for x, y in zip(a_vals.reindex(df.index), b_vals.reindex(df.index))]
L761
L762         def _mean_valid(vals: list[float]) -> float:
L763             arr = [float(v) for v in vals if np.isfinite(v)]
L764             return float(np.mean(arr)) if arr else np.nan
L765
L766         grw_q_eps_last = _pct_series(df['EPS_Q'], df.get('EPS_Q_PREV', pd.Series(np.nan, index=df.index)))
L767         grw_q_rev_last = _pct_series(df['REV_Q'], df.get('REV_Q_PREV', pd.Series(np.nan, index=df.index)))
L768         grw_q_eps_ttm = _pct_series(df['EPS'], df.get('EPS_TTM_PREV', pd.Series(np.nan, index=df.index)))
L769         grw_q_rev_ttm = _pct_series(df['REV_TTM'], df.get('REV_TTM_PREV', pd.Series(np.nan, index=df.index)))
L770
L771         grw_a_eps_yoy = _pct_series(df.get('EPS_A_LATEST', pd.Series(np.nan, index=df.index)), df.get('EPS_A_PREV', pd.Series(np.nan, index=df.index)))
L772         grw_a_rev_yoy = _pct_series(df.get('REV_A_LATEST', pd.Series(np.nan, index=df.index)), df.get('REV_A_PREV', pd.Series(np.nan, index=df.index)))
L773         grw_a_eps_cagr = pd.to_numeric(df.get('EPS_A_CAGR3', pd.Series(np.nan, index=df.index)), errors="coerce").reindex(df.index).tolist()
L774         grw_a_rev_cagr = pd.to_numeric(df.get('REV_A_CAGR3', pd.Series(np.nan, index=df.index)), errors="coerce").reindex(df.index).tolist()
L775
L776         grw_q_combined = [
L777             _mean_valid([a, b, c, d])
L778             for a, b, c, d in zip(grw_q_eps_last, grw_q_rev_last, grw_q_eps_ttm, grw_q_rev_ttm)
L779         ]
L780         grw_a_combined = [
L781             _mean_valid([a, b, c, d])
L782             for a, b, c, d in zip(grw_a_eps_yoy, grw_a_rev_yoy, grw_a_eps_cagr, grw_a_rev_cagr)
L783         ]
L784
L785         df['GRW_Q_RAW'] = pd.Series(grw_q_combined, index=df.index, dtype=float)
L786         df['GRW_A_RAW'] = pd.Series(grw_a_combined, index=df.index, dtype=float)
L787
L788         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L789             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L790             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L791             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L792             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L793             c5 = (row.get('TR_str', np.nan) > 0)
L794             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L795             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L796             c8 = (row.get('RS', np.nan) >= 0.10)
L797             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L798
L799         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L800         assert 'trend_template' in df.columns
L801
L802         def _calc_eps_abs_slope(eps_series, n=12):
L803             try:
L804                 if isinstance(eps_series, pd.Series):
L805                     series = pd.to_numeric(eps_series, errors="coerce").dropna()
L806                 elif isinstance(eps_series, (list, tuple, np.ndarray)):
L807                     series = pd.Series(eps_series, dtype=float).dropna()
L808                 else:
L809                     return 0.0
L810             except Exception:
L811                 return 0.0
L812
L813             if series.empty:
L814                 return 0.0
L815
L816             tail = series.tail(n).to_numpy(dtype=float)
L817             if tail.size < 2:
L818                 return 0.0
L819
L820             x = np.arange(tail.size, dtype=float)
L821             x = x - x.mean()
L822             y = tail - tail.mean()
L823             denom = np.dot(x, x)
L824             if denom == 0:
L825                 return 0.0
L826             slope = float(np.dot(x, y) / denom)
L827             return slope
L828
L829         df['EPS_ABS_SLOPE'] = df['EPS_SERIES'].apply(_calc_eps_abs_slope).astype(float)
L830         df.drop(columns=['EPS_SERIES'], inplace=True)
L
```