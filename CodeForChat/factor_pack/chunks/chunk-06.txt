```text
.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1117     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1118     sc._top_G = top_G
L1119     try:
L1120         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1121         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1122     except Exception:
L1123         pass
L1124     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1125     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1126     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1127     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1128     fb = getattr(sc, "_feat", None)
L1129     near_G = getattr(sc, "_near_G", [])
L1130     selected12 = list(top_G)
L1131     df = fb.df if fb is not None else pd.DataFrame()
L1132     guni = _infer_g_universe(df, selected12, near_G)
L1133     try:
L1134         fire_recent = [t for t in guni
L1135                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1136                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1137     except Exception: fire_recent = []
L1138
L1139     lines = [
L1140         "【G枠レポート｜週次モニタ（直近5営業日）】",
L1141         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L1142         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L1143         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L1144
L1145     if fire_recent:
L1146         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1147         lines.append(f"過去5営業日の検知: {fire_list}")
L1148     else:
L1149         lines.append("過去5営業日の検知: なし")
L1150
L1151     try:
L1152         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1153         if webhook:
L1154             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1155     except Exception:
L1156         pass
L1157
L1158     out = Output()
L1159     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1160     try: out._sc = sc
L1161     except Exception: pass
L1162     if hasattr(sc, "_feat"):
L1163         try:
L1164             fb = sc._feat
L1165             out.miss_df = fb.missing_logs
L1166             out.display_results(
L1167                 exist=exist,
L1168                 bench=bench,
L1169                 df_z=fb.df_z,
L1170                 g_score=fb.g_score,
L1171                 d_score_all=fb.d_score_all,
L1172                 init_G=top_G,
L1173                 init_D=top_D,
L1174                 top_G=top_G,
L1175                 top_D=top_D,
L1176                 df_full_z=getattr(fb, "df_full_z", None),
L1177                 prev_G=getattr(sc, "_prev_G", exist),
L1178                 prev_D=getattr(sc, "_prev_D", exist),
L1179             )
L1180         except Exception:
L1181             pass
L1182     out.notify_slack()
L1183     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1184               "sum_score": sumG, "objective": objG},
L1185         resD={"tickers": top_D, "avg_res_corr": avgD,
L1186               "sum_score": sumD, "objective": objD},
L1187         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1188
L1189     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1190     try:
L1191         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1192               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1193               .sort_values("G_plus_D")
L1194               .head(10)
L1195               .round(3))
L1196         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1197         _post_slack({"text": f"```{low_msg}```"})
L1198     except Exception as _e:
L1199         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1200
L1201     return sb
L1202
L1203 if __name__ == "__main__":
L1204     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1.4826 * mad + 1e-9)
L82     if np.nanstd(z) < 1e-9:
L83         r = v.rank(method="average", na_option="keep")
L84         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L85     return pd.Series(z, index=v.index, dtype=float)
L86
L87
L88 def _dump_dfz(df_z: pd.DataFrame, debug_mode: bool, max_rows: int = 400, ndigits: int = 3) -> None:
L89     """df_z を System log(INFO) へダンプする簡潔なユーティリティ."""
L90     if not debug_mode:
L91         return
L92     try:
L93         view = df_z.copy()
L94         view = view.apply(
L95             lambda s: s.round(ndigits)
L96             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L97             else s
L98         )
L99         if len(view) > max_rows:
L100             view = view.iloc[:max_rows]
L101
L102         # === NaNサマリ（列ごとの欠損件数 上位20） ===
L103         try:
L104             nan_counts = df_z.isna().sum().sort_values(ascending=False)
L105             top_nan = nan_counts[nan_counts > 0].head(20)
L106             if len(top_nan) > 0:
L107                 logger.info("NaN columns (top20):\n%s", top_nan.to_string())
L108             else:
L109                 logger.info("NaN columns: none")
L110         except Exception as exc:
L111             logger.warning("nan summary failed: %s", exc)
L112
L113         # === Zeroサマリ（列ごとのゼロ比率 上位20） ===
L114         try:
L115             zero_counts = ((df_z == 0) & (~df_z.isna())).sum()
L116             nonnull_counts = (~df_z.isna()).sum()
L117             zero_ratio = (zero_counts / nonnull_counts).sort_values(ascending=False)
L118             top_zero = zero_ratio[zero_ratio > 0].head(20)
L119             if len(top_zero) > 0:
L120                 logger.info(
L121                     "Zero-dominated columns (top20):\n%s",
L122                     top_zero.to_string(float_format=lambda x: f"{x:.2%}"),
L123                 )
L124             else:
L125                 logger.info("Zero-dominated columns: none")
L126         except Exception as exc:
L127             logger.warning("zero summary failed: %s", exc)
L128
L129         logger.info("===== DF_Z DUMP START =====")
L130         logger.info("\n%s", view.to_string(max_rows=None, max_cols=None))
L131         logger.info("===== DF_Z DUMP END =====")
L132     except Exception as exc:
L133         logger.warning("df_z dump failed: %s", exc)
L134
L135 def _safe_div(a, b):
L136     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L137     except Exception: return np.nan
L138
L139 def _safe_last(series: pd.Series, default=np.nan):
L140     try: return float(series.iloc[-1])
L141     except Exception: return default
L142
L143 D_WEIGHTS_EFF = None  # 出力表示互換のため
L144
L145
L146 def _scalar(v):
L147     """単一セル代入用に値をスカラーへ正規化する。
L148
L149     - pandas Series -> .iloc[-1]（最後を採用）
L150     - list/tuple/ndarray -> 最後の要素
L151     - それ以外          -> そのまま
L152     取得失敗時は np.nan を返す。
L153     """
L154     import numpy as _np
L155     import pandas as _pd
L156     try:
L157         if isinstance(v, _pd.Series):
L158             return v.iloc[-1] if len(v) else _np.nan
L159         if isinstance(v, (list, tuple, _np.ndarray)):
L160             return v[-1] if len(v) else _np.nan
L161         return v
L162     except Exception:
L163         return _np.nan
L164
L165
L166 # ---- Scorer 本体 -------------------------------------------------------------
L167 class Scorer:
L168     """
L169     - factor.py からは `aggregate_scores(ib, cfg)` を呼ぶだけでOK。
L170     - cfg は必須（factor.PipelineConfig を渡す）。
L171     - 旧カラム名を自動リネームして新スキーマに吸収します。
L172     """
L173
L174     # === 先頭で旧→新カラム名マップ（移行用） ===
L175     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L176     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L177
L178     # === スキーマ簡易チェック（最低限） ===
L179     @staticmethod
L180     def _validate_ib_for_scorer(ib: Any):
L181         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L182         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L183         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L184         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L1
```