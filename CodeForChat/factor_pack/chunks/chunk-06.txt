```text
068                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1069                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1070     except Exception: fire_recent = []
L1071
L1072     lines = [
L1073         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1074         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1075         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1076         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1077
L1078     if fire_recent:
L1079         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1080         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1081     else:
L1082         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1083
L1084     try:
L1085         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1086         if webhook:
L1087             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1088     except Exception:
L1089         pass
L1090
L1091     out = Output()
L1092     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1093     try: out._sc = sc
L1094     except Exception: pass
L1095     if hasattr(sc, "_feat"):
L1096         try:
L1097             fb = sc._feat
L1098             out.miss_df = fb.missing_logs
L1099             out.display_results(
L1100                 exist=exist,
L1101                 bench=bench,
L1102                 df_z=fb.df_z,
L1103                 g_score=fb.g_score,
L1104                 d_score_all=fb.d_score_all,
L1105                 init_G=top_G,
L1106                 init_D=top_D,
L1107                 top_G=top_G,
L1108                 top_D=top_D,
L1109                 df_full_z=getattr(fb, "df_full_z", None),
L1110                 prev_G=getattr(sc, "_prev_G", exist),
L1111                 prev_D=getattr(sc, "_prev_D", exist),
L1112             )
L1113         except Exception:
L1114             pass
L1115     out.notify_slack()
L1116     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1117               "sum_score": sumG, "objective": objG},
L1118         resD={"tickers": top_D, "avg_res_corr": avgD,
L1119               "sum_score": sumD, "objective": objD},
L1120         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1121
L1122     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1123     try:
L1124         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1125               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1126               .sort_values("G_plus_D")
L1127               .head(10)
L1128               .round(3))
L1129         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1130         _post_slack({"text": f"```{low_msg}```"})
L1131     except Exception as _e:
L1132         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1133
L1134     return sb
L1135
L1136 if __name__ == "__main__":
L1137     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None: return float(c)
L43     try:
L44         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L45         return float(h.iloc[-1]) if len(h) else np.nan
L46     except Exception:
L47         return np.nan
L48
L49 def _ttm_div_sum(t, lookback_days=400):
L50     try:
L51         div = yf.Ticker(t).dividends
L52         if div is None or len(div) == 0: return 0.0
L53         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L54         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L55         return ttm if ttm > 0 else float(div.tail(4).sum())
L56     except Exception:
L57         return 0.0
L58
L59 def ttm_div_yield_portfolio(tickers, price_map=None):
L60     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L61     return float(np.mean(ys)) if ys else 0.0
L62
L63 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L64 def winsorize_s(s: pd.Series, p=0.02):
L65     if s is None or s.dropna().empty: return s
L66     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L67
L68 def robust_z(s: pd.Series, p=0.02):
L69     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L70
L71 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L72     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L73     if s is None:
L74         return pd.Series(dtype=float)
L75     v = pd.to_numeric(s, errors="coerce")
L76     m = np.nanmedian(v)
L77     mad = np.nanmedian(np.abs(v - m))
L78     z = (v - m) / (1.4826 * mad + 1e-9)
L79     if np.nanstd(z) < 1e-9:
L80         r = v.rank(method="average", na_option="keep")
L81         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L82     return pd.Series(z, index=v.index, dtype=float)
L83
L84 def _safe_div(a, b):
L85     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L86     except Exception: return np.nan
L87
L88 def _safe_last(series: pd.Series, default=np.nan):
L89     try: return float(series.iloc[-1])
L90     except Exception: return default
L91
L92 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L93
L94 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L95 class Scorer:
L96     """
L97     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L98     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L99     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L100     """
L101
L102     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L103     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L104     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L105
L106     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L107     @staticmethod
L108     def _validate_ib_for_scorer(ib: Any):
L109         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L110         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L111         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L112         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L113         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L114         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L115         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L116
L117     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L118     @staticmethod
L119     def trend(s: pd.Series):
L120         if len(s)<200: return np.nan
L121         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L122         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L123         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L124         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L125         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L126         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L127         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L128         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L129         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L130         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L131         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L132         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L133
L134     @staticmethod
L135     def rs(s, b):
L136         n, nb = len(s), len(b)
L137         if n<60 or nb<60: return np.nan
L138         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L139         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L140         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L141
L142     @staticmethod
L143     def tr_str(s):
L144         if s is None:
L145             return np.nan
L146         s = s.ffill(limit=2).dropna()
L147         if len(s) < 50:
L148             return np.nan
L149         ma50 = s.rolling(50, min_periods=50).mean()
L150         last_ma = ma50.iloc[-1]
L151         last_px = s.iloc[-1]
L152         return float(last_px/last_ma - 1.0) if pd.notna(last_ma) and pd.notna(last_px) else np.nan
L153
L154     @staticmethod
L155     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L156         r = (s/b).dropna()
L157         if len(r) < win: return np.nan
L158         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L159         try: return float(np.polyfit(x, y, 1)[0])
L160         except Exception: return np.nan
L161
L162     @staticmethod
L163     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L164         ev = info_t.get('enterpriseValue', np.nan)
L165         if pd.notna(ev) and ev>0: return float(ev)
L166         mc, debt, cash = info_t.get('marketCap', np.nan), np.nan, np.nan
L167         try:
L168             bs = tk.quarterly_balance_sheet
L169             if bs is not None and not bs.empty:
L170                 c = bs.columns[0]
L171                 for k in ("Total Debt","Long Term Debt","Short Long Term Debt"):
L172                     if k in bs.index: debt = float(bs.loc[k,c]); break
L173                 for k in ("Cash And Cash Equivalents","Cash And Cash Equivalents And Short Term Investments","Cash"):
L174                     if k in bs.index: cash = float(bs.loc[k,c]); break
L175         except Exception: pass
L176         if pd.notna(mc): return float(mc + (0 if pd.isna(debt) else debt) - (0 if pd.isna(cash) else cash))
L177         return np.nan
L178
L179     @staticmethod
L180     def dividend_status(ticker: str) -> str:
L181         t = yf
```