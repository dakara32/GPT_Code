```text
 T.log("features built (scorer)")
L1102             sc._feat_logged = True
L1103         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1104     else:
L1105         fb = sc.aggregate_scores(inb, cfg)
L1106         if not hasattr(sc, "_feat_logged"):
L1107             T.log("features built (scorer)")
L1108             sc._feat_logged = True
L1109         sc._feat = fb
L1110         agg = fb.g_score if group == "G" else fb.d_score_all
L1111         if group == "D" and hasattr(fb, "df"):
L1112             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L1113
L1114     if hasattr(sc, "filter_candidates"):
L1115         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1116
L1117     selector = Selector()
L1118     if hasattr(sc, "select_diversified"):
L1119         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1120             selector=selector, prev_tickers=None,
L1121             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1122             cross_mu=cfg.drrs.cross_mu_gd)
L1123     else:
L1124         if group == "G":
L1125             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1126             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1127                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1128                 lam=cfg.drrs.G.get("lam", 0.68),
L1129                 lookback=cfg.drrs.G.get("lookback", 252),
L1130                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1131         else:
L1132             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1133             g_fixed = getattr(sc, "_top_G", None)
L1134             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1135                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1136                 lam=cfg.drrs.D.get("lam", 0.85),
L1137                 lookback=cfg.drrs.D.get("lookback", 504),
L1138                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1139                 mu=cfg.drrs.cross_mu_gd)
L1140         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1141         sum_sc = res["sum_score"]; obj = res["objective"]
L1142         if group == "D":
L1143             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1144             T.log("selection finalized (G/D)")
L1145     try:
L1146         inc = [t for t in exist if t in agg.index]
L1147         pick = _sticky_keep_current(
L1148             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1149             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1150         )
L1151     except Exception as _e:
L1152         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1153     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L1154     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L1155     try:
L1156         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1157         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1158         setattr(sc, f"_near_{group}", near10)
L1159         setattr(sc, f"_agg_{group}", agg)
L1160     except Exception:
L1161         pass
L1162
L1163     if group == "D":
L1164         T.log("save done")
L1165     if group == "G":
L1166         sc._top_G = pick
L1167     return pick, avg_r, sum_sc, obj
L1168
L1169 def run_pipeline() -> SelectionBundle:
L1170     """
L1171     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1172     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1173     """
L1174     inb = io_build_input_bundle()
L1175     cfg = PipelineConfig(
L1176         weights=WeightsConfig(g=g_weights, d=D_weights),
L1177         drrs=DRRSParams(
L1178             corrM=corrM, shrink=DRRS_SHRINK,
L1179             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1180         ),
L1181         price_max=CAND_PRICE_MAX,
L1182         debug_mode=debug_mode
L1183     )
L1184     sc = Scorer()
L1185     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1186     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1187     alpha = Scorer.spx_to_alpha(inb.spx)
L1188     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1189     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1190     sc._top_G = top_G
L1191     try:
L1192         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1193         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1194     except Exception:
L1195         pass
L1196     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1197     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1198     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1199     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1200     fb = getattr(sc, "_feat", None)
L1201     near_G = getattr(sc, "_near_G", [])
L1202     selected12 = list(top_G)
L1203     df = fb.df if fb is not None else pd.DataFrame()
L1204     guni = _infer_g_universe(df, selected12, near_G)
L1205     try:
L1206         fire_recent = [t for t in guni
L1207                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1208                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1209     except Exception: fire_recent = []
L1210
L1211     lines = [
L1212         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1213         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1214         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1215         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1216
L1217     if fire_recent:
L1218         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1219         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1220     else:
L1221         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1222
L1223     try:
L1224         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1225         if webhook:
L1226             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1227     except Exception:
L1228         pass
L1229
L1230     out = Output()
L1231     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1232     try: out._sc = sc
L1233     except Exception: pass
L1234     if hasattr(sc, "_feat"):
L1235         try:
L1236             fb = sc._feat
L1237             out.miss_df = fb.missing_logs
L1238             out.display_results(
L1239                 exist=exist,
L1240                 bench=bench,
L1241                 df_z=fb.df_z,
L1242                 g_score=fb.g_score,
L1243                 d_score_all=fb.d_score_all,
L1244                 init_G=top_G,
L1245                 init_D=top_D,
L1246                 top_G=top_G,
L1247                 top_D=top_D,
L1248                 df_full_z=getattr(fb, "df_full_z", None),
L1249                 prev_G=getattr(sc, "_prev_G", exist),
L1250                 prev_D=getattr(sc, "_prev_D", exist),
L1251             )
L1252         except Exception:
L1253             pass
L1254     out.notify_slack()
L1255     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1256               "sum_score": sumG, "objective": objG},
L1257         resD={"tickers": top_D, "avg_res_corr": avgD,
L1258               "sum_score": sumD, "objective": objD},
L1259         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1260
L1261     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1262     try:
L1263         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1264               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1265               .sort_values("G_plus_D")
L1266               .head(10)
L1267               .round(3))
L1268         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1269         _post_slack({"text": f"```{low_msg}```"})
L1270     except Exception as _e:
L1271         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1272
L1273     return sb
L1274
L1275 if __name__ == "__main__":
L1276     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import json
L32 import requests
L33 import numpy as np
L34 import pandas as pd
L35 import yfinance as yf
L36 from typing import Any, TYPE_CHECKING
L37 from scipy.stats import zscore
L38 from datetime import datetime as _dt
L39
L40 if TYPE_CHECKING:
L41     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L42
L43 logger = logging.getLogger(__name__)
L44
L45
L46 def _log(stage, msg):
L47     try:
L48         print(f"[DBG][{_dt.utcnow().isoformat(timespec='seconds')}Z][{stage}] {msg}")
L49     except Exception:
L50         print(f"[DBG][{stage}] {msg}")
L51
L52 # ---- Dividend Helpers -------------------------------------------------------
L53 def _last_close(t, price_map=None):
L54     if price_map and (c := price_map.get(t)) is not None: return float(c)
L55     try:
L56         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L57         return float(h.iloc[-1]) if len(h) else np.nan
L58     except Exception:
L59         return np.nan
L60
L61 def _ttm_div_sum(t, lookback_days=400):
L62     try:
L63         div = yf.Ticker(t).dividends
L64         if div is None or len(div) == 0: return 0.0
L65         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L66         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L67         return ttm if ttm > 0 else float(div.tail(4).sum())
L68     except Exception:
L69         return 0.0
L70
L71 def ttm_div_yield_portfolio(tickers, price_map=None):
L72     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L73     return float(np.mean(ys)) if ys else 0.0
L74
L75 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L76 def winsorize_s(s: pd.Series, p=0.02):
L77     if s is None or s.dropna().empty: return s
L78     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L79
L80 def robust_z(s: pd.Series, p=0.02):
L81     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L82
L83 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L84     """robust_z variant that preserves NaNs and falls back to rank-z when
```