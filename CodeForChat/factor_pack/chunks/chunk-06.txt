```text
drrs.D.get("lam", 0.85),
L1100                 lookback=cfg.drrs.D.get("lookback", 504),
L1101                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1102                 mu=cfg.drrs.cross_mu_gd)
L1103         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1104         sum_sc = res["sum_score"]; obj = res["objective"]
L1105         if group == "D":
L1106             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1107             T.log("selection finalized (G/D)")
L1108     try:
L1109         inc = [t for t in exist if t in agg.index]
L1110         pick = _sticky_keep_current(
L1111             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1112             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1113         )
L1114     except Exception as _e:
L1115         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1116     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L1117     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L1118     try:
L1119         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1120         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1121         setattr(sc, f"_near_{group}", near10)
L1122         setattr(sc, f"_agg_{group}", agg)
L1123     except Exception:
L1124         pass
L1125
L1126     if group == "D":
L1127         T.log("save done")
L1128     if group == "G":
L1129         sc._top_G = pick
L1130     return pick, avg_r, sum_sc, obj
L1131
L1132 def run_pipeline() -> SelectionBundle:
L1133     """
L1134     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1135     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1136     """
L1137     inb = io_build_input_bundle()
L1138     cfg = PipelineConfig(
L1139         weights=WeightsConfig(g=g_weights, d=D_weights),
L1140         drrs=DRRSParams(
L1141             corrM=corrM, shrink=DRRS_SHRINK,
L1142             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1143         ),
L1144         price_max=CAND_PRICE_MAX,
L1145         debug_mode=debug_mode
L1146     )
L1147     sc = Scorer()
L1148     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1149     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1150     alpha = Scorer.spx_to_alpha(inb.spx)
L1151     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1152     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1153     sc._top_G = top_G
L1154     try:
L1155         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1156         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1157     except Exception:
L1158         pass
L1159     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1160     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1161     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1162     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1163     fb = getattr(sc, "_feat", None)
L1164     near_G = getattr(sc, "_near_G", [])
L1165     selected12 = list(top_G)
L1166     df = fb.df if fb is not None else pd.DataFrame()
L1167     guni = _infer_g_universe(df, selected12, near_G)
L1168     try:
L1169         fire_recent = [t for t in guni
L1170                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1171                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1172     except Exception: fire_recent = []
L1173
L1174     lines = [
L1175         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1176         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1177         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1178         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1179
L1180     if fire_recent:
L1181         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1182         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1183     else:
L1184         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1185
L1186     try:
L1187         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1188         if webhook:
L1189             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1190     except Exception:
L1191         pass
L1192
L1193     out = Output()
L1194     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1195     try: out._sc = sc
L1196     except Exception: pass
L1197     if hasattr(sc, "_feat"):
L1198         try:
L1199             fb = sc._feat
L1200             out.miss_df = fb.missing_logs
L1201             out.display_results(
L1202                 exist=exist,
L1203                 bench=bench,
L1204                 df_z=fb.df_z,
L1205                 g_score=fb.g_score,
L1206                 d_score_all=fb.d_score_all,
L1207                 init_G=top_G,
L1208                 init_D=top_D,
L1209                 top_G=top_G,
L1210                 top_D=top_D,
L1211                 df_full_z=getattr(fb, "df_full_z", None),
L1212                 prev_G=getattr(sc, "_prev_G", exist),
L1213                 prev_D=getattr(sc, "_prev_D", exist),
L1214             )
L1215         except Exception:
L1216             pass
L1217     out.notify_slack()
L1218     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1219               "sum_score": sumG, "objective": objG},
L1220         resD={"tickers": top_D, "avg_res_corr": avgD,
L1221               "sum_score": sumD, "objective": objD},
L1222         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1223
L1224     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1225     try:
L1226         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1227               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1228               .sort_values("G_plus_D")
L1229               .head(10)
L1230               .round(3))
L1231         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1232         _post_slack({"text": f"```{low_msg}```"})
L1233     except Exception as _e:
L1234         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1235
L1236     return sb
L1237
L1238 if __name__ == "__main__":
L1239     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import json
L32 import requests
L33 import numpy as np
L34 import pandas as pd
L35 import yfinance as yf
L36 from typing import Any, TYPE_CHECKING
L37 from scipy.stats import zscore
L38
L39 if TYPE_CHECKING:
L40     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L41
L42 logger = logging.getLogger(__name__)
L43
L44 # ---- Dividend Helpers -------------------------------------------------------
L45 def _last_close(t, price_map=None):
L46     if price_map and (c := price_map.get(t)) is not None: return float(c)
L47     try:
L48         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L49         return float(h.iloc[-1]) if len(h) else np.nan
L50     except Exception:
L51         return np.nan
L52
L53 def _ttm_div_sum(t, lookback_days=400):
L54     try:
L55         div = yf.Ticker(t).dividends
L56         if div is None or len(div) == 0: return 0.0
L57         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L58         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L59         return ttm if ttm > 0 else float(div.tail(4).sum())
L60     except Exception:
L61         return 0.0
L62
L63 def ttm_div_yield_portfolio(tickers, price_map=None):
L64     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L65     return float(np.mean(ys)) if ys else 0.0
L66
L67 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L68 def winsorize_s(s: pd.Series, p=0.02):
L69     if s is None or s.dropna().empty: return s
L70     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L71
L72 def robust_z(s: pd.Series, p=0.02):
L73     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L74
L75 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L76     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L77     if s is None:
L78         return pd.Series(dtype=float)
L79     v = pd.to_numeric(s, errors="coerce")
L80     m = np.nanmedian(v)
L81     mad = np.nanmedian(np.abs(v - m))
L82     z = (v - m) / (1.4826 * mad + 1e-9)
L83     if np.nanstd(z) < 1e-9:
L84         r = v.rank(method="average", na_option="keep")
L85         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L86     return pd.Series(z, index=v.index, dtype=float)
L87
L88
L89 def _dump_dfz(df_z: pd.DataFrame, debug_mode: bool, max_rows: int = 400, ndigits: int = 3) -> None:
L90     """df_z ã‚’ System log(INFO) ã¸ãƒ€ãƒ³ãƒ—ã™ã‚‹ç°¡æ½”ãªãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£."""
L91     if not debug_mode:
L92         return
L93     try:
L94         view = df_z.copy()
L95         view = view.apply(
L96             lambda s: s.round(ndigits)
L97             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L98             else s
L99         )
L100         if len(view) > max_rows:
L101             view = view.iloc[:max_rows]
L102
L103         # === NaNã‚µãƒãƒªï¼ˆåˆ—ã”ã¨ã®æ¬ æä»¶æ•° ä¸Šä½20ï¼‰ ===
L104         try:
L105             nan_counts = df_z.isna().sum().sort_values(ascending=False)
L106             top_nan = nan_counts[nan_counts > 0].head(20)
L107             if len(top_nan) > 0:
L108                 logger.info("NaN columns (top20):\n%s", top_nan.to_string())
L109             else:
L110                 logger.info("NaN columns: none")
L111         except Exception as exc:
L112             logger.warning("nan summary failed: %s", exc)
L113
L114         # === Zeroã‚µãƒãƒªï¼ˆåˆ—ã”ã¨ã®ã‚¼ãƒ­æ¯”ç‡ ä¸Šä½20ï¼‰ ===
L115         try:
L116             zero_counts = ((df_z == 0) & (~df_z.isna())).sum()
L117             nonnull_counts = (~df_z.isna()).sum()
L118             zero_ratio = (zero_counts / nonnull_counts).sort_values(ascending=False)
L119             top_zero = zero_ratio[zero_ratio > 0].head(20)
L120             if len(top_zero) > 0:
L121                 logger.info(
L122                     "Zero-dominated columns (top20):\n%s",
L123                     top_zero.to_string(float_format=lambda x: f"{x:.2%}"),
L124                 )
L125             else:
L126                 logger.info("Zero-dominated columns: none")
L127         except Exception as exc:
L128             logger.warning("zero summary f
```