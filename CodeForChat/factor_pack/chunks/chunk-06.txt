```text
}).items():
L1127                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L1128                 name = {"beta": "β"}.get(base, base)
L1129                 try:
L1130                     val = f"{float(v):g}"
L1131                 except Exception:
L1132                     val = str(v)
L1133                 parts.append(f"{name}{op}{val}")
L1134             return "" if not parts else " / filter:" + " & ".join(parts)
L1135
L1136         def _inject_filter_suffix(title: str, group: str) -> str:
L1137             suf = _filter_suffix_from(FILTER_SPEC, group)
L1138             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L1139
L1140         def _blk(title, tbl, fmt=None, drop=()):
L1141             if tbl is None or getattr(tbl, 'empty', False):
L1142                 return f"{title}\n(選定なし)\n"
L1143             if drop and hasattr(tbl, 'columns'):
L1144                 keep = [c for c in tbl.columns if c not in drop]
L1145                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L1146             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L1147
L1148         message = "📈 ファクター分散最適化の結果\n"
L1149         if self.miss_df is not None and not self.miss_df.empty:
L1150             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L1151         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L1152         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L1153         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L1154         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L1155
L1156         try:
L1157             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L1158             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L1159             if r is not None:
L1160                 r.raise_for_status()
L1161         except Exception as e:
L1162             print(f"[ERR] main_post_failed: {e}")
L1163
L1164 def _infer_g_universe(feature_df, selected12=None, near5=None):
L1165     try:
L1166         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L1167         if out: return out
L1168     except Exception:
L1169         pass
L1170     base = set()
L1171     for lst in (selected12 or []), (near5 or []):
L1172         for x in (lst or []): base.add(x)
L1173     return list(base) if base else list(feature_df.index)
L1174
L1175 def _fmt_with_fire_mark(tickers, feature_df):
L1176     out = []
L1177     for t in tickers or []:
L1178         try:
L1179             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L1180             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L1181             out.append(f"{t}{' 🔥' if (br or pb) else ''}")
L1182         except Exception:
L1183             out.append(t)
L1184     return out
L1185
L1186 def _label_recent_event(t, feature_df):
L1187     try:
L1188         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L1189         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L1190         if   br and not pb: return f"{t}（ブレイクアウト確定 {dbr}）"
L1191         elif pb and not br: return f"{t}（押し目反発 {dpb}）"
L1192         elif br and pb:     return f"{t}（ブレイクアウト確定 {dbr}／押し目反発 {dpb}）"
L1193     except Exception:
L1194         pass
L1195     return t
L1196
L1197 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L1198
L1199 def io_build_input_bundle() -> InputBundle:
L1200     """
L1201     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L1202     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L1203     """
L1204     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1205     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L1206
L1207 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1208               n_target: int) -> tuple[list, float, float, float]:
L1209     """
L1210     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L1211     戻り値：(pick, avg_res_corr, sum_score, objective)
L1212     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L1213     """
L1214     sc.cfg = cfg
L1215
L1216     if hasattr(sc, "score_build_features"):
L1217         feat = sc.score_build_features(inb)
L1218         if not hasattr(sc, "_feat_logged"):
L1219             T.log("features built (scorer)")
L1220             sc._feat_logged = True
L1221         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1222     else:
L1223         fb = sc.aggregate_scores(inb, cfg)
L1224         if not hasattr(sc, "_feat_logged"):
L1225             T.log("features built (scorer)")
L1226             sc._feat_logged = True
L1227         sc._feat = fb
L1228         agg = fb.g_score if group == "G" else fb.d_score_all
L1229         if group == "D" and hasattr(fb, "df"):
L1230             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L1231
L1232     if hasattr(sc, "filter_candidates"):
L1233         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1234
L1235     selector = Selector()
L1236     if hasattr(sc, "select_diversified"):
L1237         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1238             selector=selector, prev_tickers=None,
L1239             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1240             cross_mu=cfg.drrs.cross_mu_gd)
L1241     else:
L1242         if group == "G":
L1243             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1244             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1245                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1246                 lam=cfg.drrs.G.get("lam", 0.68),
L1247                 lookback=cfg.drrs.G.get("lookback", 252),
L1248                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1249         else:
L1250             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1251             g_fixed = getattr(sc, "_top_G", None)
L1252             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1253                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1254                 lam=cfg.drrs.D.get("lam", 0.85),
L1255                 lookback=cfg.drrs.D.get("lookback", 504),
L1256                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1257                 mu=cfg.drrs.cross_mu_gd)
L1258         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1259         sum_sc = res["sum_score"]; obj = res["objective"]
L1260         if group == "D":
L1261             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1262             T.log("selection finalized (G/D)")
L1263     try:
L1264         inc = [t for t in exist if t in agg.index]
L1265         pick = _sticky_keep_current(
L1266             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1267             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1268         )
L1269     except Exception as _e:
L1270         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1271     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L1272     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L1273     try:
L1274         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1275         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1276         setattr(sc, f"_near_{group}", near10)
L1277         setattr(sc, f"_agg_{group}", agg)
L1278     except Exception:
L1279         pass
L1280
L1281     if group == "D":
L1282         T.log("save done")
L1283     if group == "G":
L1284         sc._top_G = pick
L1285     return pick, avg_r, sum_sc, obj
L1286
L1287 def run_pipeline() -> SelectionBundle:
L1288     """
L1289     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L1290     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L1291     """
L1292     inb = io_build_input_bundle()
L1293     cfg = PipelineConfig(
L1294         weights=WeightsConfig(g=g_weights, d=D_weights),
L1295         drrs=DRRSParams(
L1296             corrM=corrM, shrink=DRRS_SHRINK,
L1297             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1298         ),
L1299         price_max=CAND_PRICE_MAX,
L1300         debug_mode=debug_mode
L1301     )
L1302     sc = Scorer()
L1303     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1304     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1305     alpha = Scorer.spx_to_alpha(inb.spx)
L1306     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1307     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1308     sc._top_G = top_G
L1309     try:
L1310         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1311         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1312     except Exception:
L1313         pass
L1314     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1315     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1316     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1317     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1318     fb = getattr(sc, "_feat", None)
L1319     near_G = getattr(sc, "_near_G", [])
L1320     selected12 = list(top_G)
L1321     df = fb.df if fb is not None else pd.DataFrame()
L1322     guni = _infer_g_universe(df, selected12, near_G)
L1323     try:
L1324         fire_recent = [t for t in guni
L1325                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1326                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1327     except Exception: fire_recent = []
L1328
L1329     lines = [
L1330         "【G枠レポート｜週次モニタ（直近5営業日）】",
L1331         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L1332         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L1333         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L1334
L1335     if fire_recent:
L1336         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1337         lines.append(f"過去5営業日の検知: {fire_list}")
L1338     else:
L1339         lines.append("過去5営業日の検知: なし")
L1340
L1341     try:
L1342         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1343         if webhook:
L1344             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1345     except Exception:
L1346         pass
L1347
L1348     out = Output()
L1349     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1350     try: out._sc = sc
L1351     except Exception: pass
L1352     if hasattr(sc, "_feat"):
L1353         try:
L1354             fb = sc._feat
L1355             out.miss_df = fb.missing_logs
L1356             out.display_results(
L1357                 exist=exist,
L1358                 bench=bench,
L1359                 df_z=fb.df_z,
L1360                 g_score=fb.g_score,
L1361                 d_score_all=fb.d_score_all,
L1362                 init_G=top_G,
L1363                 init_D=top_D,
L1364                 top_G=top_G,
L1365                 
```