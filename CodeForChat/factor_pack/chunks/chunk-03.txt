```text
e","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L524
L525     @staticmethod
L526     def _first_key(d: dict, keys: list[str]):
L527         for k in keys:
L528             if k in d and d[k] is not None: return d[k]
L529         return None
L530
L531     @staticmethod
L532     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L533         for i in range(retries):
L534             r = session.get(url, params=params, timeout=15)
L535             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L536             r.raise_for_status(); return r.json()
L537         r.raise_for_status()
L538
L539     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L540         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L541         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L542         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L543         for sym in tickers:
L544             cfo_ttm = capex_ttm = None
L545             try:
L546                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L547                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L548                 for item in arr[:4]:
L549                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L550                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L551                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L552             except Exception: pass
L553             if cfo_ttm is None or capex_ttm is None:
L554                 try:
L555                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L556                     arr = j.get("cashFlow") or []
L557                     if arr:
L558                         item0 = arr[0]
L559                         if cfo_ttm is None:
L560                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L561                             if v is not None: cfo_ttm = float(v)
L562                         if capex_ttm is None:
L563                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L564                             if v is not None: capex_ttm = float(v)
L565                 except Exception: pass
L566             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L567         return pd.DataFrame(rows).set_index("ticker")
L568
L569     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L570         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L571         T.log("financials (yf) done")
L572         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L573         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L574         if need:
L575             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L576             df = yf_df.join(fh_df, how="left")
L577             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L578                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L579             print("[T] financials (finnhub) done (fallback only)")
L580         else:
L581             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L582             print("[T] financials (finnhub) skipped (no missing)")
L583         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L584         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L585         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L586         fcf_calc = cfo - capex
L587         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L588         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L589         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L590         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L591         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L592         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L593         return df[cols].sort_index()
L594
L595     def _build_eps_df(self, tickers, tickers_bulk, info, sec_map: dict | None = None):
L596         eps_rows=[]
L597         for t in tickers:
L598             info_t = info[t]
L599             sec_t = (sec_map or {}).get(t, {})
L600             eps_ttm = sec_t.get("eps_ttm", info_t.get("trailingEps", np.nan))
L601             eps_q = sec_t.get("eps_q_recent", np.nan)
L602             try:
L603                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L604                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L605                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L606                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L607                     if pd.isna(eps_q):
L608                         eps_q = qearn["Earnings"].iloc[-1]/so
L609             except Exception: pass
L610             rev_ttm = sec_t.get("rev_ttm", np.nan)
L611             rev_q = sec_t.get("rev_q_recent", np.nan)
L612             if (not sec_t) or pd.isna(rev_ttm):
L613                 try:
L614                     tk = tickers_bulk.tickers[t]
L615                     qfin = getattr(tk, "quarterly_financials", None)
L616                     if qfin is not None and not qfin.empty:
L617                         idx_lower = {str(i).lower(): i for i in qfin.index}
L618                         rev_idx = None
L619                         for name in ("Total Revenue", "TotalRevenue"):
L620                             key = name.lower()
L621                             if key in idx_lower:
L622                                 rev_idx = idx_lower[key]
L623                                 break
L624                         if rev_idx is not None:
L625                             rev_series = pd.to_numeric(qfin.loc[rev_idx], errors="coerce").dropna()
L626                             if not rev_series.empty:
L627                                 rev_ttm_yf = float(rev_series.head(4).sum())
L628                                 if pd.isna(rev_ttm):
L629                                     rev_ttm = rev_ttm_yf
L630                                 if pd.isna(rev_q):
L631                                     rev_q = float(rev_series.iloc[0])
L632                 except Exception:
L633                     pass
L634             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q,"rev_ttm":rev_ttm,"rev_q_recent":rev_q})
L635         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L636
L637     def prepare_data(self):
L638         """Fetch price and fundamental data for all tickers."""
L639         self.sec_dryrun_sample()
L640         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L641         for t in self.cand:
L642             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L643             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L644         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L645         T.log("price cap filter done (CAND_PRICE_MAX)")
L646         # 入力ティッカーの重複を除去し、現行→候補の順序を維持
L647         tickers = list(dict.fromkeys(self.exist + cand_f))
L648         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L649         data = yf.download(tickers + [self.bench], period="600d",
L650                            auto_adjust=True, progress=False, threads=False)
L651         T.log("yf.download done")
L652         px = data["Close"].dropna(how="all", axis=1).ffill(limit=2)
L653         spx = data["Close"][self.bench].reindex(px.index).ffill()
L654         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0なら無効（既定）
L655         if clip_days > 0:
L656             px  = px.tail(clip_days + 1)
L657             spx = spx.tail(clip_days + 1)
L658             logger.info("[T] price window clipped by env: %d rows (PRICE_CLIP_DAYS=%d)", len(px), clip_days)
L659         else:
L660             logger.info("[T] price window clip skipped; rows=%d", len(px))
L661         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L662         for t in tickers:
L663             try:
L664                 info[t] = tickers_bulk.tickers[t].info
L665             except Exception as e:
L666                 logger.info("[warn] %s: info fetch failed (%s)", t, e)
L667                 info[t] = {}
L668         try:
L669             sec_map = self.fetch_eps_rev_from_sec(tickers)
L670         except Exception as e:
L671             logger.warning("[SEC] fetch_eps_rev_from_sec failed: %s", e)
L672             sec_map = {}
L673
L674         def _brief_len(s):
L675             try:
L676                 if isinstance(s, pd.Series):
L677                     return int(s.dropna().size)
L678                 if isinstance(s, (list, tuple)):
L679                     return len([v for v in s if pd.notna(v)])
L680                 if isinstance(s, np.ndarray):
L681                     return int(np.count_nonzero(~pd.isna(s)))
L682                 return int(bool(s))
L683             except Exception:
L684                 return 0
L685
L686         def _has_entries(val) -> bool:
L687             try:
L688                 if isinstance(val, pd.Series):
L689                     return not val.dropna().empty
L690                 if isinstance(val, (list, tuple)):
L691                     return any(pd.notna(v) for v in val)
L692                 return bool(val)
L693             except Exception:
L694                 return False
L695
L696         have_rev = 0
L697         have_eps = 0
L698         rev_lens: list[int] = []
L699         eps_lens: list[int] = []
L700         samples: list[tuple[str, int, str, float | None, int, str, float | None]] = []
L701
L702         for t in tickers:
L703             entry = info.get(t, {})
L704             m = (sec_map or {}).get(t) or {}
L705             if entry is None or not isinstance(entry, dict):
L706                 entry = {}
L707                 info[t] = entry
L708
L709             if m:
L710                 pairs_r = m.get("rev_q_series_pairs") or []
L711                 pairs_e = m.get("eps_q_series_pairs") or []
L712                 if pairs_r:
L713                     idx = pd.to_datetime([d for (d, _v) in pairs_r], errors="coerce")
L714                     val = pd.to_numeric([v for (_d, v) in pairs_r], errors="coerce")
L715                     s = pd.Series(val, index=idx).sort_index()
L716                     entry["SEC_REV_Q_SERIES"] = s
L717                 else:
L718                     entry["SEC_REV_Q_SERIES"] = m.get("rev_q_series") or []
L719                 if pairs_e:
L720                     idx = pd.to_datetime([d for (d, _v) in pairs_e], errors="coerce")
L721                     val = pd.to_numeric([v for (_d, v) in pairs_e], errors="coerce")
L722                     s = pd.Series(v
```