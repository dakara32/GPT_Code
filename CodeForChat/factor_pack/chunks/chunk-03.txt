```text
","limit":8,"token":api_key})
L527                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L528                 for item in arr[:4]:
L529                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L530                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L531                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L532             except Exception: pass
L533             if cfo_ttm is None or capex_ttm is None:
L534                 try:
L535                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L536                     arr = j.get("cashFlow") or []
L537                     if arr:
L538                         item0 = arr[0]
L539                         if cfo_ttm is None:
L540                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L541                             if v is not None: cfo_ttm = float(v)
L542                         if capex_ttm is None:
L543                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L544                             if v is not None: capex_ttm = float(v)
L545                 except Exception: pass
L546             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L547         return pd.DataFrame(rows).set_index("ticker")
L548
L549     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L550         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L551         T.log("financials (yf) done")
L552         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L553         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L554         if need:
L555             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L556             df = yf_df.join(fh_df, how="left")
L557             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L558                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L559             print("[T] financials (finnhub) done (fallback only)")
L560         else:
L561             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L562             print("[T] financials (finnhub) skipped (no missing)")
L563         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L564         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L565         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L566         fcf_calc = cfo - capex
L567         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L568         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L569         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L570         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L571         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L572         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L573         return df[cols].sort_index()
L574
L575     def _build_eps_df(self, tickers, tickers_bulk, info, sec_map: dict | None = None):
L576         eps_rows=[]
L577         for t in tickers:
L578             info_t = info[t]
L579             sec_t = (sec_map or {}).get(t, {})
L580             eps_ttm = sec_t.get("eps_ttm", info_t.get("trailingEps", np.nan))
L581             eps_q = sec_t.get("eps_q_recent", np.nan)
L582             try:
L583                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L584                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L585                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L586                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L587                     if pd.isna(eps_q):
L588                         eps_q = qearn["Earnings"].iloc[-1]/so
L589             except Exception: pass
L590             rev_ttm = sec_t.get("rev_ttm", np.nan)
L591             rev_q = sec_t.get("rev_q_recent", np.nan)
L592             if (not sec_t) or pd.isna(rev_ttm):
L593                 try:
L594                     tk = tickers_bulk.tickers[t]
L595                     qfin = getattr(tk, "quarterly_financials", None)
L596                     if qfin is not None and not qfin.empty:
L597                         idx_lower = {str(i).lower(): i for i in qfin.index}
L598                         rev_idx = None
L599                         for name in ("Total Revenue", "TotalRevenue"):
L600                             key = name.lower()
L601                             if key in idx_lower:
L602                                 rev_idx = idx_lower[key]
L603                                 break
L604                         if rev_idx is not None:
L605                             rev_series = pd.to_numeric(qfin.loc[rev_idx], errors="coerce").dropna()
L606                             if not rev_series.empty:
L607                                 rev_ttm_yf = float(rev_series.head(4).sum())
L608                                 if pd.isna(rev_ttm):
L609                                     rev_ttm = rev_ttm_yf
L610                                 if pd.isna(rev_q):
L611                                     rev_q = float(rev_series.iloc[0])
L612                 except Exception:
L613                     pass
L614             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q,"rev_ttm":rev_ttm,"rev_q_recent":rev_q})
L615         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L616
L617     def prepare_data(self):
L618         """Fetch price and fundamental data for all tickers."""
L619         self.sec_dryrun_sample()
L620         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L621         for t in self.cand:
L622             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L623             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L624         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L625         T.log("price cap filter done (CAND_PRICE_MAX)")
L626         # 入力ティッカーの重複を除去し、現行→候補の順序を維持
L627         tickers = list(dict.fromkeys(self.exist + cand_f))
L628         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L629         data = yf.download(tickers + [self.bench], period="600d",
L630                            auto_adjust=True, progress=False, threads=False)
L631         T.log("yf.download done")
L632         px = data["Close"].dropna(how="all", axis=1).ffill(limit=2)
L633         spx = data["Close"][self.bench].reindex(px.index).ffill()
L634         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0なら無効（既定）
L635         if clip_days > 0:
L636             px  = px.tail(clip_days + 1)
L637             spx = spx.tail(clip_days + 1)
L638             logger.info("[T] price window clipped by env: %d rows (PRICE_CLIP_DAYS=%d)", len(px), clip_days)
L639         else:
L640             logger.info("[T] price window clip skipped; rows=%d", len(px))
L641         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L642         for t in tickers:
L643             try:
L644                 info[t] = tickers_bulk.tickers[t].info
L645             except Exception as e:
L646                 logger.info("[warn] %s: info fetch failed (%s)", t, e)
L647                 info[t] = {}
L648         try:
L649             sec_map = self.fetch_eps_rev_from_sec(tickers)
L650             for t in tickers:
L651                 if t in info and sec_map.get(t):
L652                     info[t]["SEC_REV_Q_SERIES"] = sec_map[t].get("rev_q_series") or []
L653                     info[t]["SEC_EPS_Q_SERIES"] = sec_map[t].get("eps_q_series") or []
L654         except Exception:
L655             sec_map = None
L656         eps_df = self._build_eps_df(tickers, tickers_bulk, info, sec_map=sec_map)
L657         # index 重複があると .loc[t, col] が Series になり代入時に ValueError を誘発する
L658         if not eps_df.index.is_unique:
L659             eps_df = eps_df[~eps_df.index.duplicated(keep="last")]
L660         eps_df = eps_df.assign(
L661             EPS_TTM=eps_df["eps_ttm"],
L662             EPS_Q_LastQ=eps_df["eps_q_recent"],
L663             REV_TTM=eps_df["rev_ttm"],
L664             REV_Q_LastQ=eps_df["rev_q_recent"],
L665         )
L666         # ここで非NaN件数をサマリ表示（欠損状況の即時把握用）
L667         try:
L668             n = len(eps_df)
L669             c_eps = int(eps_df["EPS_TTM"].notna().sum())
L670             c_rev = int(eps_df["REV_TTM"].notna().sum())
L671             print(f"[SEC] eps_ttm non-NaN: {c_eps}/{n}  rev_ttm non-NaN: {c_rev}/{n}")
L672         except Exception:
L673             pass
L674         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L675         T.log("eps/fcf prep done")
L676         returns = px[tickers].pct_change()
L677         T.log("price prep/returns done")
L678         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L679
L680 # === Selector：相関低減・選定（スコア＆リターンだけ読む） ===
L681 class Selector:
L682     # ---- DRRS helpers（Selector専用） ----
L683     @staticmethod
L684     def _z_np(X: np.ndarray) -> np.ndarray:
L685         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L686         return (np.nan_to_num(X)-m)/s
L687
L688     @classmethod
L689     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L690         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L691         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L692         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L693         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L694         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L695
L696     @classmethod
L697     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L698         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L699         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L700         if k==0: return []
L701         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L702         for _ in range(k):
L703             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L704             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L705             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L706         return sorted(S)
L707
L708     @staticmethod
L709     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L710         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L711         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L712
L713     @classmethod
L714     def s
```