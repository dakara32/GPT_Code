```text
L561                     v = _first_valid(vals)
L562                     return float(v / 4.0) if v == v else float("nan")
L563
L564                 def _quarter_from_annual_prev(vals: list[float]) -> float:
L565                     v = _nth_valid(vals, 1)
L566                     return float(v / 4.0) if v == v else float("nan")
L567
L568                 rev_lastq = _first_valid(rev_q_vals)
L569                 if rev_lastq != rev_lastq:
L570                     rev_lastq = _quarter_from_annual(rev_a_vals)
L571                 eps_lastq = _first_valid(eps_q_vals)
L572                 if eps_lastq != eps_lastq:
L573                     eps_lastq = _quarter_from_annual(eps_a_vals)
L574
L575                 rev_lastq_prev = _nth_valid(rev_q_vals, 4)
L576                 if rev_lastq_prev != rev_lastq_prev:
L577                     rev_lastq_prev = _quarter_from_annual_prev(rev_a_vals)
L578                 eps_lastq_prev = _nth_valid(eps_q_vals, 4)
L579                 if eps_lastq_prev != eps_lastq_prev:
L580                     eps_lastq_prev = _quarter_from_annual_prev(eps_a_vals)
L581
L582                 rev_ttm = self._ttm_from_q_or_a(rev_q_vals, rev_a_vals)
L583                 eps_ttm = self._ttm_from_q_or_a(eps_q_vals, eps_a_vals)
L584                 rev_ttm_prev = self._ttm_from_q_or_a(rev_q_vals[4:], rev_a_vals[1:])
L585                 eps_ttm_prev = self._ttm_from_q_or_a(eps_q_vals[4:], eps_a_vals[1:])
L586
L587                 rev_annual_latest = _first_valid(rev_a_vals)
L588                 rev_annual_prev = _nth_valid(rev_a_vals, 1)
L589                 eps_annual_latest = _first_valid(eps_a_vals)
L590                 eps_annual_prev = _nth_valid(eps_a_vals, 1)
L591
L592                 def _cagr3(vals: list[float]) -> float:
L593                     vals_valid = [v for v in vals if v == v]
L594                     if len(vals_valid) >= 3:
L595                         latest, base = float(vals_valid[0]), float(vals_valid[2])
L596                         if latest > 0 and base > 0:
L597                             try:
L598                                 return float((latest / base) ** (1 / 2) - 1.0)
L599                             except Exception:
L600                                 return float("nan")
L601                     return float("nan")
L602
L603                 rev_cagr3 = _cagr3(rev_a_vals)
L604                 eps_cagr3 = _cagr3(eps_a_vals)
L605
L606                 out[t] = {
L607                     "eps_q_recent": eps_lastq,
L608                     "eps_ttm": eps_ttm,
L609                     "eps_ttm_prev": eps_ttm_prev,
L610                     "eps_lastq_prev": eps_lastq_prev,
L611                     "rev_q_recent": rev_lastq,
L612                     "rev_ttm": rev_ttm,
L613                     "rev_ttm_prev": rev_ttm_prev,
L614                     "rev_lastq_prev": rev_lastq_prev,
L615                     # 後段でDatetimeIndex化できるよう (date,value) を保持。値だけの互換キーも残す。
L616                     # 3年運用に合わせて四半期は直近12本のみ保持（約3年=12Q）
L617                     "eps_q_series_pairs": eps_q_pairs,
L618                     "rev_q_series_pairs": rev_q_pairs,
L619                     "eps_q_series": eps_q_vals,
L620                     "rev_q_series": rev_q_vals,
L621                     "eps_a_series_pairs": eps_a_pairs,
L622                     "rev_a_series_pairs": rev_a_pairs,
L623                     "eps_a_series": eps_a_vals,
L624                     "rev_a_series": rev_a_vals,
L625                     "eps_annual_latest": eps_annual_latest,
L626                     "eps_annual_prev": eps_annual_prev,
L627                     "rev_annual_latest": rev_annual_latest,
L628                     "rev_annual_prev": rev_annual_prev,
L629                     "eps_cagr3": eps_cagr3,
L630                     "rev_cagr3": rev_cagr3,
L631                 }
L632                 n_map += 1
L633                 if any(v == v for v in rev_q_vals) or any(v == v for v in rev_a_vals):
L634                     n_rev += 1
L635                 if any(v == v for v in eps_q_vals) or any(v == v for v in eps_a_vals):
L636                     n_eps += 1
L637             except Exception:
L638                 out[t] = {}
L639                 miss_facts.append(t)
L640             time.sleep(0.30)
L641         # 取得サマリをログ（Actionsで確認しやすいよう print）
L642         try:
L643             total = len(tickers)
L644             print(f"[SEC] map={n_map}/{total}  rev_q_hit={n_rev}  eps_q_hit={n_eps}")
L645             # デバッグ: 取得本数の分布（先頭のみ）
L646             try:
L647                 lens = [len((out.get(t, {}) or {}).get("rev_q_series", [])) for t in tickers]
L648                 print(f"[SEC] rev_q_series length: min={min(lens) if lens else 0} "
L649                       f"p25={np.percentile(lens,25) if lens else 0} median={np.median(lens) if lens else 0} "
L650                       f"p75={np.percentile(lens,75) if lens else 0} max={max(lens) if lens else 0}")
L651             except Exception:
L652                 pass
L653             if miss_map:
L654                 print(f"[SEC] no CIK map: {len(miss_map)} (サンプル例) {miss_map[:20]}")
L655             if miss_facts:
L656                 print(f"[SEC] CIKあり だが対象factなし: {len(miss_facts)} (サンプル例) {miss_facts[:20]}")
L657         except Exception:
L658             pass
L659         return out
L660
L661     def sec_dryrun_sample(self, tickers: list[str] | None = None) -> None:
L662         if not _env_true("SEC_DRYRUN_SAMPLE", False):
L663             return
L664         sample = tickers or ["BRK.B", "BF.B", "GOOGL", "META", "UBER", "PBR.A", "TSM", "NARI", "EVBN", "SWAV"]
L665         print(f"[SEC-DRYRUN] sample tickers: {sample}")
L666         try:
L667             t2cik = self._sec_ticker_map()
L668             hits = 0
L669             for sym in sample:
L670                 candidates: list[str] = []
L671
L672                 def add(key: str) -> None:
L673                     if key and key not in candidates:
L674                         candidates.append(key)
L675
L676                 add((sym or "").upper())
L677                 for alt in self._normalize_ticker(sym):
L678                     add(alt)
L679                 if any(t2cik.get(key) for key in candidates):
L680                     hits += 1
L681             sec_data = self.fetch_eps_rev_from_sec(sample)
L682             rev_hits = sum(1 for v in sec_data.values() if v.get("rev_q_series"))
L683             eps_hits = sum(1 for v in sec_data.values() if v.get("eps_q_series"))
L684             total = len(sample)
L685             print(f"[SEC-DRYRUN] CIK map hit: {hits}/{total}  rev_q_series hits: {rev_hits}  eps_q_series hits: {eps_hits}")
L686         except Exception as e:
L687             print(f"[SEC-DRYRUN] error: {e}")
L688     @staticmethod
L689     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L690         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L691         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L692         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L693
L694     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L695
L696     @staticmethod
L697     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L698         if df is None or df.empty: return None
L699         idx_lower={str(i).lower():i for i in df.index}
L700         for n in names:
L701             k=n.lower()
L702             if k in idx_lower: return df.loc[idx_lower[k]]
L703         return None
L704
L705     @staticmethod
L706     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L707         if s is None or s.empty: return None
L708         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L709
L710     @staticmethod
L711     def _latest(s: pd.Series|None) -> float|None:
L712         if s is None or s.empty: return None
L713         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L714
L715     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L716         from concurrent.futures import ThreadPoolExecutor, as_completed
L717         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L718
L719         def one(t: str):
L720             try:
L721                 tk = yf.Ticker(t)  # ★ セッションは渡さない（YFがcurl_cffiで管理）
L722                 qcf = tk.quarterly_cashflow
L723                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L724                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L725                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L726                 if any(v is None for v in (cfo, capex, fcf)):
L727                     acf = tk.cashflow
L728                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L729                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L730                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L731             except Exception as e:
L732                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L733             n=np.nan
L734             return {"ticker":t,
L735                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L736                     "capex_ttm_yf": n if capex is None else capex,
L737                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L738
L739         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L740         with ThreadPoolExecutor(max_workers=mw) as ex:
L741             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L742         return pd.DataFrame(rows).set_index("ticker")
L743
L744     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L745     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L746
L747     @staticmethod
L748     def _first_key(d: dict, keys: list[str]):
L749         for k in keys:
L750             if k in d and d[k] is not None: return d[k]
L751         return None
L752
L753     @staticmethod
L754     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L755         for i in range(retries):
L756             r = session.get(url, params=params, timeout=15)
L757             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L758             r.raise_for_status(); return r.json()
L759         r.raise_for_status()
L760
L761     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L762         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L763         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L764         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L765         for sym in tickers:
L766             cfo_ttm = capex_ttm = None
L767             try:
L768                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L769                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L770                 for item in arr[:4]:
L771                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L772                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L773                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float
```