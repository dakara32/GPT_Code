```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, requests, logging
L7 from time import perf_counter
L8 from dataclasses import dataclass
L9 from typing import Any, Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 logger = logging.getLogger(__name__)
L19
L20 class T:
L21     t = perf_counter()
L22     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L23
L24 T.log("start")
L25
L26 # === ユニバースと定数（冒頭に固定） ===
L27 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L28 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L29 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L30 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L31 g_weights = {'GROWTH_F':0.30,'MOM':0.55,'VOL':-0.15}
L32 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L33 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L34 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L35 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L36
L37 # DRRS 初期プール・各種パラメータ
L38 corrM = 45
L39 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L40 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L41
L42 # クロス相関ペナルティ（未定義なら設定）
L43 try: CROSS_MU_GD
L44 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L45
L46 # 出力関連
L47 RESULTS_DIR = "results"
L48 os.makedirs(RESULTS_DIR, exist_ok=True)
L49
L50 # その他
L51 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L52
L53 # === 共有DTO（クラス間I/O契約）＋ Config ===
L54 @dataclass(frozen=True)
L55 class InputBundle:
L56     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L57     cand: List[str]
L58     tickers: List[str]
L59     bench: str
L60     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L61     px: pd.DataFrame                # data['Close']
L62     spx: pd.Series                  # data['Close'][bench]
L63     tickers_bulk: object            # yfinance.Tickers
L64     info: Dict[str, dict]           # yfinance info per ticker
L65     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L66     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L67     returns: pd.DataFrame           # px[tickers].pct_change()
L68
L69 @dataclass(frozen=True)
L70 class FeatureBundle:
L71     df: pd.DataFrame
L72     df_z: pd.DataFrame
L73     g_score: pd.Series
L74     d_score_all: pd.Series
L75     missing_logs: pd.DataFrame
L76     df_full: pd.DataFrame | None = None
L77     df_full_z: pd.DataFrame | None = None
L78     scaler: Any | None = None
L79
L80 @dataclass(frozen=True)
L81 class SelectionBundle:
L82     resG: dict
L83     resD: dict
L84     top_G: List[str]
L85     top_D: List[str]
L86     init_G: List[str]
L87     init_D: List[str]
L88
L89 @dataclass(frozen=True)
L90 class WeightsConfig:
L91     g: Dict[str,float]
L92     d: Dict[str,float]
L93
L94 @dataclass(frozen=True)
L95 class DRRSParams:
L96     corrM: int
L97     shrink: float
L98     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L99     D: Dict[str,float]
L100     cross_mu_gd: float
L101
L102 @dataclass(frozen=True)
L103 class PipelineConfig:
L104     weights: WeightsConfig
L105     drrs: DRRSParams
L106     price_max: float
L107
L108 # === 共通ユーティリティ（複数クラスで使用） ===
L109 # (unused local utils removed – use scorer.py versions if needed)
L110
L111 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L112
L113 _DEBUG_COL_ALIAS = {
L114     "GROWTH_F": "GRW",
L115     "GROWTH_F_RAW": "GRW_RAW",
L116     "TREND_SLOPE_EPS": "TR_EPS",
L117     "TREND_SLOPE_EPS_RAW": "TR_EPS_RAW",
L118     "TREND_SLOPE_REV": "TR_REV",
L119     "TREND_SLOPE_REV_RAW": "TR_REV_RAW",
L120     "TREND_SLOPE_EPS_YR": "TR_EPS_YR",
L121     "TREND_SLOPE_EPS_YR_RAW": "TR_EPS_YR_RAW",
L122     "TREND_SLOPE_REV_YR": "TR_REV_YR",
L123     "TREND_SLOPE_REV_YR_RAW": "TR_REV_YR_RAW",
L124     "BETA": "BETA_RAW",
L125 }
L126
L127 _DEBUG_COL_ORDER = [
L128     "GRW", "GRW_RAW",
L129     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L130     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L131     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L132     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L133     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW", "REV_ANN_STREAK",
L134     "RULE40", "RULE40_RAW", "FCF_MGN", "FCF_MGN_RAW",
L135     "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L136 ]
L137
L138 DEBUG_COLS = [
L139     "GRW", "GRW_RAW",
L140     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L141     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L142     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L143     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L144     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW",
L145     "REV_ANN_STREAK", "RULE40", "RULE40_RAW",
L146     "FCF_MGN", "FCF_MGN_RAW", "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L147     "GSC", "DSC"
L148 ]
L149
L150 MUST_DEBUG_COLS = {"TR_EPS", "TR_REV", "REV_Q_YOY", "REV_YOY_ACC", "RULE40", "FCF_MGN"}
L151
L152 def _post_slack(payload: dict):
L153     url = os.getenv("SLACK_WEBHOOK_URL")
L154     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L155     try:
L156         requests.post(url, json=payload).raise_for_status()
L157     except Exception as e:
L158         print(f"⚠️ Slack通知エラー: {e}")
L159
L160 def _slack_debug(text: str, chunk: int = 2800, fenced: bool = True) -> None:
L161     """Slackへデバッグテキストをコードブロックで送信（行ベース分割）。"""
L162     body = str(text or "").rstrip("\n")
L163     if not body:
L164         return
L165
L166     def _send(lines: List[str]) -> None:
L167         if not lines:
L168             return
L169         payload = "```\n" + "\n".join(lines) + "\n```" if fenced else "\n".join(lines)
L170         _post_slack({"blocks": [{"type": "section", "text": {"type": "mrkdwn", "text": payload}}]})
L171
L172     block, block_len = [], 0
L173     for raw in body.splitlines():
L174         line = raw or ""
L175         while len(line) > chunk:
L176             head, line = line[:chunk], line[chunk:]
L177             if block:
L178                 _send(block)
L179                 block, block_len = [], 0
L180             _send([head])
L181         add_len = len(line) if not block else len(line) + 1
L182         if block and block_len + add_len > chunk:
L183             _send(block)
L184             block, block_len = [], 0
L185             add_len = len(line)
L186         block.append(line)
L187         block_len += add_len
L188     _send(block)
L189
L190 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L191     src = getattr(fb, "df_full", None)
L192     if not isinstance(src, pd.DataFrame) or src.empty:
L193         src = getattr(fb, "df_full_z", None)
L194     if not isinstance(src, pd.DataFrame) or src.empty:
L195         src = getattr(fb, "df_z", None)
L196     if not isinstance(src, pd.DataFrame) or src.empty:
L197         return "df not available"
L198
L199     df_show = src.apply(pd.to_numeric, errors="coerce").rename(
L200         columns={k: v for k, v in _DEBUG_COL_ALIAS.items() if k in src.columns}
L201     )
L202
L203     missing = sorted(c for c in MUST_DEBUG_COLS if c not in df_show.columns)
L204     if missing:
L205         logger.warning("[debug] missing cols: %s", missing)
L206
L207     all_cols = _env_true("DEBUG_ALL_COLS", False)
L208     ordered = [c for c in _DEBUG_COL_ORDER if c in df_show.columns]
L209     cols = list(df_show.columns) if all_cols else ordered
L210     if not cols:
L211         cols = [c for c in df_show.columns if c not in ("GSC", "DSC")]
L212
L213     g_series = getattr(fb, "g_score", None)
L214     d_series = getattr(fb, "d_score_all", None)
L215     show_near = _env_true("DEBUG_NEAR5", True)
L216     g_sorted = g_series.sort_values(ascending=False) if show_near and hasattr(g_series, "sort_values") else None
L217     d_sorted = d_series.sort_values(ascending=False) if show_near and hasattr(d_series, "sort_values") else None
L218
L219     g_pick = list(getattr(sb, "top_G", []) or [])
L220     d_pick = list(getattr(sb, "top_D", []) or [])
L221     prevG = list(prevG or [])
L222     prevD = list(prevD or [])
L223     Gp, Dp = set(prevG), set(prevD)
L224     g_new = [t for t in g_pick if t not in Gp]
L225     g_out = [t for t in prevG if t not in g_pick]
L226     d_new = [t for t in d_pick if t not in Dp]
L227     d_out = [t for t in prevD if t not in d_pick]
L228
L229     g_miss = [t for t in (g_sorted.index if g_sorted is not None else []) if t not in g_pick][:10]
L230     used_d = set(g_pick + d_pick)
L231     d_miss = [t for t in (d_sorted.index if d_sorted is not None else []) if t not in used_d][:10]
L232
L233     def _merge_rows(*seqs):
L234         seen, out = set(), []
L235         for seq in seqs:
L236             for t in seq or []:
L237                 if t in df_show.index and t not in seen:
L238                     seen.add(t)
L239                     out.append(t)
L240         return out
L241
L242     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L243     focus = df_show.index.tolist() if all_rows else _merge_rows(g_pick + d_pick, prevG + prevD, g_miss, d_miss)
L244     if not focus:
L245         focus = df_show.index.tolist()
L246     focus = focus[:max_rows]
L247
L248     if cols:
L249         df_focus = df_show.loc[focus, cols].copy()
L250     else:
L251         df_focus = df_show.loc[focus].copy()
L252     if "GSC" not in df_focus.columns and g_series is not None:
L253         df_focus["GSC"] = [g_series.get(t, np.nan) if hasattr(g_series, "get") else np.nan for t in df_focus.index]
L254     if "DSC" not in df_focus.columns and d_series is not None:
L255         df_focus["DSC"] = [d_series.get(t, np.nan) if hasattr(d_series, "get") else np.nan for t in df_focus.index]
L256
L257     if not all_cols:
L258         extra = [c for c in df_focus.columns if c not in cols]
L259         cols = cols + [c for c in ("GSC", "DSC") if c not in cols]
L260         cols += [c for c in extra if c not in cols]
L261     else:
L262         cols = [c for c in df_focus.columns if c not in ("GSC", "DSC")]
L263         cols += [c for c in ("GSC", "DSC") if c not in cols]
L264
L265     
```