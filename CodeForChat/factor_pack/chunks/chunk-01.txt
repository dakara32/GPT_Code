```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, requests
L7 from time import perf_counter
L8 from dataclasses import dataclass, replace
L9 from typing import Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 class T:
L19     t = perf_counter()
L20     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L21
L22 T.log("start")
L23
L24 # === ユニバースと定数（冒頭に固定） ===
L25 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L26 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L27 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L28 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L29 g_weights = {'GRW':0.30,'MOM':0.55,'VOL':-0.15}
L30 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.7"))
L31 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L32 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L33 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L34
L35 # DRRS 初期プール・各種パラメータ
L36 corrM = 45
L37 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L38 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L39
L40 # クロス相関ペナルティ（未定義なら設定）
L41 try: CROSS_MU_GD
L42 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L43
L44 # 出力関連
L45 RESULTS_DIR = "results"
L46 os.makedirs(RESULTS_DIR, exist_ok=True)
L47
L48 # その他
L49 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L50
L51 def _fetch_eps_non_gaap_ttm(sym: str, token: str) -> float:
L52     try:
L53         r = requests.get("https://finnhub.io/api/v1/stock/earnings",
L54                          params={"symbol": sym, "limit": 4, "token": token}, timeout=12)
L55         arr = r.json() if r.ok else []
L56         vals = [float(x.get("epsNonGAAP", np.nan)) for x in arr[:4]]
L57         return float(np.nansum([v for v in vals if pd.notna(v)]))
L58     except Exception:
L59         return np.nan
L60
L61 # === 共有DTO（クラス間I/O契約）＋ Config ===
L62 @dataclass(frozen=True)
L63 class InputBundle:
L64     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L65     cand: List[str]
L66     tickers: List[str]
L67     bench: str
L68     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L69     px: pd.DataFrame                # data['Close']
L70     spx: pd.Series                  # data['Close'][bench]
L71     tickers_bulk: object            # yfinance.Tickers
L72     info: Dict[str, dict]           # yfinance info per ticker
L73     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L74     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L75     returns: pd.DataFrame           # px[tickers].pct_change()
L76
L77 @dataclass(frozen=True)
L78 class FeatureBundle:
L79     df: pd.DataFrame
L80     df_z: pd.DataFrame
L81     g_score: pd.Series
L82     d_score_all: pd.Series
L83     missing_logs: pd.DataFrame
L84
L85 @dataclass(frozen=True)
L86 class SelectionBundle:
L87     resG: dict
L88     resD: dict
L89     top_G: List[str]
L90     top_D: List[str]
L91     init_G: List[str]
L92     init_D: List[str]
L93
L94 @dataclass(frozen=True)
L95 class WeightsConfig:
L96     g: Dict[str,float]
L97     d: Dict[str,float]
L98
L99 @dataclass(frozen=True)
L100 class DRRSParams:
L101     corrM: int
L102     shrink: float
L103     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L104     D: Dict[str,float]
L105     cross_mu_gd: float
L106
L107 @dataclass(frozen=True)
L108 class PipelineConfig:
L109     weights: WeightsConfig
L110     drrs: DRRSParams
L111     price_max: float
L112
L113 # === 共通ユーティリティ（複数クラスで使用） ===
L114 # (unused local utils removed – use scorer.py versions if needed)
L115
L116 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L117
L118 def _post_slack(payload: dict):
L119     url = os.getenv("SLACK_WEBHOOK_URL")
L120     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L121     try:
L122         requests.post(url, json=payload).raise_for_status()
L123     except Exception as e:
L124         print(f"⚠️ Slack通知エラー: {e}")
L125
L126 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L127
L128 def _slack_debug(text: str, chunk=2800):
L129     i = 0
L130     while i < len(text):
L131         j = min(len(text), i + chunk)
L132         k = text.rfind("\n", i, j)
L133         j = k if k > i + 100 else j
L134         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L135         i = j
L136
L137 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L138     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC","eps_ttm","nEPS_ttm","eps_imputed","fcf_ttm","fcf_imputed"]
L139     all_cols = _env_true("DEBUG_ALL_COLS", False)
L140     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L141
L142     Gp, Dp = set(prevG or []), set(prevD or [])
L143     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L144     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L145
L146     show_near = _env_true("DEBUG_NEAR5", True)
L147     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L148     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L149     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L150     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L151     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L152     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L153
L154     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L155     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L156
L157     def _fmt_near(lbl, ser, lst):
L158         if ser is None: return f"{lbl}: off"
L159         g = ser.get
L160         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L161         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L162
L163     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L164           _fmt_near("G near10", gs, g_miss),
L165           _fmt_near("D near10", ds, d_miss),
L166           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L167           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L168
L169     tbl="(df_z or columns not available)"
L170     if not fb.df_z.empty and cols:
L171         idx=[t for t in focus if t in fb.df_z.index]
L172         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L173
L174     miss_txt=""
L175     if _env_true("DEBUG_MISSING_LOGS", False):
L176         miss=getattr(fb,"missing_logs",None)
L177         if miss is not None and not miss.empty:
L178             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L179
L180     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L181
L182 def _disjoint_keepG(top_G, top_D, poolD):
L183     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L184     used, D, i = set(top_G), list(top_D), 0
L185     for j, t in enumerate(D):
L186         if t in used:
L187             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L188                 i += 1
L189             if i < len(poolD):
L190                 D[j] = poolD[i]; used.add(D[j]); i += 1
L191     return top_G, D
L192
L193
L194 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L195                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L196     import pandas as pd, numpy as np
L197     sel = list(pick)
L198     if not sel: return sel
L199     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L200     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L201     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L202     thresh = kth - delta_z * sigma
L203     ranked_all = agg.sort_values(ascending=False)
L204     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L205     for t in cand:
L206         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L207         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L208         if within_score or within_rank:
L209             non_inc = [x for x in sel if x not in incumbents]
L210             if not non_inc: break
L211             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L212             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L213                 sel.remove(weakest); sel.append(t)
L214     if len(sel) > n_target:
L215         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L216     return sel
L217
L218
L219 # === Input：外部I/Oと前処理（CSV/API・欠損補完） ===
L220 class Input:
L221     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L222         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L223         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L224
L225     # ---- （Input専用）EPS補完・FCF算出系 ----
L226     @staticmethod
L227     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L228         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L229         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L230         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L231
L232     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L233
L234     @staticmethod
L235     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L236         if df is None or df.empty: return None
L237         idx_lower={str(i).lower():i for i in df.index}
L238         for n
```