```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.4   # 攻め=0.3 / 中庸=0.4 / 守り=0.5
L4 import os, json, time, requests
L5 from time import perf_counter
L6 from dataclasses import dataclass
L7 from typing import Dict, List
L8 from concurrent.futures import ThreadPoolExecutor
L9 import numpy as np
L10 import pandas as pd
L11 import yfinance as yf
L12 from scipy.stats import zscore  # used via scorer
L13 from scorer import Scorer, ttm_div_yield_portfolio
L14
L15 class T:
L16     t = perf_counter()
L17     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L18
L19 T.log("start")
L20
L21 # === ユニバースと定数（冒頭に固定） ===
L22 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L23 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L24 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L25 N_G, N_D = 12, 13  # G/D枠サイズ
L26 g_weights = {'GRW':0.40,'MOM':0.45,'VOL':-0.15}
L27 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L28 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L29 D_weights = {'QAL':0.15,'YLD':0.15,'VOL':-0.45,'TRD':0.25}
L30 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L31
L32 # DRRS 初期プール・各種パラメータ
L33 corrM = 45
L34 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L35 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L36
L37 # クロス相関ペナルティ（未定義なら設定）
L38 try: CROSS_MU_GD
L39 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L40
L41 # 出力関連
L42 RESULTS_DIR = "results"
L43 os.makedirs(RESULTS_DIR, exist_ok=True)
L44
L45 # その他
L46 debug_mode, FINNHUB_API_KEY = False, os.environ.get("FINNHUB_API_KEY")
L47
L48 # === 共有DTO（クラス間I/O契約）＋ Config ===
L49 @dataclass(frozen=True)
L50 class InputBundle:
L51     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L52     cand: List[str]
L53     tickers: List[str]
L54     bench: str
L55     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L56     px: pd.DataFrame                # data['Close']
L57     spx: pd.Series                  # data['Close'][bench]
L58     tickers_bulk: object            # yfinance.Tickers
L59     info: Dict[str, dict]           # yfinance info per ticker
L60     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L61     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L62     returns: pd.DataFrame           # px[tickers].pct_change()
L63
L64 @dataclass(frozen=True)
L65 class FeatureBundle:
L66     df: pd.DataFrame
L67     df_z: pd.DataFrame
L68     g_score: pd.Series
L69     d_score_all: pd.Series
L70     missing_logs: pd.DataFrame
L71
L72 @dataclass(frozen=True)
L73 class SelectionBundle:
L74     resG: dict
L75     resD: dict
L76     top_G: List[str]
L77     top_D: List[str]
L78     init_G: List[str]
L79     init_D: List[str]
L80
L81 @dataclass(frozen=True)
L82 class WeightsConfig:
L83     g: Dict[str,float]
L84     d: Dict[str,float]
L85
L86 @dataclass(frozen=True)
L87 class DRRSParams:
L88     corrM: int
L89     shrink: float
L90     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L91     D: Dict[str,float]
L92     cross_mu_gd: float
L93
L94 @dataclass(frozen=True)
L95 class PipelineConfig:
L96     weights: WeightsConfig
L97     drrs: DRRSParams
L98     price_max: float
L99
L100 # === 共通ユーティリティ（複数クラスで使用） ===
L101 # (unused local utils removed – use scorer.py versions if needed)
L102
L103 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L104
L105 def _post_slack(payload: dict):
L106     url = os.getenv("SLACK_WEBHOOK_URL")
L107     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L108     try:
L109         requests.post(url, json=payload).raise_for_status()
L110     except Exception as e:
L111         print(f"⚠️ Slack通知エラー: {e}")
L112
L113 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L114
L115 def _slack_debug(text: str, chunk=2800):
L116     i = 0
L117     while i < len(text):
L118         j = min(len(text), i + chunk)
L119         k = text.rfind("\n", i, j)
L120         j = k if k > i + 100 else j
L121         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L122         i = j
L123
L124 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L125     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC"]
L126     all_cols = _env_true("DEBUG_ALL_COLS", False)
L127     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L128
L129     Gp, Dp = set(prevG or []), set(prevD or [])
L130     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L131     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L132
L133     show_near = _env_true("DEBUG_NEAR5", True)
L134     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L135     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L136     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L137     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L138     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L139     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L140
L141     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L142     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L143
L144     def _fmt_near(lbl, ser, lst):
L145         if ser is None: return f"{lbl}: off"
L146         g = ser.get
L147         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L148         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L149
L150     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L151           _fmt_near("G near10", gs, g_miss),
L152           _fmt_near("D near10", ds, d_miss),
L153           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L154           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L155
L156     tbl="(df_z or columns not available)"
L157     if not fb.df_z.empty and cols:
L158         idx=[t for t in focus if t in fb.df_z.index]
L159         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L160
L161     miss_txt=""
L162     if _env_true("DEBUG_MISSING_LOGS", False):
L163         miss=getattr(fb,"missing_logs",None)
L164         if miss is not None and not miss.empty:
L165             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L166
L167     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L168
L169 def _disjoint_keepG(top_G, top_D, poolD):
L170     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L171     used, D, i = set(top_G), list(top_D), 0
L172     for j, t in enumerate(D):
L173         if t in used:
L174             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L175                 i += 1
L176             if i < len(poolD):
L177                 D[j] = poolD[i]; used.add(D[j]); i += 1
L178     return top_G, D
L179
L180 _state_file = lambda: os.path.join(RESULTS_DIR, "breadth_state.json")
L181 def load_mode(default: str="NORMAL") -> str:
L182     try:
L183         m = json.loads(open(_state_file()).read()).get("mode", default)
L184         return m if m in ("EMERG","CAUTION","NORMAL") else default
L185     except Exception:
L186         return default
L187 def save_mode(mode: str):
L188     try:
L189         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L190     except Exception:
L191         pass
L192
L193 # --- Breadth→自動しきい値→ヒステリシス→Slack先頭行を作成 ---
L194 def _build_breadth_lead_lines(inb) -> tuple[list[str], str]:
L195     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L196     C_ts = Scorer.trend_template_breadth_series(inb.px[inb.tickers], inb.spx, win_days=win)
L197     if C_ts.empty: raise RuntimeError("breadth series empty")
L198     warmup=int(os.getenv("BREADTH_WARMUP_DAYS","252")); base=C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts; C_full=int(C_ts.iloc[-1])
L199     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L200     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L201     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L202     th_in_rec, th_out_rec, th_norm_rec = max(N_G, q05), max(int(np.ceil(1.5*N_G)), q20), max(3*N_G, q60)
L203     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L204     th_in, th_out, th_norm, th_src = (th_in_rec, th_out_rec, th_norm_rec, "自動") if use_calib else (int(os.getenv("GTT_EMERG_IN",str(N_G))), int(os.getenv("GTT_EMERG_OUT",str(int(1.5*N_G)))), int(os.getenv("GTT_CAUTION_OUT",str(3*N_G))), "手動")
L205     prev = load_mode("NORMAL")
L206     if   prev == "EMERG":  mode = "EMERG" if (C_full < th_out) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L207     elif prev == "CAUTION": mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L208     else:                   mode = "EMERG" if (C_full < th_in) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L209     save_mode(mode)
L210     _MODE_JA={"EMERG":"緊急","CAUTION":"警戒","NORMAL":"通常"}; _MODE_EMOJI={"EMERG":"🚨","CAUTION":"⚠️","NORMAL":"🟢"}
L211     mode_ja,emoji,eff_days=_MODE_JA.get(mode,mode),_MODE_EMOJI.get(mode,"ℹ️"),len(base)
L212     lead_lines = [f"{emoji} *現在モード: {mode_ja}*", f"テンプレ合格本数: *{C_full}本*", "しきい値（{0}）".format(th_src),
L213         f"  ・緊急入り: <{th_in}本", f"  ・緊急解除: ≥{th_out}本", f"  ・通常復帰: ≥{th_norm}本",
L214         f"参考指標（過去~{win}営業日, 有効={eff_days}日）",
L215         f"  ・下位5%: {q05}本", f"  ・下位20%: {q20}本", f"  ・60%分位: {q60}本",]
L216     return lead_lines, mode
L217
L218 # === Input：外部I/Oと前処理（CSV/API・欠損補完） ===
L219 class Input:
L220     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L221         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L222         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L223
L224     # ---- （Input専用）EPS補完・FCF算出系 ----
L225     @staticmethod
L226     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L227         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L228         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L229         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L230
L231     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L232
L233     @staticmethod
L234     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L235         if df is None or df.empty: return None
L236         idx_lower={str(i).lower():i for i in df.index}
L237         for n in names:
L238             k=n.lower()
L239             if k in idx_lower: return df.loc[idx_lower[k]]
L240         return None
L241
L242     @staticmethod
L243     def _sum_l
```