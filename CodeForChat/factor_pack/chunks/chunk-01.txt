```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 作成日時: 2025-09-22 00:36:37 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 TOTAL_TARGETS = 20
L3
L4 # 基準のバケット数（NORMAL）
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # モード別の推奨バケット数
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # モード別のドリフト閾値（%）
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # モード別のTS（基本幅, 小数=割合）
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import logging, os, time, requests
L7 from concurrent.futures import ThreadPoolExecutor
L8 from dataclasses import dataclass
L9 from time import perf_counter
L10 from typing import Any, Dict, List, Tuple
L11
L12 import numpy as np
L13 import pandas as pd
L14 import yfinance as yf
L15 from scipy.stats import zscore  # used via scorer
L16
L17 from scorer import Scorer, ttm_div_yield_portfolio, _log, _as_numeric_series
L18 import config
L19
L20 import warnings, atexit, threading
L21 from collections import Counter, defaultdict
L22
L23 # ---------- 重複警告の集約ロジック ----------
L24 _warn_lock = threading.Lock()
L25 _warn_seen = set()                     # 初回表示済みキー
L26 _warn_count = Counter()                # (category, message, module) → 件数
L27 _warn_first_ctx = {}                   # 初回の (filename, lineno)
L28
L29 def _warn_key(message, category, filename, lineno, *_args, **_kwargs):
L30     # "同じ警告" を定義: カテゴリ + 正規化メッセージ + モジュールパス(先頭数階層)
L31     mod = filename.split("/site-packages/")[-1] if "/site-packages/" in filename else filename
L32     mod = mod.rsplit("/", 3)[-1]  # 長すぎ抑制（末尾3階層まで）
L33     msg = str(message).strip()
L34     return (category.__name__, msg, mod)
L35
L36 _orig_showwarning = warnings.showwarning
L37
L38 def _compact_showwarning(message, category, filename, lineno, file=None, line=None):
L39     key = _warn_key(message, category, filename, lineno)
L40     with _warn_lock:
L41         _warn_count[key] += 1
L42         if key not in _warn_seen:
L43             # 初回だけ1行で出す（カテゴリ | モジュール | メッセージ）
L44             _warn_seen.add(key)
L45             _warn_first_ctx[key] = (filename, lineno)
L46             # 1行フォーマット（行数節約）
L47             txt = f"[WARN][{category.__name__}] {message} | {filename}:{lineno}"
L48             print(txt)
L49         # 2回目以降は出さない（集約）
L50
L51 warnings.showwarning = _compact_showwarning
L52
L53 # ベースポリシー: 通常は警告を出す（default）→ ただし同一メッセージは集約
L54 warnings.resetwarnings()
L55 warnings.simplefilter("default")
L56
L57 # 2) ピンポイント間引き: yfinance 'Ticker.earnings' は "once"（初回のみ可視化）
L58 warnings.filterwarnings(
L59     "once",
L60     message="'Ticker.earnings' is deprecated",
L61     category=DeprecationWarning,
L62     module="yfinance"
L63 )
L64
L65 # 3) 最終サマリ: 同一警告が何回出たかを最後に1行で
L66 @atexit.register
L67 def _print_warning_summary():
L68     suppressed = []
L69     for key, cnt in _warn_count.items():
L70         if cnt > 1:
L71             (cat, msg, mod) = key
L72             filename, lineno = _warn_first_ctx.get(key, ("", 0))
L73             suppressed.append((cnt, cat, msg, mod, filename, lineno))
L74     if suppressed:
L75         suppressed.sort(reverse=True)  # 件数降順
L76         # 最多上位だけ出す（必要なら上限制御：ここでは上位10件）
L77         top = suppressed[:10]
L78         print(f"[WARN-SUMMARY] duplicated warning groups: {len(suppressed)}")
L79         for cnt, cat, msg, mod, filename, lineno in top:
L80             print(f"[WARN-SUMMARY] {cnt-1} more | [{cat}] {msg} | {mod} ({filename}:{lineno})")
L81         if len(suppressed) > len(top):
L82             print(f"[WARN-SUMMARY] ... and {len(suppressed)-len(top)} more groups suppressed")
L83
L84 # 4) 追加（任意）: 1ジョブあたりの総警告上限を設定したい場合
L85 #    例: 上限1000を超えたら以降は完全サイレント
L86 _WARN_HARD_LIMIT = int(os.getenv("WARN_HARD_LIMIT", "0") or "0")  # 0なら無効
L87 if _WARN_HARD_LIMIT > 0:
L88     _orig_warn_func = warnings.warn
L89     def _limited_warn(*a, **k):
L90         total = sum(_warn_count.values())
L91         if total < _WARN_HARD_LIMIT:
L92             return _orig_warn_func(*a, **k)
L93         # 超過後は捨てる（最後にsummaryだけ残る）
L94     warnings.warn = _limited_warn
L95
L96 # ---------- ここまでで警告の“可視性は維持”しつつ“重複で行数爆発”を抑止 ----------
L97
L98 # その他
L99 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L100
L101 logger = logging.getLogger(__name__)
L102 logging.basicConfig(level=(logging.INFO if debug_mode else logging.WARNING), force=True)
L103
L104 class T:
L105     t = perf_counter()
L106
L107     @staticmethod
L108     def log(tag):
L109         now = perf_counter()
L110         print(f"[T] {tag}: {now - T.t:.2f}s")
L111         T.t = now
L112
L113 T.log("start")
L114
L115 # === ユニバースと定数（冒頭に固定） ===
L116 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L117 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L118 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L119 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L120 g_weights = {'GROWTH_F':0.30,'MOM':0.60,'VOL':-0.10}
L121 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L122 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L123 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L124 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L125
L126 # DRRS 初期プール・各種パラメータ
L127 corrM = 45
L128 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L129 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L130
L131 # クロス相関ペナルティ（未定義なら設定）
L132 try: CROSS_MU_GD
L133 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L134
L135 # 出力関連
L136 RESULTS_DIR = "results"
L137 os.makedirs(RESULTS_DIR, exist_ok=True)
L138
L139 # === 共有DTO（クラス間I/O契約）＋ Config ===
L140 @dataclass(frozen=True)
L141 class InputBundle:
L142     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L143     cand: List[str]
L144     tickers: List[str]
L145     bench: str
L146     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L147     px: pd.DataFrame                # data['Close']
L148     spx: pd.Series                  # data['Close'][bench]
L149     tickers_bulk: object            # yfinance.Tickers
L150     info: Dict[str, dict]           # yfinance info per ticker
L151     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L152     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L153     returns: pd.DataFrame           # px[tickers].pct_change()
L154     missing_logs: pd.DataFrame
L155
L156 @dataclass(frozen=True)
L157 class FeatureBundle:
L158     df: pd.DataFrame
L159     df_z: pd.DataFrame
L160     g_score: pd.Series
L161     d_score_all: pd.Series
L162     missing_logs: pd.DataFrame
L163     df_full: pd.DataFrame | None = None
L164     df_full_z: pd.DataFrame | None = None
L165     scaler: Any | None = None
L166
L167 @dataclass(frozen=True)
L168 class SelectionBundle:
L169     resG: dict
L170     resD: dict
L171     top_G: List[str]
L172     top_D: List[str]
L173     init_G: List[str]
L174     init_D: List[str]
L175
L176 @dataclass(frozen=True)
L177 class WeightsConfig:
L178     g: Dict[str,float]
L179     d: Dict[str,float]
L180
L181 @dataclass(frozen=True)
L182 class DRRSParams:
L183     corrM: int
L184     shrink: float
L185     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L186     D: Dict[str,float]
L187     cross_mu_gd: float
L188
L189 @dataclass(frozen=True)
L190 class PipelineConfig:
L191     weights: WeightsConfig
L192     drrs: DRRSParams
L193     price_max: float
L194     debug_mode: bool = False
L195
L196 # === Utilities ===
L197 def aggregate_warnings(rows, key="message", max_items=10):
L198     """
L199     同一内容の警告を '×N' 表記でまとめる。機能変更なし（位置のみ移動）。
L200     rows: List[Dict] または List[str]
L201     """
L202     from collections import Counter
L203
L204     if not rows:
L205         return []
L206
L207     if isinstance(rows[0], dict):
L208         msgs = [str(r.get(key, "")) for r in rows if r.get(key)]
L209     else:
L210         msgs = [str(r) for r in rows if r]
L211
L212     cnt = Counter(msgs)
L213     out = [f"{m} ×{n}" if n > 1 else m for m, n in cnt.most_common()]
L214     return out[:max_items]
L215
L216
L217 def compact_missing_lines(missing_df, limit=300):
L218     if missing_df is None or getattr(missing_df, "empty", True):
L219         return []
L220
L221     df = missing_df.copy()
L222     if "ticker" not in df.columns:
L223         df = df.reset_index().rename(columns={"index": "ticker"})
L224
L225     out: list[str] = []
L226     for _, r in df.iterrows():
L227         tags: list[str] = []
L228         if bool(r.get("EPS_missing", False)):
L229             tags.append("eps")
L230         if bool(r.get("REV_missing", False)):
L231             tags.append("rev")
L232         if tags:
L233             ticker = r.get("ticker")
L234             if pd.isna(ticker) or ticker is None:
L235                 ticker = "(unknown)"
L236             else:
L237                 ticker = str(ticker)
L238             out.append(f"{ticker} : {', '.join(tags)}")
L239         if len(out) >= limit:
L240             out.append("...")
L241             break
L242
L243     return out
L244
L245 # === 共通ユーティリティ（複数クラスで使用） ===
L246 # (unused local utils removed – use scorer.py versions if needed)
L247
L248 def _build_missing_logs_after_impute(eps_df: pd.DataFrame) -> pd.DataFrame:
L249     df = eps_df.copy()
L250     required_cols = [
L251         "EPS_TTM",
L252         "EPS_Q_LastQ",
L253         "EPS_A_LATEST",
L254         "REV_TTM",
L255         "REV_Q_LastQ",
L256         "REV_A_LATEST",
L257     ]
L258     for col in required_cols:
L259         if col not in df.columns:
L260             df[col] = np.nan
L261
L262     miss_eps = df["EPS_TTM"].isna() & df["EPS_Q_LastQ"].isna() & df["EPS_A_LATEST"].isna()
L263     miss_rev = df["REV_TTM"].isna() & df["REV_Q_LastQ"].isna() & df["REV_A_LATEST"].isna()
L264
L265     rows: list[dict] = []
L266     for ticker, row in df.iterrows():
L267         eps_missing = bool(miss_eps.loc[ticker])
L268         rev_missing = bool(miss_rev.loc[ticker])
L269         if not (eps_missing or rev_missing):
L270             continue
L271         rows.append({
L272             "ticker": ticker,
L273             "EPS_missing": eps_missing,
L274             "REV_missing": rev_missing,
L275             "eps_imputed": bool(row.get("eps_imputed", False)),
L276             "EPS_TTM": row.get("EPS_TTM"),
L277             "EPS_Q_LastQ": row.get("EPS_Q_LastQ"),
L278             "EPS_A_LATEST": row.get("EPS_A_LATEST"),
L279             "REV_TTM": row.get("REV_TTM"),
L280             "REV_Q_LastQ": row.get("REV_Q_LastQ"),
L281             "REV_A_LATEST": row.get("REV_A_LATEST"),
L282         })
L283
L284     if not rows:
L285         return pd.DataFrame(
L286             columns=[
L287                 "ticker",
L288                 "EPS_missing",
L289                 "REV_missing",
L290                 "eps_imputed",
L291                 "EPS_TTM",
L292                 "EPS_Q_LastQ",
L293                 "EPS_A_LATEST",
L294                 "REV_TTM",
L295                 "R
```