```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, requests
L7 from time import perf_counter
L8 from dataclasses import dataclass, replace
L9 from typing import Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 class T:
L19     t = perf_counter()
L20     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L21
L22 T.log("start")
L23
L24 # === ユニバースと定数（冒頭に固定） ===
L25 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L26 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L27 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L28 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L29 g_weights = {'GRW':0.30,'MOM':0.55,'VOL':-0.15}
L30 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.7"))
L31 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L32 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L33 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L34
L35 # DRRS 初期プール・各種パラメータ
L36 corrM = 45
L37 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L38 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L39
L40 # クロス相関ペナルティ（未定義なら設定）
L41 try: CROSS_MU_GD
L42 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L43
L44 # 出力関連
L45 RESULTS_DIR = "results"
L46 os.makedirs(RESULTS_DIR, exist_ok=True)
L47
L48 # その他
L49 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L50 _API = (FINNHUB_API_KEY or "").strip()
L51
L52 def _fetch_eps_non_gaap_ttm_metric(sym: str, token: str) -> float:
L53     """
L54     Finnhub /stock/metric から Non-GAAPに相当するTTMを取得。
L55     第一候補: epsExclExtraItemsTTM（調整後EPSに相当）
L56     代替候補: epsNormalizedAnnual（年次だがNon-GAAPに近い）
L57     最終候補: epsTTM（GAAP、フォールバック）
L58     いずれも欠損なら NaN を返す（0.0は返さない）。
L59     """
L60     try:
L61         r = requests.get(
L62             "https://finnhub.io/api/v1/stock/metric",
L63             params={"symbol": sym, "metric": "all", "token": token},
L64             timeout=12,
L65         )
L66         j = r.json() if r.ok else {}
L67         m = (j or {}).get("metric", {}) or {}
L68         for k in ("epsExclExtraItemsTTM", "epsNormalizedAnnual", "epsTTM"):
L69             v = m.get(k, None)
L70             if v is not None:
L71                 try:
L72                     fv = float(v)
L73                     return fv
L74                 except Exception:
L75                     pass
L76         return np.nan
L77     except Exception:
L78         return np.nan
L79
L80 # === 共有DTO（クラス間I/O契約）＋ Config ===
L81 @dataclass(frozen=True)
L82 class InputBundle:
L83     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L84     cand: List[str]
L85     tickers: List[str]
L86     bench: str
L87     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L88     px: pd.DataFrame                # data['Close']
L89     spx: pd.Series                  # data['Close'][bench]
L90     tickers_bulk: object            # yfinance.Tickers
L91     info: Dict[str, dict]           # yfinance info per ticker
L92     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L93     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L94     returns: pd.DataFrame           # px[tickers].pct_change()
L95
L96 @dataclass(frozen=True)
L97 class FeatureBundle:
L98     df: pd.DataFrame
L99     df_z: pd.DataFrame
L100     g_score: pd.Series
L101     d_score_all: pd.Series
L102     missing_logs: pd.DataFrame
L103
L104 @dataclass(frozen=True)
L105 class SelectionBundle:
L106     resG: dict
L107     resD: dict
L108     top_G: List[str]
L109     top_D: List[str]
L110     init_G: List[str]
L111     init_D: List[str]
L112
L113 @dataclass(frozen=True)
L114 class WeightsConfig:
L115     g: Dict[str,float]
L116     d: Dict[str,float]
L117
L118 @dataclass(frozen=True)
L119 class DRRSParams:
L120     corrM: int
L121     shrink: float
L122     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L123     D: Dict[str,float]
L124     cross_mu_gd: float
L125
L126 @dataclass(frozen=True)
L127 class PipelineConfig:
L128     weights: WeightsConfig
L129     drrs: DRRSParams
L130     price_max: float
L131
L132 # === 共通ユーティリティ（複数クラスで使用） ===
L133 # (unused local utils removed – use scorer.py versions if needed)
L134
L135 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L136
L137 def _post_slack(payload: dict):
L138     url = os.getenv("SLACK_WEBHOOK_URL")
L139     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L140     try:
L141         requests.post(url, json=payload).raise_for_status()
L142     except Exception as e:
L143         print(f"⚠️ Slack通知エラー: {e}")
L144
L145 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L146
L147 def _slack_debug(text: str, chunk=2800):
L148     i = 0
L149     while i < len(text):
L150         j = min(len(text), i + chunk)
L151         k = text.rfind("\n", i, j)
L152         j = k if k > i + 100 else j
L153         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L154         i = j
L155
L156 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L157     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC","eps_ttm","nEPS_ttm","eps_imputed","fcf_ttm","fcf_imputed"]
L158     all_cols = _env_true("DEBUG_ALL_COLS", False)
L159     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L160
L161     Gp, Dp = set(prevG or []), set(prevD or [])
L162     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L163     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L164
L165     show_near = _env_true("DEBUG_NEAR5", True)
L166     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L167     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L168     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L169     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L170     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L171     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L172
L173     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L174     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L175
L176     def _fmt_near(lbl, ser, lst):
L177         if ser is None: return f"{lbl}: off"
L178         g = ser.get
L179         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L180         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L181
L182     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L183           _fmt_near("G near10", gs, g_miss),
L184           _fmt_near("D near10", ds, d_miss),
L185           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L186           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L187
L188     tbl="(df_z or columns not available)"
L189     if not fb.df_z.empty and cols:
L190         idx=[t for t in focus if t in fb.df_z.index]
L191         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L192
L193     miss_txt=""
L194     if _env_true("DEBUG_MISSING_LOGS", False):
L195         miss=getattr(fb,"missing_logs",None)
L196         if miss is not None and not miss.empty:
L197             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L198
L199     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L200
L201 def _disjoint_keepG(top_G, top_D, poolD):
L202     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L203     used, D, i = set(top_G), list(top_D), 0
L204     for j, t in enumerate(D):
L205         if t in used:
L206             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L207                 i += 1
L208             if i < len(poolD):
L209                 D[j] = poolD[i]; used.add(D[j]); i += 1
L210     return top_G, D
L211
L212
L213 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L214                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L215     import pandas as pd, numpy as np
L216     sel = list(pick)
L217     if not sel: return sel
L218     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L219     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L220     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L221     thresh = kth - delta_z * sigma
L222     ranked_all = agg.sort_values(ascending=False)
L223     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L224     for t in cand:
L225         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L226         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L227         if within_score or within_rank:
L228             non_inc = [x for x in sel if x not in incumbents]
L229             if not non_inc: break
L230             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L231             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L232                 sel.remove(weakest); sel.append(t)
L233     if len(sel) > n_target:
L234         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L235     return sel
L236
L237
L238 # === Input：外部I/Oと前処理（CSV/API・欠損補完） ===
L239 class Input:
L240     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L241         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L242         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L243
L244     # ---- （Input専用）EPS補完・FCF算出系 ----
L245     @staticmethod
L246     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L247         out_col = out_col or ttm_col; df = df.copy(); df["eps_impute
```