```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <factor.py>
```text
L1 """
L2 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
L3 â”ƒ ROLE of factor.py                                     â”ƒ
L4 â”ƒ  - Orchestration ONLYï¼ˆå¤–éƒ¨I/Oãƒ»SSOTãƒ»Slackå‡ºåŠ›ï¼‰     â”ƒ
L5 â”ƒ  - è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæ¡ç‚¹/ãƒ•ã‚£ãƒ«ã‚¿/ç›¸é–¢ä½æ¸›ï¼‰ã¯ scorer.py â”ƒ
L6 â”ƒ  - ã“ã“ã§ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…/å¤‰æ›´ã—ãªã„                   â”ƒ
L7 â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
L8 """
L9 # === NOTE: æ©Ÿèƒ½ãƒ»å…¥å‡ºåŠ›ãƒ»ãƒ­ã‚°æ–‡è¨€ãƒ»ä¾‹å¤–æŒ™å‹•ã¯ä¸å¤‰ã€‚å®‰å…¨ãªçŸ­ç¸®ï¼ˆimportçµ±åˆ/è¤‡æ•°ä»£å…¥/å†…åŒ…è¡¨è¨˜/ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³/ä¸€è¡ŒåŒ–/ç©ºè¡Œåœ§ç¸®ãªã©ï¼‰ã®ã¿é©ç”¨ ===
L10 BONUS_COEFF = 0.4   # æ”»ã‚=0.3 / ä¸­åº¸=0.4 / å®ˆã‚Š=0.5
L11 import os, json, time, requests
L12 from time import perf_counter
L13 from dataclasses import dataclass
L14 from typing import Dict, List
L15 from concurrent.futures import ThreadPoolExecutor
L16 import numpy as np
L17 import pandas as pd
L18 import yfinance as yf
L19 from scipy.stats import zscore  # used via scorer
L20 from scorer import Scorer, ttm_div_yield_portfolio
L21
L22
L23 class T:
L24     t = perf_counter()
L25     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L26
L27
L28 T.log("start")
L29
L30 # ===== ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã¨å®šæ•°ï¼ˆå†’é ­ã«å›ºå®šï¼‰ =====
L31 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L32 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L33 CAND_PRICE_MAX, bench = 450, '^GSPC'  # ä¾¡æ ¼ä¸Šé™ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
L34 N_G, N_D = 12, 13  # G/Dæ ã‚µã‚¤ã‚º
L35 g_weights = {'GRW':0.40,'MOM':0.45,'VOL':-0.15}
L36 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L37 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L38 D_weights = {'QAL':0.15,'YLD':0.15,'VOL':-0.45,'TRD':0.25}
L39 def _fmt_w(w): return " ".join(f"{k}{int(v*100)}" for k,v in w.items())
L40
L41 # DRRS åˆæœŸãƒ—ãƒ¼ãƒ«ãƒ»å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
L42 corrM = 45
L43 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L44 DRRS_SHRINK = 0.10  # æ®‹å·®ç›¸é–¢ã®å¯¾è§’ã‚·ãƒ¥ãƒªãƒ³ã‚¯ï¼ˆåŸºç¤ï¼‰
L45
L46 # ã‚¯ãƒ­ã‚¹ç›¸é–¢ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæœªå®šç¾©ãªã‚‰è¨­å®šï¼‰
L47 try: CROSS_MU_GD
L48 except NameError: CROSS_MU_GD = 0.40  # æ¨å¥¨ 0.35â€“0.45ï¼ˆlam=0.85æƒ³å®šï¼‰
L49
L50 # å‡ºåŠ›é–¢é€£
L51 RESULTS_DIR = "results"
L52 os.makedirs(RESULTS_DIR, exist_ok=True)
L53
L54 # ãã®ä»–
L55 debug_mode, FINNHUB_API_KEY = False, os.environ.get("FINNHUB_API_KEY")
L56
L57
L58 # ===== å…±æœ‰DTOï¼ˆã‚¯ãƒ©ã‚¹é–“I/Oå¥‘ç´„ï¼‰ï¼‹ Config =====
L59 @dataclass(frozen=True)
L60 class InputBundle:
L61     # Input â†’ Scorer ã§å—ã‘æ¸¡ã™ç´ æï¼ˆI/Oç¦æ­¢ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
L62     cand: List[str]
L63     tickers: List[str]
L64     bench: str
L65     data: pd.DataFrame              # yfinance downloadçµæœï¼ˆ'Close','Volume'ç­‰ã®éšå±¤åˆ—ï¼‰
L66     px: pd.DataFrame                # data['Close']
L67     spx: pd.Series                  # data['Close'][bench]
L68     tickers_bulk: object            # yfinance.Tickers
L69     info: Dict[str, dict]           # yfinance info per ticker
L70     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L71     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L72     returns: pd.DataFrame           # px[tickers].pct_change()
L73
L74 @dataclass(frozen=True)
L75 class FeatureBundle:
L76     df: pd.DataFrame
L77     df_z: pd.DataFrame
L78     g_score: pd.Series
L79     d_score_all: pd.Series
L80     missing_logs: pd.DataFrame
L81
L82 @dataclass(frozen=True)
L83 class SelectionBundle:
L84     resG: dict
L85     resD: dict
L86     top_G: List[str]
L87     top_D: List[str]
L88     init_G: List[str]
L89     init_D: List[str]
L90
L91 @dataclass(frozen=True)
L92 class WeightsConfig:
L93     g: Dict[str,float]
L94     d: Dict[str,float]
L95
L96 @dataclass(frozen=True)
L97 class DRRSParams:
L98     corrM: int
L99     shrink: float
L100     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L101     D: Dict[str,float]
L102     cross_mu_gd: float
L103
L104 @dataclass(frozen=True)
L105 class PipelineConfig:
L106     weights: WeightsConfig
L107     drrs: DRRSParams
L108     price_max: float
L109
L110
L111 # ===== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè¤‡æ•°ã‚¯ãƒ©ã‚¹ã§ä½¿ç”¨ï¼‰ =====
L112 # (unused local utils removed â€“ use scorer.py versions if needed)
L113
L114 def _env_true(name: str, default=False):
L115     v = os.getenv(name)
L116     return (v or str(default)).strip().lower() == "true"
L117
L118 def _post_slack(payload: dict):
L119     url = os.getenv("SLACK_WEBHOOK_URL")
L120     if not url: 
L121         print("âš ï¸ SLACK_WEBHOOK_URL æœªè¨­å®š"); return
L122     try:
L123         requests.post(url, json=payload).raise_for_status()
L124     except Exception as e:
L125         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L126
L127 def _slack(message, code=False):
L128     _post_slack({"text": f"```{message}```" if code else message})
L129
L130 def _slack_debug(text: str, chunk=2800):
L131     i = 0
L132     while i < len(text):
L133         j = min(len(text), i+chunk); k = text.rfind("\n", i, j); j = k if k > i+100 else j
L134         _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":f"```{text[i:j]}```"}}]})
L135         i = j
L136
L137 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L138     want=["TR","EPS","REV","ROE","BETA_RAW","FCF","RS","TR_str","DIV_STREAK","DSC"]
L139     all_cols = _env_true("DEBUG_ALL_COLS", False)
L140     cols = list(fb.df_z.columns if all_cols else [c for c in want if c in fb.df_z.columns])
L141
L142     Gp, Dp = set(prevG or []), set(prevD or [])
L143     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L144     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L145
L146     show_near = _env_true("DEBUG_NEAR5", True)
L147     gs = getattr(fb,"g_score",None); ds = getattr(fb,"d_score_all",None)
L148     gs = gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None
L149     ds = ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None
L150     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L151     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L152     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L153
L154     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L155     focus = list(fb.df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss))[:max_rows]
L156
L157     def _fmt_near(lbl, ser, lst):
L158         if ser is None: return f"{lbl}: off"
L159         parts=[f"{t}:{ser.get(t,float('nan')):.3f}" if pd.notna(ser.get(t)) else f"{t}:nan" for t in lst]
L160         return f"{lbl}: "+(", ".join(parts) if parts else "-")
L161
L162     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L163           _fmt_near("G near10", gs, g_miss),
L164           _fmt_near("D near10", ds, d_miss),
L165           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L166           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L167
L168     tbl="(df_z or columns not available)"
L169     if not fb.df_z.empty and cols:
L170         idx=[t for t in focus if t in fb.df_z.index]
L171         tbl=fb.df_z.loc[idx, cols].round(3).to_string(max_rows=None, max_cols=None)
L172
L173     miss_txt=""
L174     if _env_true("DEBUG_MISSING_LOGS", False):
L175         miss=getattr(fb,"missing_logs",None)
L176         if miss is not None and not miss.empty:
L177             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L178
L179     return "\n".join(head+["\nChanged/Selected (+ Near Miss)", tbl])+miss_txt
L180
L181 def _disjoint_keepG(top_G, top_D, poolD):
L182     """
L183     Gã«å«ã¾ã‚Œã‚‹éŠ˜æŸ„ã‚’Dã‹ã‚‰é™¤å»ã—ã€Dã¯poolDï¼ˆæ¬¡ç‚¹ï¼‰ã§è£œå……ã™ã‚‹ã€‚
L184     - å¼•æ•°:
L185         top_G: List[str]  â€¦ Gæœ€çµ‚12éŠ˜æŸ„
L186         top_D: List[str]  â€¦ Dæœ€çµ‚13éŠ˜æŸ„ï¼ˆé‡è¤‡ã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰
L187         poolD: List[str]  â€¦ Då€™è£œã®é †ä½ãƒªã‚¹ãƒˆï¼ˆtop_Dã‚’å«ã‚€ä¸Šä½æ‹¡å¼µï¼‰
L188     - æˆ»ã‚Šå€¤: (top_G, top_D_disjoint)
L189     - æŒ™å‹•:
L190         1) Dã«Gé‡è¤‡ãŒã‚ã‚Œã°é †ã«ç½®æ›
L191         2) ç½®æ›å€™è£œã¯ poolD ã‹ã‚‰ã€æ—¢ä½¿ç”¨(GâˆªD)ã‚’é¿ã‘ã¦å‰ã‹ã‚‰æ¡ç”¨
L192         3) è£œå……åˆ†ãŒå°½ããŸå ´åˆã¯å…ƒã®éŠ˜æŸ„ã‚’æ®‹ã™ï¼ˆå®‰å…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
L193     """
L194     used, D, i = set(top_G), list(top_D), 0
L195     for j, t in enumerate(D):
L196         if t in used:
L197             while i < len(poolD) and (poolD[i] in used or poolD[i] in D): i += 1
L198             if i < len(poolD): D[j] = poolD[i]; used.add(D[j]); i += 1
L199     return top_G, D
L200
L201 _state_file = lambda: os.path.join(RESULTS_DIR, "breadth_state.json")
L202 def load_mode(default: str="NORMAL") -> str:
L203     try:
L204         m = json.loads(open(_state_file()).read()).get("mode", default)
L205         return m if m in ("EMERG","CAUTION","NORMAL") else default
L206     except Exception: return default
L207 def save_mode(mode: str):
L208     try: open(_state_file(),"w").write(json.dumps({"mode": mode}))
L209     except Exception: pass
L210
L211 # --- Breadthâ†’è‡ªå‹•ã—ãã„å€¤â†’ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹â†’Slackå…ˆé ­è¡Œã‚’ä½œæˆ ---
L212 def _build_breadth_lead_lines(inb) -> tuple[list[str], str]:
L213     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L214     C_ts = Scorer.trend_template_breadth_series(inb.px[inb.tickers], inb.spx, win_days=win)
L215     if C_ts.empty: raise RuntimeError("breadth series empty")
L216     warmup = int(os.getenv("BREADTH_WARMUP_DAYS", "252"))
L217     base = C_ts.iloc[warmup:] if len(C_ts) > warmup else C_ts
L218     C_full = int(C_ts.iloc[-1])
L219     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L220     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L221     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L222     th_in_rec, th_out_rec, th_norm_rec = max(N_G, q05), max(int(np.ceil(1.5*N_G)), q20), max(3*N_G, q60)
L223     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L224     th_in, th_out, th_norm, th_src = (th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•") if use_calib else (
L225         int(os.getenv("GTT_EMERG_IN",    str(N_G))),
L226         int(os.getenv("GTT_EMERG_OUT",   str(int(1.5*N_G)))),
L227         int(os.getenv("GTT_CAUTION_OUT", str(3*N_G))),
L228         "æ‰‹å‹•"
L229     )
L230     prev = load_mode("NORMAL")
L231     if   prev == "EMERG":  mode = "EMERG" if (C_full < th_out) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L232     elif prev == "CAUTION": mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L233     else:                   mode = "EMERG" if (C_full < th_in) else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L234     save_mode(mode)
L235     _MODE_JA = {"EMERG":"ç·Šæ€¥", "CAUTION":"è­¦æˆ’", "NORMAL":"é€šå¸¸"}; _MODE_EMOJI = {"EMERG":"ğŸš¨", "CAUTION":"âš ï¸", "NORMAL":"ğŸŸ¢"}
L236     mode_ja, emoji, eff_days = _MODE_JA.get(mode, mode), _MODE_EMOJI.get(mode, "â„¹ï¸"), len(base)
L237     lead_lines = [
L238         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*", f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*", "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L239         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬", f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬", f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L240         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L241         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬", f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬", f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L242     ]
L243     return lead_lines, mode
L244
L245
L246 # ===== Inputï¼šå¤–éƒ¨I/Oã¨å‰å‡¦ç†ï¼ˆCSV/APIãƒ»æ¬ æè£œå®Œï¼‰ =====
L247 class Input:
L248     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L249         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L250         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L251
L252     # ---- ï¼ˆInputå°‚ç”¨ï¼‰EPSè£œå®Œãƒ»FCFç®—å‡ºç³» ----
L253     @staticmethod
L254     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L255         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L256        
```