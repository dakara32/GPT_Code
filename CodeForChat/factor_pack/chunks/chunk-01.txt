```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 作成日時: 2025-09-24 13:02:35 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 TOTAL_TARGETS = 20
L3
L4 # 基準のバケット数（NORMAL）
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # モード別の推奨バケット数
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # モード別のドリフト閾値（%）
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # モード別のTS（基本幅, 小数=割合）
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 import logging, os, time, requests
L4 from concurrent.futures import ThreadPoolExecutor
L5 from dataclasses import dataclass
L6 from time import perf_counter
L7 from typing import Any, Dict, List, Tuple
L8
L9 import numpy as np
L10 import pandas as pd
L11 import yfinance as yf
L12 from scipy.stats import zscore  # used via scorer
L13
L14 from scorer import Scorer, ttm_div_yield_portfolio, _log, _as_numeric_series
L15 import config
L16
L17 import warnings, atexit, threading
L18 from collections import Counter, defaultdict
L19
L20 # === 定数・設定・DTO（import直後に集約） ===
L21 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L22 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L23 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L24
L25 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L26
L27 _CSV_LOAD_START = perf_counter()
L28 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L29 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L30 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L31 g_weights = {'GROWTH_F':0.30,'MOM':0.60,'VOL':-0.10}
L32 D_BETA_MODE = os.environ.get("D_BETA_MODE", "z").lower()   # "raw" or "z"
L33 D_BETA_CUTOFF = float(os.environ.get("D_BETA_CUTOFF", "-0.8"))
L34 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_CUTOFF}}}
L35 D_weights = {'QAL':0.15,'YLD':0.25,'VOL':-0.40,'TRD':0.20}
L36 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L37
L38 def _zscore_series(s: pd.Series) -> pd.Series:
L39     # NaNはそのまま、標準偏差0なら全NaNにする（暴走防止）
L40     v = s.astype(float)
L41     m, std = v.mean(skipna=True), v.std(skipna=True, ddof=0)
L42     if not np.isfinite(std) or std == 0:
L43         return pd.Series(index=v.index, dtype=float)
L44     return (v - m) / std
L45
L46 # DRRS 初期プール・各種パラメータ
L47 corrM = 45
L48 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L49 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L50
L51 # クロス相関ペナルティ（未定義なら設定）
L52 try: CROSS_MU_GD
L53 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L54
L55 # 出力関連
L56 RESULTS_DIR = "results"
L57 os.makedirs(RESULTS_DIR, exist_ok=True)
L58
L59 # === 共有DTO（クラス間I/O契約）＋ Config ===
L60 @dataclass(frozen=True)
L61 class InputBundle:
L62     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L63     cand: List[str]
L64     tickers: List[str]
L65     bench: str
L66     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L67     px: pd.DataFrame                # data['Close']
L68     spx: pd.Series                  # data['Close'][bench]
L69     tickers_bulk: object            # yfinance.Tickers
L70     info: Dict[str, dict]           # yfinance info per ticker
L71     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L72     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L73     returns: pd.DataFrame           # px[tickers].pct_change()
L74     missing_logs: pd.DataFrame
L75
L76 @dataclass(frozen=True)
L77 class FeatureBundle:
L78     df: pd.DataFrame
L79     df_z: pd.DataFrame
L80     g_score: pd.Series
L81     d_score_all: pd.Series
L82     missing_logs: pd.DataFrame
L83     df_full: pd.DataFrame | None = None
L84     df_full_z: pd.DataFrame | None = None
L85     scaler: Any | None = None
L86
L87 @dataclass(frozen=True)
L88 class SelectionBundle:
L89     resG: dict
L90     resD: dict
L91     top_G: List[str]
L92     top_D: List[str]
L93     init_G: List[str]
L94     init_D: List[str]
L95
L96 @dataclass(frozen=True)
L97 class WeightsConfig:
L98     g: Dict[str,float]
L99     d: Dict[str,float]
L100
L101 @dataclass(frozen=True)
L102 class DRRSParams:
L103     corrM: int
L104     shrink: float
L105     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L106     D: Dict[str,float]
L107     cross_mu_gd: float
L108
L109 @dataclass(frozen=True)
L110 class PipelineConfig:
L111     weights: WeightsConfig
L112     drrs: DRRSParams
L113     price_max: float
L114     debug_mode: bool = False
L115
L116 # ---------- 重複警告の集約ロジック ----------
L117 _warn_lock = threading.Lock()
L118 _warn_seen = set()                     # 初回表示済みキー
L119 _warn_count = Counter()                # (category, message, module) → 件数
L120 _warn_first_ctx = {}                   # 初回の (filename, lineno)
L121
L122 def _warn_key(message, category, filename, lineno, *_args, **_kwargs):
L123     # "同じ警告" を定義: カテゴリ + 正規化メッセージ + モジュールパス(先頭数階層)
L124     mod = filename.split("/site-packages/")[-1] if "/site-packages/" in filename else filename
L125     mod = mod.rsplit("/", 3)[-1]  # 長すぎ抑制（末尾3階層まで）
L126     msg = str(message).strip()
L127     return (category.__name__, msg, mod)
L128
L129 _orig_showwarning = warnings.showwarning
L130
L131 def _compact_showwarning(message, category, filename, lineno, file=None, line=None):
L132     key = _warn_key(message, category, filename, lineno)
L133     with _warn_lock:
L134         _warn_count[key] += 1
L135         if key not in _warn_seen:
L136             # 初回だけ1行で出す（カテゴリ | モジュール | メッセージ）
L137             _warn_seen.add(key)
L138             _warn_first_ctx[key] = (filename, lineno)
L139             # 1行フォーマット（行数節約）
L140             txt = f"[WARN][{category.__name__}] {message} | {filename}:{lineno}"
L141             print(txt)
L142         # 2回目以降は出さない（集約）
L143
L144 warnings.showwarning = _compact_showwarning
L145
L146 # ベースポリシー: 通常は警告を出す（default）→ ただし同一メッセージは集約
L147 warnings.resetwarnings()
L148 warnings.simplefilter("default")
L149
L150 # 2) ピンポイント間引き: yfinance 'Ticker.earnings' は "once"（初回のみ可視化）
L151 warnings.filterwarnings(
L152     "once",
L153     message="'Ticker.earnings' is deprecated",
L154     category=DeprecationWarning,
L155     module="yfinance"
L156 )
L157
L158 # 3) 最終サマリ: 同一警告が何回出たかを最後に1行で
L159 @atexit.register
L160 def _print_warning_summary():
L161     suppressed = []
L162     for key, cnt in _warn_count.items():
L163         if cnt > 1:
L164             (cat, msg, mod) = key
L165             filename, lineno = _warn_first_ctx.get(key, ("", 0))
L166             suppressed.append((cnt, cat, msg, mod, filename, lineno))
L167     if suppressed:
L168         suppressed.sort(reverse=True)  # 件数降順
L169         # 最多上位だけ出す（必要なら上限制御：ここでは上位10件）
L170         top = suppressed[:10]
L171         print(f"[WARN-SUMMARY] duplicated warning groups: {len(suppressed)}")
L172         for cnt, cat, msg, mod, filename, lineno in top:
L173             print(f"[WARN-SUMMARY] {cnt-1} more | [{cat}] {msg} | {mod} ({filename}:{lineno})")
L174         if len(suppressed) > len(top):
L175             print(f"[WARN-SUMMARY] ... and {len(suppressed)-len(top)} more groups suppressed")
L176
L177 # 4) 追加（任意）: 1ジョブあたりの総警告上限を設定したい場合
L178 #    例: 上限1000を超えたら以降は完全サイレント
L179 _WARN_HARD_LIMIT = int(os.getenv("WARN_HARD_LIMIT", "0") or "0")  # 0なら無効
L180 if _WARN_HARD_LIMIT > 0:
L181     _orig_warn_func = warnings.warn
L182     def _limited_warn(*a, **k):
L183         total = sum(_warn_count.values())
L184         if total < _WARN_HARD_LIMIT:
L185             return _orig_warn_func(*a, **k)
L186         # 超過後は捨てる（最後にsummaryだけ残る）
L187     warnings.warn = _limited_warn
L188
L189 # ---------- ここまでで警告の“可視性は維持”しつつ“重複で行数爆発”を抑止 ----------
L190
L191 # その他
L192 logger = logging.getLogger(__name__)
L193 logging.basicConfig(level=(logging.INFO if debug_mode else logging.WARNING), force=True)
L194
L195 class T:
L196     t = perf_counter()
L197
L198     @staticmethod
L199     def log(tag):
L200         now = perf_counter()
L201         print(f"[T] {tag}: {now - T.t:.2f}s")
L202         T.t = now
L203
L204 T.log("start")
L205 try:
L206     T.t = _CSV_LOAD_START
L207 except NameError:
L208     pass
L209 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L210
L211 # === Utilities ===
L212 def aggregate_warnings(rows, key="message", max_items=10):
L213     """
L214     同一内容の警告を '×N' 表記でまとめる。機能変更なし（位置のみ移動）。
L215     rows: List[Dict] または List[str]
L216     """
L217     from collections import Counter
L218
L219     if not rows:
L220         return []
L221
L222     if isinstance(rows[0], dict):
L223         msgs = [str(r.get(key, "")) for r in rows if r.get(key)]
L224     else:
L225         msgs = [str(r) for r in rows if r]
L226
L227     cnt = Counter(msgs)
L228     out = [f"{m} ×{n}" if n > 1 else m for m, n in cnt.most_common()]
L229     return out[:max_items]
L230
L231
L232 def compact_missing_lines(missing_df, limit=300):
L233     if missing_df is None or getattr(missing_df, "empty", True):
L234         return []
L235
L236     df = missing_df.copy()
L237     if "ticker" not in df.columns:
L238         df = df.reset_index().rename(columns={"index": "ticker"})
L239
L240     out: list[str] = []
L241     for _, r in df.iterrows():
L242         tags: list[str] = []
L243         if bool(r.get("EPS_missing", False)):
L244             tags.append("eps")
L245         if bool(r.get("REV_missing", False)):
L246             tags.append("rev")
L247         if tags:
L248             ticker = r.get("ticker")
L249             if pd.isna(ticker) or ticker is None:
L250                 ticker = "(unknown)"
L251             else:
L252                 ticker = str(ticker)
L253             out.append(f"{ticker} : {', '.join(tags)}")
L254         if len(out) >= limit:
L255             out.append("...")
L256             break
L257
L258     return out
L259
L260 # === 共通ユーティリティ（複数クラスで使用） ===
L261 # (unused local utils removed – use scorer.py versions if needed)
L262
L263 def _build_missing_logs_after_impute(eps_df: pd.DataFrame) -> pd.DataFrame:
L264     df = eps_df.copy()
L265     required_cols = [
L266         "EPS_TTM",
L267         "EPS_Q_LastQ",
L268         "EPS_A_LATEST",
L269         "REV_TTM",
L270         "REV_Q_LastQ",
L271         "REV_A_LATEST",
L272     ]
L273     for col in required_cols:
L274         if col not in df.columns:
L275             df[col] = np.nan
L276
L277     miss_eps = df["EPS_TTM"].isna() & df["EPS_Q_LastQ"].isna() & df["EPS_A_LATEST"].isna()
L278     miss_rev = df["REV_TTM"].isna() & df["REV_Q_LastQ"].isna() & df["REV_A_LATEST"].isna()
L279
L280     rows: list[dict] = []
L281     for ticker, row in df.iterrows():
L282         eps_missing = bool(miss_eps.loc[ticker])
L283         rev_missing = bool(miss_rev.loc[ticker])
L284         if not (eps_missing or rev_missing):
L285             continue
L286         rows.append({
L287             "ticker": ticker,
L288             "EPS_missing": eps_missing,
L289             "REV_missing": rev_missing,
L290             "eps_imputed": bool(row.get("eps_imputed", False)),
L291             "EPS_TTM": row.get("EPS_TTM"),
L292             "EPS_Q_LastQ": row.get("EPS_Q_LastQ"),
L293             "EPS_A_LATEST": row.get("EPS_A_LATEST"),
L294             
```