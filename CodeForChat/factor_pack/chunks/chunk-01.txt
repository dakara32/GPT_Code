```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 作成日時: 2025-09-18 20:30:58 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, requests
L7 import logging
L8 from time import perf_counter
L9 from dataclasses import dataclass
L10 from typing import Any, Dict, List
L11 from concurrent.futures import ThreadPoolExecutor
L12 from types import SimpleNamespace
L13 import numpy as np
L14 import pandas as pd
L15 import yfinance as yf
L16 from scipy.stats import zscore  # used via scorer
L17 from scorer import Scorer, ttm_div_yield_portfolio
L18 import config
L19
L20 # その他
L21 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L22
L23 logger = logging.getLogger(__name__)
L24 if debug_mode:
L25     logging.basicConfig(level=logging.INFO, force=True)
L26 else:
L27     logging.basicConfig(level=logging.WARNING, force=True)
L28
L29 class T:
L30     t = perf_counter()
L31     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L32
L33 T.log("start")
L34
L35 # === ユニバースと定数（冒頭に固定） ===
L36 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L37 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L38 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L39 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L40 g_weights = {'GROWTH_F':0.35,'MOM':0.55,'VOL':-0.10}
L41 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L42 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L43 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L44 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L45
L46 # DRRS 初期プール・各種パラメータ
L47 corrM = 45
L48 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L49 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L50
L51 # クロス相関ペナルティ（未定義なら設定）
L52 try: CROSS_MU_GD
L53 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L54
L55 # 出力関連
L56 RESULTS_DIR = "results"
L57 os.makedirs(RESULTS_DIR, exist_ok=True)
L58
L59 # === 共有DTO（クラス間I/O契約）＋ Config ===
L60 @dataclass(frozen=True)
L61 class InputBundle:
L62     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L63     cand: List[str]
L64     tickers: List[str]
L65     bench: str
L66     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L67     px: pd.DataFrame                # data['Close']
L68     spx: pd.Series                  # data['Close'][bench]
L69     tickers_bulk: object            # yfinance.Tickers
L70     info: Dict[str, dict]           # yfinance info per ticker
L71     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L72     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L73     returns: pd.DataFrame           # px[tickers].pct_change()
L74
L75 @dataclass(frozen=True)
L76 class FeatureBundle:
L77     df: pd.DataFrame
L78     df_z: pd.DataFrame
L79     g_score: pd.Series
L80     d_score_all: pd.Series
L81     missing_logs: pd.DataFrame
L82     df_full: pd.DataFrame | None = None
L83     df_full_z: pd.DataFrame | None = None
L84     scaler: Any | None = None
L85
L86 @dataclass(frozen=True)
L87 class SelectionBundle:
L88     resG: dict
L89     resD: dict
L90     top_G: List[str]
L91     top_D: List[str]
L92     init_G: List[str]
L93     init_D: List[str]
L94
L95 @dataclass(frozen=True)
L96 class WeightsConfig:
L97     g: Dict[str,float]
L98     d: Dict[str,float]
L99
L100 @dataclass(frozen=True)
L101 class DRRSParams:
L102     corrM: int
L103     shrink: float
L104     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L105     D: Dict[str,float]
L106     cross_mu_gd: float
L107
L108 @dataclass(frozen=True)
L109 class PipelineConfig:
L110     weights: WeightsConfig
L111     drrs: DRRSParams
L112     price_max: float
L113
L114 # === 共通ユーティリティ（複数クラスで使用） ===
L115 # (unused local utils removed – use scorer.py versions if needed)
L116
L117 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L118
L119 _DEBUG_COL_ALIAS = {
L120     "GROWTH_F": "GRW",
L121     "GROWTH_F_RAW": "GRW_RAW",
L122     "TREND_SLOPE_EPS": "TR_EPS",
L123     "TREND_SLOPE_EPS_RAW": "TR_EPS_RAW",
L124     "TREND_SLOPE_REV": "TR_REV",
L125     "TREND_SLOPE_REV_RAW": "TR_REV_RAW",
L126     "TREND_SLOPE_EPS_YR": "TR_EPS_YR",
L127     "TREND_SLOPE_EPS_YR_RAW": "TR_EPS_YR_RAW",
L128     "TREND_SLOPE_REV_YR": "TR_REV_YR",
L129     "TREND_SLOPE_REV_YR_RAW": "TR_REV_YR_RAW",
L130     "BETA": "BETA_RAW",
L131 }
L132
L133 _DEBUG_COL_ORDER = [
L134     "GRW", "GRW_RAW",
L135     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L136     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L137     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L138     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L139     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW", "REV_ANN_STREAK",
L140     "RULE40", "RULE40_RAW", "FCF_MGN", "FCF_MGN_RAW",
L141     "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L142 ]
L143
L144 DEBUG_COLS = [
L145     "GRW", "GRW_RAW",
L146     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L147     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L148     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L149     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L150     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW",
L151     "REV_ANN_STREAK", "RULE40", "RULE40_RAW",
L152     "FCF_MGN", "FCF_MGN_RAW", "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L153     "GSC", "DSC"
L154 ]
L155
L156 MUST_DEBUG_COLS = {"TR_EPS", "TR_REV", "REV_Q_YOY", "REV_YOY_ACC", "RULE40", "FCF_MGN"}
L157
L158 def _post_slack(payload: dict):
L159     url = os.getenv("SLACK_WEBHOOK_URL")
L160     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L161     try:
L162         requests.post(url, json=payload).raise_for_status()
L163     except Exception as e:
L164         print(f"⚠️ Slack通知エラー: {e}")
L165
L166 def _slack_send_text_chunks(url: str, text: str, chunk: int = 2800) -> None:
L167     """Slackへテキストを分割送信（コードブロック形式）。"""
L168
L169     def _post_text(payload: str) -> None:
L170         try:
L171             resp = requests.post(url, json={"text": payload})
L172             print(f"[DBG] debug_post status={getattr(resp, 'status_code', None)} size={len(payload)}")
L173             if resp is not None:
L174                 resp.raise_for_status()
L175         except Exception as e:
L176             print(f"[ERR] debug_post_failed: {e}")
L177
L178     body = str(text or "").strip()
L179     if not body:
L180         print("[DBG] skip debug send: empty body")
L181         return
L182
L183     lines = body.splitlines()
L184     block: list[str] = []
L185     block_len = 0
L186
L187     def _flush() -> None:
L188         nonlocal block, block_len
L189         if not block:
L190             return
L191         payload = "```" + "\n".join(block) + "```"
L192         _post_text(payload)
L193         block, block_len = [], 0
L194
L195     for raw in lines:
L196         line = raw or ""
L197         while len(line) > chunk:
L198             head, line = line[:chunk], line[chunk:]
L199             _flush()
L200             _post_text("```" + head + "```")
L201         add_len = len(line) if not block else len(line) + 1
L202         if block and block_len + add_len > chunk:
L203             _flush()
L204             add_len = len(line)
L205         block.append(line)
L206         block_len += add_len
L207     _flush()
L208
L209 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L210     src = getattr(fb, "df_full", None)
L211     if not isinstance(src, pd.DataFrame) or src.empty:
L212         src = getattr(fb, "df_full_z", None)
L213     if not isinstance(src, pd.DataFrame) or src.empty:
L214         src = getattr(fb, "df_z", None)
L215     if not isinstance(src, pd.DataFrame) or src.empty:
L216         return ""
L217
L218     df_show = src.apply(pd.to_numeric, errors="coerce").rename(
L219         columns={k: v for k, v in _DEBUG_COL_ALIAS.items() if k in src.columns}
L220     )
L221
L222     missing = sorted(c for c in MUST_DEBUG_COLS if c not in df_show.columns)
L223     if missing:
L224         logger.warning("[debug] missing cols: %s", missing)
L225
L226     all_cols = _env_true("DEBUG_ALL_COLS", False)
L227     ordered = [c for c in _DEBUG_COL_ORDER if c in df_show.columns]
L228     cols = list(df_show.columns) if all_cols else ordered
L229     if not cols:
L230         cols = [c for c in df_show.columns if c not in ("GSC", "DSC")]
L231
L232     g_series = getattr(fb, "g_score", None)
L233     d_series = getattr(fb, "d_score_all", None)
L234     show_near = _env_true("DEBUG_NEAR5", True)
L235     g_sorted = g_series.sort_values(ascending=False) if show_near and hasattr(g_series, "sort_values") else None
L236     d_sorted = d_series.sort_values(ascending=False) if show_near and hasattr(d_series, "sort_values") else None
L237
L238     g_pick = list(getattr(sb, "top_G", []) or [])
L239     d_pick = list(getattr(sb, "top_D", []) or [])
L240     prevG = list(prevG or [])
L241     prevD = list(prevD or [])
L242     Gp, Dp = set(prevG), set(prevD)
L243     g_new = [t for t in g_pick if t not in Gp]
L244     g_out = [t for t in prevG if t not in g_pick]
L245     d_new = [t for t in d_pick if t not in Dp]
L246     d_out = [t for t in prevD if t not in d_pick]
L247
L248     g_miss = [t for t in (g_sorted.index if g_sorted is not None else []) if t not in g_pick][:10]
L249     used_d = set(g_pick + d_pick)
L250     d_miss = [t for t in (d_sorted.index if d_sorted is not None else []) if t not in used_d][:10]
L251
L252     def _merge_rows(*seqs):
L253         seen, out = set(), []
L254         for seq in seqs:
L255             for t in seq or []:
L256                 if t in df_show.index and t not in seen:
L257                     seen.add(t)
L258                     out.append(t)
L259         return out
L260
L261     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L262     focus = df_show.index.tolist() if all_rows else _merge_rows(g_pick + d_pick, prevG + prevD, g_miss, d_miss)
L263     if not focus:
L264         focus = df_show.index.tolist()
L265     focus = focus[:max_rows]
L266
L267     if cols:
L268         df_focus = df_show.loc[focus, cols].copy()
L269     else:
L270         df_focus = df_show.loc[focus].copy()
L271     if "GSC" not in df_focus.columns and g_series is not None:
L272         df_focus["GSC"] = [g_series.get(t, np.nan) if hasattr(g_series, "get") else np.nan for t in df_focus.index]
L273  
```