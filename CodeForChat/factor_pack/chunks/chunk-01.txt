```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・ログ出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, logging, requests
L7 from time import perf_counter
L8 from dataclasses import dataclass
L9 from typing import Any, Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 logger = logging.getLogger(__name__)
L19
L20 class T:
L21     t = perf_counter()
L22     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L23
L24 T.log("start")
L25
L26 # === ユニバースと定数（冒頭に固定） ===
L27 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L28 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L29 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L30 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L31 g_weights = {'GROWTH_F':0.35,'MOM':0.55,'VOL':-0.10}
L32 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L33 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L34 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L35 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L36
L37 # DRRS 初期プール・各種パラメータ
L38 corrM = 45
L39 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L40 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L41
L42 # クロス相関ペナルティ（未定義なら設定）
L43 try: CROSS_MU_GD
L44 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L45
L46 # 出力関連
L47 RESULTS_DIR = "results"
L48 os.makedirs(RESULTS_DIR, exist_ok=True)
L49
L50 # その他
L51 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L52
L53 # === 共有DTO（クラス間I/O契約）＋ Config ===
L54 @dataclass(frozen=True)
L55 class InputBundle:
L56     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L57     cand: List[str]
L58     tickers: List[str]
L59     bench: str
L60     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L61     px: pd.DataFrame                # data['Close']
L62     spx: pd.Series                  # data['Close'][bench]
L63     tickers_bulk: object            # yfinance.Tickers
L64     info: Dict[str, dict]           # yfinance info per ticker
L65     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L66     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L67     returns: pd.DataFrame           # px[tickers].pct_change()
L68
L69 @dataclass(frozen=True)
L70 class FeatureBundle:
L71     df: pd.DataFrame
L72     df_z: pd.DataFrame
L73     g_score: pd.Series
L74     d_score_all: pd.Series
L75     missing_logs: pd.DataFrame
L76     df_full: pd.DataFrame | None = None
L77     df_full_z: pd.DataFrame | None = None
L78     scaler: Any | None = None
L79
L80 @dataclass(frozen=True)
L81 class SelectionBundle:
L82     resG: dict
L83     resD: dict
L84     top_G: List[str]
L85     top_D: List[str]
L86     init_G: List[str]
L87     init_D: List[str]
L88
L89 @dataclass(frozen=True)
L90 class WeightsConfig:
L91     g: Dict[str,float]
L92     d: Dict[str,float]
L93
L94 @dataclass(frozen=True)
L95 class DRRSParams:
L96     corrM: int
L97     shrink: float
L98     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L99     D: Dict[str,float]
L100     cross_mu_gd: float
L101
L102 @dataclass(frozen=True)
L103 class PipelineConfig:
L104     weights: WeightsConfig
L105     drrs: DRRSParams
L106     price_max: float
L107
L108 # === 共通ユーティリティ（複数クラスで使用） ===
L109 # (unused local utils removed – use scorer.py versions if needed)
L110
L111 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L112
L113 _DEBUG_COL_ALIAS = {
L114     "GROWTH_F": "GRW",
L115     "GROWTH_F_RAW": "GRW_RAW",
L116     "TREND_SLOPE_EPS": "TR_EPS",
L117     "TREND_SLOPE_EPS_RAW": "TR_EPS_RAW",
L118     "TREND_SLOPE_REV": "TR_REV",
L119     "TREND_SLOPE_REV_RAW": "TR_REV_RAW",
L120     "TREND_SLOPE_EPS_YR": "TR_EPS_YR",
L121     "TREND_SLOPE_EPS_YR_RAW": "TR_EPS_YR_RAW",
L122     "TREND_SLOPE_REV_YR": "TR_REV_YR",
L123     "TREND_SLOPE_REV_YR_RAW": "TR_REV_YR_RAW",
L124     "BETA": "BETA_RAW",
L125 }
L126
L127 _DEBUG_COL_ORDER = [
L128     "GRW", "GRW_RAW",
L129     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L130     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L131     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L132     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L133     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW", "REV_ANN_STREAK",
L134     "RULE40", "RULE40_RAW", "FCF_MGN", "FCF_MGN_RAW",
L135     "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L136 ]
L137
L138 DEBUG_COLS = [
L139     "GRW", "GRW_RAW",
L140     "TR_EPS", "TR_EPS_RAW", "TR_REV", "TR_REV_RAW",
L141     "TR_EPS_YR", "TR_EPS_YR_RAW", "TR_REV_YR", "TR_REV_YR_RAW",
L142     "EPS_Q_YOY", "EPS_Q_YOY_RAW", "EPS_YOY", "EPS_YOY_RAW",
L143     "REV_Q_YOY", "REV_Q_YOY_RAW", "REV_YOY", "REV_YOY_RAW",
L144     "REV_YOY_ACC", "REV_YOY_ACC_RAW", "REV_YOY_VAR", "REV_YOY_VAR_RAW",
L145     "REV_ANN_STREAK", "RULE40", "RULE40_RAW",
L146     "FCF_MGN", "FCF_MGN_RAW", "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK",
L147     "GSC", "DSC"
L148 ]
L149
L150 MUST_DEBUG_COLS = {"TR_EPS", "TR_REV", "REV_Q_YOY", "REV_YOY_ACC", "RULE40", "FCF_MGN"}
L151
L152 def _write_debug_log(text: str, filename: str = "debug_scores.txt") -> None:
L153     """デバッグ本文を results/<filename> へ保存し、標準出力にも保存結果を出す。"""
L154     body = (text or "").strip()
L155     if not body:
L156         print("[debug] empty debug text; skip write", flush=True)
L157         return
L158     out_dir = os.path.join("results")
L159     os.makedirs(out_dir, exist_ok=True)
L160     path = os.path.join(out_dir, filename)
L161     with open(path, "w", encoding="utf-8") as f:
L162         f.write(body)
L163     print(f"[debug] written: {path} ({len(body)} chars)", flush=True)
L164
L165 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L166     src = getattr(fb, "df_full", None)
L167     if not isinstance(src, pd.DataFrame) or src.empty:
L168         src = getattr(fb, "df_full_z", None)
L169     if not isinstance(src, pd.DataFrame) or src.empty:
L170         src = getattr(fb, "df_z", None)
L171     if not isinstance(src, pd.DataFrame) or src.empty:
L172         return ""
L173
L174     df_show = src.apply(pd.to_numeric, errors="coerce").rename(
L175         columns={k: v for k, v in _DEBUG_COL_ALIAS.items() if k in src.columns}
L176     )
L177
L178     missing = sorted(c for c in MUST_DEBUG_COLS if c not in df_show.columns)
L179     if missing:
L180         logger.warning("[debug] missing cols: %s", missing)
L181
L182     ordered = [c for c in _DEBUG_COL_ORDER if c in df_show.columns]
L183     cols = ordered
L184     if not cols:
L185         cols = [c for c in df_show.columns if c not in ("GSC", "DSC")]
L186
L187     g_series = getattr(fb, "g_score", None)
L188     d_series = getattr(fb, "d_score_all", None)
L189     show_near = _env_true("DEBUG_NEAR5", True)
L190     g_sorted = g_series.sort_values(ascending=False) if show_near and hasattr(g_series, "sort_values") else None
L191     d_sorted = d_series.sort_values(ascending=False) if show_near and hasattr(d_series, "sort_values") else None
L192
L193     g_pick = list(getattr(sb, "top_G", []) or [])
L194     d_pick = list(getattr(sb, "top_D", []) or [])
L195     prevG = list(prevG or [])
L196     prevD = list(prevD or [])
L197     Gp, Dp = set(prevG), set(prevD)
L198     g_new = [t for t in g_pick if t not in Gp]
L199     g_out = [t for t in prevG if t not in g_pick]
L200     d_new = [t for t in d_pick if t not in Dp]
L201     d_out = [t for t in prevD if t not in d_pick]
L202
L203     g_miss = [t for t in (g_sorted.index if g_sorted is not None else []) if t not in g_pick][:10]
L204     used_d = set(g_pick + d_pick)
L205     d_miss = [t for t in (d_sorted.index if d_sorted is not None else []) if t not in used_d][:10]
L206
L207     def _merge_rows(*seqs):
L208         seen, out = set(), []
L209         for seq in seqs:
L210             for t in seq or []:
L211                 if t in df_show.index and t not in seen:
L212                     seen.add(t)
L213                     out.append(t)
L214         return out
L215
L216     focus = _merge_rows(g_pick + d_pick, prevG + prevD, g_miss, d_miss)
L217     if not focus:
L218         focus = df_show.index.tolist()
L219     focus = focus[:max_rows]
L220
L221     if cols:
L222         df_focus = df_show.loc[focus, cols].copy()
L223     else:
L224         df_focus = df_show.loc[focus].copy()
L225     if "GSC" not in df_focus.columns and g_series is not None:
L226         df_focus["GSC"] = [g_series.get(t, np.nan) if hasattr(g_series, "get") else np.nan for t in df_focus.index]
L227     if "DSC" not in df_focus.columns and d_series is not None:
L228         df_focus["DSC"] = [d_series.get(t, np.nan) if hasattr(d_series, "get") else np.nan for t in df_focus.index]
L229
L230     extra = [c for c in df_focus.columns if c not in cols]
L231     cols = cols + [c for c in ("GSC", "DSC") if c not in cols]
L232     cols += [c for c in extra if c not in cols]
L233
L234     body = df_focus.reindex(columns=cols).round(3).to_string(max_rows=None, max_cols=None, na_rep="nan") if focus else "(no rows)"
L235
L236     def _fmt_near(lbl, ser, lst):
L237         if ser is None:
L238             return f"{lbl}: off"
L239         get = ser.get
L240         parts = []
L241         for t in lst:
L242             val = get(t, np.nan)
L243             parts.append(f"{t}:{val:.3f}" if pd.notna(val) else f"{t}:nan")
L244         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L245
L246     head = [
L247         f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L248         _fmt_near("G near10", g_sorted, g_miss),
L249         _fmt_near("D near10", d_sorted, d_miss),
L250         f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L251         "Cols=MIN  Rows=SELECTED+CURRENT+NEAR",
L252     ]
L253
L254     lines = head + ["", "Changed/Selected (+ Near Miss + Current)", "GRW深掘り表", body]
L255     return "\n".join(lines)
L256
L257 def _disjoint_keepG(top_G, top_D, poolD):
L258     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L259     used, D, i = set(top_G), list(top_D), 0
L260     for j, t in enumerate(D):
L261         if t in used:
L262             while i < len(poolD) and (poolD[i] in used or pool
```