```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, factor.py, scorer.py, .github/workflows/weekly-report.yml, documents/README.md, documents/factor_design.md
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # 基準のバケット数（NORMAL）
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # モード別の推奨バケット数
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # モード別のドリフト閾値（%）
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # モード別のTS（基本幅, 小数=割合）
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <factor.py>
```text
L1 '''ROLE: Orchestration ONLY（外部I/O・SSOT・Slack出力）, 計算は scorer.py'''
L2 # === NOTE: 機能・入出力・ログ文言・例外挙動は不変。安全な短縮（import統合/複数代入/内包表記/メソッドチェーン/一行化/空行圧縮など）のみ適用 ===
L3 BONUS_COEFF = 0.55  # 推奨: 攻め=0.45 / 中庸=0.55 / 守り=0.65
L4 SWAP_DELTA_Z = 0.15   # 僅差判定: σの15%。(緩め=0.10 / 標準=0.15 / 固め=0.20)
L5 SWAP_KEEP_BUFFER = 3  # n_target+この順位以内の現行は保持。(粘り弱=2 / 標準=3 / 粘り強=4〜5)
L6 import os, time, requests
L7 from time import perf_counter
L8 from dataclasses import dataclass
L9 from typing import Dict, List
L10 from concurrent.futures import ThreadPoolExecutor
L11 import numpy as np
L12 import pandas as pd
L13 import yfinance as yf
L14 from scipy.stats import zscore  # used via scorer
L15 from scorer import Scorer, ttm_div_yield_portfolio
L16 import config
L17
L18 class T:
L19     t = perf_counter()
L20     log = staticmethod(lambda tag: (lambda now=perf_counter(): (print(f"[T] {tag}: {now - T.t:.2f}s"), setattr(T, "t", now))[-1])())
L21
L22 T.log("start")
L23
L24 # === ユニバースと定数（冒頭に固定） ===
L25 exist, cand = [pd.read_csv(f, header=None)[0].tolist() for f in ("current_tickers.csv","candidate_tickers.csv")]
L26 T.log(f"csv loaded: exist={len(exist)} cand={len(cand)}")
L27 CAND_PRICE_MAX, bench = 450, '^GSPC'  # 価格上限・ベンチマーク
L28 N_G, N_D = config.N_G, config.N_D  # G/D枠サイズ（NORMAL基準: G12/D8）
L29 g_weights = {'GROWTH_F':0.30,'MOM':0.55,'VOL':-0.15}
L30 D_BETA_MAX = float(os.environ.get("D_BETA_MAX", "0.8"))
L31 FILTER_SPEC = {"G":{"pre_mask":["trend_template"]},"D":{"pre_filter":{"beta_max":D_BETA_MAX}}}
L32 D_weights = {'QAL':0.1,'YLD':0.3,'VOL':-0.5,'TRD':0.1}
L33 _fmt_w = lambda w: " ".join(f"{k}{int(v*100)}" for k, v in w.items())
L34
L35 # DRRS 初期プール・各種パラメータ
L36 corrM = 45
L37 DRRS_G, DRRS_D = dict(lookback=252,n_pc=3,gamma=1.2,lam=0.68,eta=0.8), dict(lookback=504,n_pc=4,gamma=0.8,lam=0.85,eta=0.5)
L38 DRRS_SHRINK = 0.10  # 残差相関の対角シュリンク（基礎）
L39
L40 # クロス相関ペナルティ（未定義なら設定）
L41 try: CROSS_MU_GD
L42 except NameError: CROSS_MU_GD = 0.40  # 推奨 0.35–0.45（lam=0.85想定）
L43
L44 # 出力関連
L45 RESULTS_DIR = "results"
L46 os.makedirs(RESULTS_DIR, exist_ok=True)
L47
L48 # その他
L49 debug_mode, FINNHUB_API_KEY = True, os.environ.get("FINNHUB_API_KEY")
L50
L51 # === 共有DTO（クラス間I/O契約）＋ Config ===
L52 @dataclass(frozen=True)
L53 class InputBundle:
L54     # Input → Scorer で受け渡す素材（I/O禁止の生データ）
L55     cand: List[str]
L56     tickers: List[str]
L57     bench: str
L58     data: pd.DataFrame              # yfinance download結果（'Close','Volume'等の階層列）
L59     px: pd.DataFrame                # data['Close']
L60     spx: pd.Series                  # data['Close'][bench]
L61     tickers_bulk: object            # yfinance.Tickers
L62     info: Dict[str, dict]           # yfinance info per ticker
L63     eps_df: pd.DataFrame            # ['eps_ttm','eps_q_recent',...]
L64     fcf_df: pd.DataFrame            # ['fcf_ttm', ...]
L65     returns: pd.DataFrame           # px[tickers].pct_change()
L66
L67 @dataclass(frozen=True)
L68 class FeatureBundle:
L69     df: pd.DataFrame
L70     df_z: pd.DataFrame
L71     g_score: pd.Series
L72     d_score_all: pd.Series
L73     missing_logs: pd.DataFrame
L74
L75 @dataclass(frozen=True)
L76 class SelectionBundle:
L77     resG: dict
L78     resD: dict
L79     top_G: List[str]
L80     top_D: List[str]
L81     init_G: List[str]
L82     init_D: List[str]
L83
L84 @dataclass(frozen=True)
L85 class WeightsConfig:
L86     g: Dict[str,float]
L87     d: Dict[str,float]
L88
L89 @dataclass(frozen=True)
L90 class DRRSParams:
L91     corrM: int
L92     shrink: float
L93     G: Dict[str,float]   # lookback, n_pc, gamma, lam, eta
L94     D: Dict[str,float]
L95     cross_mu_gd: float
L96
L97 @dataclass(frozen=True)
L98 class PipelineConfig:
L99     weights: WeightsConfig
L100     drrs: DRRSParams
L101     price_max: float
L102
L103 # === 共通ユーティリティ（複数クラスで使用） ===
L104 # (unused local utils removed – use scorer.py versions if needed)
L105
L106 _env_true = lambda name, default=False: (os.getenv(name) or str(default)).strip().lower() == "true"
L107
L108 def _post_slack(payload: dict):
L109     url = os.getenv("SLACK_WEBHOOK_URL")
L110     if not url: print("⚠️ SLACK_WEBHOOK_URL 未設定"); return
L111     try:
L112         requests.post(url, json=payload).raise_for_status()
L113     except Exception as e:
L114         print(f"⚠️ Slack通知エラー: {e}")
L115
L116 _slack = lambda message, code=False: _post_slack({"text": f"```{message}```" if code else message})
L117
L118 def _slack_debug(text: str, chunk=2800):
L119     text = text.rstrip()
L120     if not text:
L121         return
L122     i = 0
L123     while i < len(text):
L124         j = min(len(text), i + chunk)
L125         k = text.rfind("\n", i, j)
L126         j = k if k > i + 100 else j
L127         # blocks で送る場合は code fence を二重にしない
L128         if j > i:
L129             _post_slack({"blocks":[{"type":"section","text":{"type":"mrkdwn","text":text[i:j]}}]})
L130         i = j
L131
L132 def _compact_debug(fb, sb, prevG, prevD, max_rows=140):
L133     df_z = getattr(fb, "df_z", None)
L134     if not isinstance(df_z, pd.DataFrame):
L135         df_z = pd.DataFrame()
L136     # 表示は“人が読む列名”に統一（Changed/Selected/Current すべて同じ）
L137     want = [
L138         "GRW",
L139         "TR_EPS", "TR_REV",
L140         "EPS_Q_YOY", "REV_Q_YOY", "REV_YOY_ACC", "REV_YOY_VAR",
L141         "RULE40", "FCF", "ROE", "RS", "TR_str", "BETA_RAW", "DIV_STREAK", "DSC"
L142     ]
L143     all_cols = _env_true("DEBUG_ALL_COLS", False)
L144     # df_z → 表示名の別名テーブルを作る（常に alias 済みを使う）
L145     df_show = df_z.copy()
L146     alias = {
L147         "GROWTH_F": "GRW",
L148         "TREND_SLOPE_EPS": "TR_EPS", "TREND_SLOPE_REV": "TR_REV",
L149         "EPS_Q_YOY": "EPS_Q_YOY", "REV_Q_YOY": "REV_Q_YOY",
L150         "REV_YOY_ACC": "REV_YOY_ACC", "REV_YOY_VAR": "REV_YOY_VAR",
L151         "RULE40": "RULE40", "FCF_Z": "FCF", "ROE": "ROE", "RS": "RS",
L152         "TR_END": "TR_str", "BETA": "BETA_RAW", "DIV_STREAK": "DIV_STREAK"
L153     }
L154     df_show.rename(columns={k: v for k, v in alias.items() if k in df_show.columns}, inplace=True)
L155     cols = list(df_show.columns if all_cols else [c for c in want if c in df_show.columns])
L156
L157     Gp, Dp = set(prevG or []), set(prevD or [])
L158     g_new=[t for t in (sb.top_G or []) if t not in Gp]; g_out=[t for t in Gp if t not in (sb.top_G or [])]
L159     d_new=[t for t in (sb.top_D or []) if t not in Dp]; d_out=[t for t in Dp if t not in (sb.top_D or [])]
L160
L161     show_near = _env_true("DEBUG_NEAR5", True)
L162     gs, ds = getattr(fb,"g_score",None), getattr(fb,"d_score_all",None)
L163     gs = (gs.sort_values(ascending=False) if show_near and hasattr(gs,"sort_values") else None)
L164     ds = (ds.sort_values(ascending=False) if show_near and hasattr(ds,"sort_values") else None)
L165     g_miss = ([t for t in gs.index if t not in (sb.top_G or [])][:10]) if gs is not None else []
L166     d_excl = set((sb.top_G or [])+(sb.top_D or []))
L167     d_miss = ([t for t in ds.index if t not in d_excl][:10]) if ds is not None else []
L168
L169     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L170     curr = [t for t in (exist or []) if t in df_z.index]
L171     focus = list(df_z.index) if all_rows else sorted(set(g_new+g_out+d_new+d_out+(sb.top_G or [])+(sb.top_D or [])+g_miss+d_miss+curr))[:max_rows]
L172
L173     def _fmt_near(lbl, ser, lst):
L174         if ser is None: return f"{lbl}: off"
L175         g = ser.get
L176         parts=[f"{t}:{g(t,float('nan')):.3f}" if pd.notna(g(t)) else f"{t}:nan" for t in lst]
L177         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L178
L179     head=[f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L180           _fmt_near("G near10", gs, g_miss),
L181           _fmt_near("D near10", ds, d_miss),
L182           f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L183           f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SUBSET'}"]
L184
L185     tbl="(df_z or columns not available)"
L186     if not df_show.empty and cols:
L187         idx=[t for t in focus if t in df_show.index]
L188         base=df_show.loc[idx, cols].round(3).copy()
L189         try:
L190             if gs is not None:
L191                 base["GSC"] = [gs.get(t, np.nan) for t in base.index]
L192             if ds is not None:
L193                 base["DSC"] = [ds.get(t, np.nan) for t in base.index]
L194         except Exception:
L195             pass
L196         tbl=base.to_string(max_rows=None, max_cols=None)
L197
L198     miss_txt=""
L199     if _env_true("DEBUG_MISSING_LOGS", False):
L200         miss=getattr(fb,"missing_logs",None)
L201         if miss is not None and not miss.empty:
L202             miss_txt="\nMissing data (head)\n"+miss.head(10).to_string(index=False)
L203
L204     return "\n".join(head+["\nChanged/Selected (+ Near Miss + Current)", tbl])+miss_txt
L205
L206 def _disjoint_keepG(top_G, top_D, poolD):
L207     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L208     used, D, i = set(top_G), list(top_D), 0
L209     for j, t in enumerate(D):
L210         if t in used:
L211             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L212                 i += 1
L213             if i < len(poolD):
L214                 D[j] = poolD[i]; used.add(D[j]); i += 1
L215     return top_G, D
L216
L217
L218 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L219                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L220     import pandas as pd, numpy as np
L221     sel = list(pick)
L222     if not sel: return sel
L223     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L224     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L225     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L226     thresh = kth - delta_z * sigma
L227     ranked_all = agg.sort_values(ascending=False)
L228     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L229     for t in cand:
L230         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L231         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L232         if within_score or within_rank:
L233             non_inc = [x for x in sel if x not in incumbents]
L234             if not non_inc: break
L235             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L236             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L237                 sel.remove(weakest); sel.append(t)
L238     if len(sel) > n_target:
L239         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L240     return sel
L241
L242
L243 # === Input：外部I/Oと前処理（CSV/API・欠損補完） ===
L244 class Input:
L245     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L246         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L247         self.api_key = finnhub_api_key o
```