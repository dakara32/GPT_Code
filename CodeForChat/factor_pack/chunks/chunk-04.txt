```text
ey = api_key or os.getenv("FINNHUB_API_KEY")
L784         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L785         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L786         for sym in tickers:
L787             cfo_ttm = capex_ttm = None
L788             try:
L789                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L790                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L791                 for item in arr[:4]:
L792                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L793                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L794                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L795             except Exception: pass
L796             if cfo_ttm is None or capex_ttm is None:
L797                 try:
L798                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L799                     arr = j.get("cashFlow") or []
L800                     if arr:
L801                         item0 = arr[0]
L802                         if cfo_ttm is None:
L803                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L804                             if v is not None: cfo_ttm = float(v)
L805                         if capex_ttm is None:
L806                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L807                             if v is not None: capex_ttm = float(v)
L808                 except Exception: pass
L809             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L810         return pd.DataFrame(rows).set_index("ticker")
L811
L812     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L813         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L814         _tlog("financials (yf) done")
L815         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L816         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L817         if need:
L818             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L819             df = yf_df.join(fh_df, how="left")
L820             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L821                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L822             print("[T] financials (finnhub) done (fallback only)")
L823         else:
L824             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L825             print("[T] financials (finnhub) skipped (no missing)")
L826         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L827         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L828         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L829         fcf_calc = cfo - capex
L830         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L831         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L832         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L833         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L834         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L835         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L836         return df[cols].sort_index()
L837
L838     def _build_eps_df(self, tickers, tickers_bulk, info, sec_map: dict | None = None):
L839         eps_rows=[]
L840         for t in tickers:
L841             info_t = info[t]
L842             sec_t = (sec_map or {}).get(t, {})
L843             eps_ttm = sec_t.get("eps_ttm", info_t.get("trailingEps", np.nan))
L844             eps_q = sec_t.get("eps_q_recent", np.nan)
L845             try:
L846                 tk = tickers_bulk.tickers.get(t)
L847                 if tk is None:
L848                     sym = info_t.get("_yf_symbol") if isinstance(info_t, dict) else None
L849                     if sym:
L850                         tk = tickers_bulk.tickers.get(sym)
L851                 qearn = tk.quarterly_earnings if tk is not None else None
L852                 so = info_t.get("sharesOutstanding")
L853                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L854                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L855                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L856                     if pd.isna(eps_q):
L857                         eps_q = qearn["Earnings"].iloc[-1]/so
L858             except Exception: pass
L859             rev_ttm = sec_t.get("rev_ttm", np.nan)
L860             rev_q = sec_t.get("rev_q_recent", np.nan)
L861             if (not sec_t) or pd.isna(rev_ttm):
L862                 try:
L863                     tk = tickers_bulk.tickers.get(t)
L864                     if tk is None and isinstance(info_t, dict):
L865                         sym = info_t.get("_yf_symbol")
L866                         if sym:
L867                             tk = tickers_bulk.tickers.get(sym)
L868                     qfin = getattr(tk, "quarterly_financials", None)
L869                     if qfin is not None and not qfin.empty:
L870                         idx_lower = {str(i).lower(): i for i in qfin.index}
L871                         rev_idx = None
L872                         for name in ("Total Revenue", "TotalRevenue"):
L873                             key = name.lower()
L874                             if key in idx_lower:
L875                                 rev_idx = idx_lower[key]
L876                                 break
L877                         if rev_idx is not None:
L878                             rev_series = pd.to_numeric(qfin.loc[rev_idx], errors="coerce").dropna()
L879                             if not rev_series.empty:
L880                                 rev_ttm_yf = float(rev_series.head(4).sum())
L881                                 if pd.isna(rev_ttm):
L882                                     rev_ttm = rev_ttm_yf
L883                                 if pd.isna(rev_q):
L884                                     rev_q = float(rev_series.iloc[0])
L885                 except Exception:
L886                     pass
L887             eps_rows.append({
L888                 "ticker": t,
L889                 "eps_ttm": eps_ttm,
L890                 "eps_ttm_prev": sec_t.get("eps_ttm_prev", np.nan),
L891                 "eps_q_recent": eps_q,
L892                 "eps_q_prev": sec_t.get("eps_lastq_prev", np.nan),
L893                 "rev_ttm": rev_ttm,
L894                 "rev_ttm_prev": sec_t.get("rev_ttm_prev", np.nan),
L895                 "rev_q_recent": rev_q,
L896                 "rev_q_prev": sec_t.get("rev_lastq_prev", np.nan),
L897                 "eps_annual_latest": sec_t.get("eps_annual_latest", np.nan),
L898                 "eps_annual_prev": sec_t.get("eps_annual_prev", np.nan),
L899                 "rev_annual_latest": sec_t.get("rev_annual_latest", np.nan),
L900                 "rev_annual_prev": sec_t.get("rev_annual_prev", np.nan),
L901                 "eps_cagr3": sec_t.get("eps_cagr3", np.nan),
L902                 "rev_cagr3": sec_t.get("rev_cagr3", np.nan),
L903             })
L904         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L905
L906     def prepare_data(self):
L907         """Fetch price and fundamental data for all tickers."""
L908         self.sec_dryrun_sample()
L909         # --- yfinance 用にティッカーを正規化（"$"剥がし、"."→"-"） ---
L910         def _to_yf(sym: str) -> str:
L911             s = (sym or "").strip().lstrip("$").replace("＄", "")
L912             # BRK.B / PBR.A などは Yahoo では '-' を使用
L913             yf_sym = s.replace("．", ".").replace(".", "-")
L914             return yf_sym or (sym or "")
L915
L916         cand_y = [_to_yf(t) for t in self.cand]
L917         cand_info = yf.Tickers(" ".join(cand_y))
L918
L919         def _price(orig: str, ysym: str) -> float:
L920             try:
L921                 return cand_info.tickers[ysym].fast_info.get("lastPrice", np.inf)
L922             except Exception as e:
L923                 print(f"{orig}: price fetch failed ({e})")
L924                 return np.inf
L925
L926         cand_prices = {orig: _price(orig, ysym) for orig, ysym in zip(self.cand, cand_y)}
L927         cand_f = [t for t, p in cand_prices.items() if p <= self.price_max]
L928         _tlog("price cap filter done (CAND_PRICE_MAX)")
L929         # 入力ティッカーの重複を除去し、現行→候補の順序を維持
L930         # ユニバース確定（元ティッカー保持）。yfinance には後で変換して渡す
L931         tickers = list(dict.fromkeys(self.exist + cand_f))
L932         yf_map = {t: _to_yf(t) for t in tickers}
L933         yf_list = list(dict.fromkeys([yf_map[t] for t in tickers]))
L934         _tlog(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L935         data = yf.download(yf_list + [self.bench], period="600d",
L936                            auto_adjust=True, progress=False, threads=False)
L937         _tlog("yf.download done")
L938         inv = {v: k for k, v in yf_map.items()}
L939         px = data["Close"].dropna(how="all", axis=1).ffill(limit=2)
L940         px = px.rename(columns=inv)
L941         try:
L942             if isinstance(data.columns, pd.MultiIndex):
L943                 data = data.rename(columns=inv, level=1)
L944             else:
L945                 data = data.rename(columns=inv)
L946         except Exception:
L947             pass
L948         spx = data["Close"][self.bench].reindex(px.index).ffill()
L949         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0なら無効（既定）
L950         if clip_days > 0:
L951             px, spx = px.tail(clip_days + 1), spx.tail(clip_days + 1)
L952             logger.info("[T] price window clipped by env: %d rows (PRICE_CLIP_DAYS=%d)", len(px), clip_days)
L953         else:
L954             logger.debug("[T] price window clip skipped; rows=%d", len(px))
L955         tickers_bulk, info = yf.Tickers(" ".join(yf_list)), {}
L956         for orig, ysym in yf_map.items():
L957             if ysym in tickers_bulk.tickers:
L958                 tickers_bulk.tickers[orig] = tickers_bulk.tickers[ysym]
L959         for t in tickers:
L960             try:
L961                 tk = tickers_bulk.tickers.get(t) or tickers_bulk.tickers.get(yf_map[t])
L962                 info_entry = tk.info if tk is not None else {}
L963                 if not isinstance(info_entry, dict):
L964                     info_entry = {}
L965                 info_entry.setdefault("_yf_symbol", getattr(tk, "ticker", yf_map.get(t)))
L966                 info[t] = info_entry
L967             except Exception as e:
L968                 logger.info("[warn] %s: info fetch failed (%s)", t, e)
L969                 info[t] = {}
L970         try:
L971             sec_map = self.fetch_eps_rev_from_sec(tickers)
L972         except Exception as e:
L973             logger.warning("[SEC] fetch_eps_rev_from_sec failed: %s", e)
L974             sec_map = {}
L975
L976         def _brief_len(s):
L977             try:
L978  
```