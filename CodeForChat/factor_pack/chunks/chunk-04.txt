```text
na(s['RAWρ']) else "NaN"),'RESIDρ':(f"{s['RESIDρ']:.2f}" if pd.notna(s['RESIDρ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L609         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L610         if self.debug:
L611             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L612             print("Debug Data:"); print(self.debug_table.to_string())
L613
L614         # === 追加: GSC+DSC が低い順 TOP10 ===
L615         try:
L616             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L617             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L618             all_scores = all_scores.dropna(subset=['G_plus_D'])
L619             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L620             print("Low Score Candidates (GSC+DSC bottom 10):")
L621             print(self.low10_table.to_string())
L622         except Exception as e:
L623             print(f"[warn] low-score ranking failed: {e}")
L624             self.low10_table = None
L625
L626     # --- Slack送信（元 notify_slack のロジックそのまま） ---
L627     def notify_slack(self):
L628         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L629         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (環境変数が未設定です)")
L630         def _filter_suffix_from(spec: dict, group: str) -> str:
L631             g = spec.get(group, {})
L632             parts = [str(m) for m in g.get("pre_mask", [])]
L633             for k, v in (g.get("pre_filter", {}) or {}).items():
L634                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L635                 name = {"beta": "β"}.get(base, base)
L636                 try: val = f"{float(v):g}"
L637                 except: val = str(v)
L638                 parts.append(f"{name}{op}{val}")
L639             return "" if not parts else " / filter:" + " & ".join(parts)
L640         def _inject_filter_suffix(title: str, group: str) -> str:
L641             suf = _filter_suffix_from(FILTER_SPEC, group)
L642             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L643         def _blk(title, tbl, fmt=None, drop=()):
L644             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(選定なし)\n"
L645             if drop and hasattr(tbl,'columns'):
L646                 keep = [c for c in tbl.columns if c not in drop]
L647                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L648             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L649
L650         g_title = _inject_filter_suffix(self.g_title, "G")
L651         d_title = _inject_filter_suffix(self.d_title, "D")
L652         message  = "📈 ファクター分散最適化の結果\n"
L653         if self.miss_df is not None and not self.miss_df.empty:
L654             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L655         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L656         message += _blk(d_title, self.d_table, self.d_formatters)
L657         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L658         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L659         if self.debug and self.debug_table is not None:
L660             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L661         payload = {"text": message}
L662         try:
L663             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("✅ Slack（Webhook）へ送信しました")
L664         except Exception as e: print(f"⚠️ Slack通知エラー: {e}")
L665
L666 def _infer_g_universe(feature_df, selected12=None, near5=None):
L667     try:
L668         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L669         if out: return out
L670     except Exception:
L671         pass
L672     base = set()
L673     for lst in (selected12 or []), (near5 or []):
L674         for x in (lst or []): base.add(x)
L675     return list(base) if base else list(feature_df.index)
L676
L677 def _fmt_with_fire_mark(tickers, feature_df):
L678     out = []
L679     for t in tickers or []:
L680         try:
L681             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L682             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L683             out.append(f"{t}{' 🔥' if (br or pb) else ''}")
L684         except Exception:
L685             out.append(t)
L686     return out
L687
L688 def _label_recent_event(t, feature_df):
L689     try:
L690         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L691         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L692         if   br and not pb: return f"{t}（ブレイクアウト確定 {dbr}）"
L693         elif pb and not br: return f"{t}（押し目反発 {dpb}）"
L694         elif br and pb:     return f"{t}（ブレイクアウト確定 {dbr}／押し目反発 {dpb}）"
L695     except Exception:
L696         pass
L697     return t
L698
L699 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L700
L701 def io_build_input_bundle() -> InputBundle:
L702     """
L703     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L704     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L705     """
L706     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L707     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L708
L709 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L710               n_target: int) -> tuple[list, float, float, float]:
L711     """
L712     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L713     戻り値：(pick, avg_res_corr, sum_score, objective)
L714     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L715     """
L716     sc.cfg = cfg
L717
L718     if hasattr(sc, "score_build_features"):
L719         feat = sc.score_build_features(inb)
L720         if not hasattr(sc, "_feat_logged"):
L721             T.log("features built (scorer)")
L722             sc._feat_logged = True
L723         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L724     else:
L725         fb = sc.aggregate_scores(inb, cfg)
L726         if not hasattr(sc, "_feat_logged"):
L727             T.log("features built (scorer)")
L728             sc._feat_logged = True
L729         sc._feat = fb
L730         agg = fb.g_score if group == "G" else fb.d_score_all
L731         if group == "D" and hasattr(fb, "df"):
L732             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L733
L734     if hasattr(sc, "filter_candidates"):
L735         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L736
L737     selector = Selector()
L738     if hasattr(sc, "select_diversified"):
L739         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L740             selector=selector, prev_tickers=None,
L741             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L742             cross_mu=cfg.drrs.cross_mu_gd)
L743     else:
L744         if group == "G":
L745             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L746             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L747                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L748                 lam=cfg.drrs.G.get("lam", 0.68),
L749                 lookback=cfg.drrs.G.get("lookback", 252),
L750                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L751         else:
L752             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L753             g_fixed = getattr(sc, "_top_G", None)
L754             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L755                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L756                 lam=cfg.drrs.D.get("lam", 0.85),
L757                 lookback=cfg.drrs.D.get("lookback", 504),
L758                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L759                 mu=cfg.drrs.cross_mu_gd)
L760         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L761         sum_sc = res["sum_score"]; obj = res["objective"]
L762         if group == "D":
L763             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L764             T.log("selection finalized (G/D)")
L765     try:
L766         inc = [t for t in exist if t in agg.index]
L767         pick = _sticky_keep_current(
L768             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L769             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L770         )
L771     except Exception as _e:
L772         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L773     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L774     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L775     try:
L776         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L777         near10 = list(pool.sort_values(ascending=False).head(10).index)
L778         setattr(sc, f"_near_{group}", near10)
L779         setattr(sc, f"_agg_{group}", agg)
L780     except Exception:
L781         pass
L782
L783     if group == "D":
L784         T.log("save done")
L785     if group == "G":
L786         sc._top_G = pick
L787     return pick, avg_r, sum_sc, obj
L788
L789 def run_pipeline() -> SelectionBundle:
L790     """
L791     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L792     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L793     """
L794     inb = io_build_input_bundle()
L795     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L796         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L797                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L798         price_max=CAND_PRICE_MAX)
L799     sc = Scorer()
L800     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L801     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L802     alpha = Scorer.spx_to_alpha(inb.spx)
L803     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L804     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L805     sc._top_G = top_G
L806     try:
L807         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L808         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L809     except Exception:
L810         pass
L811     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L812     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L813     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L814     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L815     fb = getattr(sc, "_feat", None)
L816     near_G = getattr(sc, "_near_G", [])
L817     selected12 = list(top_G)
L818     df = fb.df if fb is not None else pd.DataFrame()
L819     guni = _infer_g_universe(df, selected12, near_G)
L820     try:
L821         fire_recent = [t for t in guni
L822                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L823                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L824     except Exception: fire_recent = []
L825
L826     lines =
```