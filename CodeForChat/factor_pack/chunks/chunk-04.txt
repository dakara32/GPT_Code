```text
 df_z.loc[add,'D_TRD']
L653                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L654                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L655         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L656
L657         # === Changes（IN の GSC/DSC を表示。OUT は銘柄名のみ） ===
L658         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L659         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L660
L661         self.io_table = pd.DataFrame({
L662             'IN': pd.Series(in_list),
L663             '/ OUT': pd.Series(out_list)
L664         })
L665         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else '—' for t in out_list]
L666         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else '—' for t in out_list]
L667         self.io_table['GSC'] = pd.Series(g_list)
L668         self.io_table['DSC'] = pd.Series(d_list)
L669
L670         print("Changes:")
L671         print(self.io_table.to_string(index=False))
L672
L673         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L674         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L675         for name,ticks in portfolios.items():
L676             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L677             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L678             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L679             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L680             if len(ticks)>=2:
L681                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L682                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L683                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L684             else: RAW_rho = RESID_rho = np.nan
L685             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWρ':RAW_rho,'RESIDρ':RESID_rho,'DIVY':divy}
L686         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L687         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L688         cols_order = ['RET','VOL','SHP','MDD','RAWρ','RESIDρ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L689         def _fmt_row(s):
L690             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWρ':(f"{s['RAWρ']:.2f}" if pd.notna(s['RAWρ']) else "NaN"),'RESIDρ':(f"{s['RESIDρ']:.2f}" if pd.notna(s['RESIDρ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L691         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L692         if self.debug:
L693             self.debug_table = pd.concat([df_z[['TR','EPS','REV','ROE','BETA','DIV','FCF','RS','TR_str','DIV_STREAK']], g_score.rename('GSC'), d_score_all.rename('DSC')], axis=1).round(3)
L694             print("Debug Data:"); print(self.debug_table.to_string())
L695
L696         # === 追加: GSC+DSC が低い順 TOP10 ===
L697         try:
L698             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L699             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L700             all_scores = all_scores.dropna(subset=['G_plus_D'])
L701             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L702             print("Low Score Candidates (GSC+DSC bottom 10):")
L703             print(self.low10_table.to_string())
L704         except Exception as e:
L705             print(f"[warn] low-score ranking failed: {e}")
L706             self.low10_table = None
L707
L708     # --- Slack送信（元 notify_slack のロジックそのまま） ---
L709     def notify_slack(self):
L710         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L711         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (環境変数が未設定です)")
L712         def _filter_suffix_from(spec: dict, group: str) -> str:
L713             g = spec.get(group, {})
L714             parts = [str(m) for m in g.get("pre_mask", [])]
L715             for k, v in (g.get("pre_filter", {}) or {}).items():
L716                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L717                 name = {"beta": "β"}.get(base, base)
L718                 try: val = f"{float(v):g}"
L719                 except: val = str(v)
L720                 parts.append(f"{name}{op}{val}")
L721             return "" if not parts else " / filter:" + " & ".join(parts)
L722         def _inject_filter_suffix(title: str, group: str) -> str:
L723             suf = _filter_suffix_from(FILTER_SPEC, group)
L724             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L725         def _blk(title, tbl, fmt=None, drop=()):
L726             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(選定なし)\n"
L727             if drop and hasattr(tbl,'columns'):
L728                 keep = [c for c in tbl.columns if c not in drop]
L729                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L730             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L731
L732         g_title = _inject_filter_suffix(self.g_title, "G")
L733         d_title = _inject_filter_suffix(self.d_title, "D")
L734         message  = "📈 ファクター分散最適化の結果\n"
L735         if self.miss_df is not None and not self.miss_df.empty:
L736             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L737         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L738         message += _blk(d_title, self.d_table, self.d_formatters)
L739         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L740         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L741         if self.debug and self.debug_table is not None:
L742             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L743         payload = {"text": message}
L744         try:
L745             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("✅ Slack（Webhook）へ送信しました")
L746         except Exception as e: print(f"⚠️ Slack通知エラー: {e}")
L747
L748
L749 def _infer_g_universe(feature_df, selected12=None, near5=None):
L750     try:
L751         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L752         if out: return out
L753     except Exception:
L754         pass
L755     base = set()
L756     for lst in (selected12 or []), (near5 or []):
L757         for x in (lst or []): base.add(x)
L758     return list(base) if base else list(feature_df.index)
L759
L760
L761 def _fmt_with_fire_mark(tickers, feature_df):
L762     out = []
L763     for t in tickers or []:
L764         try:
L765             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L766             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L767             out.append(f"{t}{' 🔥' if (br or pb) else ''}")
L768         except Exception:
L769             out.append(t)
L770     return out
L771
L772
L773 def _label_recent_event(t, feature_df):
L774     try:
L775         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L776         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L777         if   br and not pb: return f"{t}（ブレイクアウト確定 {dbr}）"
L778         elif pb and not br: return f"{t}（押し目反発 {dpb}）"
L779         elif br and pb:     return f"{t}（ブレイクアウト確定 {dbr}／押し目反発 {dpb}）"
L780     except Exception:
L781         pass
L782     return t
L783
L784
L785 # ===== パイプライン可視化：G/D共通フロー（出力は不変） ==============================
L786
L787 def io_build_input_bundle() -> InputBundle:
L788     """
L789     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L790     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L791     """
L792     inp = Input(cand=cand, exist=exist, bench=bench,
L793                 price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY)
L794     state = inp.prepare_data()
L795     return InputBundle(
L796         cand=state["cand"], tickers=state["tickers"], bench=bench,
L797         data=state["data"], px=state["px"], spx=state["spx"],
L798         tickers_bulk=state["tickers_bulk"], info=state["info"],
L799         eps_df=state["eps_df"], fcf_df=state["fcf_df"],
L800         returns=state["returns"]
L801     )
L802
L803 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L804               n_target: int) -> tuple[list, float, float, float]:
L805     """
L806     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L807     戻り値：(pick, avg_res_corr, sum_score, objective)
L808     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L809     """
L810     sc.cfg = cfg
L811
L812     if hasattr(sc, "score_build_features"):
L813         feat = sc.score_build_features(inb)
L814         if not hasattr(sc, "_feat_logged"):
L815             T.log("features built (scorer)")
L816             sc._feat_logged = True
L817         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L818     else:
L819         fb = sc.aggregate_scores(inb, cfg)
L820         if not hasattr(sc, "_feat_logged"):
L821             T.log("features built (scorer)")
L822             sc._feat_logged = True
L823         sc._feat = fb
L824         agg = fb.g_score if group == "G" else fb.d_score_all
L825         if group == "D" and hasattr(fb, "df"):
L826             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L827
L828     if hasattr(sc, "filter_candidates"):
L829         mask = sc.filter_candidates(inb, agg, group, cfg)
L830         agg = agg[mask]
L831
L832     selector = Selector()
L833     if hasattr(sc, "select_diversified"):
L834         pick, avg_r, sum_sc, obj = sc.select_diversified(
L835             agg, group, cfg, n_target,
L836             selector=selector, prev_tickers=None,
L837             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L838             cross_mu=cfg.drrs.cross_mu_gd
L839         )
L840     else:
L841         if group == "G":
L842             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L843             res = selector.select_bucket_drrs(
L844                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L845                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L846                 lam=cfg.drrs.G.get("lam", 0.68),
L847                 lookback=cfg.drrs.G.get("lookback", 252),
L848                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0
L849             )
L850         else:
L851             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L852             g_fixed = getattr(sc, "_top_G", None)
L853             res = selector.select_bucket_drrs(
L854                 returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L855                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L856                 lam=cfg.drrs.D.get("lam", 0.85),
L857                 lookback=cfg.drrs.D.get("lookback", 504),
L858                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L859                 mu=cfg.drrs.cross_mu_gd
L860             )
L861 
```