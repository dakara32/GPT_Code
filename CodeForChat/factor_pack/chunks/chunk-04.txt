```text
                     aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L664                     out_now = sorted(set(exist) - set(top_G + top_D))  # 今回 OUT
L665                     used = set(G_UNI + add)
L666                     def _push(lst):
L667                         nonlocal add, used
L668                         for t in lst:
L669                             if len(add) == 10: break
L670                             if t in aggG.index and t not in used:
L671                                 add.append(t); used.add(t)
L672                     _push(out_now)           # ① 今回 OUT を優先
L673                     _push(list(aggG.index))  # ② まだ足りなければ上位で充填
L674                 except Exception:
L675                     pass
L676             if add:
L677                 near_tbl = pd.concat([df_z.loc[add,['GROWTH_F','MOM','TRD','VOL']], pd.Series({t: g_score.get(t) for t in add}, name='GSC')], axis=1)
L678                 self.g_table = pd.concat([self.g_table, near_tbl], axis=0)
L679         print(self.g_title); print(self.g_table.to_string(formatters=self.g_formatters))
L680
L681         extra_D = [t for t in init_D if t not in top_D][:5]; D_UNI = top_D + extra_D
L682         cols_D = ['QAL','YLD','VOL','TRD']; d_disp = pd.DataFrame(index=D_UNI)
L683         d_disp['QAL'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L684         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L685         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("⭐️" if t in top_D else "") for t in D_UNI]
L686         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L687         import scorer
L688         dw_eff = scorer.D_WEIGHTS_EFF
L689         self.d_title = (f"[D枠 / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L690                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} γ={DRRS_D['gamma']} λ={DRRS_D['lam']} μ={CROSS_MU_GD} η={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L691         if near_D:
L692             add = [t for t in near_D if t not in set(D_UNI)][:10]
L693             if add:
L694                 d_disp2 = pd.DataFrame(index=add)
L695                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L696                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L697                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L698         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L699
L700         # === Changes（IN の GSC/DSC を表示。OUT は銘柄名のみ） ===
L701         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L702         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L703
L704         self.io_table = pd.DataFrame({
L705             'IN': pd.Series(in_list),
L706             '/ OUT': pd.Series(out_list)
L707         })
L708         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else '—' for t in out_list]
L709         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else '—' for t in out_list]
L710         self.io_table['GSC'] = pd.Series(g_list)
L711         self.io_table['DSC'] = pd.Series(d_list)
L712
L713         print("Changes:")
L714         print(self.io_table.to_string(index=False))
L715
L716         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False, threads=False)['Close'].ffill(limit=2)
L717         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L718         for name,ticks in portfolios.items():
L719             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L720             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L721             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L722             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L723             if len(ticks)>=2:
L724                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L725                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L726                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L727             else: RAW_rho = RESID_rho = np.nan
L728             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWρ':RAW_rho,'RESIDρ':RESID_rho,'DIVY':divy}
L729         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L730         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L731         cols_order = ['RET','VOL','SHP','MDD','RAWρ','RESIDρ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L732         def _fmt_row(s):
L733             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWρ':(f"{s['RAWρ']:.2f}" if pd.notna(s['RAWρ']) else "NaN"),'RESIDρ':(f"{s['RESIDρ']:.2f}" if pd.notna(s['RESIDρ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L734         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L735         # === 追加: GSC+DSC が低い順 TOP10 ===
L736         try:
L737             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L738             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L739             all_scores = all_scores.dropna(subset=['G_plus_D'])
L740             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L741             print("Low Score Candidates (GSC+DSC bottom 10):")
L742             print(self.low10_table.to_string())
L743         except Exception as e:
L744             print(f"[warn] low-score ranking failed: {e}")
L745             self.low10_table = None
L746         self.debug_text = ""
L747         if debug_mode:
L748             logger.info("debug_mode=True: df_z dump handled in scorer; skipping factor-side debug output")
L749         else:
L750             logger.debug(
L751                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L752                 debug_mode, True
L753             )
L754         self._debug_logged = True
L755
L756     # --- Slack送信（元 notify_slack のロジックそのまま） ---
L757     def notify_slack(self):
L758         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L759
L760         if not SLACK_WEBHOOK_URL:
L761             print("⚠️ SLACK_WEBHOOK_URL not set (main report skipped)")
L762             return
L763
L764         def _filter_suffix_from(spec: dict, group: str) -> str:
L765             g = spec.get(group, {})
L766             parts = [str(m) for m in g.get("pre_mask", [])]
L767             for k, v in (g.get("pre_filter", {}) or {}).items():
L768                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L769                 name = {"beta": "β"}.get(base, base)
L770                 try:
L771                     val = f"{float(v):g}"
L772                 except Exception:
L773                     val = str(v)
L774                 parts.append(f"{name}{op}{val}")
L775             return "" if not parts else " / filter:" + " & ".join(parts)
L776
L777         def _inject_filter_suffix(title: str, group: str) -> str:
L778             suf = _filter_suffix_from(FILTER_SPEC, group)
L779             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L780
L781         def _blk(title, tbl, fmt=None, drop=()):
L782             if tbl is None or getattr(tbl, 'empty', False):
L783                 return f"{title}\n(選定なし)\n"
L784             if drop and hasattr(tbl, 'columns'):
L785                 keep = [c for c in tbl.columns if c not in drop]
L786                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L787             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L788
L789         message = "📈 ファクター分散最適化の結果\n"
L790         if self.miss_df is not None and not self.miss_df.empty:
L791             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L792         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L793         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L794         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L795         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L796
L797         try:
L798             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L799             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L800             if r is not None:
L801                 r.raise_for_status()
L802         except Exception as e:
L803             print(f"[ERR] main_post_failed: {e}")
L804
L805 def _infer_g_universe(feature_df, selected12=None, near5=None):
L806     try:
L807         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L808         if out: return out
L809     except Exception:
L810         pass
L811     base = set()
L812     for lst in (selected12 or []), (near5 or []):
L813         for x in (lst or []): base.add(x)
L814     return list(base) if base else list(feature_df.index)
L815
L816 def _fmt_with_fire_mark(tickers, feature_df):
L817     out = []
L818     for t in tickers or []:
L819         try:
L820             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L821             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L822             out.append(f"{t}{' 🔥' if (br or pb) else ''}")
L823         except Exception:
L824             out.append(t)
L825     return out
L826
L827 def _label_recent_event(t, feature_df):
L828     try:
L829         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L830         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L831         if   br and not pb: return f"{t}（ブレイクアウト確定 {dbr}）"
L832         elif pb and not br: return f"{t}（押し目反発 {dpb}）"
L833         elif br and pb:     return f"{t}（ブレイクアウト確定 {dbr}／押し目反発 {dpb}）"
L834     except Exception:
L835         pass
L836     return t
L837
L838 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L839
L840 def io_build_input_bundle() -> InputBundle:
L841     """
L842     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L843     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L844     """
L845     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L846     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L847
L848 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L849               n_target: int) -> tuple[list, float, float, float]:
L850     """
L851     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L852     戻り値：(pick, avg_res_corr, sum_score, objective)
L853     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L854     """
L855
```