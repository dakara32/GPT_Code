```text
'], d_disp['YLD'], d_disp['VOL'], d_disp['TRD'] = df_z.loc[D_UNI,'D_QAL'], df_z.loc[D_UNI,'D_YLD'], df_z.loc[D_UNI,'D_VOL_RAW'], df_z.loc[D_UNI,'D_TRD']
L643         dsc_series = pd.Series({t: d_score_all.get(t) for t in D_UNI}, name='DSC')
L644         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("â­ï¸" if t in top_D else "") for t in D_UNI]
L645         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L646         import scorer
L647         dw_eff = scorer.D_WEIGHTS_EFF
L648         self.d_title = (f"[Dæ  / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L649                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L650         if near_D:
L651             add = [t for t in near_D if t not in set(D_UNI)][:10]
L652             if add:
L653                 d_disp2 = pd.DataFrame(index=add)
L654                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L655                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L656                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L657         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L658
L659         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L660         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L661         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L662
L663         self.io_table = pd.DataFrame({
L664             'IN': pd.Series(in_list),
L665             '/ OUT': pd.Series(out_list)
L666         })
L667         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L668         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L669         self.io_table['GSC'] = pd.Series(g_list)
L670         self.io_table['DSC'] = pd.Series(d_list)
L671
L672         print("Changes:")
L673         print(self.io_table.to_string(index=False))
L674
L675         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False)['Close']
L676         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L677         for name,ticks in portfolios.items():
L678             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L679             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L680             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L681             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L682             if len(ticks)>=2:
L683                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L684                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L685                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L686             else: RAW_rho = RESID_rho = np.nan
L687             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L688         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L689         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L690         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L691         def _fmt_row(s):
L692             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L693         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L694         if self.debug:
L695             dbg_df = df_z.rename(columns={k: v for k, v in _DEBUG_COL_ALIAS.items() if k in df_z.columns})
L696             dbg_cols = [c for c in _DEBUG_COL_ORDER if c in dbg_df.columns]
L697             if not dbg_cols:
L698                 dbg_cols = [c for c in dbg_df.columns if c not in ("GSC", "DSC")]
L699             debug_tbl = dbg_df.reindex(columns=dbg_cols).copy()
L700             if hasattr(g_score, "get"):
L701                 debug_tbl["GSC"] = [g_score.get(t, np.nan) for t in debug_tbl.index]
L702             if hasattr(d_score_all, "get"):
L703                 debug_tbl["DSC"] = [d_score_all.get(t, np.nan) for t in debug_tbl.index]
L704             order = dbg_cols + [c for c in ("GSC", "DSC") if c not in dbg_cols]
L705             self.debug_table = debug_tbl.reindex(columns=order).round(3)
L706             print("Debug Data:"); print(self.debug_table.to_string())
L707
L708         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L709         try:
L710             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L711             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L712             all_scores = all_scores.dropna(subset=['G_plus_D'])
L713             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L714             print("Low Score Candidates (GSC+DSC bottom 10):")
L715             print(self.low10_table.to_string())
L716         except Exception as e:
L717             print(f"[warn] low-score ranking failed: {e}")
L718             self.low10_table = None
L719
L720     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L721     def notify_slack(self):
L722         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L723         if not SLACK_WEBHOOK_URL: raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L724         def _filter_suffix_from(spec: dict, group: str) -> str:
L725             g = spec.get(group, {})
L726             parts = [str(m) for m in g.get("pre_mask", [])]
L727             for k, v in (g.get("pre_filter", {}) or {}).items():
L728                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L729                 name = {"beta": "Î²"}.get(base, base)
L730                 try: val = f"{float(v):g}"
L731                 except: val = str(v)
L732                 parts.append(f"{name}{op}{val}")
L733             return "" if not parts else " / filter:" + " & ".join(parts)
L734         def _inject_filter_suffix(title: str, group: str) -> str:
L735             suf = _filter_suffix_from(FILTER_SPEC, group)
L736             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L737         def _blk(title, tbl, fmt=None, drop=()):
L738             if tbl is None or getattr(tbl,'empty',False): return f"{title}\n(é¸å®šãªã—)\n"
L739             if drop and hasattr(tbl,'columns'):
L740                 keep = [c for c in tbl.columns if c not in drop]
L741                 tbl, fmt = tbl[keep], {k:v for k,v in (fmt or {}).items() if k in keep}
L742             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L743
L744         g_title = _inject_filter_suffix(self.g_title, "G")
L745         d_title = _inject_filter_suffix(self.d_title, "D")
L746         message  = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L747         if self.miss_df is not None and not self.miss_df.empty:
L748             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L749         message += _blk(g_title, self.g_table, self.g_formatters, drop=("TRD",))
L750         message += _blk(d_title, self.d_table, self.d_formatters)
L751         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table,'empty',False) else f"```{self.io_table.to_string(index=False)}```\n")
L752         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L753         if self.debug and self.debug_table is not None:
L754             message += "\nDebug Data\n```" + self.debug_table.to_string() + "```"
L755         payload = {"text": message}
L756         try:
L757             resp = requests.post(SLACK_WEBHOOK_URL, json=payload); resp.raise_for_status(); print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L758         except Exception as e: print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L759
L760 def _infer_g_universe(feature_df, selected12=None, near5=None):
L761     try:
L762         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L763         if out: return out
L764     except Exception:
L765         pass
L766     base = set()
L767     for lst in (selected12 or []), (near5 or []):
L768         for x in (lst or []): base.add(x)
L769     return list(base) if base else list(feature_df.index)
L770
L771 def _fmt_with_fire_mark(tickers, feature_df):
L772     out = []
L773     for t in tickers or []:
L774         try:
L775             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L776             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L777             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L778         except Exception:
L779             out.append(t)
L780     return out
L781
L782 def _label_recent_event(t, feature_df):
L783     try:
L784         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L785         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L786         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L787         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L788         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L789     except Exception:
L790         pass
L791     return t
L792
L793 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L794
L795 def io_build_input_bundle() -> InputBundle:
L796     """
L797     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L798     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L799     """
L800     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L801     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L802
L803 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L804               n_target: int) -> tuple[list, float, float, float]:
L805     """
L806     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L807     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L808     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L809     """
L810     sc.cfg = cfg
L811
L812     if hasattr(sc, "score_build_features"):
L813         feat = sc.score_build_features(inb)
L814         if not hasattr(sc, "_feat_logged"):
L815             T.log("features built (scorer)")
L816             sc._feat_logged = True
L817         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L818     else:
L819         fb = sc.aggregate_scores(inb, cfg)
L820         if not hasattr(sc, "_feat_logged"):
L821             T.log("features built (scorer)")
L822             sc._feat_logged = True
L823         sc._feat = fb
L824         agg = fb.g_score if group == "G" else fb.d_score_all
L825         if group == "D" and hasattr(fb, "df"):
L826             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L827
L828     if hasattr(sc, "filter_candidates"):
L829         agg = agg[sc.filter_candidates(inb, agg, grou
```