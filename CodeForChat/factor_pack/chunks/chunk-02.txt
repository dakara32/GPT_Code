```text
:
L281             node = facts.get(ns, {}) if isinstance(facts, dict) else {}
L282             for tg in tags:
L283                 try:
L284                     units = node[tg]["units"]
L285                 except Exception:
L286                     continue
L287                 picks: list[dict] = []
L288                 if "USD/shares" in units:
L289                     picks.extend(list(units["USD/shares"]))
L290                 if "USD" in units:
L291                     picks.extend(list(units["USD"]))
L292                 if not picks:
L293                     for arr in units.values():
L294                         picks.extend(list(arr))
L295                 out.extend(picks)
L296         return out
L297
L298     @staticmethod
L299     def _only_quarterly(arr: list[dict]) -> list[dict]:
L300         """companyfactsの混在配列から『四半期』だけを抽出。
L301
L302         - frame に "Q" を含む（例: CY2024Q2I）
L303         - fp が Q1/Q2/Q3/Q4
L304         - form が 10-Q/10-Q/A/6-K
L305         """
L306         if not arr:
L307             return []
L308         q_forms = {"10-Q", "10-Q/A", "6-K"}
L309         out = [
L310             x
L311             for x in arr
L312             if (
L313                 "Q" in (x.get("frame") or "").upper()
L314                 or (x.get("fp") or "").upper() in {"Q1", "Q2", "Q3", "Q4"}
L315                 or (x.get("form") or "").upper() in q_forms
L316             )
L317         ]
L318         out.sort(key=lambda x: (x.get("end") or ""), reverse=True)
L319         return out
L320
L321     @staticmethod
L322     def _series_from_facts_with_dates(arr, key_val="val", key_dt="end", normalize=float):
L323         """companyfactsアイテム配列から (date,value) を返す。dateはYYYY-MM-DDを想定。"""
L324         out: List[Tuple[str, float]] = []
L325         for x in (arr or []):
L326             try:
L327                 d = x.get(key_dt)
L328                 if d is None:
L329                     continue
L330                 v = x.get(key_val)
L331                 out.append((str(d), normalize(v) if v is not None else float("nan")))
L332             except Exception:
L333                 continue
L334         out.sort(key=lambda t: t[0], reverse=True)
L335         return out
L336
L337     def fetch_eps_rev_from_sec(self, tickers: list[str]) -> dict:
L338         out = {}
L339         t2cik = self._sec_ticker_map()
L340         n_map = n_rev = n_eps = 0
L341         miss_map: list[str] = []
L342         miss_facts: list[str] = []
L343         for t in tickers:
L344             base = (t or "").upper()
L345             candidates: list[str] = []
L346             for key in [base, *self._normalize_ticker(t)]:
L347                 if key and key not in candidates:
L348                     candidates.append(key)
L349             cik = next((t2cik.get(key) for key in candidates if t2cik.get(key)), None)
L350             if not cik:
L351                 out[t] = {}
L352                 miss_map.append(t)
L353                 continue
L354             try:
L355                 j = self._sec_companyfacts(cik)
L356                 facts = j or {}
L357                 rev_tags = [
L358                     "Revenues",
L359                     "RevenueFromContractWithCustomerExcludingAssessedTax",
L360                     "SalesRevenueNet",
L361                     "SalesRevenueGoodsNet",
L362                     "SalesRevenueServicesNet",
L363                     "Revenue",
L364                 ]
L365                 eps_tags = [
L366                     "EarningsPerShareDiluted",
L367                     "EarningsPerShareBasicAndDiluted",
L368                     "EarningsPerShare",
L369                     "EarningsPerShareBasic",
L370                 ]
L371                 rev_arr = self._units_for_tags(facts, ["us-gaap", "ifrs-full"], rev_tags)
L372                 eps_arr = self._units_for_tags(facts, ["us-gaap", "ifrs-full"], eps_tags)
L373                 rev_q_items = self._only_quarterly(rev_arr)
L374                 eps_q_items = self._only_quarterly(eps_arr)
L375                 # (date,value) で取得
L376                 rev_pairs = self._series_from_facts_with_dates(rev_q_items)
L377                 eps_pairs = self._series_from_facts_with_dates(eps_q_items)
L378                 rev_vals = [v for (_d, v) in rev_pairs]
L379                 eps_vals = [v for (_d, v) in eps_pairs]
L380                 rev_q = float(rev_vals[0]) if rev_vals else float("nan")
L381                 eps_q = float(eps_vals[0]) if eps_vals else float("nan")
L382                 rev_ttm = float(sum(v for v in rev_vals[:4] if v == v)) if rev_vals else float("nan")
L383                 eps_ttm = float(sum(v for v in eps_vals[:4] if v == v)) if eps_vals else float("nan")
L384                 out[t] = {
L385                     "eps_q_recent": eps_q,
L386                     "eps_ttm": eps_ttm,
L387                     "rev_q_recent": rev_q,
L388                     "rev_ttm": rev_ttm,
L389                     # 後段でDatetimeIndex化できるよう (date,value) を保持。値だけの互換キーも残す。
L390                     "eps_q_series_pairs": eps_pairs[:16],
L391                     "rev_q_series_pairs": rev_pairs[:16],
L392                     "eps_q_series": eps_vals[:16],
L393                     "rev_q_series": rev_vals[:16],
L394                 }
L395                 n_map += 1
L396                 if rev_vals:
L397                     n_rev += 1
L398                 if eps_vals:
L399                     n_eps += 1
L400             except Exception:
L401                 out[t] = {}
L402                 miss_facts.append(t)
L403             time.sleep(0.30)
L404         # 取得サマリをログ（Actionsで確認しやすいよう print）
L405         try:
L406             total = len(tickers)
L407             print(f"[SEC] map={n_map}/{total}  rev_q_hit={n_rev}  eps_q_hit={n_eps}")
L408             # デバッグ: 取得本数の分布（先頭のみ）
L409             try:
L410                 lens = [len((out.get(t, {}) or {}).get("rev_q_series", [])) for t in tickers]
L411                 print(f"[SEC] rev_q_series length: min={min(lens) if lens else 0} "
L412                       f"p25={np.percentile(lens,25) if lens else 0} median={np.median(lens) if lens else 0} "
L413                       f"p75={np.percentile(lens,75) if lens else 0} max={max(lens) if lens else 0}")
L414             except Exception:
L415                 pass
L416             if miss_map:
L417                 print(f"[SEC] no CIK map: {len(miss_map)} (サンプル例) {miss_map[:20]}")
L418             if miss_facts:
L419                 print(f"[SEC] CIKあり だが対象factなし: {len(miss_facts)} (サンプル例) {miss_facts[:20]}")
L420         except Exception:
L421             pass
L422         return out
L423
L424     def sec_dryrun_sample(self, tickers: list[str] | None = None) -> None:
L425         if not _env_true("SEC_DRYRUN_SAMPLE", False):
L426             return
L427         sample = tickers or ["BRK.B", "BF.B", "GOOGL", "META", "UBER", "PBR.A", "TSM", "NARI", "EVBN", "SWAV"]
L428         print(f"[SEC-DRYRUN] sample tickers: {sample}")
L429         try:
L430             t2cik = self._sec_ticker_map()
L431             hits = 0
L432             for sym in sample:
L433                 candidates: list[str] = []
L434
L435                 def add(key: str) -> None:
L436                     if key and key not in candidates:
L437                         candidates.append(key)
L438
L439                 add((sym or "").upper())
L440                 for alt in self._normalize_ticker(sym):
L441                     add(alt)
L442                 if any(t2cik.get(key) for key in candidates):
L443                     hits += 1
L444             sec_data = self.fetch_eps_rev_from_sec(sample)
L445             rev_hits = sum(1 for v in sec_data.values() if v.get("rev_q_series"))
L446             eps_hits = sum(1 for v in sec_data.values() if v.get("eps_q_series"))
L447             total = len(sample)
L448             print(f"[SEC-DRYRUN] CIK map hit: {hits}/{total}  rev_q_series hits: {rev_hits}  eps_q_series hits: {eps_hits}")
L449         except Exception as e:
L450             print(f"[SEC-DRYRUN] error: {e}")
L451     @staticmethod
L452     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L453         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L454         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L455         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L456
L457     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L458
L459     @staticmethod
L460     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L461         if df is None or df.empty: return None
L462         idx_lower={str(i).lower():i for i in df.index}
L463         for n in names:
L464             k=n.lower()
L465             if k in idx_lower: return df.loc[idx_lower[k]]
L466         return None
L467
L468     @staticmethod
L469     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L470         if s is None or s.empty: return None
L471         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L472
L473     @staticmethod
L474     def _latest(s: pd.Series|None) -> float|None:
L475         if s is None or s.empty: return None
L476         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L477
L478     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L479         from concurrent.futures import ThreadPoolExecutor, as_completed
L480         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L481
L482         def one(t: str):
L483             try:
L484                 tk = yf.Ticker(t)  # ★ セッションは渡さない（YFがcurl_cffiで管理）
L485                 qcf = tk.quarterly_cashflow
L486                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L487                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L488                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L489                 if any(v is None for v in (cfo, capex, fcf)):
L490                     acf = tk.cashflow
L491                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L492                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L493                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L494             except Exception as e:
L495                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L496             n=np.nan
L497             return {"ticker":t,
L498                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L499                     "capex_ttm_yf": n if capex is None else capex,
L500                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L501
L502         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L503         with ThreadPoolExecutor(max_workers=mw) as ex:
L504             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L505         return pd.DataFrame(rows).set_index("ticker")
L506
L507     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L508     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L509
L510     @staticmethod
L511     def _first_key(d: dict, keys: list[str]):
L512         for k in keys:
L513             if k in d and d[k] is not None: return d[k]
L514         return None
L515
L516     @staticmethod
L517     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L518         for i in range(retries):
L519             r = session.get(url, params=params, timeout
```