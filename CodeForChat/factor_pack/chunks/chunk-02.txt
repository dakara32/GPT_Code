```text
g_fmt = dbg.apply(_fmt_col)
L269
L270     order = [c for c in DEBUG_COLS if c in dbg_fmt.columns]
L271     extra = [c for c in dbg_fmt.columns if c not in order]
L272     if extra:
L273         order.extend(extra)
L274     return dbg_fmt.reindex(columns=order)
L275
L276     all_rows = _env_true("DEBUG_ALL_ROWS", False)
L277
L278     def _merge_rows(*seqs):
L279         seen, out = set(), []
L280         for seq in seqs:
L281             for t in seq or []:
L282                 if t in df_show.index and t not in seen:
L283                     seen.add(t)
L284                     out.append(t)
L285         return out
L286
L287     focus = df_show.index.tolist() if all_rows else _merge_rows(g_pick + d_pick, [t for t in (exist or [])], g_miss, d_miss)
L288     if not focus:
L289         focus = df_show.index.tolist()
L290     focus = focus[:max_rows]
L291
L292     def _fmt_near(lbl, ser, lst):
L293         if ser is None:
L294             return f"{lbl}: off"
L295         get = ser.get
L296         parts = []
L297         for t in lst:
L298             val = get(t, np.nan)
L299             parts.append(f"{t}:{val:.3f}" if pd.notna(val) else f"{t}:nan")
L300         return f"{lbl}: " + (", ".join(parts) if parts else "-")
L301
L302     head = [
L303         f"G new/out: {len(g_new)}/{len(g_out)}  D new/out: {len(d_new)}/{len(d_out)}",
L304         _fmt_near("G near10", g_sorted, g_miss),
L305         _fmt_near("D near10", d_sorted, d_miss),
L306         f"Filters: G pre_mask=['trend_template'], D pre_filter={{'beta_max': {D_BETA_MAX}}}",
L307         f"Cols={'ALL' if all_cols else 'MIN'}  Rows={'ALL' if all_rows else 'SELECTED+CURRENT+NEAR'}",
L308     ]
L309
L310     if not focus or not cols:
L311         body = "(no rows or columns to display)"
L312     else:
L313         base = df_show.loc[focus, cols].copy()
L314         if "GSC" not in base.columns and g_series is not None:
L315             base["GSC"] = [g_series.get(t, np.nan) if hasattr(g_series, "get") else np.nan for t in base.index]
L316         if "DSC" not in base.columns and d_series is not None:
L317             base["DSC"] = [d_series.get(t, np.nan) if hasattr(d_series, "get") else np.nan for t in base.index]
L318         out_cols = cols + [c for c in ("GSC", "DSC") if c not in cols]
L319         body = base.reindex(columns=out_cols).round(3).to_string(max_rows=None, max_cols=None, na_rep="nan")
L320
L321     miss_txt = ""
L322     if _env_true("DEBUG_MISSING_LOGS", False):
L323         miss = getattr(fb, "missing_logs", None)
L324         if miss is not None and not miss.empty:
L325             miss_txt = "\nMissing data (head)\n" + miss.head(10).to_string(index=False)
L326
L327     return "\n".join(head + ["\nChanged/Selected (+ Near Miss + Current)", body]) + miss_txt
L328
L329 def _disjoint_keepG(top_G, top_D, poolD):
L330     """G重複をDから除去し、poolDで順次補充（枯渇時は元銘柄維持）。"""
L331     used, D, i = set(top_G), list(top_D), 0
L332     for j, t in enumerate(D):
L333         if t in used:
L334             while i < len(poolD) and (poolD[i] in used or poolD[i] in D):
L335                 i += 1
L336             if i < len(poolD):
L337                 D[j] = poolD[i]; used.add(D[j]); i += 1
L338     return top_G, D
L339
L340
L341 def _sticky_keep_current(agg: pd.Series, pick: list[str], incumbents: list[str],
L342                          n_target: int, delta_z: float, keep_buffer: int) -> list[str]:
L343     import pandas as pd, numpy as np
L344     sel = list(pick)
L345     if not sel: return sel
L346     ranked_sel = agg.reindex(sel).sort_values(ascending=False)
L347     kth = ranked_sel.iloc[min(len(sel), n_target)-1]
L348     sigma = float(agg.std()) if pd.notna(agg.std()) else 0.0
L349     thresh = kth - delta_z * sigma
L350     ranked_all = agg.sort_values(ascending=False)
L351     cand = [t for t in incumbents if (t not in sel) and (t in agg.index)]
L352     for t in cand:
L353         within_score = (pd.notna(agg[t]) and agg[t] >= thresh)
L354         within_rank  = (t in ranked_all.index) and (ranked_all.index.get_loc(t) < n_target + keep_buffer)
L355         if within_score or within_rank:
L356             non_inc = [x for x in sel if x not in incumbents]
L357             if not non_inc: break
L358             weakest = min(non_inc, key=lambda x: agg.get(x, -np.inf))
L359             if weakest in sel and agg.get(t, -np.inf) >= agg.get(weakest, -np.inf):
L360                 sel.remove(weakest); sel.append(t)
L361     if len(sel) > n_target:
L362         sel = sorted(sel, key=lambda x: agg.get(x, -1e9), reverse=True)[:n_target]
L363     return sel
L364
L365
L366 # === Input：外部I/Oと前処理（CSV/API・欠損補完） ===
L367 class Input:
L368     def __init__(self, cand, exist, bench, price_max, finnhub_api_key=None):
L369         self.cand, self.exist, self.bench, self.price_max = cand, exist, bench, price_max
L370         self.api_key = finnhub_api_key or os.environ.get("FINNHUB_API_KEY")
L371
L372     # ---- （Input専用）EPS補完・FCF算出系 ----
L373     @staticmethod
L374     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L375         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L376         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L377         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L378
L379     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L380
L381     @staticmethod
L382     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L383         if df is None or df.empty: return None
L384         idx_lower={str(i).lower():i for i in df.index}
L385         for n in names:
L386             k=n.lower()
L387             if k in idx_lower: return df.loc[idx_lower[k]]
L388         return None
L389
L390     @staticmethod
L391     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L392         if s is None or s.empty: return None
L393         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L394
L395     @staticmethod
L396     def _latest(s: pd.Series|None) -> float|None:
L397         if s is None or s.empty: return None
L398         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L399
L400     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L401         from concurrent.futures import ThreadPoolExecutor, as_completed
L402         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L403
L404         def one(t: str):
L405             try:
L406                 tk = yf.Ticker(t)  # ★ セッションは渡さない（YFがcurl_cffiで管理）
L407                 qcf = tk.quarterly_cashflow
L408                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L409                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L410                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L411                 if any(v is None for v in (cfo, capex, fcf)):
L412                     acf = tk.cashflow
L413                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L414                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L415                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L416             except Exception as e:
L417                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L418             n=np.nan
L419             return {"ticker":t,
L420                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L421                     "capex_ttm_yf": n if capex is None else capex,
L422                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L423
L424         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L425         with ThreadPoolExecutor(max_workers=mw) as ex:
L426             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L427         return pd.DataFrame(rows).set_index("ticker")
L428
L429     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L430     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L431
L432     @staticmethod
L433     def _first_key(d: dict, keys: list[str]):
L434         for k in keys:
L435             if k in d and d[k] is not None: return d[k]
L436         return None
L437
L438     @staticmethod
L439     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L440         for i in range(retries):
L441             r = session.get(url, params=params, timeout=15)
L442             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L443             r.raise_for_status(); return r.json()
L444         r.raise_for_status()
L445
L446     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L447         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L448         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L449         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L450         for sym in tickers:
L451             cfo_ttm = capex_ttm = None
L452             try:
L453                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L454                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L455                 for item in arr[:4]:
L456                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L457                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L458                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L459             except Exception: pass
L460             if cfo_ttm is None or capex_ttm is None:
L461                 try:
L462                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L463                     arr = j.get("cashFlow") or []
L464                     if arr:
L465                         item0 = arr[0]
L466                         if cfo_ttm is None:
L467                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L468                             if v is not None: cfo_ttm = float(v)
L469                         if capex_ttm is None:
L470                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L471                             if v is not None: capex_ttm = float(v)
L472                 except Exception: pass
L473             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L474         return pd.DataFrame(rows).set_index("ticker")
L475
L476     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L477         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L478         T.log("financials (yf) done")
L479         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L480         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L481         if need:
L482             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L483             df = yf_df.join(fh_df, how="left")
L484             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_f
```