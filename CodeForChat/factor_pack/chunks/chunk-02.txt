```text
v.empty else None
L242
L243     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L244         from concurrent.futures import ThreadPoolExecutor, as_completed
L245         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L246
L247         def one(t: str):
L248             try:
L249                 tk = yf.Ticker(t)  # ★ セッションは渡さない（YFがcurl_cffiで管理）
L250                 qcf = tk.quarterly_cashflow
L251                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L252                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L253                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L254                 if any(v is None for v in (cfo, capex, fcf)):
L255                     acf = tk.cashflow
L256                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L257                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L258                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L259             except Exception as e:
L260                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L261             n=np.nan
L262             return {"ticker":t,
L263                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L264                     "capex_ttm_yf": n if capex is None else capex,
L265                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L266
L267         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L268         with ThreadPoolExecutor(max_workers=mw) as ex:
L269             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L270         return pd.DataFrame(rows).set_index("ticker")
L271
L272     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L273     _FINN_CAPEX_KEYS = ["capitalExpenditure","capitalExpenditures","purchaseOfPPE","investmentsInPropertyPlantAndEquipment"]
L274
L275     @staticmethod
L276     def _first_key(d: dict, keys: list[str]):
L277         for k in keys:
L278             if k in d and d[k] is not None: return d[k]
L279         return None
L280
L281     @staticmethod
L282     def _finn_get(session: requests.Session, url: str, params: dict, retries: int=3, sleep_s: float=0.5):
L283         for i in range(retries):
L284             r = session.get(url, params=params, timeout=15)
L285             if r.status_code==429: time.sleep(min(2**i*sleep_s,4.0)); continue
L286             r.raise_for_status(); return r.json()
L287         r.raise_for_status()
L288
L289     def fetch_cfo_capex_ttm_finnhub(self, tickers: list[str], api_key: str|None=None) -> pd.DataFrame:
L290         api_key = api_key or os.getenv("FINNHUB_API_KEY")
L291         if not api_key: raise ValueError("Finnhub API key not provided. Set FINNHUB_API_KEY or pass api_key=")
L292         base, s, rows = "https://finnhub.io/api/v1", requests.Session(), []
L293         for sym in tickers:
L294             cfo_ttm = capex_ttm = None
L295             try:
L296                 j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"quarterly","limit":8,"token":api_key})
L297                 arr = j.get("cashFlow") or []; cfo_vals, capex_vals = [], []
L298                 for item in arr[:4]:
L299                     cfo_vals.append(self._first_key(item,self._FINN_CFO_KEYS)); capex_vals.append(self._first_key(item,self._FINN_CAPEX_KEYS))
L300                 if any(v is not None for v in cfo_vals): cfo_ttm = float(np.nansum([np.nan if v is None else float(v) for v in cfo_vals]))
L301                 if any(v is not None for v in capex_vals): capex_ttm = float(np.nansum([np.nan if v is None else float(v) for v in capex_vals]))
L302             except Exception: pass
L303             if cfo_ttm is None or capex_ttm is None:
L304                 try:
L305                     j = self._finn_get(s, f"{base}/stock/cash-flow", {"symbol":sym,"frequency":"annual","limit":1,"token":api_key})
L306                     arr = j.get("cashFlow") or []
L307                     if arr:
L308                         item0 = arr[0]
L309                         if cfo_ttm is None:
L310                             v = self._first_key(item0,self._FINN_CFO_KEYS)
L311                             if v is not None: cfo_ttm = float(v)
L312                         if capex_ttm is None:
L313                             v = self._first_key(item0,self._FINN_CAPEX_KEYS)
L314                             if v is not None: capex_ttm = float(v)
L315                 except Exception: pass
L316             rows.append({"ticker":sym,"cfo_ttm_fh":np.nan if cfo_ttm is None else cfo_ttm,"capex_ttm_fh":np.nan if capex_ttm is None else capex_ttm})
L317         return pd.DataFrame(rows).set_index("ticker")
L318
L319     def compute_fcf_with_fallback(self, tickers: list[str], finnhub_api_key: str|None=None) -> pd.DataFrame:
L320         yf_df = self.fetch_cfo_capex_ttm_yf(tickers)
L321         T.log("financials (yf) done")
L322         miss_mask = yf_df[["cfo_ttm_yf","capex_ttm_yf","fcf_ttm_yf_direct"]].isna().any(axis=1)
L323         need = yf_df.index[miss_mask].tolist(); print(f"[T] yf financials missing: {len(need)} {need[:10]}{'...' if len(need)>10 else ''}")
L324         if need:
L325             fh_df = self.fetch_cfo_capex_ttm_finnhub(need, api_key=finnhub_api_key)
L326             df = yf_df.join(fh_df, how="left")
L327             for col_yf, col_fh in [("cfo_ttm_yf","cfo_ttm_fh"),("capex_ttm_yf","capex_ttm_fh")]:
L328                 df[col_yf] = df[col_yf].fillna(df[col_fh])
L329             print("[T] financials (finnhub) done (fallback only)")
L330         else:
L331             df = yf_df.assign(cfo_ttm_fh=np.nan, capex_ttm_fh=np.nan)
L332             print("[T] financials (finnhub) skipped (no missing)")
L333         df["cfo_ttm"]  = df["cfo_ttm_yf"].where(df["cfo_ttm_yf"].notna(), df["cfo_ttm_fh"])
L334         df["capex_ttm"] = df["capex_ttm_yf"].where(df["capex_ttm_yf"].notna(), df["capex_ttm_fh"])
L335         cfo, capex = pd.to_numeric(df["cfo_ttm"], errors="coerce"), pd.to_numeric(df["capex_ttm"], errors="coerce").abs()
L336         fcf_calc = cfo - capex
L337         fcf_direct = pd.to_numeric(df.get("fcf_ttm_yf_direct"), errors="coerce")
L338         df["fcf_ttm"] = fcf_calc.where(fcf_calc.notna(), fcf_direct)
L339         df["cfo_source"]  = np.where(df["cfo_ttm_yf"].notna(),"yfinance",np.where(df["cfo_ttm_fh"].notna(),"finnhub",""))
L340         df["capex_source"] = np.where(df["capex_ttm_yf"].notna(),"yfinance",np.where(df["capex_ttm_fh"].notna(),"finnhub",""))
L341         df["fcf_imputed"] = df[["cfo_ttm","capex_ttm"]].isna().any(axis=1) & df["fcf_ttm"].notna()
L342         cols = ["cfo_ttm_yf","capex_ttm_yf","cfo_ttm_fh","capex_ttm_fh","cfo_ttm","capex_ttm","fcf_ttm","fcf_ttm_yf_direct","cfo_source","capex_source","fcf_imputed"]
L343         return df[cols].sort_index()
L344
L345     def _build_eps_df(self, tickers, tickers_bulk, info):
L346         eps_rows=[]
L347         for t in tickers:
L348             info_t, eps_ttm, eps_q = info[t], info[t].get("trailingEps", np.nan), np.nan
L349             try:
L350                 qearn, so = tickers_bulk.tickers[t].quarterly_earnings, info_t.get("sharesOutstanding")
L351                 if so and qearn is not None and not qearn.empty and "Earnings" in qearn.columns:
L352                     eps_ttm_q = qearn["Earnings"].head(4).sum()/so
L353                     if pd.notna(eps_ttm_q) and (pd.isna(eps_ttm) or (abs(eps_ttm)>0 and abs(eps_ttm/eps_ttm_q)>3)): eps_ttm = eps_ttm_q
L354                     eps_q = qearn["Earnings"].iloc[-1]/so
L355             except Exception: pass
L356             eps_rows.append({"ticker":t,"eps_ttm":eps_ttm,"eps_q_recent":eps_q})
L357         return self.impute_eps_ttm(pd.DataFrame(eps_rows).set_index("ticker"))
L358
L359     def prepare_data(self):
L360         """Fetch price and fundamental data for all tickers."""
L361         cand_info = yf.Tickers(" ".join(self.cand)); cand_prices = {}
L362         for t in self.cand:
L363             try: cand_prices[t] = cand_info.tickers[t].fast_info.get("lastPrice", np.inf)
L364             except Exception as e: print(f"{t}: price fetch failed ({e})"); cand_prices[t] = np.inf
L365         cand_f = [t for t,p in cand_prices.items() if p<=self.price_max]
L366         T.log("price cap filter done (CAND_PRICE_MAX)")
L367         tickers = sorted(set(self.exist + cand_f))
L368         T.log(f"universe prepared: unique={len(tickers)} bench={self.bench}")
L369         data = yf.download(tickers + [self.bench], period="600d", auto_adjust=True, progress=False)
L370         T.log("yf.download done")
L371         px, spx = data["Close"], data["Close"][self.bench]
L372         clip_days = int(os.getenv("PRICE_CLIP_DAYS", "0"))   # 0なら無効（既定）
L373         if clip_days > 0:
L374             px  = px.tail(clip_days + 1)
L375             spx = spx.tail(clip_days + 1)
L376             print(f"[T] price window clipped by env: {len(px)} rows (PRICE_CLIP_DAYS={clip_days})")
L377         else:
L378             print(f"[T] price window clip skipped; rows={len(px)}")
L379         tickers_bulk, info = yf.Tickers(" ".join(tickers)), {}
L380         for t in tickers:
L381             try: info[t] = tickers_bulk.tickers[t].info
L382             except Exception as e: print(f"{t}: info fetch failed ({e})"); info[t] = {}
L383         eps_df = self._build_eps_df(tickers, tickers_bulk, info)
L384         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L385         T.log("eps/fcf prep done")
L386         returns = px[tickers].pct_change()
L387         T.log("price prep/returns done")
L388         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L389
L390 # === Selector：相関低減・選定（スコア＆リターンだけ読む） ===
L391 class Selector:
L392     # ---- DRRS helpers（Selector専用） ----
L393     @staticmethod
L394     def _z_np(X: np.ndarray) -> np.ndarray:
L395         X = np.asarray(X, dtype=np.float32); m = np.nanmean(X, axis=0, keepdims=True); s = np.nanstd(X, axis=0, keepdims=True)+1e-9
L396         return (np.nan_to_num(X)-m)/s
L397
L398     @classmethod
L399     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L400         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L401         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L402         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L403         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L404         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L405
L406     @classmethod
L407     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L408         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L409         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L410         if k==0: return []
L411         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L412         for _ in range(k):
L413             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L414             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L415             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L416         return sorted(S)
L417
L418     @staticmethod
L419     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L420         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L421         return float(s[id
```