```text
list[str], tags: list[str]) -> list[dict]:
L280         """facts から namespace/tag を横断して units 配列を収集（存在順に連結）。"""
L281         out: list[dict] = []
L282         facts = facts or {}
L283         for ns in namespaces:
L284             try:
L285                 node = facts.get("facts", {}).get(ns, {})
L286             except Exception:
L287                 node = {}
L288             for tg in tags:
L289                 try:
L290                     units = node[tg]["units"]
L291                 except Exception:
L292                     continue
L293                 picks: list[dict] = []
L294                 if "USD/shares" in units:
L295                     picks.extend(list(units["USD/shares"]))
L296                 if "USD" in units:
L297                     picks.extend(list(units["USD"]))
L298                 if not picks:
L299                     for arr in units.values():
L300                         picks.extend(list(arr))
L301                 out.extend(picks)
L302         return out
L303
L304     @staticmethod
L305     def _only_quarterly(arr: list[dict]) -> list[dict]:
L306         """companyfactsの混在配列から『四半期』だけを抽出。
L307
L308         - frame に "Q" を含む（例: CY2024Q2I）
L309         - fp が Q1/Q2/Q3/Q4
L310         - form が 10-Q/10-Q/A/6-K
L311         """
L312         if not arr:
L313             return []
L314         q_forms = {"10-Q", "10-Q/A", "6-K"}
L315
L316         def is_q(x: dict) -> bool:
L317             frame = (x.get("frame") or "").upper()
L318             fp = (x.get("fp") or "").upper()
L319             form = (x.get("form") or "").upper()
L320             return ("Q" in frame) or (fp in {"Q1", "Q2", "Q3", "Q4"}) or (form in q_forms)
L321
L322         out = [x for x in arr if is_q(x)]
L323         out.sort(key=lambda x: (x.get("end") or ""), reverse=True)
L324         return out
L325
L326     @staticmethod
L327     def _series_from_facts_with_dates(arr, key_val="val", key_dt="end", normalize=float):
L328         """companyfactsアイテム配列から (date,value) を返す。dateはYYYY-MM-DDを想定。"""
L329         out: List[Tuple[str, float]] = []
L330         for x in (arr or []):
L331             try:
L332                 v = x.get(key_val)
L333                 d = x.get(key_dt)
L334                 if d is None:
L335                     continue
L336                 out.append((str(d), normalize(v) if v is not None else float("nan")))
L337             except Exception:
L338                 continue
L339         # end(=日付)の降順にソート（最新→古い）
L340         out.sort(key=lambda t: t[0], reverse=True)
L341         return out
L342
L343     def fetch_eps_rev_from_sec(self, tickers: list[str]) -> dict:
L344         out = {}
L345         t2cik = self._sec_ticker_map()
L346         n_map = n_rev = n_eps = 0
L347         miss_map: list[str] = []
L348         miss_facts: list[str] = []
L349         for t in tickers:
L350             candidates: list[str] = []
L351
L352             def add(key: str) -> None:
L353                 if key and key not in candidates:
L354                     candidates.append(key)
L355
L356             add((t or "").upper())
L357             for key in self._normalize_ticker(t):
L358                 add(key)
L359
L360             cik = None
L361             for key in candidates:
L362                 cik = t2cik.get(key)
L363                 if cik:
L364                     break
L365             if not cik:
L366                 out[t] = {}
L367                 miss_map.append(t)
L368                 continue
L369             try:
L370                 j = self._sec_companyfacts(cik)
L371                 facts = j or {}
L372                 rev_tags = [
L373                     "Revenues",
L374                     "RevenueFromContractWithCustomerExcludingAssessedTax",
L375                     "SalesRevenueNet",
L376                     "SalesRevenueGoodsNet",
L377                     "SalesRevenueServicesNet",
L378                     "Revenue",
L379                 ]
L380                 eps_tags = [
L381                     "EarningsPerShareDiluted",
L382                     "EarningsPerShareBasicAndDiluted",
L383                     "EarningsPerShare",
L384                     "EarningsPerShareBasic",
L385                 ]
L386                 rev_arr = self._units_for_tags(facts, ["us-gaap", "ifrs-full"], rev_tags)
L387                 eps_arr = self._units_for_tags(facts, ["us-gaap", "ifrs-full"], eps_tags)
L388                 rev_q_items = self._only_quarterly(rev_arr)
L389                 eps_q_items = self._only_quarterly(eps_arr)
L390                 # (date,value) で取得
L391                 rev_pairs = self._series_from_facts_with_dates(rev_q_items)
L392                 eps_pairs = self._series_from_facts_with_dates(eps_q_items)
L393                 rev_vals = [v for (_d, v) in rev_pairs]
L394                 eps_vals = [v for (_d, v) in eps_pairs]
L395                 rev_q = float(rev_vals[0]) if rev_vals else float("nan")
L396                 eps_q = float(eps_vals[0]) if eps_vals else float("nan")
L397                 rev_ttm = float(sum([v for v in rev_vals[:4] if v == v])) if rev_vals else float("nan")
L398                 eps_ttm = float(sum([v for v in eps_vals[:4] if v == v])) if eps_vals else float("nan")
L399                 out[t] = {
L400                     "eps_q_recent": eps_q,
L401                     "eps_ttm": eps_ttm,
L402                     "rev_q_recent": rev_q,
L403                     "rev_ttm": rev_ttm,
L404                     # 後段でDatetimeIndex化できるよう (date,value) を保持。値だけの互換キーも残す。
L405                     "eps_q_series_pairs": eps_pairs[:16],
L406                     "rev_q_series_pairs": rev_pairs[:16],
L407                     "eps_q_series": eps_vals[:16],
L408                     "rev_q_series": rev_vals[:16],
L409                 }
L410                 n_map += 1
L411                 if rev_vals:
L412                     n_rev += 1
L413                 if eps_vals:
L414                     n_eps += 1
L415             except Exception:
L416                 out[t] = {}
L417                 miss_facts.append(t)
L418             time.sleep(0.30)
L419         # 取得サマリをログ（Actionsで確認しやすいよう print）
L420         try:
L421             total = len(tickers)
L422             print(f"[SEC] map={n_map}/{total}  rev_q_hit={n_rev}  eps_q_hit={n_eps}")
L423             # デバッグ: 取得本数の分布（先頭のみ）
L424             try:
L425                 lens = [len((out.get(t, {}) or {}).get("rev_q_series", [])) for t in tickers]
L426                 print(f"[SEC] rev_q_series length: min={min(lens) if lens else 0} "
L427                       f"p25={np.percentile(lens,25) if lens else 0} median={np.median(lens) if lens else 0} "
L428                       f"p75={np.percentile(lens,75) if lens else 0} max={max(lens) if lens else 0}")
L429             except Exception:
L430                 pass
L431             if miss_map:
L432                 print(f"[SEC] no CIK map: {len(miss_map)} (サンプル例) {miss_map[:20]}")
L433             if miss_facts:
L434                 print(f"[SEC] CIKあり だが対象factなし: {len(miss_facts)} (サンプル例) {miss_facts[:20]}")
L435         except Exception:
L436             pass
L437         return out
L438
L439     def sec_dryrun_sample(self, tickers: list[str] | None = None) -> None:
L440         if not _env_true("SEC_DRYRUN_SAMPLE", False):
L441             return
L442         sample = tickers or ["BRK.B", "BF.B", "GOOGL", "META", "UBER", "PBR.A", "TSM", "NARI", "EVBN", "SWAV"]
L443         print(f"[SEC-DRYRUN] sample tickers: {sample}")
L444         try:
L445             t2cik = self._sec_ticker_map()
L446             hits = 0
L447             for sym in sample:
L448                 candidates: list[str] = []
L449
L450                 def add(key: str) -> None:
L451                     if key and key not in candidates:
L452                         candidates.append(key)
L453
L454                 add((sym or "").upper())
L455                 for alt in self._normalize_ticker(sym):
L456                     add(alt)
L457                 if any(t2cik.get(key) for key in candidates):
L458                     hits += 1
L459             sec_data = self.fetch_eps_rev_from_sec(sample)
L460             rev_hits = sum(1 for v in sec_data.values() if v.get("rev_q_series"))
L461             eps_hits = sum(1 for v in sec_data.values() if v.get("eps_q_series"))
L462             total = len(sample)
L463             print(f"[SEC-DRYRUN] CIK map hit: {hits}/{total}  rev_q_series hits: {rev_hits}  eps_q_series hits: {eps_hits}")
L464         except Exception as e:
L465             print(f"[SEC-DRYRUN] error: {e}")
L466     @staticmethod
L467     def impute_eps_ttm(df: pd.DataFrame, ttm_col: str="eps_ttm", q_col: str="eps_q_recent", out_col: str|None=None) -> pd.DataFrame:
L468         out_col = out_col or ttm_col; df = df.copy(); df["eps_imputed"] = False
L469         cand = df[q_col]*4; ok = df[ttm_col].isna() & cand.replace([np.inf,-np.inf], np.nan).notna()
L470         df.loc[ok, out_col], df.loc[ok,"eps_imputed"] = cand[ok], True; return df
L471
L472     _CF_ALIASES = {"cfo":["Operating Cash Flow","Total Cash From Operating Activities"], "capex":["Capital Expenditure","Capital Expenditures"]}
L473
L474     @staticmethod
L475     def _pick_row(df: pd.DataFrame, names: list[str]) -> pd.Series|None:
L476         if df is None or df.empty: return None
L477         idx_lower={str(i).lower():i for i in df.index}
L478         for n in names:
L479             k=n.lower()
L480             if k in idx_lower: return df.loc[idx_lower[k]]
L481         return None
L482
L483     @staticmethod
L484     def _sum_last_n(s: pd.Series|None, n: int) -> float|None:
L485         if s is None or s.empty: return None
L486         v=s.dropna().astype(float); return None if v.empty else v.iloc[:n].sum()
L487
L488     @staticmethod
L489     def _latest(s: pd.Series|None) -> float|None:
L490         if s is None or s.empty: return None
L491         v=s.dropna().astype(float); return v.iloc[0] if not v.empty else None
L492
L493     def fetch_cfo_capex_ttm_yf(self, tickers: list[str]) -> pd.DataFrame:
L494         from concurrent.futures import ThreadPoolExecutor, as_completed
L495         pick, sumn, latest, aliases = self._pick_row, self._sum_last_n, self._latest, self._CF_ALIASES
L496
L497         def one(t: str):
L498             try:
L499                 tk = yf.Ticker(t)  # ★ セッションは渡さない（YFがcurl_cffiで管理）
L500                 qcf = tk.quarterly_cashflow
L501                 cfo_q, capex_q = pick(qcf, aliases["cfo"]), pick(qcf, aliases["capex"])
L502                 fcf_q = pick(qcf, ["Free Cash Flow","FreeCashFlow","Free cash flow"])
L503                 cfo, capex, fcf = sumn(cfo_q,4), sumn(capex_q,4), sumn(fcf_q,4)
L504                 if any(v is None for v in (cfo, capex, fcf)):
L505                     acf = tk.cashflow
L506                     if cfo   is None: cfo   = latest(pick(acf, aliases["cfo"]))
L507                     if capex is None: capex = latest(pick(acf, aliases["capex"]))
L508                     if fcf   is None: fcf   = latest(pick(acf, ["Free Cash Flow","FreeCashFlow","Free cash flow"]))
L509             except Exception as e:
L510                 print(f"[warn] yf financials error: {t}: {e}"); cfo=capex=fcf=None
L511             n=np.nan
L512             return {"ticker":t,
L513                     "cfo_ttm_yf":   n if cfo   is None else cfo,
L514                     "capex_ttm_yf": n if capex is None else capex,
L515                     "fcf_ttm_yf_direct": n if fcf is None else fcf}
L516
L517         rows, mw = [], int(os.getenv("FIN_THREADS","8"))
L518         with ThreadPoolExecutor(max_workers=mw) as ex:
L519             rows=[f.result() for f in as_completed(ex.submit(one,t) for t in tickers)]
L520         return pd.DataFrame(rows).set_index("ticker")
L521
L522     _FINN_CFO_KEYS = ["netCashProvidedByOperatingActivities","netCashFromOperatingActivities","cashFlowFromOperatingActivities","operatingCashFlow"]
L523     _FINN_CAPEX_KEYS = ["capitalExpenditure","ca
```