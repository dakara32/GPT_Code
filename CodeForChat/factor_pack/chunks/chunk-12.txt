```text
n("display.max_colwidth", None)
L1189             pd.set_option("display.width", None)
L1190             page = int(getattr(cfg, "debug_dfz_page", 50))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50è¡Œå˜ä½
L1191             n = len(df_z)
L1192             logger.info("=== df_z FULL DUMP start === rows=%d cols=%d page=%d", n, df_z.shape[1], page)
L1193             for i in range(0, n, page):
L1194                 j = min(i + page, n)
L1195                 try:
L1196                     chunk_str = df_z.iloc[i:j].to_string()
L1197                 except Exception:
L1198                     chunk_str = df_z.iloc[i:j].astype(str).to_string()
L1199                 logger.info("--- df_z rows %d..%d ---\n%s", i, j-1, chunk_str)
L1200             logger.info("=== df_z FULL DUMP end ===")
L1201
L1202         # === begin: BIO LOSS PENALTY =====================================
L1203         try:
L1204             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L1205         except Exception:
L1206             penalty_z = 0.8
L1207
L1208         def _is_bio_like(t: str) -> bool:
L1209             inf = info.get(t, {}) if isinstance(info, dict) else {}
L1210             sec = str(inf.get("sector", "")).lower()
L1211             ind = str(inf.get("industry", "")).lower()
L1212             if "health" not in sec:
L1213                 return False
L1214             keys = ("biotech", "biopharma", "pharma")
L1215             return any(k in ind for k in keys)
L1216
L1217         tickers_s = pd.Index(df_z.index)
L1218         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L1219         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L1220         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L1221
L1222         if bool(mask_bio_loss.any()) and penalty_z > 0:
L1223             df_z.loc[mask_bio_loss, "GROWTH_F"] = df_z.loc[mask_bio_loss, "GROWTH_F"] - penalty_z
L1224             df_z["GROWTH_F"] = df_z["GROWTH_F"].clip(-3.0, 3.0)
L1225         # === end: BIO LOSS PENALTY =======================================
L1226
L1227         assert not any(c.endswith("_RAW") for c in df_z.columns)
L1228         for c in ["DIV_TTM_PS","DIV_YOY","LOW52PCT25_EXCESS","MA50_OVER_200"]:
L1229             assert c not in df_z.columns
L1230
L1231         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L1232         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L1233
L1234         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L1235         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L1236         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L1237         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L1238
L1239         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L1240         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L1241         g_score_all = df_z.mul(pd.Series(cfg.weights.g)).sum(axis=1)
L1242
L1243         d_comp = pd.concat({
L1244             'QAL': df_z['D_QAL'],
L1245             'YLD': df_z['D_YLD'],
L1246             'VOL': df_z['D_VOL_RAW'],
L1247             'TRD': df_z['D_TRD']
L1248         }, axis=1)
L1249         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L1250         globals()['D_WEIGHTS_EFF'] = dw.copy()
L1251         d_score_all = d_comp.mul(dw, axis=1).sum(axis=1)
L1252
L1253         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L1254         mask = df['trend_template']
L1255         if not bool(mask.any()):
L1256             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L1257                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L1258                 (df.get('RS', np.nan) >= 0.08) &
L1259                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L1260                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L1261                 (df.get('MA150_OVER_200', np.nan) > 0) &
L1262                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L1263                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L1264             df['trend_template'] = mask
L1265
L1266         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L1267         g_score = g_score_all.loc[mask]
L1268         Scorer.g_score = g_score
L1269         df_z['GSC'] = g_score_all
L1270         df_z['DSC'] = d_score_all
L1271
L1272         try:
L1273             current = (pd.read_csv("current_tickers.csv")
L1274                   .iloc[:, 0]
L1275                   .str.upper()
L1276                   .tolist())
L1277         except FileNotFoundError:
L1278             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L1279             current = []
L1280
L1281         mask_bonus = g_score.index.isin(current)
L1282         if mask_bonus.any():
L1283             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L1284             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L1285             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L1286             sigma_g = g_score.std()
L1287             if pd.isna(sigma_g):
L1288                 sigma_g = 0.0
L1289             bonus_g = round(k * sigma_g, 3)
L1290             g_score.loc[mask_bonus] += bonus_g
L1291             Scorer.g_score = g_score
L1292             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L1293             sigma_d = d_score_all.std()
L1294             if pd.isna(sigma_d):
L1295                 sigma_d = 0.0
L1296             bonus_d = round(k * sigma_d, 3)
L1297             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L1298
L1299         try:
L1300             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L1301         except Exception:
L1302             pass
L1303
L1304         df_full = df.copy()
L1305         df_full_z = df_z.copy()
L1306
L1307         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L1308         return FeatureBundle(df=df,
L1309             df_z=df_z,
L1310             g_score=g_score,
L1311             d_score_all=d_score_all,
L1312             missing_logs=pd.DataFrame(missing_logs),
L1313             df_full=df_full,
L1314             df_full_z=df_full_z,
L1315             scaler=None)
L1316
L1317 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L1318     """
L1319     Gæ ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã«å¯¾ã—ã€ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š/æŠ¼ã—ç›®åç™ºã®ã€Œç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç«ã€ã‚’åˆ¤å®šã—ã€
L1320     æ¬¡ã®åˆ—ã‚’ feature_df ã«è¿½åŠ ã™ã‚‹ï¼ˆindex=tickerï¼‰ã€‚
L1321       - G_BREAKOUT_recent_5d : bool
L1322       - G_BREAKOUT_last_date : str "YYYY-MM-DD"
L1323       - G_PULLBACK_recent_5d : bool
L1324       - G_PULLBACK_last_date : str "YYYY-MM-DD"
L1325       - G_PIVOT_price        : float
L1326     å¤±æ•—ã—ã¦ã‚‚ä¾‹å¤–ã¯æ¡ã‚Šæ½°ã—ã€æ—¢å­˜å‡¦ç†ã‚’é˜»å®³ã—ãªã„ã€‚
L1327     """
L1328     try:
L1329         px   = bundle.px                      # çµ‚å€¤ DataFrame
L1330         hi   = bundle.data['High']
L1331         lo   = bundle.data['Low']
L1332         vol  = bundle.data['Volume']
L1333         bench= bundle.spx                     # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ Series
L1334
L1335         # Gãƒ¦ãƒ‹ãƒãƒ¼ã‚¹æ¨å®šï¼šself.g_universe å„ªå…ˆ â†’ feature_df['group']=='G' â†’ å…¨éŠ˜æŸ„
L1336         g_universe = getattr(self_obj, "g_universe", None)
L1337         if g_universe is None:
L1338             try:
L1339                 g_universe = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L1340             except Exception:
L1341                 g_universe = list(feature_df.index)
L1342         if not g_universe:
L1343             return feature_df
L1344
L1345         # æŒ‡æ¨™
L1346         px = px.ffill(limit=2)
L1347         ema21 = px[g_universe].ewm(span=21, adjust=False).mean()
L1348         ma50  = px[g_universe].rolling(50).mean()
L1349         ma150 = px[g_universe].rolling(150).mean()
L1350         ma200 = px[g_universe].rolling(200).mean()
L1351         atr20 = (hi[g_universe] - lo[g_universe]).rolling(20).mean()
L1352         vol20 = vol[g_universe].rolling(20).mean()
L1353         vol50 = vol[g_universe].rolling(50).mean()
L1354
L1355         # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆæ ¼
L1356         trend_template_ok = (px[g_universe] > ma50) & (px[g_universe] > ma150) & (px[g_universe] > ma200) \
L1357                             & (ma150 > ma200) & (ma200.diff() > 0)
L1358
L1359         # æ±ç”¨ãƒ”ãƒœãƒƒãƒˆï¼šç›´è¿‘65å–¶æ¥­æ—¥ã®é«˜å€¤ï¼ˆå½“æ—¥é™¤å¤–ï¼‰
L1360         pivot_price = hi[g_universe].rolling(65).max().shift(1)
L1361
L1362         # ç›¸å¯¾åŠ›ï¼šå¹´å†…é«˜å€¤æ›´æ–°
L1363         bench_aligned = bench.reindex(px.index).ffill()
L1364         rs = px[g_universe].div(bench_aligned, axis=0)
L1365         rs_high = rs.rolling(252).max().shift(1)
L1366
L1367         # ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆã€Œç™ºç”Ÿæ—¥ã€ï¼šæ¡ä»¶ç«‹ã¡ä¸ŠãŒã‚Š
L1368         breakout_today = trend_template_ok & (px[g_universe] > pivot_price) \
L1369                          & (vol[g_universe] >= 1.5 * vol50) & (rs > rs_high)
L1370         breakout_event = breakout_today & ~breakout_today.shift(1).fillna(False)
L1371
L1372         # æŠ¼ã—ç›®åç™ºã€Œç™ºç”Ÿæ—¥ã€ï¼šEMA21å¸¯Ã—å‡ºæ¥é«˜ãƒ‰ãƒ©ã‚¤ã‚¢ãƒƒãƒ—Ã—å‰æ—¥é«˜å€¤è¶ŠãˆÃ—çµ‚å€¤EMA21ä¸Š
L1373         near_ema21_band = px[g_universe].between(ema21 - atr20, ema21 + atr20)
L1374         volume_dryup = (vol20 / vol50) <= 1.0
L1375         pullback_bounce_confirmed = (px[g_universe] > hi[g_universe].shift(1)) & (px[g_universe] > ema21)
L1376         pullback_today = trend_template_ok & near_ema21_band & volume_dryup & pullback_bounce_confirmed
L1377         pullback_event = pullback_today & ~pullback_today.shift(1).fillna(False)
L1378
L1379         # ç›´è¿‘Nå–¶æ¥­æ—¥å†…ã®ç™ºç« / æœ€çµ‚ç™ºç”Ÿæ—¥
L1380         rows = []
L1381         for t in g_universe:
L1382             def _recent_and_date(s, win):
L1383                 sw = s[t].iloc[-win:]
L1384                 if sw.any():
L1385                     d = sw[sw].index[-1]
L1386                     return True, d.strftime("%Y-%m-%d")
L1387                 return False, ""
L1388             br_recent, br_date = _recent_and_date(breakout_event, win_breakout)
L1389             pb_recent, pb_date = _recent_and_date(pullback_event, win_pullback)
L1390             rows.append((t, {
L1391                 "G_BREAKOUT_recent_5d": br_recent,
L1392                 "G_BREAKOUT_last_date": br_date,
L1393                 "G_PULLBACK_recent_5d": pb_recent,
L1394                 "G_PULLBACK_last_date": pb_date,
L1395                 "G_PIVOT_price": float(pivot_price[t].iloc[-1]) if t in pivot_price.columns else float('nan'),
L1396             }))
L1397         flags = pd.DataFrame({k: v for k, v in rows}).T
L1398
L1399         # åˆ—ã‚’ä½œæˆãƒ»ä¸Šæ›¸ã
L1400         cols = ["G_BREAKOUT_recent_5d","G_BREAKOUT_last_date","G_PULLBACK_recent_5d","G_PULLBACK_last_date","G_PIVOT_price"]
L1401         for c in cols:
L1402             if c not in feature_df.columns:
L1403                 feature_df[c] = np.nan
L1404         feature_df.loc[flags.index, flags.columns] = flags
L1405
L1406     except Exception:
L1407         pass
L1408     return feature_df
L1409
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v3
L24
L25       - name: Setup Python
L26         uses: actions/setup-python@v5
L27         with:
L28           python-version: '3.x'
L29           cache: 'pip'
L30           cache-dependency-path: requirements.txt
L31
L32       - name: Install dependencies
L33         run: pip install 
```