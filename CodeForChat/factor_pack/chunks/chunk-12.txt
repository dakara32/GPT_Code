```text
et_option("display.width", None)
L917             page = int(getattr(cfg, "debug_dfz_page", 50))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50è¡Œå˜ä½
L918             n = len(df_z)
L919             logger.info("=== df_z FULL DUMP start === rows=%d cols=%d page=%d", n, df_z.shape[1], page)
L920             try:
L921                 for i in range(0, n, page):
L922                     j = min(i + page, n)
L923                     try:
L924                         chunk_str = df_z.iloc[i:j].to_string()
L925                     except Exception:
L926                         chunk_str = df_z.iloc[i:j].astype(str).to_string()
L927                     logger.info("--- df_z rows %d..%d ---\n%s", i, j-1, chunk_str)
L928             finally:
L929                 if beta_debug_cols:
L930                     df_z.drop(columns=[c for c in beta_debug_cols if c in df_z.columns], inplace=True)
L931             logger.info("=== df_z FULL DUMP end ===")
L932
L933         # === begin: BIO LOSS PENALTY =====================================
L934         try:
L935             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L936         except Exception:
L937             penalty_z = 0.8
L938
L939         def _is_bio_like(t: str) -> bool:
L940             inf = info.get(t, {}) if isinstance(info, dict) else {}
L941             sec = str(inf.get("sector", "")).lower()
L942             ind = str(inf.get("industry", "")).lower()
L943             if "health" not in sec:
L944                 return False
L945             keys = ("biotech", "biopharma", "pharma")
L946             return any(k in ind for k in keys)
L947
L948         tickers_s = pd.Index(df_z.index)
L949         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L950         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L951         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L952
L953         if bool(mask_bio_loss.any()) and penalty_z > 0:
L954             df_z.loc[mask_bio_loss, "GROWTH_F"] = df_z.loc[mask_bio_loss, "GROWTH_F"] - penalty_z
L955             df_z["GROWTH_F"] = df_z["GROWTH_F"].clip(-3.0, 3.0)
L956         # === end: BIO LOSS PENALTY =======================================
L957
L958         _debug_only_cols = [c for c in df_z.columns if c.endswith("_RAW")]
L959         _no_score_cols = ["DIV_TTM_PS", "DIV_YOY", "LOW52PCT25_EXCESS", "MA50_OVER_200"]
L960         _drop_cols = [c for c in (_debug_only_cols + _no_score_cols) if c in df_z.columns]
L961         if _drop_cols:
L962             df_z = df_z.drop(columns=_drop_cols, errors="ignore")
L963
L964         assert not any(c.endswith("_RAW") for c in df_z.columns)
L965         for c in ["DIV_TTM_PS","DIV_YOY","LOW52PCT25_EXCESS","MA50_OVER_200"]:
L966             assert c not in df_z.columns
L967
L968         df_z['TRD'] = 0.0  # TRDã¯ã‚¹ã‚³ã‚¢å¯„ä¸ã‹ã‚‰å¤–ã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šã¯ãƒ•ã‚£ãƒ«ã‚¿ã§è¡Œã†ï¼ˆåˆ—ã¯è¡¨ç¤ºäº’æ›ã®ãŸã‚æ®‹ã™ï¼‰
L969         if 'BETA' not in df_z.columns: df_z['BETA'] = robust_z(df['BETA'])
L970
L971         df_z['D_VOL_RAW'] = robust_z(0.40*df_z['DOWNSIDE_DEV'] + 0.22*df_z['RESID_VOL'] + 0.18*df_z['MDD_1Y'] - 0.10*df_z['DOWN_OUTPERF'] - 0.05*df_z['EXT_200'] - 0.08*df_z['SIZE'] - 0.10*df_z['LIQ'] + 0.10*df_z['BETA'])
L972         df_z['D_QAL']     = robust_z(0.35*df_z['QAL'] + 0.20*df_z['FCF'] + 0.15*df_z['CURR_RATIO'] - 0.15*df_z['DEBT2EQ'] - 0.15*df_z['EPS_VAR_8Q'])
L973         df_z['D_YLD']     = robust_z(0.45*df_z['DIV'] + 0.25*df_z['DIV_STREAK'] + 0.20*df_z['DIV_FCF_COVER'] - 0.10*df_z['DIV_VAR5'])
L974         df_z['D_TRD']     = robust_z(0.40*df_z.get('MA200_SLOPE_5M',0) - 0.30*df_z.get('EXT_200',0) + 0.15*df_z.get('NEAR_52W_HIGH',0) + 0.15*df_z['TR'])
L975
L976         # --- é‡ã¿ã¯ cfg ã‚’å„ªå…ˆï¼ˆå¤–éƒ¨ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ï¼‰ ---
L977         # â‘  å…¨éŠ˜æŸ„ã§ G/D ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºï¼ˆunmaskedï¼‰
L978         g_weights = pd.Series(cfg.weights.g, dtype=float)
L979         need_g = ["GROWTH_F", "MOM"]
L980         dbg_cols = ["GROWTH_F", "MOM", "VOL"]
L981         if all(c in df_z.columns for c in need_g):
L982             mask_g = df_z[need_g].notna().all(axis=1)
L983         else:
L984             mask_g = pd.Series(False, index=df_z.index, dtype=bool)
L985         for c in dbg_cols:
L986             if c in df_z.columns:
L987                 df_z[f"DBGRW.{c}"] = df_z[c]
L988         df_fill_g = df_z.reindex(columns=g_weights.index, fill_value=np.nan).copy()
L989         for c in df_fill_g.columns:
L990             if c not in need_g:
L991                 df_fill_g[c] = df_fill_g[c].fillna(0)
L992         g_score_all = _as_numeric_series(
L993             df_fill_g.mul(g_weights.reindex(df_fill_g.columns)).sum(axis=1, skipna=False)
L994         )
L995         g_score_all = g_score_all.where(mask_g)
L996
L997         d_comp = pd.concat({
L998             'QAL': df_z['D_QAL'],
L999             'YLD': df_z['D_YLD'],
L1000             'VOL': df_z['D_VOL_RAW'],
L1001             'TRD': df_z['D_TRD']
L1002         }, axis=1)
L1003         dw = pd.Series(cfg.weights.d, dtype=float).reindex(['QAL','YLD','VOL','TRD']).fillna(0.0)
L1004         globals()['D_WEIGHTS_EFF'] = dw.copy()
L1005         need_d_candidates = ["VOL", "QAL"]
L1006         mask_d = pd.Series(True, index=d_comp.index, dtype=bool)
L1007         for c in need_d_candidates:
L1008             if c in d_comp.columns:
L1009                 mask_d &= d_comp[c].notna()
L1010             else:
L1011                 mask_d &= False
L1012         df_fill_d = d_comp.copy()
L1013         for c in df_fill_d.columns:
L1014             if c not in need_d_candidates:
L1015                 df_fill_d[c] = df_fill_d[c].fillna(0)
L1016         d_score_all = _as_numeric_series(
L1017             df_fill_d.mul(dw, axis=1).sum(axis=1, skipna=False)
L1018         )
L1019         d_score_all = d_score_all.where(mask_d)
L1020
L1021         # â‘¡ ãƒ†ãƒ³ãƒ—ãƒ¬åˆ¤å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰
L1022         mask = df['trend_template']
L1023         if not bool(mask.any()):
L1024             mask = ((df.get('P_OVER_LOW52', np.nan) >= 0.25) &
L1025                 (df.get('NEAR_52W_HIGH', np.nan) >= -0.30) &
L1026                 (df.get('RS', np.nan) >= 0.08) &
L1027                 (df.get('MA200_SLOPE_1M', np.nan) > 0) &
L1028                 (df.get('P_OVER_150', np.nan) > 0) & (df.get('P_OVER_200', np.nan) > 0) &
L1029                 (df.get('MA150_OVER_200', np.nan) > 0) &
L1030                 (df.get('MA50_OVER_150', np.nan) > 0) & (df.get('MA50_OVER_200', np.nan) > 0) &
L1031                 (df.get('TR_str', np.nan) > 0)).fillna(False)
L1032             df['trend_template'] = mask
L1033
L1034         # â‘¢ æ¡ç”¨ç”¨ã¯ maskã€è¡¨ç¤º/åˆ†æç”¨ã¯åˆ—ã§å…¨éŠ˜æŸ„ä¿å­˜
L1035         g_score = _as_numeric_series(g_score_all.loc[mask])
L1036         Scorer.g_score = g_score
L1037         df_z['GSC'] = g_score_all
L1038         df_z['DSC'] = d_score_all
L1039
L1040         try:
L1041             current = (pd.read_csv("current_tickers.csv")
L1042                   .iloc[:, 0]
L1043                   .str.upper()
L1044                   .tolist())
L1045         except FileNotFoundError:
L1046             warnings.warn("current_tickers.csv not found â€” bonus skipped")
L1047             current = []
L1048
L1049         mask_bonus = g_score.index.isin(current)
L1050         if mask_bonus.any():
L1051             # 1) factor.BONUS_COEFF ã‹ã‚‰ k ã‚’æ±ºã‚ã€ç„¡ã‘ã‚Œã° 0.4
L1052             k = float(getattr(sys.modules.get("factor"), "BONUS_COEFF", 0.4))
L1053             # 2) g å´ã® Ïƒ ã‚’å–ã‚Šã€NaN ãªã‚‰ 0 ã«ä¸¸ã‚ã‚‹
L1054             sigma_g = g_score.std()
L1055             if pd.isna(sigma_g):
L1056                 sigma_g = 0.0
L1057             bonus_g = round(k * sigma_g, 3)
L1058             g_score.loc[mask_bonus] += bonus_g
L1059             Scorer.g_score = g_score
L1060             # 3) D å´ã‚‚åŒæ§˜ã« Ïƒ ã® NaN ã‚’ã‚±ã‚¢
L1061             sigma_d = d_score_all.std()
L1062             if pd.isna(sigma_d):
L1063                 sigma_d = 0.0
L1064             bonus_d = round(k * sigma_d, 3)
L1065             d_score_all.loc[d_score_all.index.isin(current)] += bonus_d
L1066
L1067         try:
L1068             df = _apply_growth_entry_flags(df, ib, self, win_breakout=5, win_pullback=5)
L1069         except Exception:
L1070             pass
L1071
L1072         df_full = df.copy()
L1073         df_full_z = df_z.copy()
L1074
L1075         from factor import FeatureBundle  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L1076         missing_logs_df = getattr(ib, "missing_logs", pd.DataFrame())
L1077         if not isinstance(missing_logs_df, pd.DataFrame):
L1078             try:
L1079                 missing_logs_df = pd.DataFrame(missing_logs_df)
L1080             except Exception:
L1081                 missing_logs_df = pd.DataFrame()
L1082
L1083         return FeatureBundle(df=df,
L1084             df_z=df_z,
L1085             g_score=g_score,
L1086             d_score_all=d_score_all,
L1087             missing_logs=missing_logs_df,
L1088             df_full=df_full,
L1089             df_full_z=df_full_z,
L1090             scaler=None)
L1091
L1092 def _apply_growth_entry_flags(feature_df, bundle, self_obj, win_breakout=5, win_pullback=5):
L1093     """ä»¥å‰ã¯ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆ/æŠ¼ã—ç›®åç™ºãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸ã—ã¦ã„ãŸãŒã€ç¾åœ¨ã¯ç„¡åŠ¹åŒ–ã€‚"""
L1094     return feature_df
L1095
L1096
```

## <.github/workflows/weekly-report.yml>
```text
L1 name: Weekly Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '0 0 * * 6'  # UTC 00:00 â†’ JST 09:00ï¼ˆåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15     permissions:
L16       contents: write
L17
L18     steps:
L19       - name: Debug start
L20         run: echo 'ğŸš€ DEBUGstarted'
L21               
L22       - name: Checkout repository
L23         uses: actions/checkout@v4
L24         with:
L25           fetch-depth: 0
L26           persist-credentials: true
L27
L28       - name: Setup Python
L29         uses: actions/setup-python@v5
L30         with:
L31           python-version: '3.x'
L32           cache: 'pip'
L33           cache-dependency-path: requirements.txt
L34
L35       - name: Install dependencies
L36         run: pip install -r requirements.txt
L37
L38       - name: Prepare results directory
L39         run: mkdir -p results
L40
L41       - name: Run factor & scoring
L42         env:
L43           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L44           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L45           FIN_THREADS: "8"
L46           SEC_CONTACT_EMAIL: ${{ secrets.SEC_CONTACT_EMAIL }}
L47         run: python factor.py
L48
L49       - name: Commit & push current_tickers.csv (rebase-safe)
L50         shell: bash
L51         run: |
L52           set -euo pipefail
L53           BR="${GITHUB_REF_NAME:-main}"
L54
L55           git config user.name  "github-actions[bot]"
L56           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L57           git config pull.rebase true
L58           git config --global --add safe.directory "$PWD"
L59
L60           if [[ -n "$(git status --porcelain current_tickers.csv)" ]]; then
L61             git add current_tickers.csv
L62             git commit -m "chore: update current_tickers.csv bucket ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))" || true
L63
L64             git fetch origin "$BR" --prune
L65             git pull --rebase origin "$BR" || true
L66
L67             if ! git push origin "HEAD:$BR"; then
L68               git push --force-with-lease origin "HEAD:$BR"
L69             fi
L70           else
L71             echo "No changes in current_tickers.csv"
L72           fi
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚³ãƒ³ãƒœï¼šGã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDD Ã— ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰*
L20
L21 ### â‘  Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDï¼ˆGrowth
```