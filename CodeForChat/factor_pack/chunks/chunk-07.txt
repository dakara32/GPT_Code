```text
"D":
L1356         T.log("save done")
L1357     if group == "G":
L1358         sc._top_G = pick
L1359     return pick, avg_r, sum_sc, obj
L1360
L1361 def run_pipeline() -> SelectionBundle:
L1362     """
L1363     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L1364     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L1365     """
L1366     inb = io_build_input_bundle()
L1367     cfg = PipelineConfig(
L1368         weights=WeightsConfig(g=g_weights, d=D_weights),
L1369         drrs=DRRSParams(
L1370             corrM=corrM, shrink=DRRS_SHRINK,
L1371             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1372         ),
L1373         price_max=CAND_PRICE_MAX,
L1374         debug_mode=debug_mode
L1375     )
L1376     sc = Scorer()
L1377     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1378     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1379     alpha = Scorer.spx_to_alpha(inb.spx)
L1380     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1381     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1382     sc._top_G = top_G
L1383     try:
L1384         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1385         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1386     except Exception:
L1387         pass
L1388     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1389     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1390     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1391     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1392     fb = getattr(sc, "_feat", None)
L1393     near_G = getattr(sc, "_near_G", [])
L1394     selected12 = list(top_G)
L1395     df = fb.df if fb is not None else pd.DataFrame()
L1396     guni = _infer_g_universe(df, selected12, near_G)
L1397     try:
L1398         fire_recent = [t for t in guni
L1399                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1400                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1401     except Exception: fire_recent = []
L1402
L1403     lines = [
L1404         "【G枠レポート｜週次モニタ（直近5営業日）】",
L1405         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L1406         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L1407         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L1408
L1409     if fire_recent:
L1410         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1411         lines.append(f"過去5営業日の検知: {fire_list}")
L1412     else:
L1413         lines.append("過去5営業日の検知: なし")
L1414
L1415     try:
L1416         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1417         if webhook:
L1418             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1419     except Exception:
L1420         pass
L1421
L1422     out = Output()
L1423     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1424     try: out._sc = sc
L1425     except Exception: pass
L1426     if hasattr(sc, "_feat"):
L1427         try:
L1428             fb = sc._feat
L1429             out.miss_df = fb.missing_logs
L1430             out.display_results(
L1431                 exist=exist,
L1432                 bench=bench,
L1433                 df_z=fb.df_z,
L1434                 g_score=fb.g_score,
L1435                 d_score_all=fb.d_score_all,
L1436                 init_G=top_G,
L1437                 init_D=top_D,
L1438                 top_G=top_G,
L1439                 top_D=top_D,
L1440                 df_full_z=getattr(fb, "df_full_z", None),
L1441                 prev_G=getattr(sc, "_prev_G", exist),
L1442                 prev_D=getattr(sc, "_prev_D", exist),
L1443             )
L1444         except Exception:
L1445             pass
L1446     out.notify_slack()
L1447     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1448               "sum_score": sumG, "objective": objG},
L1449         resD={"tickers": top_D, "avg_res_corr": avgD,
L1450               "sum_score": sumD, "objective": objD},
L1451         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1452
L1453     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1454     try:
L1455         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1456               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1457               .sort_values("G_plus_D")
L1458               .head(10)
L1459               .round(3))
L1460         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1461         _post_slack({"text": f"```{low_msg}```"})
L1462     except Exception as _e:
L1463         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1464
L1465     return sb
L1466
L1467 if __name__ == "__main__":
L1468     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import json, logging, os, requests, sys, warnings
L30 import numpy as np
L31 import pandas as pd
L32 import yfinance as yf
L33 from typing import Any, TYPE_CHECKING
L34 from scipy.stats import zscore
L35 from datetime import datetime as _dt
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L39
L40 logger = logging.getLogger(__name__)
L41
L42
L43 def _log(stage, msg):
L44     try:
L45         print(f"[DBG][{_dt.utcnow().isoformat(timespec='seconds')}Z][{stage}] {msg}")
L46     except Exception:
L47         print(f"[DBG][{stage}] {msg}")
L48
L49
L50 # ---- Dividend Helpers -------------------------------------------------------
L51 def _last_close(t, price_map=None):
L52     if price_map and (c := price_map.get(t)) is not None: return float(c)
L53     try:
L54         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L55         return float(h.iloc[-1]) if len(h) else np.nan
L56     except Exception:
L57         return np.nan
L58
L59 def _ttm_div_sum(t, lookback_days=400):
L60     try:
L61         div = yf.Ticker(t).dividends
L62         if div is None or len(div) == 0: return 0.0
L63         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L64         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L65         return ttm if ttm > 0 else float(div.tail(4).sum())
L66     except Exception:
L67         return 0.0
L68
L69 def ttm_div_yield_portfolio(tickers, price_map=None):
L70     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L71     return float(np.mean(ys)) if ys else 0.0
L72
L73 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L74 def _as_numeric_series(s: pd.Series) -> pd.Series:
L75     """Series を float dtype に強制変換し、index を保持する。"""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     return pd.Series(v.values, index=getattr(s, "index", None), dtype=float, name=getattr(s, "name", None))
L80
L81
L82 def _scalar(x):
L83     """
L84     入力を安全に float スカラへ変換する。
L85
L86     許容する入力パターン:
L87       - pandas.Series: 非NaNの最後の値を採用
L88       - numpy スカラ/配列: 最後の要素を採用
L89       - その他の数値っぽい値: float へ変換
L90
L91     変換できない場合は np.nan を返す。
L92     """
L93
L94     if x is None:
L95         return np.nan
L96
L97     # pandas.Series の場合は非NaNの最後の値を採用
L98     if isinstance(x, pd.Series):
L99         s = pd.to_numeric(x, errors="coerce").dropna()
L100         return float(s.iloc[-1]) if not s.empty else np.nan
L101
L102     # numpy スカラ (item() を持つ) ※文字列は除外
L103     if hasattr(x, "item") and not isinstance(x, (str, bytes)):
L104         try:
L105             return float(x.item())
L106         except Exception:
L107             pass
L108
L109     # 配列様のオブジェクト
L110     try:
L111         arr = np.asarray(x, dtype=float).ravel()
L112         return float(arr[-1]) if arr.size else np.nan
L113     except Exception:
L114         pass
L115
L116     # 最後に素直に float 変換を試す
L117     try:
L118         return float(x)
L119     except Exception:
L120         return np.nan
L121
L122
L123 def winsorize_s(s: pd.Series, p=0.02):
L124     if s is None or s.dropna().empty: return s
L125     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L126
L127 def robust_z(s: pd.Series, p=0.02):
L128     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L129
L130 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L131     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L132     if s is None:
L133         return pd.Series(dtype=float)
L134     v = pd.to_numeric(s, errors="coerce")
L135     m = np.nanmedian(v)
L136     mad = np.nanmedian(np.abs(v - m))
L137     z = (v - m) / (1.4826 * mad + 1e-9)
L138     if np.nanstd(z) < 1e-9:
L139         r = v.rank(method="average", na_option="keep")
L140         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L141     return pd.Series(z, index=v.index, dtype=float)
L142
L143
L144 def _safe_div(a, b):
L145     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L146     except Exception: return np.nan
L147
L148 def _safe_last(series: pd.Series, default=np.nan):
L149     try: return float(series.iloc[-1])
L150     except Exception: return default
L151
L152
L153 def _ensure_series(x):
L154     if x is None:
L155         return pd.Series(dtype=float)
L156     if isinstance(x, pd.Series):
L157         return x.dropna()
L158     if isinstance(x, (list, tuple)):
L159         if len(x) and isinstance(x[0], (tuple, list)) and len(x[0]) == 2:
L160             dt = pd.to_datetime([d for d, _ in x], errors="coerce")
L161             v = pd.to_numeric([_v for _, _v in x], errors="coerce")
L162             return pd.Series(v, index=dt).dropna()
L163         return pd.Series(pd.to_numeric(list(x), errors="coerce")).dropna()
L164     try:
L165         return pd.Series(x).dropna()
L166     except Exception:
L167         return pd.Series(dtype=float)
L168
L169
L170 def _to_quarterly(s: pd.Series) -> pd.Series:
L171     if s.empty or not isinstance(s.index, pd.DatetimeIndex):
L172         return s
L173     return s.resample("Q").last().dropna()
L174
L175
L176 def _ttm_yoy_from_quarterly(qs: pd.Series) -> pd.Series:
L177     if qs is None or qs.empty:
L178         return pd.Series(dtype=float)
L179     ttm = qs.rolling(4, min_periods=2).sum()
L180     yoy = ttm.pct_change(4)
L181     return yoy
L182
L183
L184
L185
L186 class
```