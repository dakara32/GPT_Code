```text
           df.loc[t,'ADV60_USD'] = adv60
L401
L402             # --- 売上/利益の加速度等 ---
L403             REV_Q_YOY=EPS_Q_YOY=REV_YOY_ACC=REV_YOY_VAR=np.nan
L404             REV_ANNUAL_STREAK = np.nan
L405             try:
L406                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L407                 if qe is not None and not qe.empty:
L408                     if 'Revenue' in qe.columns:
L409                         rev = qe['Revenue'].dropna().astype(float)
L410                         if len(rev)>=5: REV_Q_YOY = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5])
L411                         if len(rev)>=6:
L412                             yoy_now = _safe_div(rev.iloc[-1]-rev.iloc[-5], rev.iloc[-5]); yoy_prev = _safe_div(rev.iloc[-2]-rev.iloc[-6], rev.iloc[-6])
L413                             if pd.notna(yoy_now) and pd.notna(yoy_prev): REV_YOY_ACC = yoy_now - yoy_prev
L414                         yoy_list=[]
L415                         for k in range(1,5):
L416                             if len(rev)>=4+k:
L417                                 y = _safe_div(rev.iloc[-k]-rev.iloc[-(k+4)], rev.iloc[-(k+4)])
L418                                 if pd.notna(y): yoy_list.append(y)
L419                         if len(yoy_list)>=2: REV_YOY_VAR = float(np.std(yoy_list, ddof=1))
L420                         # NEW: 年次の持続性（直近から遡って前年比プラスが何年連続か、四半期4本揃う完全年のみ）
L421                         try:
L422                             g = rev.groupby(rev.index.year)
L423                             ann_sum, cnt = g.sum(), g.count()
L424                             ann_sum = ann_sum[cnt >= 4]
L425                             if len(ann_sum) >= 3:
L426                                 yoy = ann_sum.pct_change().dropna()
L427                                 streak = 0
L428                                 for v in yoy.iloc[::-1]:
L429                                     if pd.isna(v) or v <= 0:
L430                                         break
L431                                     streak += 1
L432                                 REV_ANNUAL_STREAK = float(streak)
L433                         except Exception:
L434                             pass
L435                     if 'Earnings' in qe.columns and so:
L436                         eps_series = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L437                         if len(eps_series)>=5 and pd.notna(eps_series.iloc[-5]) and eps_series.iloc[-5]!=0:
L438                             EPS_Q_YOY = _safe_div(eps_series.iloc[-1]-eps_series.iloc[-5], eps_series.iloc[-5])
L439             except Exception: pass
L440             df.loc[t,'REV_Q_YOY'], df.loc[t,'EPS_Q_YOY'], df.loc[t,'REV_YOY_ACC'], df.loc[t,'REV_YOY_VAR'] = REV_Q_YOY, EPS_Q_YOY, REV_YOY_ACC, REV_YOY_VAR
L441             df.loc[t,'REV_ANN_STREAK'] = REV_ANNUAL_STREAK
L442
L443             # --- Rule of 40 や周辺 ---
L444             total_rev_ttm = d.get('totalRevenue',np.nan)
L445             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L446             df.loc[t,'FCF_MGN'] = FCF_MGN
L447             rule40 = np.nan
L448             try:
L449                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L450             except Exception: pass
L451             df.loc[t,'RULE40'] = rule40
L452
L453             # --- トレンド補助 ---
L454             sma50  = s.rolling(50).mean()
L455             sma150 = s.rolling(150).mean()
L456             sma200 = s.rolling(200).mean()
L457             p = _safe_last(s)
L458
L459             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L460                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L461             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L462                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L463
L464             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L465             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L466
L467             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L468             if len(sma200.dropna()) >= 21:
L469                 cur200 = _safe_last(sma200)
L470                 old2001 = float(sma200.iloc[-21])
L471                 if old2001:
L472                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L473
L474             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L475             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L476             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L477             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L478             if len(sma200.dropna())>=105:
L479                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L480                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L481             # NEW: 200日線が連続で上向きの「日数」
L482             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L483             try:
L484                 s200 = sma200.dropna()
L485                 if len(s200) >= 2:
L486                     diff200 = s200.diff()
L487                     up = 0
L488                     for v in diff200.iloc[::-1]:
L489                         if pd.isna(v) or v <= 0:
L490                             break
L491                         up += 1
L492                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L493             except Exception:
L494                 pass
L495             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L496             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L497             if hi52 and hi52>0 and pd.notna(p):
L498                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L499             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L500             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L501
L502             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L503
L504             # --- 欠損メモ ---
L505             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L506             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L507             if need_finnhub:
L508                 fin_data = self.fetch_finnhub_metrics(t)
L509                 for col in need_finnhub:
L510                     val = fin_data.get(col)
L511                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L512             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L513                 if pd.isna(df.loc[t,col]):
L514                     if col=='DIV':
L515                         status = self.dividend_status(t)
L516                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L517                     else:
L518                         missing_logs.append({'Ticker':t,'Column':col})
L519
L520         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L521             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L522             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L523             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L524             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L525             c5 = (row.get('TR_str', np.nan) > 0)
L526             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L527             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L528             c8 = (row.get('RS', np.nan) >= 0.10)
L529             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L530
L531         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L532         assert 'trend_template' in df.columns
L533
L534         # === Z化と合成 ===
L535         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L536
L537         for _c in ('DIV_TTM_PS', 'DIV_FCF_COVER'):
L538             if _c in df.columns:
L539                 df[_c] = df[_c].fillna(0.0)
L540
L541         df_z = pd.DataFrame(index=df.index)
L542         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L543         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L544         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L545         for col in ['REV_Q_YOY','EPS_Q_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']: df_z[col] = robust_z(df[col])
L546         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L547
L548         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L549         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L550         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L551         df_z['GROWTH_F']  = robust_z(0.25*df_z['REV']          # ↓0.30→0.25
L552             + 0.20*df_z['EPS_Q_YOY']
L553             + 0.15*df_z['REV_Q_YOY']
L554             + 0.15*df_z['REV_YOY_ACC']
L555             + 0.10*df_z['RULE40']
L556             + 0.10*df_z['FCF_MGN']
L557             + 0.10*df_z['EPS']          # ★追加：黒字優遇／赤字減点
L558             + 0.05*df_z['REV_ANN_STREAK']
L559             - 0.05*df_z['REV_YOY_VAR']).clip(-3.0,3.0)
L560         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L561             + 0.15*df_z['TR_str']
L562             + 0.15*df_z['RS_SLOPE_6W']
L563             + 0.15*df_z['RS_SLOPE_13W']
L564             + 0.10*df_z['MA200_SLOPE_5M']
L565             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L566         df_z['VOL'] = robust_z(df['BETA'])
L567         df_z.rename(columns={'GROWTH_F':'GRW','MOM_F':'MOM','QUALITY_F':'QAL','YIELD_F':'YLD'}, inplace=True)
L568
L569         # === begin: BIO LOSS PENALTY =====================================
L570         try:
L571             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L572         except Exception:
L573             penalty_z = 0.8
L574
L575         def _is_bio_like(t: str) -> bool:
L576             inf = info.get(t, {}) if isinstance(info, dict) else {}
L577             sec = str(inf.get("sector", "")).lower()
L578             ind = str(inf.get("industry", "")).lower()
L579             if "health" not in sec:
L580                 return False
L581             keys = ("biotech", "biopharma", "pharma")
L582             return any(k in ind for k in keys)
L583
L584         tickers_s = pd.Index(df_z.index)
L585         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L586         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L587         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L588
L589         if bool(mask_bio_loss.any()) and penalty_z > 0:
L590             df_z.loc[mask_bio_loss, "GRW"] = df_z.loc[mask_bio_loss, "GRW"] - penalty_z
L591             df_z["GRW"] = df_z["GRW"].clip(-3.0, 3.0)
L592         # === end: BIO LOSS PENALTY =======================================
L593
L594         df_z['TRD'] = 0.0  # TRDはスコア寄与から外し、テンプレ判定はフィルタで行う（列は表示互換のため残す）
L595         if 'BETA' not in df_z.column
```