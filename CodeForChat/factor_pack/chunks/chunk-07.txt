```text
from(spec: dict, group: str) -> str:
L1372             g = spec.get(group, {})
L1373             parts = [str(m) for m in g.get("pre_mask", [])]
L1374             for k, v in (g.get("pre_filter", {}) or {}).items():
L1375                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L1376                 name = {"beta": "Î²"}.get(base, base)
L1377                 try:
L1378                     val = f"{float(v):g}"
L1379                 except Exception:
L1380                     val = str(v)
L1381                 parts.append(f"{name}{op}{val}")
L1382             return "" if not parts else " / filter:" + " & ".join(parts)
L1383
L1384         def _inject_filter_suffix(title: str, group: str) -> str:
L1385             suf = _filter_suffix_from(FILTER_SPEC, group)
L1386             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L1387
L1388         def _blk(title, tbl, fmt=None, drop=()):
L1389             if tbl is None or getattr(tbl, 'empty', False):
L1390                 return f"{title}\n(é¸å®šãªã—)\n"
L1391             if drop and hasattr(tbl, 'columns'):
L1392                 keep = [c for c in tbl.columns if c not in drop]
L1393                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L1394             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L1395
L1396         message = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L1397         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L1398         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L1399         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L1400         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L1401
L1402         try:
L1403             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L1404             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L1405             if r is not None:
L1406                 r.raise_for_status()
L1407         except Exception as e:
L1408             print(f"[ERR] main_post_failed: {e}")
L1409
L1410 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L1411
L1412 def io_build_input_bundle() -> InputBundle:
L1413     """
L1414     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L1415     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L1416     """
L1417     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1418     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"], missing_logs=state["missing_logs"])
L1419
L1420 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1421               n_target: int) -> tuple[list, float, float, float]:
L1422     """
L1423     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L1424     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L1425     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L1426     """
L1427     sc.cfg = cfg
L1428
L1429     if hasattr(sc, "score_build_features"):
L1430         feat = sc.score_build_features(inb)
L1431         if not hasattr(sc, "_feat_logged"):
L1432             _tlog("features built (scorer)")
L1433             sc._feat_logged = True
L1434         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1435     else:
L1436         if not hasattr(sc, "_feat"):
L1437             fb = sc.aggregate_scores(inb, cfg)
L1438             sc._feat = fb
L1439         else:
L1440             fb = sc._feat
L1441         if not hasattr(sc, "_feat_logged"):
L1442             _tlog("features built (scorer)")
L1443             sc._feat_logged = True
L1444         agg = fb.g_score if group == "G" else fb.d_score_all
L1445         if group == "D" and hasattr(fb, "df"):
L1446             beta_raw = fb.df['BETA'].astype(float)
L1447             if D_BETA_MODE == "z":
L1448                 beta_for_filter = _zscore_series(beta_raw)
L1449             else:
L1450                 beta_for_filter = beta_raw
L1451
L1452             beta_mask = (beta_for_filter <= D_BETA_CUTOFF).reindex(agg.index, fill_value=False)
L1453             agg = agg[beta_mask]
L1454
L1455             if isinstance(agg, pd.Series):
L1456                 _min = agg.min(skipna=True)
L1457                 floor = (0.0 if not np.isfinite(_min) else float(_min)) - 1e6
L1458                 agg = agg.fillna(floor)
L1459
L1460             try:
L1461                 logger.info(
L1462                     "D-filter mode=%s cutoff=%s | pass=%d raw[mean=%.3f std=%.3f] z[meanâ‰ˆ0 stdâ‰ˆ1]",
L1463                     D_BETA_MODE,
L1464                     D_BETA_CUTOFF,
L1465                     int(beta_mask.sum()),
L1466                     float(beta_raw.mean(skipna=True)),
L1467                     float(beta_raw.std(skipna=True, ddof=0)),
L1468                 )
L1469             except Exception:
L1470                 pass
L1471
L1472     if hasattr(sc, "filter_candidates"):
L1473         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1474
L1475     if isinstance(agg, pd.Series):
L1476         agg = _as_numeric_series(agg)
L1477
L1478     selector = Selector()
L1479     if hasattr(sc, "select_diversified"):
L1480         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1481             selector=selector, prev_tickers=None,
L1482             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1483             cross_mu=cfg.drrs.cross_mu_gd)
L1484     else:
L1485         if group == "G":
L1486             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1487             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1488                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1489                 lam=cfg.drrs.G.get("lam", 0.68),
L1490                 lookback=cfg.drrs.G.get("lookback", 252),
L1491                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1492         else:
L1493             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1494             g_fixed = getattr(sc, "_top_G", None)
L1495             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1496                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1497                 lam=cfg.drrs.D.get("lam", 0.85),
L1498                 lookback=cfg.drrs.D.get("lookback", 504),
L1499                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1500                 mu=cfg.drrs.cross_mu_gd)
L1501         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1502         sum_sc = res["sum_score"]; obj = res["objective"]
L1503         if group == "D":
L1504             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1505             _tlog("selection finalized (G/D)")
L1506     try:
L1507         inc = [t for t in exist if t in agg.index]
L1508         pick = _sticky_keep_current(
L1509             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1510             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1511         )
L1512     except Exception as _e:
L1513         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1514     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L1515     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L1516     try:
L1517         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1518         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1519         setattr(sc, f"_near_{group}", near10)
L1520         setattr(sc, f"_agg_{group}", agg)
L1521     except Exception:
L1522         pass
L1523
L1524     if group == "D":
L1525         _tlog("save done")
L1526     if group == "G":
L1527         sc._top_G = pick
L1528     return pick, avg_r, sum_sc, obj
L1529
L1530 def run_pipeline() -> SelectionBundle:
L1531     """
L1532     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1533     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1534     """
L1535     inb = io_build_input_bundle()
L1536     cfg = PipelineConfig(
L1537         weights=WeightsConfig(g=g_weights, d=D_weights),
L1538         drrs=DRRSParams(
L1539             corrM=corrM, shrink=DRRS_SHRINK,
L1540             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1541         ),
L1542         price_max=CAND_PRICE_MAX,
L1543         debug_mode=debug_mode
L1544     )
L1545     sc = Scorer()
L1546     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1547     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False).index)
L1548     alpha = Scorer.spx_to_alpha(inb.spx)
L1549     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1550     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1551     sc._top_G = top_G
L1552     try:
L1553         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False)
L1554         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1555     except Exception:
L1556         pass
L1557     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1558     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1559     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1560     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1561     fb = getattr(sc, "_feat", None)
L1562     out = Output()
L1563     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1564     try:
L1565         out._sc = sc
L1566     except Exception:
L1567         pass
L1568     if hasattr(sc, "_feat"):
L1569         try:
L1570             fb = sc._feat
L1571             out.miss_df = fb.missing_logs
L1572             out.display_results(
L1573                 exist=exist,
L1574                 bench=bench,
L1575                 df_raw=fb.df,
L1576                 df_z=fb.df_z,
L1577                 g_score=fb.g_score,
L1578                 d_score_all=fb.d_score_all,
L1579                 init_G=top_G,
L1580                 init_D=top_D,
L1581                 top_G=top_G,
L1582                 top_D=top_D,
L1583                 df_full_z=getattr(fb, "df_full_z", None),
L1584                 prev_G=getattr(sc, "_prev_G", exist),
L1585                 prev_D=getattr(sc, "_prev_D", exist),
L1586             )
L1587             try:
L1588                 DBG_COLS = ["GSC", "GROWTH_F", "MOM", "VOL", "DBGRW.GROWTH_F", "DBGRW.MOM", "DBGRW.VOL"]
L1589                 cols = [c for c in DBG_COLS if c in fb.df_z.columns]
L1590                 idx = [t for t in top_G if t in fb.df_z.index]
L1591                 out.debug_table = fb.df_z.loc[idx, cols].round(2) if idx and cols else None
L1592             except Exception:
L1593                 out.debug_table = None
L1594         except Exception:
L1595             pass
L1596     out.notify_slack()
L1597     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1598               "sum_score": sumG, "objective": objG},
L1599         resD={"tickers": top_D, "avg_res_corr": avgD,
L1600               "sum_score": sumD, "objective": objD},
L1601         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1602
L1603     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1604     try:
L1605         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1606               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1607               .sort_v
```