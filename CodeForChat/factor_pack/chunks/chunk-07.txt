```text
ds')}Z][{stage}] {msg}")
L71     except Exception:
L72         print(f"[DBG][{stage}] {msg}")
L73
L74
L75 def _detect_used_cols(df, df_z):
L76     used = set()
L77
L78     try:
L79         import factor as _f
L80
L81         for k in getattr(_f, "g_weights", {}).keys():
L82             if k in df_z.columns:
L83                 used.add(k)
L84     except Exception:
L85         pass
L86
L87     try:
L88         import scorer as _sc
L89
L90         for k in getattr(_sc, "D_WEIGHTS_EFF", {}).keys():
L91             if k in df_z.columns:
L92                 used.add(k)
L93     except Exception:
L94         pass
L95
L96     for k in [
L97         "GROWTH_F",
L98         "MOM",
L99         "TRD",
L100         "VOL",
L101         "D_QAL",
L102         "D_YLD",
L103         "D_VOL_RAW",
L104         "D_TRD",
L105     ]:
L106         if k in df_z.columns:
L107             used.add(k)
L108
L109     grw_cols = [
L110         "GRW_PATH",
L111         "GRW_FLEX_SCORE",
L112         "GROWTH_F",
L113         "GRW_REV_YOY_Q",
L114         "GRW_REV_ACC_Q",
L115         "GRW_REV_QOQ",
L116         "GRW_REV_TTM2",
L117         "GRW_REV_YOY_Y",
L118         "GRW_PRICE_PROXY",
L119     ]
L120     for k in grw_cols:
L121         if (k in df.columns) or (k in df_z.columns):
L122             used.add(k)
L123
L124     for c in df_z.columns:
L125         if isinstance(c, str) and c.startswith("D_"):
L126             used.add(c)
L127
L128     num = df_z.select_dtypes(include=["number"])
L129     if not num.empty:
L130         var_top = num.var().sort_values(ascending=False).head(20).index.tolist()
L131         used.update(var_top)
L132
L133     return sorted(used)
L134
L135
L136 def _reorder_for_debug(df, df_z, factor_cols=FACTOR_COLUMNS):
L137     cols: list[str] = []
L138     for fac in ["GRW", "MOM", "VOL", "QUAL", "VAL"]:
L139         for c in factor_cols.get(fac, []):
L140             if c in getattr(df_z, "columns", []) or c in getattr(df, "columns", []):
L141                 cols.append(c)
L142     seen: set[str] = set()
L143     ordered: list[str] = []
L144     for c in cols:
L145         if c not in seen:
L146             ordered.append(c)
L147             seen.add(c)
L148     return ordered
L149
L150
L151 def dump_dfz_scoped(df, df_z, *, topk=20, logger=None):
L152     import numpy as np, pandas as pd, logging
L153
L154     lg = logger or logging.getLogger(__name__)
L155
L156     if not DEBUG_SCOPE_STRICT:
L157         dfz = df_z.copy()
L158         lg.info("DEBUG scope: disabled (showing ALL %d columns).", dfz.shape[1])
L159     else:
L160         rel = _detect_used_cols(df, df_z)
L161         dfz = df_z[[c for c in rel if c in df_z.columns]].copy()
L162         if dfz.shape[1] < 15:
L163             num = df_z.select_dtypes(include=["number"])
L164             add = []
L165             if not num.empty:
L166                 add = [
L167                     c
L168                     for c in num.var().sort_values(ascending=False).head(30).index
L169                     if c not in dfz.columns
L170                 ]
L171                 if dfz.shape[1] < 15:
L172                     add = add[: 15 - dfz.shape[1]]
L173                 else:
L174                     add = []
L175             dfz = pd.concat([dfz, df_z[add]], axis=1)
L176             lg.info("DEBUG scope too small → fallback add %d cols", len(add))
L177         excluded = [c for c in df_z.columns if c not in dfz.columns]
L178         lg.info(
L179             "DEBUG scope: %d relevant cols kept, %d excluded.",
L180             dfz.shape[1],
L181             len(excluded),
L182         )
L183
L184     nan_top = dfz.isna().sum().sort_values(ascending=False).head(topk)
L185     lg.info("scorer:NaN columns (top%d):", topk)
L186     for c, n in nan_top.items():
L187         lg.info("%s\t%d", c, int(n))
L188
L189     num_dfz = dfz.select_dtypes(include=["number"])
L190     if not num_dfz.empty:
L191         ztop = (num_dfz == 0).mean().sort_values(ascending=False).head(topk)
L192         lg.info("scorer:Zero-dominated columns (top%d):", topk)
L193         for c, r in ztop.items():
L194             lg.info("%s\t%.2f%%", c, 100.0 * float(r))
L195
L196     return dfz
L197
L198
L199 def save_factor_debug_csv(df, df_z, path="out/factor_debug_latest.csv"):
L200     import os, pandas as pd, logging
L201
L202     lg = logging.getLogger(__name__)
L203     try:
L204         cols = _reorder_for_debug(df, df_z)
L205         dump = pd.DataFrame(index=df.index)
L206         for c in cols:
L207             if c in getattr(df, "columns", []):
L208                 dump[c] = df[c]
L209             if c in getattr(df_z, "columns", []):
L210                 dump[c] = df_z[c]
L211         dump.reset_index(names=["symbol"], inplace=True)
L212         if path:
L213             dirpath = os.path.dirname(path) or "."
L214             os.makedirs(dirpath, exist_ok=True)
L215             dump.to_csv(path, index=False)
L216         lg.info(
L217             "factor debug CSV saved: %s (cols=%d rows=%d)",
L218             path,
L219             dump.shape[1],
L220             dump.shape[0],
L221         )
L222     except Exception as e:
L223         lg.warning("factor debug CSV failed: %s", e)
L224
L225
L226 def log_grw_stats(df, df_z, logger):
L227     import numpy as np, pandas as pd
L228
L229     try:
L230         s = pd.to_numeric(df.get("GRW_FLEX_SCORE", pd.Series(dtype=float)), errors="coerce")
L231         z = pd.to_numeric(df_z.get("GROWTH_F", pd.Series(dtype=float)), errors="coerce")
L232         if s.size:
L233             logger.info(
L234                 "GRW raw stats: n=%d, median=%.3f, mad=%.3f, std=%.3f",
L235                 s.count(),
L236                 np.nanmedian(s),
L237                 np.nanmedian(np.abs(s - np.nanmedian(s))),
L238                 np.nanstd(s),
L239             )
L240         if z.size and not z.dropna().empty:
L241             clip_hi = float((z >= 2.95).mean() * 100.0)
L242             clip_lo = float((z <= -2.95).mean() * 100.0)
L243             logger.info(
L244                 "GRW z stats: min=%.2f, p25=%.2f, med=%.2f, p75=%.2f, max=%.2f, clipped_hi=%.1f%%, clipped_lo=%.1f%%",
L245                 np.nanmin(z),
L246                 np.nanpercentile(z.dropna(), 25),
L247                 np.nanmedian(z),
L248                 np.nanpercentile(z.dropna(), 75),
L249                 np.nanmax(z),
L250                 clip_hi,
L251                 clip_lo,
L252             )
L253         if "GRW_PATH" in getattr(df, "columns", []):
L254             logger.info(
L255                 "GRW path breakdown: %s",
L256                 df["GRW_PATH"].value_counts(dropna=False).to_dict(),
L257             )
L258     except Exception as e:
L259         logger.warning("GRW stats log failed: %s", e)
L260
L261
L262 def _grw_record_to_df(t: str, info_t: dict, df):
L263     if not isinstance(df, pd.DataFrame):
L264         return
L265     raw_parts = info_t.get("DEBUG_GRW_PARTS") if isinstance(info_t, dict) else None
L266     parts: dict[str, Any] = {}
L267     if isinstance(raw_parts, str):
L268         try:
L269             parts = json.loads(raw_parts)
L270         except Exception:
L271             parts = {}
L272     elif isinstance(raw_parts, dict):
L273         parts = raw_parts
L274     path = info_t.get("DEBUG_GRW_PATH") if isinstance(info_t, dict) else None
L275     score = info_t.get("GRW_SCORE") if isinstance(info_t, dict) else None
L276
L277     def _part_value(key: str):
L278         value = parts.get(key) if isinstance(parts, dict) else None
L279         if value is None:
L280             return np.nan
L281         try:
L282             return float(value)
L283         except Exception:
L284             return np.nan
L285
L286     df.loc[t, "GRW_PATH"] = path
L287     df.loc[t, "GRW_FLEX_SCORE"] = np.nan if score is None else float(score)
L288     df.loc[t, "GRW_REV_YOY_Q"] = _part_value("rev_yoy_q")
L289     df.loc[t, "GRW_REV_ACC_Q"] = _part_value("rev_acc_q")
L290     df.loc[t, "GRW_REV_QOQ"] = _part_value("rev_qoq")
L291     df.loc[t, "GRW_REV_TTM2"] = _part_value("rev_ttm2")
L292     df.loc[t, "GRW_REV_YOY_Y"] = _part_value("rev_yoy_y")
L293     df.loc[t, "GRW_PRICE_PROXY"] = _part_value("price_proxy")
L294
L295 # ---- Dividend Helpers -------------------------------------------------------
L296 def _last_close(t, price_map=None):
L297     if price_map and (c := price_map.get(t)) is not None: return float(c)
L298     try:
L299         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L300         return float(h.iloc[-1]) if len(h) else np.nan
L301     except Exception:
L302         return np.nan
L303
L304 def _ttm_div_sum(t, lookback_days=400):
L305     try:
L306         div = yf.Ticker(t).dividends
L307         if div is None or len(div) == 0: return 0.0
L308         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L309         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L310         return ttm if ttm > 0 else float(div.tail(4).sum())
L311     except Exception:
L312         return 0.0
L313
L314 def ttm_div_yield_portfolio(tickers, price_map=None):
L315     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L316     return float(np.mean(ys)) if ys else 0.0
L317
L318 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L319 def winsorize_s(s: pd.Series, p=0.02):
L320     if s is None or s.dropna().empty: return s
L321     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L322
L323 def robust_z(s: pd.Series, p=0.02):
L324     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L325
L326 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L327     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L328     if s is None:
L329         return pd.Series(dtype=float)
L330     v = pd.to_numeric(s, errors="coerce")
L331     m = np.nanmedian(v)
L332     mad = np.nanmedian(np.abs(v - m))
L333     z = (v - m) / (1.4826 * mad + 1e-9)
L334     if np.nanstd(z) < 1e-9:
L335         r = v.rank(method="average", na_option="keep")
L336         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L337     return pd.Series(z, index=v.index, dtype=float)
L338
L339
L340 def _dump_dfz(
L341     df: pd.DataFrame,
L342     df_z: pd.DataFrame,
L343     debug_mode: bool,
L344     max_rows: int = 400,
L345     ndigits: int = 3,
L346 ) -> None:
L347     """df_z を System log(INFO) へダンプする簡潔なユーティリティ."""
L348
L349     if not debug_mode:
L350         return
L351     try:
L352         dfz_scoped = dump_dfz_scoped(df, df_z, topk=20, logger=logger)
L353         ordered = _reorder_for_debug(df, df_z)
L354         rel_set = set(dfz_scoped.columns)
L355         view_cols = [c for c in ordered if c in rel_set]
L356         if not view_cols:
L357             view_cols = list(dfz_scoped.columns)
L358         view = dfz_scoped[view_cols].copy()
L359         view = view.apply(
L360             lambda s: s.round(ndigits)
L361             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L362             else s
L363         )
L364         if len(view) > max_rows:
L365             view = view.iloc[:max_rows]
L366
L367         logger.info("===== DF_Z DUMP START =====")
L368         logger.info("\n%s", view.to_string(max_rows=None, max_cols=None))
L369         logger.info("===== DF_Z DUMP END =====")
L370     except Exception as exc:
L371         logger.warning("df_z dump failed: %s", exc)
L372
L373 def _safe_div(a, b):
L374     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L375     except Exception: return np.nan
L376
L377 def _safe_last(series: pd.Series, default=np.nan):
L378     try: return float(series.iloc[-1])
L379     except Exception: return default
L380
L381
L382 def _ensure_series(x):
L383     if x is None:
L384         return pd.Series(dtype=float)
L385     if isinstance
```