```text
_G}: なし",
L1360         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L1361
L1362     if fire_recent:
L1363         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1364         lines.append(f"過去5営業日の検知: {fire_list}")
L1365     else:
L1366         lines.append("過去5営業日の検知: なし")
L1367
L1368     try:
L1369         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1370         if webhook:
L1371             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1372     except Exception:
L1373         pass
L1374
L1375     out = Output()
L1376     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1377     try: out._sc = sc
L1378     except Exception: pass
L1379     if hasattr(sc, "_feat"):
L1380         try:
L1381             fb = sc._feat
L1382             out.miss_df = fb.missing_logs
L1383             out.display_results(
L1384                 exist=exist,
L1385                 bench=bench,
L1386                 df_z=fb.df_z,
L1387                 g_score=fb.g_score,
L1388                 d_score_all=fb.d_score_all,
L1389                 init_G=top_G,
L1390                 init_D=top_D,
L1391                 top_G=top_G,
L1392                 top_D=top_D,
L1393                 df_full_z=getattr(fb, "df_full_z", None),
L1394                 prev_G=getattr(sc, "_prev_G", exist),
L1395                 prev_D=getattr(sc, "_prev_D", exist),
L1396             )
L1397         except Exception:
L1398             pass
L1399     out.notify_slack()
L1400     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1401               "sum_score": sumG, "objective": objG},
L1402         resD={"tickers": top_D, "avg_res_corr": avgD,
L1403               "sum_score": sumD, "objective": objD},
L1404         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1405
L1406     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1407     try:
L1408         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1409               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1410               .sort_values("G_plus_D")
L1411               .head(10)
L1412               .round(3))
L1413         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1414         _post_slack({"text": f"```{low_msg}```"})
L1415     except Exception as _e:
L1416         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1417
L1418     return sb
L1419
L1420 if __name__ == "__main__":
L1421     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import json, logging, os, requests, sys, warnings
L30 import numpy as np
L31 import pandas as pd
L32 import yfinance as yf
L33 from typing import Any, TYPE_CHECKING
L34 from scipy.stats import zscore
L35 from datetime import datetime as _dt
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L39
L40 logger = logging.getLogger(__name__)
L41
L42
L43 def _log(stage, msg):
L44     try:
L45         print(f"[DBG][{_dt.utcnow().isoformat(timespec='seconds')}Z][{stage}] {msg}")
L46     except Exception:
L47         print(f"[DBG][{stage}] {msg}")
L48
L49
L50 # ---- Debug helpers ----------------------------------------------------------
L51 def _flatten_for_debug(d, prefix="DBG_GRW"):
L52     """
L53     ネストしたdict/list/tupleを、df_z列に入れやすい一次元dictへ。
L54     例: {"w":0.68,"path":"P5","core":{"rev_yoy_mean":1.73,"eps_yoy_mean":0.72,"accel":0.45}}
L55       -> {"DBG_GRW.w":0.68,"DBG_GRW.path":"P5","DBG_GRW.core.rev_yoy_mean":1.73,...}
L56     """
L57     out = {}
L58     if d is None:
L59         return out
L60
L61     def rec(k, v):
L62         if isinstance(v, dict):
L63             for kk, vv in v.items():
L64                 rec(f"{k}.{str(kk)}", vv)
L65         elif isinstance(v, (list, tuple, np.ndarray)):
L66             try:
L67                 out[k] = list(v[:6])
L68             except Exception:
L69                 out[k] = list(v)
L70         else:
L71             out[k] = v
L72
L73     if isinstance(d, dict):
L74         for k, v in d.items():
L75             rec(f"{prefix}.{str(k)}", v)
L76     return out
L77
L78
L79 # ---- Dividend Helpers -------------------------------------------------------
L80 def _last_close(t, price_map=None):
L81     if price_map and (c := price_map.get(t)) is not None: return float(c)
L82     try:
L83         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L84         return float(h.iloc[-1]) if len(h) else np.nan
L85     except Exception:
L86         return np.nan
L87
L88 def _ttm_div_sum(t, lookback_days=400):
L89     try:
L90         div = yf.Ticker(t).dividends
L91         if div is None or len(div) == 0: return 0.0
L92         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L93         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L94         return ttm if ttm > 0 else float(div.tail(4).sum())
L95     except Exception:
L96         return 0.0
L97
L98 def ttm_div_yield_portfolio(tickers, price_map=None):
L99     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L100     return float(np.mean(ys)) if ys else 0.0
L101
L102 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L103 def winsorize_s(s: pd.Series, p=0.02):
L104     if s is None or s.dropna().empty: return s
L105     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L106
L107 def robust_z(s: pd.Series, p=0.02):
L108     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L109
L110 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L111     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L112     if s is None:
L113         return pd.Series(dtype=float)
L114     v = pd.to_numeric(s, errors="coerce")
L115     m = np.nanmedian(v)
L116     mad = np.nanmedian(np.abs(v - m))
L117     z = (v - m) / (1.4826 * mad + 1e-9)
L118     if np.nanstd(z) < 1e-9:
L119         r = v.rank(method="average", na_option="keep")
L120         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L121     return pd.Series(z, index=v.index, dtype=float)
L122
L123
L124 def _safe_div(a, b):
L125     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L126     except Exception: return np.nan
L127
L128 def _safe_last(series: pd.Series, default=np.nan):
L129     try: return float(series.iloc[-1])
L130     except Exception: return default
L131
L132
L133 def _ensure_series(x):
L134     if x is None:
L135         return pd.Series(dtype=float)
L136     if isinstance(x, pd.Series):
L137         return x.dropna()
L138     if isinstance(x, (list, tuple)):
L139         if len(x) and isinstance(x[0], (tuple, list)) and len(x[0]) == 2:
L140             dt = pd.to_datetime([d for d, _ in x], errors="coerce")
L141             v = pd.to_numeric([_v for _, _v in x], errors="coerce")
L142             return pd.Series(v, index=dt).dropna()
L143         return pd.Series(pd.to_numeric(list(x), errors="coerce")).dropna()
L144     try:
L145         return pd.Series(x).dropna()
L146     except Exception:
L147         return pd.Series(dtype=float)
L148
L149
L150 def _to_quarterly(s: pd.Series) -> pd.Series:
L151     if s.empty or not isinstance(s.index, pd.DatetimeIndex):
L152         return s
L153     return s.resample("Q").last().dropna()
L154
L155
L156 def _ttm_yoy_from_quarterly(qs: pd.Series) -> pd.Series:
L157     if qs is None or qs.empty:
L158         return pd.Series(dtype=float)
L159     ttm = qs.rolling(4, min_periods=2).sum()
L160     yoy = ttm.pct_change(4)
L161     return yoy
L162
L163
L164 def _nz(x) -> float:
L165     if x is None:
L166         return 0.0
L167     try:
L168         value = float(x)
L169     except Exception:
L170         return 0.0
L171     if not np.isfinite(value):
L172         return 0.0
L173     return value
L174
L175
L176 def _winsor(x, lo=-2.0, hi=2.0) -> float:
L177     v = _nz(x)
L178     if v < lo:
L179         return float(lo)
L180     if v > hi:
L181         return float(hi)
L182     return float(v)
L183
L184
L185 def _round_debug(x, ndigits: int = 4):
L186     try:
L187         value = float(x)
L188     except Exception:
L189         return None
L190     if not np.isfinite(value):
L191         return None
L192     return round(value, ndigits)
L193
L194
L195 def _calc_grw_flexible(
L196     ticker: str,
L197     info_entry: dict | None,
L198     close_series: pd.Series | None,
L199     volume_series: pd.Series | None,
L200 ):
L201     info_entry = info_entry if isinstance(info_entry, dict) else {}
L202
L203     s_rev_q = _ensure_series(info_entry.get("SEC_REV_Q_SERIES"))
L204     s_eps_q = _ensure_series(info_entry.get("SEC_EPS_Q_SERIES"))
L205     s_rev_y = _ensure_series(info_entry.get("SEC_REV_Y_SERIES"))
L206
L207     nQ = int(getattr(s_rev_q, "size", 0))
L208     nY = int(getattr(s_rev_y, "size", 0))
L209
L210     parts: dict[str, Any] = {"nQ": nQ, "nY": nY}
L211     path = "NONE"
L212     w = 0.0
L213
L214     def _valid_ratio(a, b):
L215         try:
L216             na, nb = float(a), float(b)
L217         except Exception:
L218             return None
L219         if not np.isfinite(na) or not np.isfinite(nb) or nb == 0:
L220             return None
L221         return na, nb
L222
L223     def yoy_q(series: pd.Series) -> float | None:
L224         s = _ensure_series(series)
L225         if s.empty:
L226             return None
L227         s = s.sort_index()
L228         if isinstance(s.index, pd.DatetimeIndex):
L229             last_idx = s.index[-1]
L230             window_start = last_idx - pd.DateOffset(months=15)
L231             window_end = last_idx - pd.DateOffset(months=9)
L232             candidates = s.loc[(s.index >= window_start) & (s.index <= window_end)]
L233             if candidates.empty:
L234                 candidates = s.loc[s.index <= window_end]
L235             if candidates.empty:
L236                 return None
L237             v1 = candidates.iloc[-1]
L238             v0 = s.iloc[-1]
L239         else:
L240             if s.size < 5:
L241                 return None
L242             v0 = s.iloc[-1]
L243             v1 = s.iloc[-5]
L244         pair = _valid_ratio(v0, v1)
L245         if pair is None:
L246             return None
L247         a, b = pair
L248         return float(a / b - 1.0)
L249
L250     def qoq(series: pd.Series) -> float | None:
L251         s = _ensure_series(series)
L252         if s.size < 2:
L253             return None
L254         s = s.sort_index()
L2
```