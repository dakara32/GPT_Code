```text
p = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L1371                 name = {"beta": "β"}.get(base, base)
L1372                 try:
L1373                     val = f"{float(v):g}"
L1374                 except Exception:
L1375                     val = str(v)
L1376                 parts.append(f"{name}{op}{val}")
L1377             return "" if not parts else " / filter:" + " & ".join(parts)
L1378
L1379         def _inject_filter_suffix(title: str, group: str) -> str:
L1380             suf = _filter_suffix_from(FILTER_SPEC, group)
L1381             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L1382
L1383         def _blk(title, tbl, fmt=None, drop=()):
L1384             if tbl is None or getattr(tbl, 'empty', False):
L1385                 return f"{title}\n(選定なし)\n"
L1386             if drop and hasattr(tbl, 'columns'):
L1387                 keep = [c for c in tbl.columns if c not in drop]
L1388                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L1389             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L1390
L1391         message = "📈 ファクター分散最適化の結果\n"
L1392         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L1393         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L1394         message += "Changes\n" + ("(変更なし)\n" if self._changes_empty else f"```{self._changes_text}```\n")
L1395         message += "Performance Comparison:\n```" + self._performance_text + "```"
L1396
L1397         try:
L1398             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L1399             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L1400             if r is not None:
L1401                 r.raise_for_status()
L1402         except Exception as e:
L1403             print(f"[ERR] main_post_failed: {e}")
L1404
L1405 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L1406
L1407 def io_build_input_bundle() -> InputBundle:
L1408     """
L1409     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L1410     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L1411     """
L1412     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1413     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"], missing_logs=state["missing_logs"])
L1414
L1415 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1416               n_target: int) -> tuple[list, float, float, float]:
L1417     """
L1418     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L1419     戻り値：(pick, avg_res_corr, sum_score, objective)
L1420     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L1421     """
L1422     sc.cfg = cfg
L1423
L1424     if hasattr(sc, "score_build_features"):
L1425         feat = sc.score_build_features(inb)
L1426         if not hasattr(sc, "_feat_logged"):
L1427             _tlog("features built (scorer)")
L1428             sc._feat_logged = True
L1429         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1430     else:
L1431         if not hasattr(sc, "_feat"):
L1432             fb = sc.aggregate_scores(inb, cfg)
L1433             sc._feat = fb
L1434         else:
L1435             fb = sc._feat
L1436         if not hasattr(sc, "_feat_logged"):
L1437             _tlog("features built (scorer)")
L1438             sc._feat_logged = True
L1439         agg = fb.g_score if group == "G" else fb.d_score_all
L1440         if group == "D" and hasattr(fb, "df"):
L1441             beta_raw = fb.df['BETA'].astype(float)
L1442             if D_BETA_MODE == "z":
L1443                 beta_for_filter = _zscore_series(beta_raw)
L1444             else:
L1445                 beta_for_filter = beta_raw
L1446
L1447             beta_mask = (beta_for_filter <= D_BETA_CUTOFF).reindex(agg.index, fill_value=False)
L1448             agg = agg[beta_mask]
L1449
L1450             if isinstance(agg, pd.Series):
L1451                 _min = agg.min(skipna=True)
L1452                 floor = (0.0 if not np.isfinite(_min) else float(_min)) - 1e6
L1453                 agg = agg.fillna(floor)
L1454
L1455             try:
L1456                 logger.info(
L1457                     "D-filter mode=%s cutoff=%s | pass=%d raw[mean=%.3f std=%.3f] z[mean≈0 std≈1]",
L1458                     D_BETA_MODE,
L1459                     D_BETA_CUTOFF,
L1460                     int(beta_mask.sum()),
L1461                     float(beta_raw.mean(skipna=True)),
L1462                     float(beta_raw.std(skipna=True, ddof=0)),
L1463                 )
L1464             except Exception:
L1465                 pass
L1466
L1467     if hasattr(sc, "filter_candidates"):
L1468         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1469
L1470     if isinstance(agg, pd.Series):
L1471         agg = _as_numeric_series(agg)
L1472
L1473     selector = Selector()
L1474     if hasattr(sc, "select_diversified"):
L1475         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1476             selector=selector, prev_tickers=None,
L1477             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1478             cross_mu=cfg.drrs.cross_mu_gd)
L1479     else:
L1480         if group == "G":
L1481             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1482             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1483                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1484                 lam=cfg.drrs.G.get("lam", 0.68),
L1485                 lookback=cfg.drrs.G.get("lookback", 252),
L1486                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1487         else:
L1488             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1489             g_fixed = getattr(sc, "_top_G", None)
L1490             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1491                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1492                 lam=cfg.drrs.D.get("lam", 0.85),
L1493                 lookback=cfg.drrs.D.get("lookback", 504),
L1494                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1495                 mu=cfg.drrs.cross_mu_gd)
L1496         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1497         sum_sc = res["sum_score"]; obj = res["objective"]
L1498         if group == "D":
L1499             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1500             _tlog("selection finalized (G/D)")
L1501     try:
L1502         inc = [t for t in exist if t in agg.index]
L1503         pick = _sticky_keep_current(
L1504             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1505             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1506         )
L1507     except Exception as _e:
L1508         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1509     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L1510     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L1511     try:
L1512         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1513         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1514         setattr(sc, f"_near_{group}", near10)
L1515         setattr(sc, f"_agg_{group}", agg)
L1516     except Exception:
L1517         pass
L1518
L1519     if group == "D":
L1520         _tlog("save done")
L1521     if group == "G":
L1522         sc._top_G = pick
L1523     return pick, avg_r, sum_sc, obj
L1524
L1525 def run_pipeline() -> SelectionBundle:
L1526     """
L1527     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L1528     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L1529     """
L1530     inb = io_build_input_bundle()
L1531     cfg = PipelineConfig(
L1532         weights=WeightsConfig(g=g_weights, d=D_weights),
L1533         drrs=DRRSParams(
L1534             corrM=corrM, shrink=DRRS_SHRINK,
L1535             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1536         ),
L1537         price_max=CAND_PRICE_MAX,
L1538         debug_mode=debug_mode
L1539     )
L1540     sc = Scorer()
L1541     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1542     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False).index)
L1543     alpha = Scorer.spx_to_alpha(inb.spx)
L1544     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1545     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1546     sc._top_G = top_G
L1547     try:
L1548         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False)
L1549         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1550     except Exception:
L1551         pass
L1552     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1553     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1554     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1555     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1556     fb = getattr(sc, "_feat", None)
L1557     out = Output()
L1558     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1559     try:
L1560         out._sc = sc
L1561     except Exception:
L1562         pass
L1563     if hasattr(sc, "_feat"):
L1564         try:
L1565             fb = sc._feat
L1566             out.display_results(
L1567                 exist=exist,
L1568                 bench=bench,
L1569                 df_raw=fb.df,
L1570                 df_z=fb.df_z,
L1571                 g_score=fb.g_score,
L1572                 d_score_all=fb.d_score_all,
L1573                 init_G=top_G,
L1574                 init_D=top_D,
L1575                 top_G=top_G,
L1576                 top_D=top_D,
L1577                 df_full_z=getattr(fb, "df_full_z", None),
L1578                 prev_G=getattr(sc, "_prev_G", exist),
L1579                 prev_D=getattr(sc, "_prev_D", exist),
L1580             )
L1581         except Exception:
L1582             pass
L1583     out.notify_slack()
L1584     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1585               "sum_score": sumG, "objective": objG},
L1586         resD={"tickers": top_D, "avg_res_corr": avgD,
L1587               "sum_score": sumD, "objective": objD},
L1588         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1589
L1590     # [ADD] G/D選定結果で current_tickers.csv の bucket を部分上書き
L1591     try:
L1592         _update_bucket_by_selection("current_tickers.csv", top_G, top_D)
L1593     except Exception as e:
L1594         logging.warning("bucket update skipped: %s", e)
L1595         # 失敗しても本処理は継続（I/O都合で安全側）
L1596
L1597     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1598     try:
L1599         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1600               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1601               .sort_values("G_plus_D")
L1602               .head(10)
L1603               .round(3))
L1604         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1605         _post_slack({"text": f"```{low_msg}```"})
L1606     except Exception as _e:
L1607         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1608
L1609     return sb
L1610
L1611
L1612 # --- Slack / warning helpers (relocated without logic changes) ---
L1613
L1614
L1615 def _post_slack(payload: d
```