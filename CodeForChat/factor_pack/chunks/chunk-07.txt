```text
r t in D_UNI}, name='DSC')
L1443         self.d_table = pd.concat([d_disp, dsc_series], axis=1); self.d_table.index = [t + ("⭐️" if t in top_D else "") for t in D_UNI]
L1444         self.d_formatters = {col:"{:.2f}".format for col in cols_D}; self.d_formatters['DSC']="{:.3f}".format
L1445         import scorer
L1446         dw_eff = scorer.D_WEIGHTS_EFF
L1447         self.d_title = (f"[D枠 / {N_D} / {_fmt_w(dw_eff)} / corrM={corrM} / "
L1448                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} γ={DRRS_D['gamma']} λ={DRRS_D['lam']} μ={CROSS_MU_GD} η={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L1449         if near_D:
L1450             add = [t for t in near_D if t not in set(D_UNI)][:10]
L1451             if add:
L1452                 d_disp2 = pd.DataFrame(index=add)
L1453                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L1454                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L1455                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L1456         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L1457
L1458         # === Changes（IN の GSC/DSC を表示。OUT は銘柄名のみ） ===
L1459         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L1460         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L1461
L1462         self.io_table = pd.DataFrame({
L1463             'IN': pd.Series(in_list),
L1464             '/ OUT': pd.Series(out_list)
L1465         })
L1466         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else '—' for t in out_list]
L1467         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else '—' for t in out_list]
L1468         self.io_table['GSC'] = pd.Series(g_list)
L1469         self.io_table['DSC'] = pd.Series(d_list)
L1470
L1471         print("Changes:")
L1472         print(self.io_table.to_string(index=False))
L1473
L1474         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False, threads=False)['Close'].ffill(limit=2)
L1475         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L1476         for name,ticks in portfolios.items():
L1477             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L1478             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L1479             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L1480             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L1481             if len(ticks)>=2:
L1482                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L1483                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L1484                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L1485             else: RAW_rho = RESID_rho = np.nan
L1486             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWρ':RAW_rho,'RESIDρ':RESID_rho,'DIVY':divy}
L1487         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L1488         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L1489         cols_order = ['RET','VOL','SHP','MDD','RAWρ','RESIDρ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L1490         def _fmt_row(s):
L1491             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWρ':(f"{s['RAWρ']:.2f}" if pd.notna(s['RAWρ']) else "NaN"),'RESIDρ':(f"{s['RESIDρ']:.2f}" if pd.notna(s['RESIDρ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L1492         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L1493         # === 追加: GSC+DSC が低い順 TOP10 ===
L1494         try:
L1495             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L1496             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L1497             all_scores = all_scores.dropna(subset=['G_plus_D'])
L1498             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L1499             print("Low Score Candidates (GSC+DSC bottom 10):")
L1500             print(self.low10_table.to_string())
L1501         except Exception as e:
L1502             print(f"[warn] low-score ranking failed: {e}")
L1503             self.low10_table = None
L1504         self.debug_text = ""
L1505         if debug_mode:
L1506             logger.info("debug_mode=True: df_z dump handled in scorer; skipping factor-side debug output")
L1507         else:
L1508             logger.debug(
L1509                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L1510                 debug_mode, True
L1511             )
L1512         self._debug_logged = True
L1513
L1514     # --- Slack送信（元 notify_slack のロジックそのまま） ---
L1515     def notify_slack(self):
L1516         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L1517
L1518         if not SLACK_WEBHOOK_URL:
L1519             print("⚠️ SLACK_WEBHOOK_URL not set (main report skipped)")
L1520             return
L1521
L1522         def _filter_suffix_from(spec: dict, group: str) -> str:
L1523             g = spec.get(group, {})
L1524             parts = [str(m) for m in g.get("pre_mask", [])]
L1525             for k, v in (g.get("pre_filter", {}) or {}).items():
L1526                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L1527                 name = {"beta": "β"}.get(base, base)
L1528                 try:
L1529                     val = f"{float(v):g}"
L1530                 except Exception:
L1531                     val = str(v)
L1532                 parts.append(f"{name}{op}{val}")
L1533             return "" if not parts else " / filter:" + " & ".join(parts)
L1534
L1535         def _inject_filter_suffix(title: str, group: str) -> str:
L1536             suf = _filter_suffix_from(FILTER_SPEC, group)
L1537             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L1538
L1539         def _blk(title, tbl, fmt=None, drop=()):
L1540             if tbl is None or getattr(tbl, 'empty', False):
L1541                 return f"{title}\n(選定なし)\n"
L1542             if drop and hasattr(tbl, 'columns'):
L1543                 keep = [c for c in tbl.columns if c not in drop]
L1544                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L1545             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L1546
L1547         message = "📈 ファクター分散最適化の結果\n"
L1548         miss_df, truncated, total = self._miss_disp_info or self._prepare_missing_display(self.miss_df)
L1549         lines = compact_missing_lines(miss_df, limit=300)
L1550         missing_txt = "Missing Data:\n```" + "\n".join(lines) + "```" if lines else ""
L1551         trunc_note = f"...省略 ({total}件中 上位20件のみ表示)" if truncated else ""
L1552         if missing_txt:
L1553             message += missing_txt + ("\n" + trunc_note if trunc_note else "") + "\n"
L1554         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L1555         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L1556         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L1557         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L1558
L1559         try:
L1560             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L1561             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L1562             if r is not None:
L1563                 r.raise_for_status()
L1564         except Exception as e:
L1565             print(f"[ERR] main_post_failed: {e}")
L1566
L1567 def _infer_g_universe(feature_df, selected12=None, near5=None):
L1568     try:
L1569         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L1570         if out: return out
L1571     except Exception:
L1572         pass
L1573     base = set()
L1574     for lst in (selected12 or []), (near5 or []):
L1575         for x in (lst or []): base.add(x)
L1576     return list(base) if base else list(feature_df.index)
L1577
L1578 def _fmt_with_fire_mark(tickers, feature_df):
L1579     # breakout/pullback 補助は廃止 → no-op（安全のため列参照なし）
L1580     return [str(t) for t in (tickers or [])]
L1581
L1582 def _label_recent_event(t, feature_df):
L1583     # ラベル付けは廃止 → no-op
L1584     return t
L1585
L1586 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L1587
L1588 def io_build_input_bundle() -> InputBundle:
L1589     """
L1590     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L1591     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L1592     """
L1593     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1594     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"], missing_logs=state["missing_logs"])
L1595
L1596 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1597               n_target: int) -> tuple[list, float, float, float]:
L1598     """
L1599     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L1600     戻り値：(pick, avg_res_corr, sum_score, objective)
L1601     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L1602     """
L1603     sc.cfg = cfg
L1604
L1605     if hasattr(sc, "score_build_features"):
L1606         feat = sc.score_build_features(inb)
L1607         if not hasattr(sc, "_feat_logged"):
L1608             T.log("features built (scorer)")
L1609             sc._feat_logged = True
L1610         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1611     else:
L1612         fb = sc.aggregate_scores(inb, cfg)
L1613         if not hasattr(sc, "_feat_logged"):
L1614             T.log("features built (scorer)")
L1615             sc._feat_logged = True
L1616         sc._feat = fb
L1617         agg = fb.g_score if group == "G" else fb.d_score_all
L1618         if group == "D" and hasattr(fb, "df"):
L1619             beta_raw = fb.df['BETA'].astype(float)
L1620             if D_BETA_MODE == "z":
L1621                 beta_for_filter = _zscore_series(beta_raw)
L1622             else:
L1623                 beta_for_filter = beta_raw
L1624
L1625             beta_mask = (beta_for_filter <= D_BETA_CUTOFF).reindex(agg.index, fill_value=False)
L1626             agg = agg[beta_mask]
L1627
L1628             if isinstance(agg, pd.Series):
L1629                 _min = agg.min(skipna=True)
L1630                 floor = (0.0 if not np.isfinite(_min) else float(_min)) - 1e6
L1631                 agg = agg.fillna(floor)
L1632
L1633             try:
L1634                 logger.info(
L1635                     "D-filter mode=%s cutoff=%s | pass=%d raw[mean=%.3f std=%.3f] z[mean≈0 std≈1]",
L1636                     D_BETA_MODE,
L1637                     D_BETA_CUTOFF,
L1638                     int(beta_mask.sum()),
L1639                     float(beta_raw.mean(skipna=True)),
L1640                     float(beta_raw.std(skipna=True, ddof=0)),
L1641            
```