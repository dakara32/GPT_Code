```text
439                         f"LB={DRRS_D['lookback']} nPC={DRRS_D['n_pc']} Î³={DRRS_D['gamma']} Î»={DRRS_D['lam']} Î¼={CROSS_MU_GD} Î·={DRRS_D['eta']} shrink={DRRS_SHRINK}]")
L1440         if near_D:
L1441             add = [t for t in near_D if t not in set(D_UNI)][:10]
L1442             if add:
L1443                 d_disp2 = pd.DataFrame(index=add)
L1444                 d_disp2['QAL'], d_disp2['YLD'], d_disp2['VOL'], d_disp2['TRD'] = df_z.loc[add,'D_QAL'], df_z.loc[add,'D_YLD'], df_z.loc[add,'D_VOL_RAW'], df_z.loc[add,'D_TRD']
L1445                 near_tbl = pd.concat([d_disp2, pd.Series({t: d_score_all.get(t) for t in add}, name='DSC')], axis=1)
L1446                 self.d_table = pd.concat([self.d_table, near_tbl], axis=0)
L1447         print(self.d_title); print(self.d_table.to_string(formatters=self.d_formatters))
L1448
L1449         # === Changesï¼ˆIN ã® GSC/DSC ã‚’è¡¨ç¤ºã€‚OUT ã¯éŠ˜æŸ„åã®ã¿ï¼‰ ===
L1450         in_list = sorted(set(list(top_G)+list(top_D)) - set(exist))
L1451         out_list = sorted(set(exist) - set(list(top_G)+list(top_D)))
L1452
L1453         self.io_table = pd.DataFrame({
L1454             'IN': pd.Series(in_list),
L1455             '/ OUT': pd.Series(out_list)
L1456         })
L1457         g_list = [f"{g_score.get(t):.3f}" if pd.notna(g_score.get(t)) else 'â€”' for t in out_list]
L1458         d_list = [f"{d_score_all.get(t):.3f}" if pd.notna(d_score_all.get(t)) else 'â€”' for t in out_list]
L1459         self.io_table['GSC'] = pd.Series(g_list)
L1460         self.io_table['DSC'] = pd.Series(d_list)
L1461
L1462         print("Changes:")
L1463         print(self.io_table.to_string(index=False))
L1464
L1465         all_tickers = list(set(exist + list(top_G) + list(top_D) + [bench])); prices = yf.download(all_tickers, period='1y', auto_adjust=True, progress=False, threads=False)['Close'].ffill(limit=2)
L1466         ret = prices.pct_change(); portfolios = {'CUR':exist,'NEW':list(top_G)+list(top_D)}; metrics={}
L1467         for name,ticks in portfolios.items():
L1468             pr = ret[ticks].mean(axis=1, skipna=True).dropna(); cum = (1+pr).cumprod()-1; n = len(pr)
L1469             if n>=252: ann_ret, ann_vol = (1+cum.iloc[-1])**(252/n)-1, pr.std()*np.sqrt(252)
L1470             else: ann_ret, ann_vol = cum.iloc[-1], pr.std()*np.sqrt(n)
L1471             sharpe, drawdown = ann_ret/ann_vol, (cum - cum.cummax()).min()
L1472             if len(ticks)>=2:
L1473                 C_raw = ret[ticks].corr(); RAW_rho = C_raw.mask(np.eye(len(ticks), dtype=bool)).stack().mean()
L1474                 R = ret[ticks].dropna().to_numpy(); C_resid = Selector.residual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L1475                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L1476             else: RAW_rho = RESID_rho = np.nan
L1477             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L1478         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L1479         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L1480         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L1481         def _fmt_row(s):
L1482             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L1483         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L1484         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L1485         try:
L1486             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L1487             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L1488             all_scores = all_scores.dropna(subset=['G_plus_D'])
L1489             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L1490             print("Low Score Candidates (GSC+DSC bottom 10):")
L1491             print(self.low10_table.to_string())
L1492         except Exception as e:
L1493             print(f"[warn] low-score ranking failed: {e}")
L1494             self.low10_table = None
L1495         self.debug_text = ""
L1496         if debug_mode:
L1497             logger.info("debug_mode=True: df_z dump handled in scorer; skipping factor-side debug output")
L1498         else:
L1499             logger.debug(
L1500                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L1501                 debug_mode, True
L1502             )
L1503         self._debug_logged = True
L1504
L1505     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L1506     def notify_slack(self):
L1507         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L1508
L1509         if not SLACK_WEBHOOK_URL:
L1510             print("âš ï¸ SLACK_WEBHOOK_URL not set (main report skipped)")
L1511             return
L1512
L1513         def _filter_suffix_from(spec: dict, group: str) -> str:
L1514             g = spec.get(group, {})
L1515             parts = [str(m) for m in g.get("pre_mask", [])]
L1516             for k, v in (g.get("pre_filter", {}) or {}).items():
L1517                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L1518                 name = {"beta": "Î²"}.get(base, base)
L1519                 try:
L1520                     val = f"{float(v):g}"
L1521                 except Exception:
L1522                     val = str(v)
L1523                 parts.append(f"{name}{op}{val}")
L1524             return "" if not parts else " / filter:" + " & ".join(parts)
L1525
L1526         def _inject_filter_suffix(title: str, group: str) -> str:
L1527             suf = _filter_suffix_from(FILTER_SPEC, group)
L1528             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L1529
L1530         def _blk(title, tbl, fmt=None, drop=()):
L1531             if tbl is None or getattr(tbl, 'empty', False):
L1532                 return f"{title}\n(é¸å®šãªã—)\n"
L1533             if drop and hasattr(tbl, 'columns'):
L1534                 keep = [c for c in tbl.columns if c not in drop]
L1535                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L1536             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L1537
L1538         message = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L1539         miss_df, truncated, total = self._miss_disp_info or self._prepare_missing_display(self.miss_df)
L1540         lines = compact_missing_lines(miss_df, limit=300)
L1541         missing_txt = "Missing Data:\n```" + "\n".join(lines) + "```" if lines else ""
L1542         trunc_note = f"...çœç•¥ ({total}ä»¶ä¸­ ä¸Šä½20ä»¶ã®ã¿è¡¨ç¤º)" if truncated else ""
L1543         if missing_txt:
L1544             message += missing_txt + ("\n" + trunc_note if trunc_note else "") + "\n"
L1545         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L1546         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L1547         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L1548         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L1549
L1550         try:
L1551             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L1552             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L1553             if r is not None:
L1554                 r.raise_for_status()
L1555         except Exception as e:
L1556             print(f"[ERR] main_post_failed: {e}")
L1557
L1558 def _infer_g_universe(feature_df, selected12=None, near5=None):
L1559     try:
L1560         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L1561         if out: return out
L1562     except Exception:
L1563         pass
L1564     base = set()
L1565     for lst in (selected12 or []), (near5 or []):
L1566         for x in (lst or []): base.add(x)
L1567     return list(base) if base else list(feature_df.index)
L1568
L1569 def _fmt_with_fire_mark(tickers, feature_df):
L1570     out = []
L1571     for t in tickers or []:
L1572         try:
L1573             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L1574             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L1575             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L1576         except Exception:
L1577             out.append(t)
L1578     return out
L1579
L1580 def _label_recent_event(t, feature_df):
L1581     try:
L1582         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L1583         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L1584         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L1585         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L1586         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L1587     except Exception:
L1588         pass
L1589     return t
L1590
L1591 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L1592
L1593 def io_build_input_bundle() -> InputBundle:
L1594     """
L1595     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L1596     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L1597     """
L1598     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1599     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"], missing_logs=state["missing_logs"])
L1600
L1601 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1602               n_target: int) -> tuple[list, float, float, float]:
L1603     """
L1604     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L1605     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L1606     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L1607     """
L1608     sc.cfg = cfg
L1609
L1610     if hasattr(sc, "score_build_features"):
L1611         feat = sc.score_build_features(inb)
L1612         if not hasattr(sc, "_feat_logged"):
L1613             T.log("features built (scorer)")
L1614             sc._feat_logged = True
L1615         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1616     else:
L1617         fb = sc.aggregate_scores(inb, cfg)
L1618         if not hasattr(sc, "_feat_logged"):
L1619             T.log("features built (scorer)")
L1620             sc._feat_logged = True
L1621         sc._feat = fb
L1622         agg = fb.g_score if group == "G" else fb.d_score_all
L1623         if group == "D" and hasattr(fb, "df"):
L1624             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L1625
L1626     if hasattr(sc, "filter_candidates"):
L1627         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1628
L1629     if isinstance(agg, pd.Series):
L1630         agg = _as_numeric_series(agg)
L1631
L1632     selector = Selector()
L1633     if hasattr(sc, "select_diversified"):
L1634         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1635             selector=selector, prev_tickers=None,
L1636             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1637             cross_mu=cfg.drrs.cross_mu_gd)
L1638     else:
L1639         if group == "G":
L1640             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1
```