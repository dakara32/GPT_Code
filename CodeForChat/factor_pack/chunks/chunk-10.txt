```text
98             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L499
L500             # --- 長期移動平均/位置 ---
L501             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L502             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L503
L504             # --- 配当の詳細系 ---
L505             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L506             try:
L507                 divs = yf.Ticker(t).dividends.dropna()
L508                 if not divs.empty:
L509                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L510                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L511                     ann = divs.groupby(divs.index.year).sum()
L512                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L513                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L514                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L515                 so = d.get('sharesOutstanding',None)
L516                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L517                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L518             except Exception: pass
L519             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L520
L521             # --- 財務安定性 ---
L522             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L523
L524             # --- EPS 変動 ---
L525             EPS_VAR_8Q = np.nan
L526             try:
L527                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L528                 if qe is not None and not qe.empty and so:
L529                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L530                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L531             except Exception: pass
L532             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L533
L534             # --- サイズ/流動性 ---
L535             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L536             try:
L537                 if isinstance(volume_series_full, pd.Series):
L538                     vol_series = volume_series_full.reindex(s.index).dropna()
L539                     if len(vol_series) >= 5:
L540                         aligned_px = s.reindex(vol_series.index).dropna()
L541                         if len(aligned_px) == len(vol_series):
L542                             dv = (vol_series*aligned_px).rolling(60).mean()
L543                             if not dv.dropna().empty:
L544                                 adv60 = float(dv.dropna().iloc[-1])
L545             except Exception:
L546                 pass
L547             df.loc[t,'ADV60_USD'] = adv60
L548
L549             # --- Rule of 40 や周辺 ---
L550             total_rev_ttm = d.get('totalRevenue',np.nan)
L551             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L552             df.loc[t,'FCF_MGN'] = FCF_MGN
L553             rule40 = np.nan
L554             try:
L555                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L556             except Exception: pass
L557             df.loc[t,'RULE40'] = rule40
L558
L559             # --- トレンド補助 ---
L560             sma50  = s.rolling(50).mean()
L561             sma150 = s.rolling(150).mean()
L562             sma200 = s.rolling(200).mean()
L563             p = _safe_last(s)
L564
L565             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L566                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L567             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L568                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L569
L570             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L571             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L572
L573             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L574             if len(sma200.dropna()) >= 21:
L575                 cur200 = _safe_last(sma200)
L576                 old2001 = float(sma200.iloc[-21])
L577                 if old2001:
L578                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L579
L580             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L581             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L582             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L583             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L584             if len(sma200.dropna())>=105:
L585                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L586                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L587             # NEW: 200日線が連続で上向きの「日数」
L588             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L589             try:
L590                 s200 = sma200.dropna()
L591                 if len(s200) >= 2:
L592                     diff200 = s200.diff()
L593                     up = 0
L594                     for v in diff200.iloc[::-1]:
L595                         if pd.isna(v) or v <= 0:
L596                             break
L597                         up += 1
L598                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L599             except Exception:
L600                 pass
L601             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L602             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L603             if hi52 and hi52>0 and pd.notna(p):
L604                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L605             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L606             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L607
L608             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L609
L610             # --- 欠損メモ ---
L611             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L612             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L613             if need_finnhub:
L614                 fin_data = self.fetch_finnhub_metrics(t)
L615                 for col in need_finnhub:
L616                     val = fin_data.get(col)
L617                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L618             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L619                 if pd.isna(df.loc[t,col]):
L620                     if col=='DIV':
L621                         status = self.dividend_status(t)
L622                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L623                     else:
L624                         missing_logs.append({'Ticker':t,'Column':col})
L625
L626         def _pick_series(entry: dict, keys: list[str]):
L627             for k in keys:
L628                 val = entry.get(k) if isinstance(entry, dict) else None
L629                 if val is None:
L630                     continue
L631                 try:
L632                     if hasattr(val, "empty") and getattr(val, "empty"):
L633                         continue
L634                 except Exception:
L635                     pass
L636                 if isinstance(val, (list, tuple)) and len(val) == 0:
L637                     continue
L638                 return val
L639             return None
L640
L641         def _has_sec_series(val) -> bool:
L642             try:
L643                 if isinstance(val, pd.Series):
L644                     return not val.dropna().empty
L645                 if isinstance(val, (list, tuple)):
L646                     return any(pd.notna(v) for v in val)
L647                 return bool(val)
L648             except Exception:
L649                 return False
L650
L651         def _series_len(val) -> int:
L652             try:
L653                 if isinstance(val, pd.Series):
L654                     return int(val.dropna().size)
L655                 if isinstance(val, (list, tuple)):
L656                     return len(val)
L657                 return int(bool(val))
L658             except Exception:
L659                 return 0
L660
L661         for t in tickers:
L662             try:
L663                 d = info.get(t, {}) or {}
L664                 rev_series = d.get("SEC_REV_Q_SERIES")
L665                 eps_series = d.get("SEC_EPS_Q_SERIES")
L666                 fallback_qearn = False
L667                 try:
L668                     qe = tickers_bulk.tickers[t].quarterly_earnings
L669                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L670                 except Exception:
L671                     qe = None
L672
L673                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L674                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L675                 r_raw = _ensure_series(r_src)
L676                 e_raw = _ensure_series(e_src)
L677
L678                 r_q = _to_quarterly(r_raw)
L679                 e_q = _to_quarterly(e_raw)
L680
L681                 df.at[t, "EPS_SERIES"] = e_q
L682
L683                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L684                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L685
L686                 def _q_yoy(qs):
L687                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L688
L689                 rev_q_yoy = _q_yoy(r_q)
L690                 eps_q_yoy = _q_yoy(e_q)
L691
L692                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L693                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L694                         ann = qs.groupby(qs.index.year).last().pct_change()
L695                         ann_dn = ann.dropna()
L696                         if not ann_dn.empty:
L697                             y = float(ann_dn.iloc[-1])
L698                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L699                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L700                             return y, acc, var
L701                     yoy_dn = yoy_ttm.dropna()
L702                     if yoy_dn.empty:
L703                         return np.nan, np.nan, np.nan
L704                     return (
L705                         float(yoy_dn.iloc[-1]),
L706                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L707                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L708                     )
L709
L710                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L711                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L712
L713                 def _pos_streak(s: pd.Series):
L714                     s = s.dropna()
L715                     if s.empty:
L716                         return np.nan
L717                     b = (s > 0).astype(int).to_numpy()[::-1]
L718                     k = 0
L719                     for v in b:
L720                         if v == 1:
L721                             k += 1
L722        
```