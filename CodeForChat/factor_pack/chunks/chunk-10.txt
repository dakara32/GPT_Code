```text
            if need_finnhub:
L851                 fin_data = self.fetch_finnhub_metrics(t)
L852                 for col in need_finnhub:
L853                     val = fin_data.get(col)
L854                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L855             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L856                 if pd.isna(df.loc[t,col]):
L857                     if col=='DIV':
L858                         status = self.dividend_status(t)
L859                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L860                     else:
L861                         missing_logs.append({'Ticker':t,'Column':col})
L862
L863         def _pick_series(entry: dict, keys: list[str]):
L864             for k in keys:
L865                 val = entry.get(k) if isinstance(entry, dict) else None
L866                 if val is None:
L867                     continue
L868                 try:
L869                     if hasattr(val, "empty") and getattr(val, "empty"):
L870                         continue
L871                 except Exception:
L872                     pass
L873                 if isinstance(val, (list, tuple)) and len(val) == 0:
L874                     continue
L875                 return val
L876             return None
L877
L878         def _has_sec_series(val) -> bool:
L879             try:
L880                 if isinstance(val, pd.Series):
L881                     return not val.dropna().empty
L882                 if isinstance(val, (list, tuple)):
L883                     return any(pd.notna(v) for v in val)
L884                 return bool(val)
L885             except Exception:
L886                 return False
L887
L888         def _series_len(val) -> int:
L889             try:
L890                 if isinstance(val, pd.Series):
L891                     return int(val.dropna().size)
L892                 if isinstance(val, (list, tuple)):
L893                     return len(val)
L894                 return int(bool(val))
L895             except Exception:
L896                 return 0
L897
L898         cnt_rev_series = sum(1 for _t, d in info.items() if _has_sec_series(d.get("SEC_REV_Q_SERIES")))
L899         cnt_eps_series = sum(1 for _t, d in info.items() if _has_sec_series(d.get("SEC_EPS_Q_SERIES")))
L900         logger.info(
L901             "[DERIV] SEC series presence: REV_Q=%d, EPS_Q=%d (universe=%d)",
L902             cnt_rev_series,
L903             cnt_eps_series,
L904             len(info),
L905         )
L906
L907         rev_q_ge5 = 0
L908         ttm_yoy_avail = 0
L909         wrote_growth = 0
L910
L911         for t in tickers:
L912             try:
L913                 d = info.get(t, {}) or {}
L914                 rev_series = d.get("SEC_REV_Q_SERIES")
L915                 eps_series = d.get("SEC_EPS_Q_SERIES")
L916                 fallback_qearn = False
L917                 try:
L918                     qe = tickers_bulk.tickers[t].quarterly_earnings
L919                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L920                 except Exception:
L921                     qe = None
L922                 logger.debug(
L923                     "[DERIV] %s: rev_q_len=%s eps_q_len=%s fallback_qearn=%s",
L924                     t,
L925                     _series_len(rev_series),
L926                     _series_len(eps_series),
L927                     fallback_qearn,
L928                 )
L929
L930                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L931                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L932                 r_raw = _ensure_series(r_src)
L933                 e_raw = _ensure_series(e_src)
L934                 _log("DERIV_SRC", f"{t} rev_raw_len={r_raw.size} eps_raw_len={e_raw.size}")
L935
L936                 r_q = _to_quarterly(r_raw)
L937                 e_q = _to_quarterly(e_raw)
L938                 _log("DERIV_Q", f"{t} rev_q_len={r_q.size} eps_q_len={e_q.size}")
L939                 if r_q.size >= 5:
L940                     rev_q_ge5 += 1
L941
L942                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L943                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L944                 has_ttm = int(not r_yoy_ttm.dropna().empty)
L945                 ttm_yoy_avail += has_ttm
L946                 _log("DERIV_TTM", f"{t} rev_ttm_yoy_len={r_yoy_ttm.dropna().size} eps_ttm_yoy_len={e_yoy_ttm.dropna().size}")
L947
L948                 def _q_yoy(qs):
L949                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L950
L951                 rev_q_yoy = _q_yoy(r_q)
L952                 eps_q_yoy = _q_yoy(e_q)
L953
L954                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L955                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L956                         ann = qs.groupby(qs.index.year).last().pct_change()
L957                         ann_dn = ann.dropna()
L958                         if not ann_dn.empty:
L959                             y = float(ann_dn.iloc[-1])
L960                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L961                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L962                             return y, acc, var
L963                     yoy_dn = yoy_ttm.dropna()
L964                     if yoy_dn.empty:
L965                         return np.nan, np.nan, np.nan
L966                     return (
L967                         float(yoy_dn.iloc[-1]),
L968                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L969                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L970                     )
L971
L972                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L973                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L974
L975                 def _pos_streak(s: pd.Series):
L976                     s = s.dropna()
L977                     if s.empty:
L978                         return np.nan
L979                     b = (s > 0).astype(int).to_numpy()[::-1]
L980                     k = 0
L981                     for v in b:
L982                         if v == 1:
L983                             k += 1
L984                         else:
L985                             break
L986                     return float(k)
L987
L988                 rev_ann_streak = _pos_streak(r_yoy_ttm)
L989
L990                 df.loc[t, "REV_Q_YOY"] = rev_q_yoy
L991                 df.loc[t, "EPS_Q_YOY"] = eps_q_yoy
L992                 df.loc[t, "REV_YOY"] = rev_yoy
L993                 df.loc[t, "EPS_YOY"] = eps_yoy
L994                 df.loc[t, "REV_YOY_ACC"] = rev_acc
L995                 df.loc[t, "REV_YOY_VAR"] = rev_var
L996                 df.loc[t, "REV_ANN_STREAK"] = rev_ann_streak
L997
L998                 wrote_growth += 1
L999                 _log(
L1000                     "DERIV_WRITE",
L1001                     f"{t} wrote: Q_YOY(rev={rev_q_yoy}, eps={eps_q_yoy}) ANN(rev_yoy={rev_yoy}, acc={rev_acc}, var={rev_var}) streak={rev_ann_streak}",
L1002                 )
L1003
L1004             except Exception as e:
L1005                 logger.warning("[DERIV_WARN] %s growth-derivatives failed: %s", t, e)
L1006                 _log("DERIV_WARN", f"{t} {type(e).__name__}: {e}")
L1007
L1008         _log("DERIV_SUMMARY", f"rev_q_len>=5: {rev_q_ge5}/{len(tickers)}  ttm_yoy_available: {ttm_yoy_avail}  wrote_growth_for: {wrote_growth}")
L1009
L1010         try:
L1011             cols = [
L1012                 "REV_Q_YOY",
L1013                 "EPS_Q_YOY",
L1014                 "REV_YOY",
L1015                 "EPS_YOY",
L1016                 "REV_YOY_ACC",
L1017                 "REV_YOY_VAR",
L1018                 "REV_ANN_STREAK",
L1019             ]
L1020             cnt = {c: int(df[c].count()) for c in cols if c in df.columns}
L1021             _log("DERIV_NONNAN_COUNTS", str(cnt))
L1022         except Exception as e:
L1023             _log("DERIV_NONNAN_COUNTS", f"error: {e}")
L1024
L1025         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L1026             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L1027             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L1028             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L1029             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L1030             c5 = (row.get('TR_str', np.nan) > 0)
L1031             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L1032             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L1033             c8 = (row.get('RS', np.nan) >= 0.10)
L1034             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L1035
L1036         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L1037         assert 'trend_template' in df.columns
L1038
L1039         # === Z化と合成 ===
L1040         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L1041
L1042         df_z = pd.DataFrame(index=df.index)
L1043         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L1044         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L1045         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L1046
L1047         # === Growth深掘り系（欠損保持z + RAW併載） ===
L1048         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L1049         for col in grw_cols:
L1050             if col in df.columns:
L1051                 raw = pd.to_numeric(df[col], errors="coerce")
L1052                 df_z[col] = robust_z_keepnan(raw)
L1053                 df_z[f'{col}_RAW'] = raw
L1054         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L1055             if k in df.columns and k not in df_z.columns:
L1056                 raw = pd.to_numeric(df[k], errors="coerce")
L1057                 df_z[k] = robust_z_keepnan(raw)
L1058                 df_z[f'{k}_RAW'] = raw
L1059         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L1060
L1061         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L1062         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L1063         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L1064
L1065         # EPSが赤字でもFCFが黒字なら実質黒字とみなす
L1066         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L1067         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L1068
L1069         # ===== トレンドスロープ算出 =====
L1070         def zpos(x):
L1071             arr = robust_z(x)
L1072             idx = getattr(x, 'index', df_z.index)
L1073             return pd.Series(arr, index=idx).fillna(0.0)
L1074
L1075         def relu(x):
L1076             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L1077             return ser.clip(lower=0).fillna(0.0)
L1078
L1079         # 売上トレンドスロープ（四半期）
L1080         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L1081         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L1082         slope_rev_combo = slope_rev - 0.25*noise_rev
L1083         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L1084         df_z['TREND_SLOPE_REV'] =
```