```text
[-21])
L891                 if old2001:
L892                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L893
L894             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L895             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L896             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L897             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L898             if len(sma200.dropna())>=105:
L899                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L900                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L901             # NEW: 200日線が連続で上向きの「日数」
L902             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L903             try:
L904                 s200 = sma200.dropna()
L905                 if len(s200) >= 2:
L906                     diff200 = s200.diff()
L907                     up = 0
L908                     for v in diff200.iloc[::-1]:
L909                         if pd.isna(v) or v <= 0:
L910                             break
L911                         up += 1
L912                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L913             except Exception:
L914                 pass
L915             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L916             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L917             if hi52 and hi52>0 and pd.notna(p):
L918                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L919             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L920             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L921
L922             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L923
L924             # --- 欠損メモ ---
L925             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L926             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L927             if need_finnhub:
L928                 fin_data = self.fetch_finnhub_metrics(t)
L929                 for col in need_finnhub:
L930                     val = fin_data.get(col)
L931                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L932             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L933                 if pd.isna(df.loc[t,col]):
L934                     if col=='DIV':
L935                         status = self.dividend_status(t)
L936                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L937                     else:
L938                         missing_logs.append({'Ticker':t,'Column':col})
L939
L940         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L941             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L942             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L943             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L944             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L945             c5 = (row.get('TR_str', np.nan) > 0)
L946             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L947             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L948             c8 = (row.get('RS', np.nan) >= 0.10)
L949             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L950
L951         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L952         assert 'trend_template' in df.columns
L953
L954         # === Z化と合成 ===
L955         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L956
L957         df_z = pd.DataFrame(index=df.index)
L958         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L959         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L960         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L961
L962         # === Growth深掘り系（欠損保持z + RAW併載） ===
L963         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L964         for col in grw_cols:
L965             if col in df.columns:
L966                 raw = pd.to_numeric(df[col], errors="coerce")
L967                 df_z[col] = robust_z_keepnan(raw)
L968                 df_z[f'{col}_RAW'] = raw
L969         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L970             if k in df.columns and k not in df_z.columns:
L971                 raw = pd.to_numeric(df[k], errors="coerce")
L972                 df_z[k] = robust_z_keepnan(raw)
L973                 df_z[f'{k}_RAW'] = raw
L974         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L975
L976         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L977         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L978         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L979
L980         # EPSが赤字でもFCFが黒字なら実質黒字とみなす
L981         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L982         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L983
L984         # ===== トレンドスロープ算出 =====
L985         def zpos(x):
L986             arr = robust_z(x)
L987             idx = getattr(x, 'index', df_z.index)
L988             return pd.Series(arr, index=idx).fillna(0.0)
L989
L990         def relu(x):
L991             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L992             return ser.clip(lower=0).fillna(0.0)
L993
L994         # 売上トレンドスロープ（四半期）
L995         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L996         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L997         slope_rev_combo = slope_rev - 0.25*noise_rev
L998         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L999         df_z['TREND_SLOPE_REV'] = slope_rev_combo.clip(-3.0, 3.0)
L1000
L1001         # EPSトレンドスロープ（四半期）
L1002         slope_eps = 0.60*zpos(df_z['EPS_Q_YOY']) + 0.40*zpos(df_z['EPS_POS'])
L1003         df_z['TREND_SLOPE_EPS_RAW'] = slope_eps
L1004         df_z['TREND_SLOPE_EPS'] = slope_eps.clip(-3.0, 3.0)
L1005
L1006         # 年次トレンド（サブ）
L1007         slope_rev_yr = zpos(df_z['REV_YOY'])
L1008         slope_eps_yr = zpos(df_z.get('EPS_YOY', pd.Series(0.0, index=df.index)))
L1009         streak_base = df['REV_ANN_STREAK'].clip(lower=0).fillna(0)
L1010         streak_yr = streak_base / (streak_base.abs() + 1.0)
L1011         slope_rev_yr_combo = 0.7*slope_rev_yr + 0.3*streak_yr
L1012         df_z['TREND_SLOPE_REV_YR_RAW'] = slope_rev_yr_combo
L1013         df_z['TREND_SLOPE_REV_YR'] = slope_rev_yr_combo.clip(-3.0, 3.0)
L1014         df_z['TREND_SLOPE_EPS_YR_RAW'] = slope_eps_yr
L1015         df_z['TREND_SLOPE_EPS_YR'] = slope_eps_yr.clip(-3.0, 3.0)
L1016
L1017         # ===== GRW flexible score (variable data paths) =====
L1018         grw_raw = pd.to_numeric(df.get('GRW_FLEX_SCORE'), errors="coerce")
L1019         df_z['GRW_FLEX_SCORE_RAW'] = grw_raw
L1020         df_z['GROWTH_F_RAW'] = grw_raw
L1021         df_z['GROWTH_F'] = robust_z_keepnan(grw_raw).clip(-3.0, 3.0)
L1022         df_z['GRW_FLEX_WEIGHT'] = pd.to_numeric(df.get('GRW_FLEX_WEIGHT'), errors="coerce")
L1023         df_z['GRW_FLEX_CORE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_CORE'), errors="coerce")
L1024         df_z['GRW_FLEX_PRICE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_PRICE'), errors="coerce")
L1025
L1026         # Debug dump for GRW composition (console OFF by default; enable only with env)
L1027         if bool(os.getenv("GRW_CONSOLE_DEBUG")):
L1028             try:
L1029                 cols = ['GROWTH_F', 'GROWTH_F_RAW', 'GRW_FLEX_WEIGHT']
L1030                 use_cols = [c for c in cols if c in df_z.columns]
L1031                 i = df_z[use_cols].copy() if use_cols else pd.DataFrame(index=df_z.index)
L1032                 i.sort_values('GROWTH_F', ascending=False, inplace=True)
L1033                 limit = max(0, min(40, len(i)))
L1034                 print("[DEBUG: GRW]")
L1035                 for t in i.index[:limit]:
L1036                     row = i.loc[t]
L1037                     parts = []
L1038                     if pd.notna(row.get('GROWTH_F')):
L1039                         parts.append(f"GROWTH_F={row.get('GROWTH_F'):.3f}")
L1040                     raw_val = row.get('GROWTH_F_RAW')
L1041                     if pd.notna(raw_val):
L1042                         parts.append(f"GROWTH_F_RAW={raw_val:.3f}")
L1043                     weight_val = row.get('GRW_FLEX_WEIGHT')
L1044                     if pd.notna(weight_val):
L1045                         parts.append(f"w={weight_val:.2f}")
L1046                     path_val = None
L1047                     try:
L1048                         path_val = info.get(t, {}).get('DEBUG_GRW_PATH')
L1049                     except Exception:
L1050                         path_val = None
L1051                     if not path_val and 'DEBUG_GRW_PATH' in df.columns:
L1052                         path_val = df.at[t, 'DEBUG_GRW_PATH']
L1053                     if path_val:
L1054                         parts.append(f"PATH={path_val}")
L1055                     parts_json = None
L1056                     try:
L1057                         parts_json = info.get(t, {}).get('DEBUG_GRW_PARTS')
L1058                     except Exception:
L1059                         parts_json = None
L1060                     if not parts_json and 'DEBUG_GRW_PARTS' in df.columns:
L1061                         parts_json = df.at[t, 'DEBUG_GRW_PARTS']
L1062                     if parts_json:
L1063                         parts.append(f"PARTS={parts_json}")
L1064                     if not parts:
L1065                         parts.append('no-data')
L1066                     print(f"Ticker: {t} | " + " ".join(parts))
L1067                 print()
L1068             except Exception as exc:
L1069                 print(f"[ERR] GRW debug dump failed: {exc}")
L1070
L1071         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L1072             + 0.15*df_z['TR_str']
L1073             + 0.15*df_z['RS_SLOPE_6W']
L1074             + 0.15*df_z['RS_SLOPE_13W']
L1075             + 0.10*df_z['MA200_SLOPE_5M']
L1076             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L1077         df_z['VOL'] = robust_z(df['BETA'])
L1078         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L1079         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L1080
L1081         _dump_dfz(df_z=df_z, debug_mode=getattr(cfg, "debug_mode", False))
L1082
L1083         # === begin: BIO LOSS PENALTY =====================================
L1084         try:
L1085             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L1086         except Exception:
L1087             penalty_z = 0.8
L1088
L1089         def _is_bio_like(t: str) -> bool:
L1090             inf = info.get(t, {}) if isinstance(info, dict) else {}
L1091             sec = str(inf.get("sector", "")).lower()
L1092             ind = str(inf.get("industry", "")).lower()
L1093             if "health" not in sec:
L1094                 return False
L1095             keys = ("biotech", "biopharma", "pharma")
L1096           
```