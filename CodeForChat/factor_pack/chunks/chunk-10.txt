```text
dropna()) >= 21:
L791                 cur200 = _safe_last(sma200)
L792                 old2001 = float(sma200.iloc[-21])
L793                 if old2001:
L794                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L795
L796             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L797             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L798             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L799             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L800             if len(sma200.dropna())>=105:
L801                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L802                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L803             # NEW: 200日線が連続で上向きの「日数」
L804             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L805             try:
L806                 s200 = sma200.dropna()
L807                 if len(s200) >= 2:
L808                     diff200 = s200.diff()
L809                     up = 0
L810                     for v in diff200.iloc[::-1]:
L811                         if pd.isna(v) or v <= 0:
L812                             break
L813                         up += 1
L814                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L815             except Exception:
L816                 pass
L817             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L818             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L819             if hi52 and hi52>0 and pd.notna(p):
L820                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L821             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L822             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L823
L824             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L825
L826             # --- 欠損メモ ---
L827             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L828             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L829             if need_finnhub:
L830                 fin_data = self.fetch_finnhub_metrics(t)
L831                 for col in need_finnhub:
L832                     val = fin_data.get(col)
L833                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L834             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L835                 if pd.isna(df.loc[t,col]):
L836                     if col=='DIV':
L837                         status = self.dividend_status(t)
L838                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L839                     else:
L840                         missing_logs.append({'Ticker':t,'Column':col})
L841
L842         def _pick_series(entry: dict, keys: list[str]):
L843             for k in keys:
L844                 val = entry.get(k) if isinstance(entry, dict) else None
L845                 if val is None:
L846                     continue
L847                 try:
L848                     if hasattr(val, "empty") and getattr(val, "empty"):
L849                         continue
L850                 except Exception:
L851                     pass
L852                 if isinstance(val, (list, tuple)) and len(val) == 0:
L853                     continue
L854                 return val
L855             return None
L856
L857         def _has_sec_series(val) -> bool:
L858             try:
L859                 if isinstance(val, pd.Series):
L860                     return not val.dropna().empty
L861                 if isinstance(val, (list, tuple)):
L862                     return any(pd.notna(v) for v in val)
L863                 return bool(val)
L864             except Exception:
L865                 return False
L866
L867         def _series_len(val) -> int:
L868             try:
L869                 if isinstance(val, pd.Series):
L870                     return int(val.dropna().size)
L871                 if isinstance(val, (list, tuple)):
L872                     return len(val)
L873                 return int(bool(val))
L874             except Exception:
L875                 return 0
L876
L877         for t in tickers:
L878             try:
L879                 d = info.get(t, {}) or {}
L880                 rev_series = d.get("SEC_REV_Q_SERIES")
L881                 eps_series = d.get("SEC_EPS_Q_SERIES")
L882                 fallback_qearn = False
L883                 try:
L884                     qe = tickers_bulk.tickers[t].quarterly_earnings
L885                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L886                 except Exception:
L887                     qe = None
L888
L889                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L890                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L891                 r_raw = _ensure_series(r_src)
L892                 e_raw = _ensure_series(e_src)
L893
L894                 r_q = _to_quarterly(r_raw)
L895                 e_q = _to_quarterly(e_raw)
L896
L897                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L898                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L899
L900                 def _q_yoy(qs):
L901                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L902
L903                 rev_q_yoy = _q_yoy(r_q)
L904                 eps_q_yoy = _q_yoy(e_q)
L905
L906                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L907                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L908                         ann = qs.groupby(qs.index.year).last().pct_change()
L909                         ann_dn = ann.dropna()
L910                         if not ann_dn.empty:
L911                             y = float(ann_dn.iloc[-1])
L912                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L913                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L914                             return y, acc, var
L915                     yoy_dn = yoy_ttm.dropna()
L916                     if yoy_dn.empty:
L917                         return np.nan, np.nan, np.nan
L918                     return (
L919                         float(yoy_dn.iloc[-1]),
L920                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L921                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L922                     )
L923
L924                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L925                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L926
L927                 def _pos_streak(s: pd.Series):
L928                     s = s.dropna()
L929                     if s.empty:
L930                         return np.nan
L931                     b = (s > 0).astype(int).to_numpy()[::-1]
L932                     k = 0
L933                     for v in b:
L934                         if v == 1:
L935                             k += 1
L936                         else:
L937                             break
L938                     return float(k)
L939
L940                 rev_ann_streak = _pos_streak(r_yoy_ttm)
L941
L942                 df.loc[t, "REV_Q_YOY"] = rev_q_yoy
L943                 df.loc[t, "EPS_Q_YOY"] = eps_q_yoy
L944                 df.loc[t, "REV_YOY"] = rev_yoy
L945                 df.loc[t, "EPS_YOY"] = eps_yoy
L946                 df.loc[t, "REV_YOY_ACC"] = rev_acc
L947                 df.loc[t, "REV_YOY_VAR"] = rev_var
L948                 df.loc[t, "REV_ANN_STREAK"] = rev_ann_streak
L949
L950             except Exception as e:
L951                 logger.warning("growth-derivatives failed: %s: %s", t, e)
L952
L953         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L954             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L955             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L956             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L957             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L958             c5 = (row.get('TR_str', np.nan) > 0)
L959             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L960             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L961             c8 = (row.get('RS', np.nan) >= 0.10)
L962             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L963
L964         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L965         assert 'trend_template' in df.columns
L966
L967         # === Z化と合成 ===
L968         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L969
L970         df_z = pd.DataFrame(index=df.index)
L971         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L972         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L973         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L974
L975         # === Growth深掘り系（欠損保持z + RAW併載） ===
L976         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L977         for col in grw_cols:
L978             if col in df.columns:
L979                 raw = pd.to_numeric(df[col], errors="coerce")
L980                 df_z[col] = robust_z_keepnan(raw)
L981                 df_z[f'{col}_RAW'] = raw
L982         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L983             if k in df.columns and k not in df_z.columns:
L984                 raw = pd.to_numeric(df[k], errors="coerce")
L985                 df_z[k] = robust_z_keepnan(raw)
L986                 df_z[f'{k}_RAW'] = raw
L987         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L988
L989         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L990         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L991         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L992
L993         # EPSが赤字でもFCFが黒字なら実質黒字とみなす
L994         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L995         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L996
L997         # ===== トレンドスロープ算出 =====
L998         def zpos(x):
L999             arr = robust_z(x)
L1000             idx = getattr(x, 'index', df_z.index)
L1001             return pd.Series(arr, index=idx).fillna(0.0)
L1002
L1003         def relu(x):
L1004             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L1005             return ser.clip(lower=0).fillna(0.0)
L1006
L1007         # 売上トレンドスロープ（四半期）
L1008         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L1009         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L1010         slope_rev_combo = slope_rev - 0.25*noise_rev
L1011         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L1012         df_z['TREND_SLOPE_REV'] = slope_rev_combo.clip(-3.0, 3.0)
L1013
L1014         # EPSトレンドスロープ（四半期）
L1015         slope_eps = 0.60*zpos(df_z['EPS_Q_YOY']) + 0.40*zpos(df_z['EPS_POS'])
L
```