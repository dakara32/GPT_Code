```text
[r6<0]
L904                 if len(neg)>=10: DOWNSIDE_DEV = float(neg.std(ddof=0)*np.sqrt(252))
L905             df.loc[t,'DOWNSIDE_DEV'] = DOWNSIDE_DEV
L906
L907             MDD_1Y = np.nan
L908             try:
L909                 w = s.iloc[-min(len(s),252):].dropna()
L910                 if len(w)>=30:
L911                     roll_max = w.cummax(); MDD_1Y = float((w/roll_max - 1.0).min())
L912             except Exception: pass
L913             df.loc[t,'MDD_1Y'] = MDD_1Y
L914
L915             RESID_VOL = np.nan
L916             if n>=120:
L917                 rr, rrm = r.iloc[-n:].align(rm.iloc[-n:], join='inner')
L918                 if len(rr)==len(rrm) and len(rr)>=120 and rrm.var()>0:
L919                     beta = float(np.cov(rr, rrm)[0,1]/np.var(rrm)); resid = rr - beta*rrm
L920                     RESID_VOL = float(resid.std(ddof=0)*np.sqrt(252))
L921             df.loc[t,'RESID_VOL'] = RESID_VOL
L922
L923             DOWN_OUTPERF = np.nan
L924             if n>=60:
L925                 m, x = rm.iloc[-n:], r.iloc[-n:]; mask = m<0
L926                 if mask.sum()>=10:
L927                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L928                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L929             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L930
L931             # --- 長期移動平均/位置 ---
L932             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L933             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L934
L935             # --- 配当の詳細系 ---
L936             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L937             try:
L938                 divs = yf.Ticker(t).dividends.dropna()
L939                 if not divs.empty:
L940                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L941                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L942                     ann = divs.groupby(divs.index.year).sum()
L943                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L944                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L945                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L946                 so = d.get('sharesOutstanding',None)
L947                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L948                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L949             except Exception: pass
L950             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L951
L952             # --- 財務安定性 ---
L953             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L954
L955             # --- EPS 変動 ---
L956             EPS_VAR_8Q = np.nan
L957             try:
L958                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L959                 if qe is not None and not qe.empty and so:
L960                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L961                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L962             except Exception: pass
L963             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L964
L965             # --- サイズ/流動性 ---
L966             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L967             try:
L968                 if isinstance(volume_series_full, pd.Series):
L969                     vol_series = volume_series_full.reindex(s.index).dropna()
L970                     if len(vol_series) >= 5:
L971                         aligned_px = s.reindex(vol_series.index).dropna()
L972                         if len(aligned_px) == len(vol_series):
L973                             dv = (vol_series*aligned_px).rolling(60).mean()
L974                             if not dv.dropna().empty:
L975                                 adv60 = float(dv.dropna().iloc[-1])
L976             except Exception:
L977                 pass
L978             df.loc[t,'ADV60_USD'] = adv60
L979
L980             # --- Rule of 40 や周辺 ---
L981             total_rev_ttm = d.get('totalRevenue',np.nan)
L982             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L983             df.loc[t,'FCF_MGN'] = FCF_MGN
L984             rule40 = np.nan
L985             try:
L986                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L987             except Exception: pass
L988             df.loc[t,'RULE40'] = rule40
L989
L990             # --- トレンド補助 ---
L991             sma50  = s.rolling(50).mean()
L992             sma150 = s.rolling(150).mean()
L993             sma200 = s.rolling(200).mean()
L994             p = _safe_last(s)
L995
L996             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L997                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L998             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L999                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L1000
L1001             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L1002             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L1003
L1004             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L1005             if len(sma200.dropna()) >= 21:
L1006                 cur200 = _safe_last(sma200)
L1007                 old2001 = float(sma200.iloc[-21])
L1008                 if old2001:
L1009                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L1010
L1011             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L1012             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L1013             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L1014             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L1015             if len(sma200.dropna())>=105:
L1016                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L1017                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L1018             # NEW: 200日線が連続で上向きの「日数」
L1019             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L1020             try:
L1021                 s200 = sma200.dropna()
L1022                 if len(s200) >= 2:
L1023                     diff200 = s200.diff()
L1024                     up = 0
L1025                     for v in diff200.iloc[::-1]:
L1026                         if pd.isna(v) or v <= 0:
L1027                             break
L1028                         up += 1
L1029                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L1030             except Exception:
L1031                 pass
L1032             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L1033             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L1034             if hi52 and hi52>0 and pd.notna(p):
L1035                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L1036             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L1037             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L1038
L1039             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L1040
L1041             # --- 欠損メモ ---
L1042             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L1043             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L1044             if need_finnhub:
L1045                 fin_data = self.fetch_finnhub_metrics(t)
L1046                 for col in need_finnhub:
L1047                     val = fin_data.get(col)
L1048                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L1049             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L1050                 if pd.isna(df.loc[t,col]):
L1051                     if col=='DIV':
L1052                         status = self.dividend_status(t)
L1053                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L1054                     else:
L1055                         missing_logs.append({'Ticker':t,'Column':col})
L1056
L1057         def _pick_series(entry: dict, keys: list[str]):
L1058             for k in keys:
L1059                 val = entry.get(k) if isinstance(entry, dict) else None
L1060                 if val is None:
L1061                     continue
L1062                 try:
L1063                     if hasattr(val, "empty") and getattr(val, "empty"):
L1064                         continue
L1065                 except Exception:
L1066                     pass
L1067                 if isinstance(val, (list, tuple)) and len(val) == 0:
L1068                     continue
L1069                 return val
L1070             return None
L1071
L1072         def _has_sec_series(val) -> bool:
L1073             try:
L1074                 if isinstance(val, pd.Series):
L1075                     return not val.dropna().empty
L1076                 if isinstance(val, (list, tuple)):
L1077                     return any(pd.notna(v) for v in val)
L1078                 return bool(val)
L1079             except Exception:
L1080                 return False
L1081
L1082         def _series_len(val) -> int:
L1083             try:
L1084                 if isinstance(val, pd.Series):
L1085                     return int(val.dropna().size)
L1086                 if isinstance(val, (list, tuple)):
L1087                     return len(val)
L1088                 return int(bool(val))
L1089             except Exception:
L1090                 return 0
L1091
L1092         cnt_rev_series = sum(1 for _t, d in info.items() if _has_sec_series(d.get("SEC_REV_Q_SERIES")))
L1093         cnt_eps_series = sum(1 for _t, d in info.items() if _has_sec_series(d.get("SEC_EPS_Q_SERIES")))
L1094         logger.info(
L1095             "[DERIV] SEC series presence: REV_Q=%d, EPS_Q=%d (universe=%d)",
L1096             cnt_rev_series,
L1097             cnt_eps_series,
L1098             len(info),
L1099         )
L1100
L1101         rev_q_ge5 = 0
L1102         ttm_yoy_avail = 0
L1103         wrote_growth = 0
L1104
L1105         for t in tickers:
L1106             try:
L1107                 d = info.get(t, {}) or {}
L1108                 rev_series = d.get("SEC_REV_Q_SERIES")
L1109                 eps_series = d.get("SEC_EPS_Q_SERIES")
L1110                 fallback_qearn = False
L1111                 try:
L1112                     qe = tickers_bulk.tickers[t].quarterly_earnings
L1113                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L1114                 except Exception:
L1115                     qe = None
L1116                 logger.debug(
L1117                     "[DERIV] %s: rev_q_len=%s eps_q_len=%s fallback_qearn=%s",
L1118                     t,
L1119                     _series_len(rev_series),
L1120                     _series_len(eps_series),
L1121                     fallback_qearn,
L1122                 )
L1123
L1124                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L1125                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L1126                 r_raw = _ensure_series(r_src)
L1127  
```