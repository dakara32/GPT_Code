```text
     if old2001:
L889                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L890
L891             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L892             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L893             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L894             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L895             if len(sma200.dropna())>=105:
L896                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L897                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L898             # NEW: 200日線が連続で上向きの「日数」
L899             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L900             try:
L901                 s200 = sma200.dropna()
L902                 if len(s200) >= 2:
L903                     diff200 = s200.diff()
L904                     up = 0
L905                     for v in diff200.iloc[::-1]:
L906                         if pd.isna(v) or v <= 0:
L907                             break
L908                         up += 1
L909                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L910             except Exception:
L911                 pass
L912             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L913             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L914             if hi52 and hi52>0 and pd.notna(p):
L915                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L916             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L917             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L918
L919             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L920
L921             # --- 欠損メモ ---
L922             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L923             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L924             if need_finnhub:
L925                 fin_data = self.fetch_finnhub_metrics(t)
L926                 for col in need_finnhub:
L927                     val = fin_data.get(col)
L928                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L929             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L930                 if pd.isna(df.loc[t,col]):
L931                     if col=='DIV':
L932                         status = self.dividend_status(t)
L933                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L934                     else:
L935                         missing_logs.append({'Ticker':t,'Column':col})
L936
L937         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L938             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L939             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L940             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L941             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L942             c5 = (row.get('TR_str', np.nan) > 0)
L943             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L944             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L945             c8 = (row.get('RS', np.nan) >= 0.10)
L946             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L947
L948         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L949         assert 'trend_template' in df.columns
L950
L951         # === Z化と合成 ===
L952         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L953
L954         df_z = pd.DataFrame(index=df.index)
L955         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L956         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L957         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L958
L959         # === Growth深掘り系（欠損保持z + RAW併載） ===
L960         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L961         for col in grw_cols:
L962             if col in df.columns:
L963                 raw = pd.to_numeric(df[col], errors="coerce")
L964                 df_z[col] = robust_z_keepnan(raw)
L965                 df_z[f'{col}_RAW'] = raw
L966         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L967             if k in df.columns and k not in df_z.columns:
L968                 raw = pd.to_numeric(df[k], errors="coerce")
L969                 df_z[k] = robust_z_keepnan(raw)
L970                 df_z[f'{k}_RAW'] = raw
L971         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L972
L973         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L974         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L975         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L976
L977         # EPSが赤字でもFCFが黒字なら実質黒字とみなす
L978         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L979         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L980
L981         # ===== トレンドスロープ算出 =====
L982         def zpos(x):
L983             arr = robust_z(x)
L984             idx = getattr(x, 'index', df_z.index)
L985             return pd.Series(arr, index=idx).fillna(0.0)
L986
L987         def relu(x):
L988             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L989             return ser.clip(lower=0).fillna(0.0)
L990
L991         # 売上トレンドスロープ（四半期）
L992         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L993         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L994         slope_rev_combo = slope_rev - 0.25*noise_rev
L995         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L996         df_z['TREND_SLOPE_REV'] = slope_rev_combo.clip(-3.0, 3.0)
L997
L998         # EPSトレンドスロープ（四半期）
L999         slope_eps = 0.60*zpos(df_z['EPS_Q_YOY']) + 0.40*zpos(df_z['EPS_POS'])
L1000         df_z['TREND_SLOPE_EPS_RAW'] = slope_eps
L1001         df_z['TREND_SLOPE_EPS'] = slope_eps.clip(-3.0, 3.0)
L1002
L1003         # 年次トレンド（サブ）
L1004         slope_rev_yr = zpos(df_z['REV_YOY'])
L1005         slope_eps_yr = zpos(df_z.get('EPS_YOY', pd.Series(0.0, index=df.index)))
L1006         streak_base = df['REV_ANN_STREAK'].clip(lower=0).fillna(0)
L1007         streak_yr = streak_base / (streak_base.abs() + 1.0)
L1008         slope_rev_yr_combo = 0.7*slope_rev_yr + 0.3*streak_yr
L1009         df_z['TREND_SLOPE_REV_YR_RAW'] = slope_rev_yr_combo
L1010         df_z['TREND_SLOPE_REV_YR'] = slope_rev_yr_combo.clip(-3.0, 3.0)
L1011         df_z['TREND_SLOPE_EPS_YR_RAW'] = slope_eps_yr
L1012         df_z['TREND_SLOPE_EPS_YR'] = slope_eps_yr.clip(-3.0, 3.0)
L1013
L1014         # ===== GRW flexible score (variable data paths) =====
L1015         grw_raw = pd.to_numeric(df.get('GRW_FLEX_SCORE'), errors="coerce")
L1016         df_z['GRW_FLEX_SCORE_RAW'] = grw_raw
L1017         df_z['GROWTH_F_RAW'] = grw_raw
L1018         df_z['GROWTH_F'] = robust_z_keepnan(grw_raw).clip(-3.0, 3.0)
L1019         df_z['GRW_FLEX_WEIGHT'] = pd.to_numeric(df.get('GRW_FLEX_WEIGHT'), errors="coerce")
L1020         df_z['GRW_FLEX_CORE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_CORE'), errors="coerce")
L1021         df_z['GRW_FLEX_PRICE_RAW'] = pd.to_numeric(df.get('GRW_FLEX_PRICE'), errors="coerce")
L1022
L1023         # Debug dump for GRW composition (console OFF by default; enable only with env)
L1024         if bool(os.getenv("GRW_CONSOLE_DEBUG")):
L1025             try:
L1026                 cols = ['GROWTH_F', 'GROWTH_F_RAW', 'GRW_FLEX_WEIGHT']
L1027                 use_cols = [c for c in cols if c in df_z.columns]
L1028                 i = df_z[use_cols].copy() if use_cols else pd.DataFrame(index=df_z.index)
L1029                 i.sort_values('GROWTH_F', ascending=False, inplace=True)
L1030                 limit = max(0, min(40, len(i)))
L1031                 print("[DEBUG: GRW]")
L1032                 for t in i.index[:limit]:
L1033                     row = i.loc[t]
L1034                     parts = []
L1035                     if pd.notna(row.get('GROWTH_F')):
L1036                         parts.append(f"GROWTH_F={row.get('GROWTH_F'):.3f}")
L1037                     raw_val = row.get('GROWTH_F_RAW')
L1038                     if pd.notna(raw_val):
L1039                         parts.append(f"GROWTH_F_RAW={raw_val:.3f}")
L1040                     weight_val = row.get('GRW_FLEX_WEIGHT')
L1041                     if pd.notna(weight_val):
L1042                         parts.append(f"w={weight_val:.2f}")
L1043                     path_val = None
L1044                     try:
L1045                         path_val = info.get(t, {}).get('DEBUG_GRW_PATH')
L1046                     except Exception:
L1047                         path_val = None
L1048                     if not path_val and 'DEBUG_GRW_PATH' in df.columns:
L1049                         path_val = df.at[t, 'DEBUG_GRW_PATH']
L1050                     if path_val:
L1051                         parts.append(f"PATH={path_val}")
L1052                     parts_json = None
L1053                     try:
L1054                         parts_json = info.get(t, {}).get('DEBUG_GRW_PARTS')
L1055                     except Exception:
L1056                         parts_json = None
L1057                     if not parts_json and 'DEBUG_GRW_PARTS' in df.columns:
L1058                         parts_json = df.at[t, 'DEBUG_GRW_PARTS']
L1059                     if parts_json:
L1060                         parts.append(f"PARTS={parts_json}")
L1061                     if not parts:
L1062                         parts.append('no-data')
L1063                     print(f"Ticker: {t} | " + " ".join(parts))
L1064                 print()
L1065             except Exception as exc:
L1066                 print(f"[ERR] GRW debug dump failed: {exc}")
L1067
L1068         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L1069             + 0.15*df_z['TR_str']
L1070             + 0.15*df_z['RS_SLOPE_6W']
L1071             + 0.15*df_z['RS_SLOPE_13W']
L1072             + 0.10*df_z['MA200_SLOPE_5M']
L1073             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L1074         df_z['VOL'] = robust_z(df['BETA'])
L1075         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L1076         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L1077
L1078         _dump_dfz(df_z=df_z, debug_mode=getattr(cfg, "debug_mode", False))
L1079
L1080         # === begin: BIO LOSS PENALTY =====================================
L1081         try:
L1082             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L1083         except Exception:
L1084             penalty_z = 0.8
L1085
L1086         def _is_bio_like(t: str) -> bool:
L1087             inf = info.get(t, {}) if isinstance(info, dict) else {}
L1088             sec = str(inf.get("sector", "")).lower()
L1089             ind = str(inf.get("industry", "")).lower()
L1090             if "health" not in sec:
L1091                 return False
L1092             keys = ("biotech", "biopharma", "pharma")
L1093             return any(k in ind for 
```