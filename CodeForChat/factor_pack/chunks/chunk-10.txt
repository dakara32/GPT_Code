```text
k.sum()>=10:
L497                     mr, sr = float(m[mask].mean()), float(x[mask].mean())
L498                     DOWN_OUTPERF = (sr - mr)/abs(mr) if mr!=0 else np.nan
L499             df.loc[t,'DOWN_OUTPERF'] = DOWN_OUTPERF
L500
L501             # --- 長期移動平均/位置 ---
L502             sma200 = s.rolling(200).mean(); df.loc[t,'EXT_200'] = np.nan
L503             if pd.notna(sma200.iloc[-1]) and sma200.iloc[-1]!=0: df.loc[t,'EXT_200'] = abs(float(s.iloc[-1]/sma200.iloc[-1]-1.0))
L504
L505             # --- 配当の詳細系 ---
L506             DIV_TTM_PS=DIV_VAR5=DIV_YOY=DIV_FCF_COVER=np.nan
L507             try:
L508                 divs = yf.Ticker(t).dividends.dropna()
L509                 if not divs.empty:
L510                     last_close = s.iloc[-1]; div_1y = float(divs[divs.index >= (divs.index.max()-pd.Timedelta(days=365))].sum())
L511                     DIV_TTM_PS = div_1y if div_1y>0 else np.nan
L512                     ann = divs.groupby(divs.index.year).sum()
L513                     if len(ann)>=2 and ann.iloc[-2]!=0: DIV_YOY = float(ann.iloc[-1]/ann.iloc[-2]-1.0)
L514                     tail = ann.iloc[-5:] if len(ann)>=5 else ann
L515                     if len(tail)>=3 and tail.mean()!=0: DIV_VAR5 = float(tail.std(ddof=1)/abs(tail.mean()))
L516                 so = d.get('sharesOutstanding',None)
L517                 if so and pd.notna(DIV_TTM_PS) and pd.notna(fcf_val) and fcf_val!=0:
L518                     DIV_FCF_COVER = float((fcf_val)/(DIV_TTM_PS*float(so)))
L519             except Exception: pass
L520             df.loc[t,'DIV_TTM_PS'], df.loc[t,'DIV_VAR5'], df.loc[t,'DIV_YOY'], df.loc[t,'DIV_FCF_COVER'] = DIV_TTM_PS, DIV_VAR5, DIV_YOY, DIV_FCF_COVER
L521
L522             # --- 財務安定性 ---
L523             df.loc[t,'DEBT2EQ'], df.loc[t,'CURR_RATIO'] = d.get('debtToEquity',np.nan), d.get('currentRatio',np.nan)
L524
L525             # --- EPS 変動 ---
L526             EPS_VAR_8Q = np.nan
L527             try:
L528                 qe, so = tickers_bulk.tickers[t].quarterly_earnings, d.get('sharesOutstanding',None)
L529                 if qe is not None and not qe.empty and so:
L530                     eps_q = (qe['Earnings'].dropna().astype(float)/float(so)).replace([np.inf,-np.inf],np.nan)
L531                     if len(eps_q)>=4: EPS_VAR_8Q = float(eps_q.iloc[-min(8,len(eps_q)):].std(ddof=1))
L532             except Exception: pass
L533             df.loc[t,'EPS_VAR_8Q'] = EPS_VAR_8Q
L534
L535             # --- サイズ/流動性 ---
L536             df.loc[t,'MARKET_CAP'] = d.get('marketCap',np.nan); adv60 = np.nan
L537             try:
L538                 if isinstance(volume_series_full, pd.Series):
L539                     vol_series = volume_series_full.reindex(s.index).dropna()
L540                     if len(vol_series) >= 5:
L541                         aligned_px = s.reindex(vol_series.index).dropna()
L542                         if len(aligned_px) == len(vol_series):
L543                             dv = (vol_series*aligned_px).rolling(60).mean()
L544                             if not dv.dropna().empty:
L545                                 adv60 = float(dv.dropna().iloc[-1])
L546             except Exception:
L547                 pass
L548             df.loc[t,'ADV60_USD'] = adv60
L549
L550             # --- Rule of 40 や周辺 ---
L551             total_rev_ttm = d.get('totalRevenue',np.nan)
L552             FCF_MGN = _safe_div(fcf_val, total_rev_ttm)
L553             df.loc[t,'FCF_MGN'] = FCF_MGN
L554             rule40 = np.nan
L555             try:
L556                 r = df.loc[t,'REV']; rule40 = (r if pd.notna(r) else np.nan) + (FCF_MGN if pd.notna(FCF_MGN) else np.nan)
L557             except Exception: pass
L558             df.loc[t,'RULE40'] = rule40
L559
L560             # --- トレンド補助 ---
L561             sma50  = s.rolling(50).mean()
L562             sma150 = s.rolling(150).mean()
L563             sma200 = s.rolling(200).mean()
L564             p = _safe_last(s)
L565
L566             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L567                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L568             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L569                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L570
L571             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L572             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L573
L574             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L575             if len(sma200.dropna()) >= 21:
L576                 cur200 = _safe_last(sma200)
L577                 old2001 = float(sma200.iloc[-21])
L578                 if old2001:
L579                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L580
L581             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L582             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L583             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L584             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L585             if len(sma200.dropna())>=105:
L586                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L587                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L588             # NEW: 200日線が連続で上向きの「日数」
L589             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L590             try:
L591                 s200 = sma200.dropna()
L592                 if len(s200) >= 2:
L593                     diff200 = s200.diff()
L594                     up = 0
L595                     for v in diff200.iloc[::-1]:
L596                         if pd.isna(v) or v <= 0:
L597                             break
L598                         up += 1
L599                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L600             except Exception:
L601                 pass
L602             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L603             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L604             if hi52 and hi52>0 and pd.notna(p):
L605                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L606             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L607             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L608
L609             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L610
L611             # --- 欠損メモ ---
L612             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L613             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L614             if need_finnhub:
L615                 fin_data = self.fetch_finnhub_metrics(t)
L616                 for col in need_finnhub:
L617                     val = fin_data.get(col)
L618                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L619             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L620                 if pd.isna(df.loc[t,col]):
L621                     if col=='DIV':
L622                         status = self.dividend_status(t)
L623                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L624                     else:
L625                         missing_logs.append({'Ticker':t,'Column':col})
L626
L627         def _pick_series(entry: dict, keys: list[str]):
L628             for k in keys:
L629                 val = entry.get(k) if isinstance(entry, dict) else None
L630                 if val is None:
L631                     continue
L632                 try:
L633                     if hasattr(val, "empty") and getattr(val, "empty"):
L634                         continue
L635                 except Exception:
L636                     pass
L637                 if isinstance(val, (list, tuple)) and len(val) == 0:
L638                     continue
L639                 return val
L640             return None
L641
L642         def _has_sec_series(val) -> bool:
L643             try:
L644                 if isinstance(val, pd.Series):
L645                     return not val.dropna().empty
L646                 if isinstance(val, (list, tuple)):
L647                     return any(pd.notna(v) for v in val)
L648                 return bool(val)
L649             except Exception:
L650                 return False
L651
L652         def _series_len(val) -> int:
L653             try:
L654                 if isinstance(val, pd.Series):
L655                     return int(val.dropna().size)
L656                 if isinstance(val, (list, tuple)):
L657                     return len(val)
L658                 return int(bool(val))
L659             except Exception:
L660                 return 0
L661
L662         for t in tickers:
L663             try:
L664                 d = info.get(t, {}) or {}
L665                 rev_series = d.get("SEC_REV_Q_SERIES")
L666                 eps_series = d.get("SEC_EPS_Q_SERIES")
L667                 fallback_qearn = False
L668                 try:
L669                     qe = tickers_bulk.tickers[t].quarterly_earnings
L670                     fallback_qearn = bool(qe is not None and not getattr(qe, "empty", True))
L671                 except Exception:
L672                     qe = None
L673
L674                 r_src = _pick_series(d, ["SEC_REV_Q_SERIES", "rev_q_series_pairs", "rev_q_series"])
L675                 e_src = _pick_series(d, ["SEC_EPS_Q_SERIES", "eps_q_series_pairs", "eps_q_series"])
L676                 r_raw = _ensure_series(r_src)
L677                 e_raw = _ensure_series(e_src)
L678
L679                 r_q = _to_quarterly(r_raw)
L680                 e_q = _to_quarterly(e_raw)
L681
L682                 df.at[t, "EPS_SERIES"] = e_q
L683
L684                 r_yoy_ttm = _ttm_yoy_from_quarterly(r_q)
L685                 e_yoy_ttm = _ttm_yoy_from_quarterly(e_q)
L686
L687                 def _q_yoy(qs):
L688                     return np.nan if qs is None or len(qs) < 5 else float(qs.iloc[-1] / qs.iloc[-5] - 1.0)
L689
L690                 rev_q_yoy = _q_yoy(r_q)
L691                 eps_q_yoy = _q_yoy(e_q)
L692
L693                 def _annual_from(qs: pd.Series, yoy_ttm: pd.Series):
L694                     if isinstance(qs.index, pd.DatetimeIndex) and len(qs) >= 8:
L695                         ann = qs.groupby(qs.index.year).last().pct_change()
L696                         ann_dn = ann.dropna()
L697                         if not ann_dn.empty:
L698                             y = float(ann_dn.iloc[-1])
L699                             acc = float(ann_dn.tail(3).mean()) if ann_dn.size >= 3 else np.nan
L700                             var = float(ann_dn.tail(4).var()) if ann_dn.size >= 4 else np.nan
L701                             return y, acc, var
L702                     yoy_dn = yoy_ttm.dropna()
L703                     if yoy_dn.empty:
L704                         return np.nan, np.nan, np.nan
L705                     return (
L706                         float(yoy_dn.iloc[-1]),
L707                         float(yoy_dn.tail(3).mean() if yoy_dn.size >= 3 else np.nan),
L708                         float(yoy_dn.tail(4).var() if yoy_dn.size >= 4 else np.nan),
L709                     )
L710
L711                 rev_yoy, rev_acc, rev_var = _annual_from(r_q, r_yoy_ttm)
L712                 eps_yoy, _, _ = _annual_from(e_q, e_yoy_ttm)
L713
L714                 def _pos_streak(s: pd.Series):
L715                     s = s.dropna()
L716                     if s.empty:
L717                         return np.nan
L718                     b = (s > 0).astype(int).to_n
```