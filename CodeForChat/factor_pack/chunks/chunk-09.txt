```text
         df.loc[t,'RULE40'] = rule40
L576
L577             # --- トレンド補助 ---
L578             sma50  = s.rolling(50).mean()
L579             sma150 = s.rolling(150).mean()
L580             sma200 = s.rolling(200).mean()
L581             p = _safe_last(s)
L582
L583             df.loc[t,'MA50_OVER_150'] = (_safe_last(sma50)/_safe_last(sma150) - 1
L584                 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan)
L585             df.loc[t,'MA150_OVER_200'] = (_safe_last(sma150)/_safe_last(sma200) - 1
L586                 if pd.notna(_safe_last(sma150)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan)
L587
L588             lo52 = s[-252:].min() if len(s)>=252 else s.min()
L589             df.loc[t,'P_OVER_LOW52'] = (p/lo52 - 1) if (lo52 and lo52>0 and pd.notna(p)) else np.nan
L590
L591             df.loc[t,'MA200_SLOPE_1M'] = np.nan
L592             if len(sma200.dropna()) >= 21:
L593                 cur200 = _safe_last(sma200)
L594                 old2001 = float(sma200.iloc[-21])
L595                 if old2001:
L596                     df.loc[t,'MA200_SLOPE_1M'] = cur200/old2001 - 1
L597
L598             df.loc[t,'P_OVER_150'] = p/_safe_last(sma150)-1 if pd.notna(_safe_last(sma150)) and _safe_last(sma150)!=0 else np.nan
L599             df.loc[t,'P_OVER_200'] = p/_safe_last(sma200)-1 if pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L600             df.loc[t,'MA50_OVER_200'] = _safe_last(sma50)/_safe_last(sma200)-1 if pd.notna(_safe_last(sma50)) and pd.notna(_safe_last(sma200)) and _safe_last(sma200)!=0 else np.nan
L601             df.loc[t,'MA200_SLOPE_5M'] = np.nan
L602             if len(sma200.dropna())>=105:
L603                 cur200, old200 = _safe_last(sma200), float(sma200.iloc[-105])
L604                 if old200 and old200!=0: df.loc[t,'MA200_SLOPE_5M'] = cur200/old200 - 1
L605             # NEW: 200日線が連続で上向きの「日数」
L606             df.loc[t,'MA200_UP_STREAK_D'] = np.nan
L607             try:
L608                 s200 = sma200.dropna()
L609                 if len(s200) >= 2:
L610                     diff200 = s200.diff()
L611                     up = 0
L612                     for v in diff200.iloc[::-1]:
L613                         if pd.isna(v) or v <= 0:
L614                             break
L615                         up += 1
L616                     df.loc[t,'MA200_UP_STREAK_D'] = float(up)
L617             except Exception:
L618                 pass
L619             df.loc[t,'LOW52PCT25_EXCESS'] = np.nan if (lo52 is None or lo52<=0 or pd.isna(p)) else (p/(lo52*1.25)-1)
L620             hi52 = s[-252:].max() if len(s)>=252 else s.max(); df.loc[t,'NEAR_52W_HIGH'] = np.nan
L621             if hi52 and hi52>0 and pd.notna(p):
L622                 d_hi = (p/hi52)-1.0; df.loc[t,'NEAR_52W_HIGH'] = -abs(min(0.0, d_hi))
L623             df.loc[t,'RS_SLOPE_6W'] = self.rs_line_slope(s, ib.spx, 30)
L624             df.loc[t,'RS_SLOPE_13W'] = self.rs_line_slope(s, ib.spx, 65)
L625
L626             df.loc[t,'DIV_STREAK'] = self.div_streak(t)
L627
L628             # --- 欠損メモ ---
L629             fin_cols = ['REV','ROE','BETA','DIV','FCF']
L630             need_finnhub = [col for col in fin_cols if pd.isna(df.loc[t,col])]
L631             if need_finnhub:
L632                 fin_data = self.fetch_finnhub_metrics(t)
L633                 for col in need_finnhub:
L634                     val = fin_data.get(col)
L635                     if val is not None and not pd.isna(val): df.loc[t,col] = val
L636             for col in fin_cols + ['EPS','RS','TR_str','DIV_STREAK']:
L637                 if pd.isna(df.loc[t,col]):
L638                     if col=='DIV':
L639                         status = self.dividend_status(t)
L640                         if status!='none_confident': missing_logs.append({'Ticker':t,'Column':col,'Status':status})
L641                     else:
L642                         missing_logs.append({'Ticker':t,'Column':col})
L643
L644         def _trend_template_pass(row, rs_alpha_thresh=0.10):
L645             c1 = (row.get('P_OVER_150', np.nan) > 0) and (row.get('P_OVER_200', np.nan) > 0)
L646             c2 = (row.get('MA150_OVER_200', np.nan) > 0)
L647             c3 = (row.get('MA200_SLOPE_1M', np.nan) > 0)
L648             c4 = (row.get('MA50_OVER_150', np.nan) > 0) and (row.get('MA50_OVER_200', np.nan) > 0)
L649             c5 = (row.get('TR_str', np.nan) > 0)
L650             c6 = (row.get('P_OVER_LOW52', np.nan) >= 0.30)
L651             c7 = (row.get('NEAR_52W_HIGH', np.nan) >= -0.25)
L652             c8 = (row.get('RS', np.nan) >= 0.10)
L653             return bool(c1 and c2 and c3 and c4 and c5 and c6 and c7 and c8)
L654
L655         if 'trend_template' not in df.columns: df['trend_template'] = df.apply(_trend_template_pass, axis=1).fillna(False)
L656         assert 'trend_template' in df.columns
L657
L658         # === Z化と合成 ===
L659         for col in ['ROE','FCF','REV','EPS']: df[f'{col}_W'] = winsorize_s(df[col], 0.02)
L660
L661         df_z = pd.DataFrame(index=df.index)
L662         for col in ['EPS','REV','ROE','FCF','RS','TR_str','BETA','DIV','DIV_STREAK']: df_z[col] = robust_z(df[col])
L663         df_z['REV'], df_z['EPS'], df_z['TR'] = robust_z(df['REV_W']), robust_z(df['EPS_W']), robust_z(df['TR'])
L664         for col in ['P_OVER_150','P_OVER_200','MA50_OVER_200','MA200_SLOPE_5M','LOW52PCT25_EXCESS','NEAR_52W_HIGH','RS_SLOPE_6W','RS_SLOPE_13W','MA200_UP_STREAK_D']: df_z[col] = robust_z(df[col])
L665
L666         # === Growth深掘り系（欠損保持z + RAW併載） ===
L667         grw_cols = ['REV_Q_YOY','EPS_Q_YOY','REV_YOY','EPS_YOY','REV_YOY_ACC','REV_YOY_VAR','FCF_MGN','RULE40','REV_ANN_STREAK']
L668         for col in grw_cols:
L669             if col in df.columns:
L670                 raw = pd.to_numeric(df[col], errors="coerce")
L671                 df_z[col] = robust_z_keepnan(raw)
L672                 df_z[f'{col}_RAW'] = raw
L673         for k in ("TREND_SLOPE_EPS", "TREND_SLOPE_REV"):
L674             if k in df.columns and k not in df_z.columns:
L675                 raw = pd.to_numeric(df[k], errors="coerce")
L676                 df_z[k] = robust_z_keepnan(raw)
L677                 df_z[f'{k}_RAW'] = raw
L678         for col in ['DOWNSIDE_DEV','MDD_1Y','RESID_VOL','DOWN_OUTPERF','EXT_200','DIV_TTM_PS','DIV_VAR5','DIV_YOY','DIV_FCF_COVER','DEBT2EQ','CURR_RATIO','EPS_VAR_8Q','MARKET_CAP','ADV60_USD']: df_z[col] = robust_z(df[col])
L679
L680         df_z['SIZE'], df_z['LIQ'] = robust_z(np.log1p(df['MARKET_CAP'])), robust_z(np.log1p(df['ADV60_USD']))
L681         df_z['QUALITY_F'] = robust_z(0.6*df['FCF_W'] + 0.4*df['ROE_W']).clip(-3.0,3.0)
L682         df_z['YIELD_F']   = 0.3*df_z['DIV'] + 0.7*df_z['DIV_STREAK']
L683
L684         # EPSが赤字でもFCFが黒字なら実質黒字とみなす
L685         eps_pos_mask = (df['EPS'] > 0) | (df['FCF_MGN'] > 0)
L686         df_z['EPS_POS'] = df_z['EPS'].where(eps_pos_mask, 0.0)
L687
L688         # ===== トレンドスロープ算出 =====
L689         def zpos(x):
L690             arr = robust_z(x)
L691             idx = getattr(x, 'index', df_z.index)
L692             return pd.Series(arr, index=idx).fillna(0.0)
L693
L694         def relu(x):
L695             ser = x if isinstance(x, pd.Series) else pd.Series(x, index=df_z.index)
L696             return ser.clip(lower=0).fillna(0.0)
L697
L698         # 売上トレンドスロープ（四半期）
L699         slope_rev = 0.70*zpos(df_z['REV_Q_YOY']) + 0.30*zpos(df_z['REV_YOY_ACC'])
L700         noise_rev = relu(robust_z(df_z['REV_YOY_VAR']) - 0.8)
L701         slope_rev_combo = slope_rev - 0.25*noise_rev
L702         df_z['TREND_SLOPE_REV_RAW'] = slope_rev_combo
L703         df_z['TREND_SLOPE_REV'] = slope_rev_combo.clip(-3.0, 3.0)
L704
L705         # EPSトレンドスロープ（四半期）
L706         slope_eps = 0.60*zpos(df_z['EPS_Q_YOY']) + 0.40*zpos(df_z['EPS_POS'])
L707         df_z['TREND_SLOPE_EPS_RAW'] = slope_eps
L708         df_z['TREND_SLOPE_EPS'] = slope_eps.clip(-3.0, 3.0)
L709
L710         # 年次トレンド（サブ）
L711         slope_rev_yr = zpos(df_z['REV_YOY'])
L712         slope_eps_yr = zpos(df_z.get('EPS_YOY', pd.Series(0.0, index=df.index)))
L713         streak_base = df['REV_ANN_STREAK'].clip(lower=0).fillna(0)
L714         streak_yr = streak_base / (streak_base.abs() + 1.0)
L715         slope_rev_yr_combo = 0.7*slope_rev_yr + 0.3*streak_yr
L716         df_z['TREND_SLOPE_REV_YR_RAW'] = slope_rev_yr_combo
L717         df_z['TREND_SLOPE_REV_YR'] = slope_rev_yr_combo.clip(-3.0, 3.0)
L718         df_z['TREND_SLOPE_EPS_YR_RAW'] = slope_eps_yr
L719         df_z['TREND_SLOPE_EPS_YR'] = slope_eps_yr.clip(-3.0, 3.0)
L720
L721         # ===== 新GRW合成式（SEPA寄りシフト） =====
L722         _nz = lambda name: df_z.get(name, pd.Series(0.0, index=df_z.index)).fillna(0.0)
L723         grw_combo = (
L724               0.20*_nz('REV_Q_YOY')
L725             + 0.10*_nz('REV_YOY_ACC')
L726             + 0.10*_nz('REV_ANN_STREAK')
L727             - 0.05*_nz('REV_YOY_VAR')
L728             + 0.10*_nz('TREND_SLOPE_REV')
L729             + 0.15*_nz('EPS_Q_YOY')
L730             + 0.05*_nz('EPS_POS')
L731             + 0.20*_nz('TREND_SLOPE_EPS')
L732             + 0.05*_nz('TREND_SLOPE_REV_YR')
L733             + 0.03*_nz('TREND_SLOPE_EPS_YR')
L734             + 0.10*_nz('FCF_MGN')
L735             + 0.05*_nz('RULE40')
L736         )
L737         df_z['GROWTH_F_RAW'] = grw_combo
L738         df_z['GROWTH_F'] = robust_z(grw_combo).clip(-3.0, 3.0)
L739
L740         # Debug dump for GRW composition (console OFF by default; enable only with env)
L741         if bool(os.getenv("GRW_CONSOLE_DEBUG")):
L742             try:
L743                 i = df_z[['GROWTH_F', 'GROWTH_F_RAW']].copy()
L744                 i.sort_values('GROWTH_F', ascending=False, inplace=True)
L745                 limit = max(0, min(40, len(i)))
L746                 print("[DEBUG: GRW]")
L747                 for t in i.index[:limit]:
L748                     row = i.loc[t]
L749                     parts = [f"GROWTH_F={row['GROWTH_F']:.3f}"]
L750                     if pd.notna(row.get('GROWTH_F_RAW')):
L751                         parts.append(f"GROWTH_F_RAW={row['GROWTH_F_RAW']:.3f}")
L752                     print(f"Ticker: {t} | " + " ".join(parts))
L753                 print()
L754             except Exception as exc:
L755                 print(f"[ERR] GRW debug dump failed: {exc}")
L756
L757         df_z['MOM_F'] = robust_z(0.40*df_z['RS']
L758             + 0.15*df_z['TR_str']
L759             + 0.15*df_z['RS_SLOPE_6W']
L760             + 0.15*df_z['RS_SLOPE_13W']
L761             + 0.10*df_z['MA200_SLOPE_5M']
L762             + 0.10*df_z['MA200_UP_STREAK_D']).clip(-3.0,3.0)
L763         df_z['VOL'] = robust_z(df['BETA'])
L764         df_z['QAL'], df_z['YLD'], df_z['MOM'] = df_z['QUALITY_F'], df_z['YIELD_F'], df_z['MOM_F']
L765         df_z.drop(columns=['QUALITY_F','YIELD_F','MOM_F'], inplace=True, errors='ignore')
L766
L767         _dump_dfz(df_z=df_z, debug_mode=getattr(cfg, "debug_mode", False))
L768
L769         # === begin: BIO LOSS PENALTY =====================================
L770         try:
L771             penalty_z = float(os.getenv("BIO_LOSS_PENALTY_Z", "0.8"))
L772         except Exception:
L773             penalty_z = 0.8
L774
L775         def _is_bio_like(t: str) -> bool:
L776             inf = info.get(t, {}) if isinstance(info, dict) else {}
L777             sec = str(inf.get("sector", "")).lower()
L778             ind = str(inf.get("industry", "")).lower()
L779             if "health" not in sec:
L780                 return False
L781             keys = ("biotech", "biopharma", "pharma")
L782             return any(k in ind for k in keys)
L783
L784         tickers_s = pd.Index(df_z.index)
L785         is_bio = pd.Series({t: _is_bio_like(t) for t in tickers_s})
L786         is_loss = pd.Series({t: (pd.notna(df.loc[t,"EPS"]) and df.loc[t,"EPS"] <= 0) for t in tickers_s})
L787         mask_bio_loss = (is_bio & is_loss).reindex(df_z.index).fillna(False)
L788
L789         if bool(mask_bi
```