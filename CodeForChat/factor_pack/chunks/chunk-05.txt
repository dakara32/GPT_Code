```text

L843     try:
L844         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L845         if out: return out
L846     except Exception:
L847         pass
L848     base = set()
L849     for lst in (selected12 or []), (near5 or []):
L850         for x in (lst or []): base.add(x)
L851     return list(base) if base else list(feature_df.index)
L852
L853 def _fmt_with_fire_mark(tickers, feature_df):
L854     out = []
L855     for t in tickers or []:
L856         try:
L857             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L858             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L859             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L860         except Exception:
L861             out.append(t)
L862     return out
L863
L864 def _label_recent_event(t, feature_df):
L865     try:
L866         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L867         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L868         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L869         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L870         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L871     except Exception:
L872         pass
L873     return t
L874
L875 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L876
L877 def io_build_input_bundle() -> InputBundle:
L878     """
L879     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L880     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L881     """
L882     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L883     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L884
L885 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L886               n_target: int) -> tuple[list, float, float, float]:
L887     """
L888     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L889     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L890     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L891     """
L892     sc.cfg = cfg
L893
L894     if hasattr(sc, "score_build_features"):
L895         feat = sc.score_build_features(inb)
L896         if not hasattr(sc, "_feat_logged"):
L897             T.log("features built (scorer)")
L898             sc._feat_logged = True
L899         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L900     else:
L901         fb = sc.aggregate_scores(inb, cfg)
L902         if not hasattr(sc, "_feat_logged"):
L903             T.log("features built (scorer)")
L904             sc._feat_logged = True
L905         sc._feat = fb
L906         agg = fb.g_score if group == "G" else fb.d_score_all
L907         if group == "D" and hasattr(fb, "df"):
L908             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L909
L910     if hasattr(sc, "filter_candidates"):
L911         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L912
L913     selector = Selector()
L914     if hasattr(sc, "select_diversified"):
L915         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L916             selector=selector, prev_tickers=None,
L917             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L918             cross_mu=cfg.drrs.cross_mu_gd)
L919     else:
L920         if group == "G":
L921             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L922             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L923                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L924                 lam=cfg.drrs.G.get("lam", 0.68),
L925                 lookback=cfg.drrs.G.get("lookback", 252),
L926                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L927         else:
L928             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L929             g_fixed = getattr(sc, "_top_G", None)
L930             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L931                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L932                 lam=cfg.drrs.D.get("lam", 0.85),
L933                 lookback=cfg.drrs.D.get("lookback", 504),
L934                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L935                 mu=cfg.drrs.cross_mu_gd)
L936         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L937         sum_sc = res["sum_score"]; obj = res["objective"]
L938         if group == "D":
L939             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L940             T.log("selection finalized (G/D)")
L941     try:
L942         inc = [t for t in exist if t in agg.index]
L943         pick = _sticky_keep_current(
L944             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L945             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L946         )
L947     except Exception as _e:
L948         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L949     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L950     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L951     try:
L952         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L953         near10 = list(pool.sort_values(ascending=False).head(10).index)
L954         setattr(sc, f"_near_{group}", near10)
L955         setattr(sc, f"_agg_{group}", agg)
L956     except Exception:
L957         pass
L958
L959     if group == "D":
L960         T.log("save done")
L961     if group == "G":
L962         sc._top_G = pick
L963     return pick, avg_r, sum_sc, obj
L964
L965 def run_pipeline() -> SelectionBundle:
L966     """
L967     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L968     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L969     """
L970     inb = io_build_input_bundle()
L971     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L972         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L973                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L974         price_max=CAND_PRICE_MAX)
L975     sc = Scorer()
L976     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L977     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L978     alpha = Scorer.spx_to_alpha(inb.spx)
L979     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L980     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L981     sc._top_G = top_G
L982     try:
L983         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L984         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L985     except Exception:
L986         pass
L987     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L988     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L989     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L990     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L991     fb = getattr(sc, "_feat", None)
L992     near_G = getattr(sc, "_near_G", [])
L993     selected12 = list(top_G)
L994     df = fb.df if fb is not None else pd.DataFrame()
L995     guni = _infer_g_universe(df, selected12, near_G)
L996     try:
L997         fire_recent = [t for t in guni
L998                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L999                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1000     except Exception: fire_recent = []
L1001
L1002     lines = [
L1003         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1004         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1005         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1006         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1007
L1008     if fire_recent:
L1009         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1010         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1011     else:
L1012         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1013
L1014     try:
L1015         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1016         if webhook:
L1017             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1018     except Exception:
L1019         pass
L1020
L1021     out = Output()
L1022     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1023     try: out._sc = sc
L1024     except Exception: pass
L1025     if hasattr(sc, "_feat"):
L1026         try:
L1027             fb = sc._feat
L1028             out.miss_df = fb.missing_logs
L1029             out.display_results(
L1030                 exist=exist,
L1031                 bench=bench,
L1032                 df_z=fb.df_z,
L1033                 g_score=fb.g_score,
L1034                 d_score_all=fb.d_score_all,
L1035                 init_G=top_G,
L1036                 init_D=top_D,
L1037                 top_G=top_G,
L1038                 top_D=top_D,
L1039                 df_full_z=getattr(fb, "df_full_z", None),
L1040                 prev_G=getattr(sc, "_prev_G", exist),
L1041                 prev_D=getattr(sc, "_prev_D", exist),
L1042             )
L1043         except Exception:
L1044             pass
L1045     out.notify_slack()
L1046     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1047               "sum_score": sumG, "objective": objG},
L1048         resD={"tickers": top_D, "avg_res_corr": avgD,
L1049               "sum_score": sumD, "objective": objD},
L1050         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1051
L1052     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1053     try:
L1054         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1055               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1056               .sort_values("G_plus_D")
L1057               .head(10)
L1058               .round(3))
L1059         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1060         _post_slack({"text": f"```{low_msg}```"})
L1061     except Exception as _e:
L1062         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1063
L1064     return sb
L1065
L1066 if __name__ == "__main__":
L1067     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # ==
```