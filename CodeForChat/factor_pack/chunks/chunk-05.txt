```text
cted12, near_G)
L846     try:
L847         fire_recent = [t for t in guni
L848                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L849                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L850     except Exception: fire_recent = []
L851
L852     lines = [
L853         "【G枠レポート｜週次モニタ（直近5営業日）】",
L854         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L855         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L856         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L857
L858     if fire_recent:
L859         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L860         lines.append(f"過去5営業日の検知: {fire_list}")
L861     else:
L862         lines.append("過去5営業日の検知: なし")
L863
L864     try:
L865         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L866         if webhook:
L867             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L868     except Exception:
L869         pass
L870
L871     out = Output()
L872     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L873     try: out._sc = sc
L874     except Exception: pass
L875     if hasattr(sc, "_feat"):
L876         try:
L877             fb = sc._feat
L878             out.miss_df = fb.missing_logs
L879             out.display_results(
L880                 exist=exist,
L881                 bench=bench,
L882                 df_z=fb.df_z,
L883                 g_score=fb.g_score,
L884                 d_score_all=fb.d_score_all,
L885                 init_G=top_G,
L886                 init_D=top_D,
L887                 top_G=top_G,
L888                 top_D=top_D,
L889                 df_full_z=getattr(fb, "df_full_z", None),
L890                 prev_G=getattr(sc, "_prev_G", exist),
L891                 prev_D=getattr(sc, "_prev_D", exist),
L892             )
L893         except Exception:
L894             pass
L895     out.notify_slack()
L896     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L897               "sum_score": sumG, "objective": objG},
L898         resD={"tickers": top_D, "avg_res_corr": avgD,
L899               "sum_score": sumD, "objective": objD},
L900         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L901
L902     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L903     try:
L904         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L905               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L906               .sort_values("G_plus_D")
L907               .head(10)
L908               .round(3))
L909         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L910         _post_slack({"text": f"```{low_msg}```"})
L911     except Exception as _e:
L912         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L913
L914     return sb
L915
L916 if __name__ == "__main__":
L917     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1.4826 * mad + 1e-9)
L82     if np.nanstd(z) < 1e-9:
L83         r = v.rank(method="average", na_option="keep")
L84         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L85     return pd.Series(z, index=v.index, dtype=float)
L86
L87
L88 def _fetch_revenue_quarterly_via_finnhub(symbol: str):
L89     """Fetch quarterly revenue via Finnhub when yfinance data is unavailable.
L90
L91     Returns a pandas.Series indexed by "YYYYQn" (ascending) or ``None`` when
L92     an API token is missing, data is not found, or any error occurs. No
L93     exception is propagated to keep behaviour identical without a token.
L94     """
L95     api_key = os.getenv("FINNHUB_API_KEY", "").strip()
L96     if not api_key:
L97         return None
L98     try:
L99         url = "https://finnhub.io/api/v1/stock/financials-reported"
L100         params = {"symbol": symbol, "token": api_key}
L101         r = requests.get(url, params=params, timeout=10)
L102         r.raise_for_status()
L103         payload = r.json() or {}
L104         rows = []
L105         for item in payload.get("data", []) or []:
L106             rep = (item or {}).get("report", {})
L107             ic = rep.get("ic", {}) if isinstance(rep, dict) else {}
L108             rev_val = None
L109             if isinstance(ic, dict):
L110                 revenue_node = ic.get("revenue")
L111                 if isinstance(revenue_node, dict):
L112                     rev_val = revenue_node.get("value")
L113                 if rev_val is None:
L114                     total_node = ic.get("totalRevenue")
L115                     if isinstance(total_node, dict):
L116                         rev_val = total_node.get("value")
L117             if rev_val is None:
L118                 continue
L119             year = item.get("year")
L120             quarter = item.get("quarter")
L121             if year is None or quarter is None:
L122                 continue
L123             try:
L124                 rows.append((int(year), int(quarter), float(rev_val)))
L125             except Exception:
L126                 continue
L127         if not rows:
L128             return None
L129         rows.sort(key=lambda x: (x[0], x[1]))
L130         idx = [f"{y}Q{q}" for y, q, _ in rows]
L131         vals = [v for _, _, v in rows]
L132         return pd.Series(vals, index=idx, name="Revenue")
L133     except Exception:
L134         return None
L135
L136
L137 def _dump_dfz(df_z: pd.DataFrame, debug_mode: bool, max_rows: int = 400, ndigits: int = 3) -> None:
L138     """df_z を System log(INFO) へダンプする簡潔なユーティリティ."""
L139     if not debug_mode:
L140         return
L141     try:
L142         view = df_z.copy()
L143         view = view.apply(
L144             lambda s: s.round(ndigits)
L145             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L146             else s
L147         )
L148         if len(view) > max_rows:
L149             view = view.iloc[:max_rows]
L150
L151         # === NaNサマリ（列ごとの欠損件数 上位20） ===
L152         try:
L153             nan_counts = df_z.isna().sum().sort_values(ascending=False)
L154             top_nan = nan_counts[nan_counts > 0].head(20)
L155             if len(top_nan) > 0:
L156                 logger.info("NaN columns (top20):\n%s", top_nan.to_string())
L157             else:
L158                 logger.info("NaN columns: none")
L159         except Exception as exc:
L160             logger.warning("nan summary failed: %s", exc)
L161
L162         # === Zeroサマリ（列ごとのゼロ比率 上位20） ===
L163         try:
L164             zero_counts = ((df_z == 0) & (~df_z.isna())).sum()
L165             nonnull_counts = (~df_z.isna()).sum()
L166             zero_ratio = (zero_counts / nonnull_counts).sort_values(ascending=False)
L167             top_zero = zero_ratio[zero_ratio > 0].head(20)
L168             if len(top_zero) > 0:
L169                 logger.info(
L170                     "Zero-dominated columns (top20):\n%s",
L171                     top_zero.to_string(float_format=lambda x: f"{x:.2%}"),
L172                 )
L173             else:
L174                 logger.info("Zero-dominated columns: none")
L175         except Exception as exc:
L176             logger.warning("zero summary failed: %s", exc)
L177
L178         logger.info("===== DF_Z DUMP START =====")
L179         logger.info("\n%s", view.to_string(max_rows=None, max_cols=None))
L180         logger.info("===== DF_Z DUMP END =====")
L181     except Exception as exc:
L182         logger.warning("df_z dump failed: %s", exc)
L183
L184 def _safe_div(a, b):
L185     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L186     except Exception: return np.nan
L187
L188 def _safe_last(series: pd.Series, default=np.nan):
L189     try: return float(series.iloc[-1])
L190     except Exception: return default
L191
L192 D_WEIGHTS_EFF = None  # 出力表示互換のため
L193
L194 # ---- Scorer 本体 -------------------------------------------------------------
L195 class Scorer:
L196     """
L197     - factor.py からは `aggregate_scores(ib, cfg)` を呼ぶだけでOK。
L198     - cfg は必須（factor.PipelineConfig を渡す）。
L199     - 旧カラム名を自動リネームして新スキーマに吸収します。
L200     """
L201
L202     # === 先頭で旧→新カラム名マップ（移行用） ===
L203     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L204     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L205
L206     # === スキーマ簡易チェック（最低限） ===
L207     @staticmethod
L208     def _validate_ib_for_scorer(ib: Any):
L2
```