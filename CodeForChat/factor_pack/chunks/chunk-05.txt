```text
feat_logged = True
L858         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L859     else:
L860         fb = sc.aggregate_scores(inb, cfg)
L861         if not hasattr(sc, "_feat_logged"):
L862             T.log("features built (scorer)")
L863             sc._feat_logged = True
L864         sc._feat = fb
L865         agg = fb.g_score if group == "G" else fb.d_score_all
L866         if group == "D" and hasattr(fb, "df"):
L867             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L868
L869     if hasattr(sc, "filter_candidates"):
L870         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L871
L872     selector = Selector()
L873     if hasattr(sc, "select_diversified"):
L874         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L875             selector=selector, prev_tickers=None,
L876             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L877             cross_mu=cfg.drrs.cross_mu_gd)
L878     else:
L879         if group == "G":
L880             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L881             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L882                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L883                 lam=cfg.drrs.G.get("lam", 0.68),
L884                 lookback=cfg.drrs.G.get("lookback", 252),
L885                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L886         else:
L887             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L888             g_fixed = getattr(sc, "_top_G", None)
L889             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L890                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L891                 lam=cfg.drrs.D.get("lam", 0.85),
L892                 lookback=cfg.drrs.D.get("lookback", 504),
L893                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L894                 mu=cfg.drrs.cross_mu_gd)
L895         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L896         sum_sc = res["sum_score"]; obj = res["objective"]
L897         if group == "D":
L898             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L899             T.log("selection finalized (G/D)")
L900     try:
L901         inc = [t for t in exist if t in agg.index]
L902         pick = _sticky_keep_current(
L903             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L904             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L905         )
L906     except Exception as _e:
L907         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L908     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L909     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L910     try:
L911         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L912         near10 = list(pool.sort_values(ascending=False).head(10).index)
L913         setattr(sc, f"_near_{group}", near10)
L914         setattr(sc, f"_agg_{group}", agg)
L915     except Exception:
L916         pass
L917
L918     if group == "D":
L919         T.log("save done")
L920     if group == "G":
L921         sc._top_G = pick
L922     return pick, avg_r, sum_sc, obj
L923
L924 def run_pipeline() -> SelectionBundle:
L925     """
L926     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L927     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L928     """
L929     inb = io_build_input_bundle()
L930     cfg = PipelineConfig(
L931         weights=WeightsConfig(g=g_weights, d=D_weights),
L932         drrs=DRRSParams(
L933             corrM=corrM, shrink=DRRS_SHRINK,
L934             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L935         ),
L936         price_max=CAND_PRICE_MAX,
L937         debug_mode=debug_mode
L938     )
L939     sc = Scorer()
L940     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L941     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L942     alpha = Scorer.spx_to_alpha(inb.spx)
L943     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L944     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L945     sc._top_G = top_G
L946     try:
L947         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L948         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L949     except Exception:
L950         pass
L951     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L952     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L953     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L954     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L955     fb = getattr(sc, "_feat", None)
L956     near_G = getattr(sc, "_near_G", [])
L957     selected12 = list(top_G)
L958     df = fb.df if fb is not None else pd.DataFrame()
L959     guni = _infer_g_universe(df, selected12, near_G)
L960     try:
L961         fire_recent = [t for t in guni
L962                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L963                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L964     except Exception: fire_recent = []
L965
L966     lines = [
L967         "【G枠レポート｜週次モニタ（直近5営業日）】",
L968         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L969         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L970         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L971
L972     if fire_recent:
L973         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L974         lines.append(f"過去5営業日の検知: {fire_list}")
L975     else:
L976         lines.append("過去5営業日の検知: なし")
L977
L978     try:
L979         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L980         if webhook:
L981             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L982     except Exception:
L983         pass
L984
L985     out = Output()
L986     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L987     try: out._sc = sc
L988     except Exception: pass
L989     if hasattr(sc, "_feat"):
L990         try:
L991             fb = sc._feat
L992             out.miss_df = fb.missing_logs
L993             out.display_results(
L994                 exist=exist,
L995                 bench=bench,
L996                 df_z=fb.df_z,
L997                 g_score=fb.g_score,
L998                 d_score_all=fb.d_score_all,
L999                 init_G=top_G,
L1000                 init_D=top_D,
L1001                 top_G=top_G,
L1002                 top_D=top_D,
L1003                 df_full_z=getattr(fb, "df_full_z", None),
L1004                 prev_G=getattr(sc, "_prev_G", exist),
L1005                 prev_D=getattr(sc, "_prev_D", exist),
L1006             )
L1007         except Exception:
L1008             pass
L1009     out.notify_slack()
L1010     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1011               "sum_score": sumG, "objective": objG},
L1012         resD={"tickers": top_D, "avg_res_corr": avgD,
L1013               "sum_score": sumD, "objective": objD},
L1014         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1015
L1016     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1017     try:
L1018         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1019               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1020               .sort_values("G_plus_D")
L1021               .head(10)
L1022               .round(3))
L1023         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1024         _post_slack({"text": f"```{low_msg}```"})
L1025     except Exception as _e:
L1026         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1027
L1028     return sb
L1029
L1030 if __name__ == "__main__":
L1031     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1.4826 * mad + 1e-9)
L82     if np.nanstd(z) < 1e-9:
L83         r = v.rank(method="average", na_option="keep")
L84         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L85     return pd.Series(z, index=v.index, dtype=float)
L86
L87
L88 def _d
```