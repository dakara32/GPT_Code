```text
cfg.drrs.D.get("gamma", 0.8),
L865                 lam=cfg.drrs.D.get("lam", 0.85),
L866                 lookback=cfg.drrs.D.get("lookback", 504),
L867                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L868                 mu=cfg.drrs.cross_mu_gd
L869             )
L870         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L871         sum_sc = res["sum_score"]; obj = res["objective"]
L872         if group == "D":
L873             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L874             T.log("selection finalized (G/D)")
L875     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L876     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L877     try:
L878         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L879         near10 = list(pool.sort_values(ascending=False).head(10).index)
L880         setattr(sc, f"_near_{group}", near10)
L881         setattr(sc, f"_agg_{group}", agg)
L882     except Exception:
L883         pass
L884
L885     if group == "D":
L886         T.log("save done")
L887     if group == "G":
L888         sc._top_G = pick
L889     return pick, avg_r, sum_sc, obj
L890
L891 def run_pipeline() -> SelectionBundle:
L892     """
L893     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L894     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L895     """
L896     inb = io_build_input_bundle()
L897     cfg = PipelineConfig(
L898         weights=WeightsConfig(g=g_weights, d=D_weights),
L899         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L900                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L901         price_max=CAND_PRICE_MAX
L902     )
L903     sc = Scorer()
L904     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L905     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L906     alpha = Scorer.spx_to_alpha(inb.spx)
L907     sectors = {t: (inb.info.get(t, {}).get("sector") or "U") for t in poolG}
L908     scores = {t: Scorer.g_score.get(t, 0.0) for t in poolG}
L909     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L910     sc._top_G = top_G
L911     try:
L912         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L913         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L914     except Exception:
L915         pass
L916     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L917     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L918     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L919     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L920     fb = getattr(sc, "_feat", None)
L921     near_G = getattr(sc, "_near_G", [])
L922     selected12 = list(top_G)
L923     df = fb.df if fb is not None else pd.DataFrame()
L924     guni = _infer_g_universe(df, selected12, near_G)
L925     try:
L926         fire_recent = [t for t in guni
L927                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L928                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L929     except Exception:
L930         fire_recent = []
L931
L932     # --- Breadthè¡Œã‚’ä¸¦åˆ—ã§å…ˆè¡Œè¨ˆç®—ï¼ˆInputBundleã®ã¿ä¾å­˜ï¼‰ ---
L933     breadth_fut = None
L934     try:
L935         ex = ThreadPoolExecutor(max_workers=2)
L936         breadth_fut = ex.submit(_build_breadth_lead_lines, inb)
L937     except Exception:
L938         breadth_fut = None
L939
L940     lines = [
L941         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L942         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L943         f"é¸å®š12: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else "é¸å®š12: ãªã—",
L944         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",
L945     ]
L946     # --- ä¸¦åˆ—çµæœã‚’ã“ã“ã§åˆæµï¼ˆå¤±æ•—ã—ã¦ã‚‚æ—¢å­˜ã®å‡ºåŠ›ã¯ç¶™ç¶šï¼‰ ---
L947     if breadth_fut is not None:
L948         try:
L949             lead_lines, _mode = breadth_fut.result()
L950             lines = lead_lines + lines
L951         except Exception as _e:
L952             lines = [f"Breadthè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {_e}"] + lines
L953
L954     if fire_recent:
L955         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L956         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L957     else:
L958         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L959
L960     try:
L961         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L962         if webhook:
L963             requests.post(webhook, json={"text": "\n".join(lines)}, timeout=10)
L964     except Exception:
L965         pass
L966
L967     out = Output(debug=debug_mode)
L968     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L969     try: out._sc = sc
L970     except Exception: pass
L971     if hasattr(sc, "_feat"):
L972         try:
L973             out.miss_df = sc._feat.missing_logs
L974             out.display_results(
L975                 exist=exist, bench=bench, df_z=sc._feat.df_z,
L976                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L977                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D
L978             )
L979         except Exception:
L980             pass
L981     out.notify_slack()
L982     sb = SelectionBundle(
L983         resG={"tickers": top_G, "avg_res_corr": avgG,
L984               "sum_score": sumG, "objective": objG},
L985         resD={"tickers": top_D, "avg_res_corr": avgD,
L986               "sum_score": sumD, "objective": objD},
L987         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D
L988     )
L989
L990     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L991     try:
L992         _low_df = (
L993             pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L994               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L995               .sort_values("G_plus_D")
L996               .head(10)
L997               .round(3)
L998         )
L999         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L1000                "```"
L1001                + _low_df.to_string(index=True, index_names=False)
L1002                + "\n```")
L1003     except Exception as _e:
L1004         _slack(f"Low Score Candidates: ä½œæˆå¤±æ•—: {_e}")
L1005
L1006     if debug_mode:
L1007         try:
L1008             _slack_debug(_compact_debug(fb, sb, [], []))
L1009         except Exception as e:
L1010             print(f"[debug skipped] {e}")
L1011
L1012     return sb
L1013
L1014 if __name__ == "__main__":
L1015     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py 
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None:
L43         return float(c)
L44     try:
L45         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L46         return float(h.iloc[-1]) if len(h) else np.nan
L47     except Exception:
L48         return np.nan
L49
L50 def _ttm_div_sum(t, lookback_days=400):
L51     try:
L52         div = yf.Ticker(t).dividends
L53         if div is None or len(div) == 0:
L54             return 0.0
L55         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L56         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L57         return ttm if ttm > 0 else float(div.tail(4).sum())
L58     except Exception:
L59         return 0.0
L60
L61 def ttm_div_yield_portfolio(tickers, price_map=None):
L62     ys = []
L63     for t in tickers:
L64         c = _last_close(t, price_map)
L65         if not np.isfinite(c) or c <= 0:
L66             ys.append(0.0)
L67             continue
L68         s = _ttm_div_sum(t)
L69         ys.append(s / c if s > 0 else 0.0)
L70     return float(np.mean(ys)) if ys else 0.0
L71
L72 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L73 def winsorize_s(s: pd.Series, p=0.02):
L74     if s is None or s.dropna().empty: return s
L75     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L76
L77 def robust_z(s: pd.Series, p=0.02):
L78     s2 = winsorize_s(s, p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L79
L80 def _safe_div(a, b):
L81     try:
L82         if b is None or float(b)==0 or pd.isna(b): return np.nan
L83         return float(a)/float(b)
L84     except Exception: return np.nan
L85
L86 def _safe_last(series: pd.Series, default=np.nan):
L87     try: return float(series.iloc[-1])
L88     except Exception: return default
L89
L90 D_WEIGHTS_EFF = None  # å‡ºåŠ›è¡¨ç¤ºäº’æ›ã®ãŸã‚
L91
L92 # ---- Scorer æœ¬ä½“ -------------------------------------------------------------
L93 class Scorer:
L94     """
L95     - factor.py ã‹ã‚‰ã¯ `aggregate_scores(ib, cfg)` ã‚’å‘¼ã¶ã ã‘ã§OKã€‚
L96     - cfg ã¯å¿…é ˆï¼ˆfactor.PipelineConfig ã‚’æ¸¡ã™ï¼‰ã€‚
L97     - æ—§ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦æ–°ã‚¹ã‚­ãƒ¼ãƒã«å¸åã—ã¾ã™ã€‚
L98     """
L99
L100     # === å…ˆé ­ã§æ—§â†’æ–°ã‚«ãƒ©ãƒ åãƒãƒƒãƒ—ï¼ˆç§»è¡Œç”¨ï¼‰ ===
L101     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L102     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L103
L104     # === ã‚¹ã‚­ãƒ¼ãƒç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€ä½é™ï¼‰ ===
L105     @staticmethod
L106     def _validate_ib_for_scorer(ib: Any):
L107         must_attrs = ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"]
L108         miss = [a for a in must_attrs if not hasattr(ib, a) or getattr(ib, a) is None]
L109         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L110
L111         # å¾Œæ–¹äº’æ›ã®ãŸã‚ã€ã¾ãš rename ã‚’è©¦ã¿ã‚‹
L112         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME.keys()):
L113             ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L114         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME.keys()):
L115             ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L116
L117         # å¿…é ˆåˆ—ã®å­˜åœ¨ç¢ºèª
L118         need_eps = {"EPS_TTM","EPS_Q_LastQ"}
L119         need_fcf = {"FCF_TTM"}
L120         if not need_eps.issubset(set(ib.eps_df.columns)):
L121             raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L122         if not need_fcf.issubset(set(ib.fcf_df.columns)):
L123             raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L124
L125     # ----ï¼ˆScorerå°‚ç”¨ï¼‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ»æŒ‡æ¨™ç³» ----
L126     @staticmethod
L127     def trend(s: pd.Series):
L128         if len(s)<200: return
```