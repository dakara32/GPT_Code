```text
title: str, group: str) -> str:
L848             suf = _filter_suffix_from(FILTER_SPEC, group)
L849             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L850
L851         def _blk(title, tbl, fmt=None, drop=()):
L852             if tbl is None or getattr(tbl, 'empty', False):
L853                 return f"{title}\n(é¸å®šãªã—)\n"
L854             if drop and hasattr(tbl, 'columns'):
L855                 keep = [c for c in tbl.columns if c not in drop]
L856                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L857             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L858
L859         message = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L860         if self.miss_df is not None and not self.miss_df.empty:
L861             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L862         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L863         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L864         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L865         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L866
L867         try:
L868             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L869             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L870             if r is not None:
L871                 r.raise_for_status()
L872         except Exception as e:
L873             print(f"[ERR] main_post_failed: {e}")
L874
L875 def _infer_g_universe(feature_df, selected12=None, near5=None):
L876     try:
L877         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L878         if out: return out
L879     except Exception:
L880         pass
L881     base = set()
L882     for lst in (selected12 or []), (near5 or []):
L883         for x in (lst or []): base.add(x)
L884     return list(base) if base else list(feature_df.index)
L885
L886 def _fmt_with_fire_mark(tickers, feature_df):
L887     out = []
L888     for t in tickers or []:
L889         try:
L890             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L891             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L892             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L893         except Exception:
L894             out.append(t)
L895     return out
L896
L897 def _label_recent_event(t, feature_df):
L898     try:
L899         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L900         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L901         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L902         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L903         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L904     except Exception:
L905         pass
L906     return t
L907
L908 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L909
L910 def io_build_input_bundle() -> InputBundle:
L911     """
L912     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L913     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L914     """
L915     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L916     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L917
L918 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L919               n_target: int) -> tuple[list, float, float, float]:
L920     """
L921     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L922     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L923     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L924     """
L925     sc.cfg = cfg
L926
L927     if hasattr(sc, "score_build_features"):
L928         feat = sc.score_build_features(inb)
L929         if not hasattr(sc, "_feat_logged"):
L930             T.log("features built (scorer)")
L931             sc._feat_logged = True
L932         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L933     else:
L934         fb = sc.aggregate_scores(inb, cfg)
L935         if not hasattr(sc, "_feat_logged"):
L936             T.log("features built (scorer)")
L937             sc._feat_logged = True
L938         sc._feat = fb
L939         agg = fb.g_score if group == "G" else fb.d_score_all
L940         if group == "D" and hasattr(fb, "df"):
L941             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L942
L943     if hasattr(sc, "filter_candidates"):
L944         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L945
L946     selector = Selector()
L947     if hasattr(sc, "select_diversified"):
L948         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L949             selector=selector, prev_tickers=None,
L950             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L951             cross_mu=cfg.drrs.cross_mu_gd)
L952     else:
L953         if group == "G":
L954             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L955             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L956                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L957                 lam=cfg.drrs.G.get("lam", 0.68),
L958                 lookback=cfg.drrs.G.get("lookback", 252),
L959                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L960         else:
L961             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L962             g_fixed = getattr(sc, "_top_G", None)
L963             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L964                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L965                 lam=cfg.drrs.D.get("lam", 0.85),
L966                 lookback=cfg.drrs.D.get("lookback", 504),
L967                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L968                 mu=cfg.drrs.cross_mu_gd)
L969         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L970         sum_sc = res["sum_score"]; obj = res["objective"]
L971         if group == "D":
L972             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L973             T.log("selection finalized (G/D)")
L974     try:
L975         inc = [t for t in exist if t in agg.index]
L976         pick = _sticky_keep_current(
L977             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L978             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L979         )
L980     except Exception as _e:
L981         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L982     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L983     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L984     try:
L985         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L986         near10 = list(pool.sort_values(ascending=False).head(10).index)
L987         setattr(sc, f"_near_{group}", near10)
L988         setattr(sc, f"_agg_{group}", agg)
L989     except Exception:
L990         pass
L991
L992     if group == "D":
L993         T.log("save done")
L994     if group == "G":
L995         sc._top_G = pick
L996     return pick, avg_r, sum_sc, obj
L997
L998 def run_pipeline() -> SelectionBundle:
L999     """
L1000     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1001     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1002     """
L1003     inb = io_build_input_bundle()
L1004     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L1005         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L1006                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L1007         price_max=CAND_PRICE_MAX)
L1008     sc = Scorer()
L1009     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1010     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1011     alpha = Scorer.spx_to_alpha(inb.spx)
L1012     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1013     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1014     sc._top_G = top_G
L1015     try:
L1016         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1017         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1018     except Exception:
L1019         pass
L1020     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1021     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1022     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1023     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1024     fb = getattr(sc, "_feat", None)
L1025     near_G = getattr(sc, "_near_G", [])
L1026     selected12 = list(top_G)
L1027     df = fb.df if fb is not None else pd.DataFrame()
L1028     guni = _infer_g_universe(df, selected12, near_G)
L1029     try:
L1030         fire_recent = [t for t in guni
L1031                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1032                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1033     except Exception: fire_recent = []
L1034
L1035     lines = [
L1036         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1037         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1038         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1039         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1040
L1041     if fire_recent:
L1042         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1043         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1044     else:
L1045         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1046
L1047     try:
L1048         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1049         if webhook:
L1050             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1051     except Exception:
L1052         pass
L1053
L1054     out = Output()
L1055     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1056     try: out._sc = sc
L1057     except Exception: pass
L1058     if hasattr(sc, "_feat"):
L1059         try:
L1060             fb = sc._feat
L1061             out.miss_df = fb.missing_logs
L1062             out.display_results(
L1063                 exist=exist,
L1064                 bench=bench,
L1065                 df_z=fb.df_z,
L1066                 g_score=fb.g_score,
L1067                 d_score_all=fb.d_score_all,
L1068                 init_G=top_G,
L1069                 init_D=top_D,
L1070                 top_G=top_G,
L1071                 top_D=top_D,
L1072                 df_full_z=getattr(fb, "df_full_z", None),
L1073                 prev_G=getattr(sc, "_prev_G", exist),
L1074                 prev_D=getattr(sc, "_prev_D", exist),
L1075             )
L1076         except Exception:
L1077             pass
L1078     out.notify_slack()
L1079     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1080               "sum_score": sumG, "objective": objG},
L1081         resD={"tickers": top_D, "avg_res_corr": avgD,
L1082               "sum_score": sumD, "objective": objD},
L1083         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1084
L1085     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1086     try:
L1087         _low_df = (pd.DataFram
```