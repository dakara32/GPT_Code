```text
I/Oはここだけで実施し、計算はScorerに委譲。
L842     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L843     """
L844     inb = io_build_input_bundle()
L845     cfg = PipelineConfig(
L846         weights=WeightsConfig(g=g_weights, d=D_weights),
L847         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L848                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L849         price_max=CAND_PRICE_MAX
L850     )
L851     sc = Scorer()
L852     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L853     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L854     alpha = Scorer.spx_to_alpha(inb.spx)
L855     sectors = {t: (inb.info.get(t, {}).get("sector") or "U") for t in poolG}
L856     scores = {t: Scorer.g_score.get(t, 0.0) for t in poolG}
L857     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L858     sc._top_G = top_G
L859     try:
L860         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L861         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L862     except Exception:
L863         pass
L864     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L865     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L866     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L867     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L868     fb = getattr(sc, "_feat", None)
L869     near_G = getattr(sc, "_near_G", [])
L870     selected12 = list(top_G)
L871     df = fb.df if fb is not None else pd.DataFrame()
L872     guni = _infer_g_universe(df, selected12, near_G)
L873     try:
L874         fire_recent = [t for t in guni
L875                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L876                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L877     except Exception:
L878         fire_recent = []
L879
L880     # === 先頭ヘッダ（モード・しきい値・分位）をテキストブロック化して差し込み ===
L881     try:
L882         lead_lines, _mode = _build_breadth_lead_lines(inb)  # 既存の関数（以前の改修で追加済み）
L883         head_block = "```" + "\n".join(lead_lines) + "```"
L884     except Exception:
L885         head_block = ""  # フェイルセーフ（ヘッダなしでも後続は継続）
L886
L887     lines = [
L888         head_block,
L889         "【G枠レポート｜週次モニタ（直近5営業日）】",
L890         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L891         f"選定12: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else "選定12: なし",
L892         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",
L893     ]
L894
L895     if fire_recent:
L896         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L897         lines.append(f"過去5営業日の検知: {fire_list}")
L898     else:
L899         lines.append("過去5営業日の検知: なし")
L900
L901     try:
L902         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L903         if webhook:
L904             # 先頭の head_block を含む複数行をそのまま送信（Slack側で```がコードブロックとして描画）
L905             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""] )}, timeout=10)
L906     except Exception:
L907         pass
L908
L909     out = Output(debug=debug_mode)
L910     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L911     try: out._sc = sc
L912     except Exception: pass
L913     if hasattr(sc, "_feat"):
L914         try:
L915             out.miss_df = sc._feat.missing_logs
L916             out.display_results(
L917                 exist=exist, bench=bench, df_z=sc._feat.df_z,
L918                 g_score=sc._feat.g_score, d_score_all=sc._feat.d_score_all,
L919                 init_G=top_G, init_D=top_D, top_G=top_G, top_D=top_D
L920             )
L921         except Exception:
L922             pass
L923     out.notify_slack()
L924     sb = SelectionBundle(
L925         resG={"tickers": top_G, "avg_res_corr": avgG,
L926               "sum_score": sumG, "objective": objG},
L927         resD={"tickers": top_D, "avg_res_corr": avgD,
L928               "sum_score": sumD, "objective": objD},
L929         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D
L930     )
L931
L932     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L933     try:
L934         _low_df = (
L935             pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L936               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L937               .sort_values("G_plus_D")
L938               .head(10)
L939               .round(3)
L940         )
L941         _slack("Low Score Candidates (GSC+DSC bottom 10)\n"
L942                "```"
L943                + _low_df.to_string(index=True, index_names=False)
L944                + "\n```")
L945     except Exception as _e:
L946         _slack(f"Low Score Candidates: 作成失敗: {_e}")
L947
L948     if debug_mode:
L949         try:
L950             _slack_debug(_compact_debug(fb, sb, [], []))
L951         except Exception as e:
L952             print(f"[debug skipped] {e}")
L953
L954     return sb
L955
L956 if __name__ == "__main__":
L957     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py 
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import os, sys, warnings
L30 import requests
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36
L37 if TYPE_CHECKING:
L38     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L39
L40 # ---- Dividend Helpers -------------------------------------------------------
L41 def _last_close(t, price_map=None):
L42     if price_map and (c := price_map.get(t)) is not None:
L43         return float(c)
L44     try:
L45         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L46         return float(h.iloc[-1]) if len(h) else np.nan
L47     except Exception:
L48         return np.nan
L49
L50 def _ttm_div_sum(t, lookback_days=400):
L51     try:
L52         div = yf.Ticker(t).dividends
L53         if div is None or len(div) == 0:
L54             return 0.0
L55         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L56         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L57         return ttm if ttm > 0 else float(div.tail(4).sum())
L58     except Exception:
L59         return 0.0
L60
L61 def ttm_div_yield_portfolio(tickers, price_map=None):
L62     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L63     return float(np.mean(ys)) if ys else 0.0
L64
L65 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L66 def winsorize_s(s: pd.Series, p=0.02):
L67     if s is None or s.dropna().empty: return s
L68     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L69
L70 def robust_z(s: pd.Series, p=0.02):
L71     s2 = winsorize_s(s, p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L72
L73 def _safe_div(a, b):
L74     try:
L75         if b is None or float(b)==0 or pd.isna(b): return np.nan
L76         return float(a)/float(b)
L77     except Exception: return np.nan
L78
L79 def _safe_last(series: pd.Series, default=np.nan):
L80     try: return float(series.iloc[-1])
L81     except Exception: return default
L82
L83 D_WEIGHTS_EFF = None  # 出力表示互換のため
L84
L85 # ---- Scorer 本体 -------------------------------------------------------------
L86 class Scorer:
L87     """
L88     - factor.py からは `aggregate_scores(ib, cfg)` を呼ぶだけでOK。
L89     - cfg は必須（factor.PipelineConfig を渡す）。
L90     - 旧カラム名を自動リネームして新スキーマに吸収します。
L91     """
L92
L93     # === 先頭で旧→新カラム名マップ（移行用） ===
L94     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L95     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L96
L97     # === スキーマ簡易チェック（最低限） ===
L98     @staticmethod
L99     def _validate_ib_for_scorer(ib: Any):
L100         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L101         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L102         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L103         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L104         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L105         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L106         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L107
L108     # ----（Scorer専用）テクニカル・指標系 ----
L109     @staticmethod
L110     def trend(s: pd.Series):
L111         if len(s)<200: return np.nan
L112         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L113         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L114         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L115         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L116         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L117         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L118         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L119         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L120         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L121         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L122         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L123         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L124
L125     @staticmethod
L126     def rs(s, b):
L127         n, nb = len(s), len(b)
L128         if n<60 or nb<60: return np.nan
L129         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L130         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L131         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L132
L133     @staticmethod
L134     def tr_str(s):
L135         if len(s)<50: return np.nan
L136         return s.iloc[-1]/s.rolling(50).mean().iloc[-1] - 1
L137
L138     @staticmethod
L139     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L140         r = (s/b).dropna()
L141         if len(r) < win: return np.nan
L142         y, x = np.log(r.i
```