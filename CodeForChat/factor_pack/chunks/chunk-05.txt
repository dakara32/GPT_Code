```text

L982         samples: list[tuple[str, int, str, float | None, int, str, float | None]] = []
L983
L984         for t in tickers:
L985             entry = info.get(t, {})
L986             m = (sec_map or {}).get(t) or {}
L987             if entry is None or not isinstance(entry, dict):
L988                 entry = {}
L989                 info[t] = entry
L990
L991             if m:
L992                 pairs_r = m.get("rev_q_series_pairs") or []
L993                 pairs_e = m.get("eps_q_series_pairs") or []
L994                 if pairs_r:
L995                     idx = pd.to_datetime([d for (d, _v) in pairs_r], errors="coerce")
L996                     val = pd.to_numeric([v for (_d, v) in pairs_r], errors="coerce")
L997                     s = pd.Series(val, index=idx).sort_index()
L998                     entry["SEC_REV_Q_SERIES"] = s
L999                 else:
L1000                     entry["SEC_REV_Q_SERIES"] = m.get("rev_q_series") or []
L1001                 if pairs_e:
L1002                     idx = pd.to_datetime([d for (d, _v) in pairs_e], errors="coerce")
L1003                     val = pd.to_numeric([v for (_d, v) in pairs_e], errors="coerce")
L1004                     s = pd.Series(val, index=idx).sort_index()
L1005                     entry["SEC_EPS_Q_SERIES"] = s
L1006                 else:
L1007                     entry["SEC_EPS_Q_SERIES"] = m.get("eps_q_series") or []
L1008
L1009             r = entry.get("SEC_REV_Q_SERIES")
L1010             e = entry.get("SEC_EPS_Q_SERIES")
L1011             # 年次は直近3件（約3年）だけ保持。重み分岐の nY 判定は従来通り。
L1012             try:
L1013                 if hasattr(r, "index") and isinstance(r.index, pd.DatetimeIndex):
L1014                     y = r.resample("Y").sum().dropna()
L1015                     entry["SEC_REV_Y_SERIES"] = y.tail(3)
L1016                 else:
L1017                     entry["SEC_REV_Y_SERIES"] = []
L1018             except Exception:
L1019                 entry["SEC_REV_Y_SERIES"] = []
L1020             ry = entry.get("SEC_REV_Y_SERIES")
L1021             if _has_entries(r):
L1022                 have_rev += 1
L1023             if _has_entries(e):
L1024                 have_eps += 1
L1025             lr = _brief_len(r)
L1026             le = _brief_len(e)
L1027             rev_lens.append(lr)
L1028             eps_lens.append(le)
L1029             rev_y_lens.append(_brief_len(ry))
L1030             if len(samples) < 8:
L1031                 try:
L1032                     rd = getattr(r, "index", [])[-1] if lr > 0 else None
L1033                     rv = float(r.iloc[-1]) if lr > 0 else None
L1034                     ed = getattr(e, "index", [])[-1] if le > 0 else None
L1035                     ev = float(e.iloc[-1]) if le > 0 else None
L1036                     samples.append((t, lr, str(rd) if rd is not None else "-", rv, le, str(ed) if ed is not None else "-", ev))
L1037                 except Exception:
L1038                     samples.append((t, lr, "-", None, le, "-", None))
L1039
L1040         logger.info("[SEC] series attach: rev_q=%d/%d, eps_q=%d/%d", have_rev, len(tickers), have_eps, len(tickers))
L1041         logger.info(
L1042             "[SEC_SERIES] rev_q=%d (<=12), eps_q=%d (<=12), rev_y=%d (<=3)",
L1043             max(rev_lens) if rev_lens else 0,
L1044             max(eps_lens) if eps_lens else 0,
L1045             max(rev_y_lens) if rev_y_lens else 0,
L1046         )
L1047
L1048         if rev_lens:
L1049             rev_lens_sorted = sorted(rev_lens)
L1050             eps_lens_sorted = sorted(eps_lens)
L1051             _log(
L1052                 "SEC_SERIES",
L1053                 f"rev_len min/med/max={rev_lens_sorted[0]}/{rev_lens_sorted[len(rev_lens)//2]}/{rev_lens_sorted[-1]} "
L1054                 f"eps_len min/med/max={eps_lens_sorted[0]}/{eps_lens_sorted[len(eps_lens)//2]}/{eps_lens_sorted[-1]}",
L1055             )
L1056         for (t, lr, rd, rv, le, ed, ev) in samples:
L1057             _log("SEC_SERIES_SMP", f"{t}  rev_len={lr} last=({rd},{rv})  eps_len={le} last=({ed},{ev})")
L1058         eps_df = self._build_eps_df(tickers, tickers_bulk, info, sec_map=sec_map)
L1059         # index 重複があると .loc[t, col] が Series になり代入時に ValueError を誘発する
L1060         if not eps_df.index.is_unique:
L1061             eps_df = eps_df[~eps_df.index.duplicated(keep="last")]
L1062         eps_df = eps_df.assign(
L1063             EPS_TTM=eps_df["eps_ttm"],
L1064             EPS_TTM_PREV=eps_df.get("eps_ttm_prev", np.nan),
L1065             EPS_Q_LastQ=eps_df["eps_q_recent"],
L1066             EPS_Q_Prev=eps_df.get("eps_q_prev", np.nan),
L1067             REV_TTM=eps_df["rev_ttm"],
L1068             REV_TTM_PREV=eps_df.get("rev_ttm_prev", np.nan),
L1069             REV_Q_LastQ=eps_df["rev_q_recent"],
L1070             REV_Q_Prev=eps_df.get("rev_q_prev", np.nan),
L1071             EPS_A_LATEST=eps_df.get("eps_annual_latest", np.nan),
L1072             EPS_A_PREV=eps_df.get("eps_annual_prev", np.nan),
L1073             REV_A_LATEST=eps_df.get("rev_annual_latest", np.nan),
L1074             REV_A_PREV=eps_df.get("rev_annual_prev", np.nan),
L1075             EPS_A_CAGR3=eps_df.get("eps_cagr3", np.nan),
L1076             REV_A_CAGR3=eps_df.get("rev_cagr3", np.nan),
L1077         )
L1078         # ここで非NaN件数をサマリ表示（欠損状況の即時把握用）
L1079         try:
L1080             n = len(eps_df)
L1081             c_eps = int(eps_df["EPS_TTM"].notna().sum())
L1082             c_rev = int(eps_df["REV_TTM"].notna().sum())
L1083             print(f"[SEC] eps_ttm non-NaN: {c_eps}/{n}  rev_ttm non-NaN: {c_rev}/{n}")
L1084         except Exception:
L1085             pass
L1086         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L1087         T.log("eps/fcf prep done")
L1088         returns = px[tickers].pct_change()
L1089         T.log("price prep/returns done")
L1090         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns)
L1091
L1092 # === Selector：相関低減・選定（スコア＆リターンだけ読む） ===
L1093 class Selector:
L1094     # ---- DRRS helpers（Selector専用） ----
L1095     @staticmethod
L1096     def _z_np(X: np.ndarray) -> np.ndarray:
L1097         X = np.asarray(X, dtype=np.float32)
L1098         m = np.nanmean(X, axis=0, keepdims=True)
L1099         s = np.nanstd(X, axis=0, keepdims=True)
L1100         # 分母0/全NaN列の安全化：std==0 を 1 に置換（z=0に収束）
L1101         s = np.where(np.isfinite(s) & (s > 0), s, 1.0).astype(np.float32)
L1102         with np.errstate(invalid="ignore", divide="ignore"):
L1103             Z = (np.nan_to_num(X) - np.nan_to_num(m)) / s
L1104         return np.nan_to_num(Z)
L1105
L1106     @classmethod
L1107     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L1108         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L1109         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L1110         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L1111         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L1112         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L1113
L1114     @classmethod
L1115     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L1116         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L1117         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L1118         if k==0: return []
L1119         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L1120         for _ in range(k):
L1121             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L1122             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L1123             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L1124         return sorted(S)
L1125
L1126     @staticmethod
L1127     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L1128         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L1129         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L1130
L1131     @classmethod
L1132     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L1133         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L1134         while improved and passes<max_pass:
L1135             improved, passes = False, passes+1
L1136             for i,out in enumerate(list(S)):
L1137                 for inn in range(len(score)):
L1138                     if inn in S: continue
L1139                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L1140                     if v>best+1e-10: S, best, improved = cand, v, True; break
L1141                 if improved: break
L1142         return S, best
L1143
L1144     @staticmethod
L1145     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L1146         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L1147         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L1148         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L1149         return float(s[idx].sum() - lam*within - mu*cross)
L1150
L1151     @classmethod
L1152     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L1153         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L1154         while improved and passes<max_pass:
L1155             improved, passes = False, passes+1
L1156             for i,out in enumerate(list(S)):
L1157                 for inn in range(N):
L1158                     if inn in S: continue
L1159                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L1160                     if v>best+1e-10: S, best, improved = cand, v, True; break
L1161                 if improved: break
L1162         return S, best
L1163
L1164     @staticmethod
L1165     def avg_corr(C: np.ndarray, idx) -> float:
L1166         k = len(idx); P = C[np.ix_(idx, idx)]
L1167         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L1168
L1169     @classmethod
L1170     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L1171         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L1172         union = [t for t in pool_tickers if t in returns_df.columns]
L1173         for t in g_fixed:
L1174             if t not in union: union.append(t)
L1175         Rdf_all = returns_df[union]; Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all)>=lookback else Rdf_all; Rdf_all = Rdf_all.dropna()
L1176         pool_eff, g_eff = [t for t in pool_tickers if t in Rdf_all.columns], [t for t in g_fixed if t in Rdf_all.columns]
L1177         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L1178         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L1179         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L1180         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L1181         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L1182         if len(g_eff)>0 and mu>0.0:
L1183             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_a
```