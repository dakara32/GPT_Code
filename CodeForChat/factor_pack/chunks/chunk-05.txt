```text
cted12, near_G)
L846     try:
L847         fire_recent = [t for t in guni
L848                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L849                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L850     except Exception: fire_recent = []
L851
L852     lines = [
L853         "【G枠レポート｜週次モニタ（直近5営業日）】",
L854         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L855         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L856         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L857
L858     if fire_recent:
L859         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L860         lines.append(f"過去5営業日の検知: {fire_list}")
L861     else:
L862         lines.append("過去5営業日の検知: なし")
L863
L864     try:
L865         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L866         if webhook:
L867             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L868     except Exception:
L869         pass
L870
L871     out = Output()
L872     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L873     try: out._sc = sc
L874     except Exception: pass
L875     if hasattr(sc, "_feat"):
L876         try:
L877             fb = sc._feat
L878             out.miss_df = fb.missing_logs
L879             out.display_results(
L880                 exist=exist,
L881                 bench=bench,
L882                 df_z=fb.df_z,
L883                 g_score=fb.g_score,
L884                 d_score_all=fb.d_score_all,
L885                 init_G=top_G,
L886                 init_D=top_D,
L887                 top_G=top_G,
L888                 top_D=top_D,
L889                 df_full_z=getattr(fb, "df_full_z", None),
L890                 prev_G=getattr(sc, "_prev_G", exist),
L891                 prev_D=getattr(sc, "_prev_D", exist),
L892             )
L893         except Exception:
L894             pass
L895     out.notify_slack()
L896     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L897               "sum_score": sumG, "objective": objG},
L898         resD={"tickers": top_D, "avg_res_corr": avgD,
L899               "sum_score": sumD, "objective": objD},
L900         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L901
L902     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L903     try:
L904         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L905               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L906               .sort_values("G_plus_D")
L907               .head(10)
L908               .round(3))
L909         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L910         _post_slack({"text": f"```{low_msg}```"})
L911     except Exception as _e:
L912         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L913
L914     return sb
L915
L916 if __name__ == "__main__":
L917     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #
L26 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1.4826 * mad + 1e-9)
L82     if np.nanstd(z) < 1e-9:
L83         r = v.rank(method="average", na_option="keep")
L84         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L85     return pd.Series(z, index=v.index, dtype=float)
L86
L87
L88 def _dump_dfz(df_z: pd.DataFrame, debug_mode: bool, max_rows: int = 400, ndigits: int = 3) -> None:
L89     """df_z を System log(INFO) へダンプする簡潔なユーティリティ."""
L90     if not debug_mode:
L91         return
L92     try:
L93         view = df_z.copy()
L94         view = view.apply(
L95             lambda s: s.round(ndigits)
L96             if getattr(getattr(s, "dtype", None), "kind", "") in ("f", "i")
L97             else s
L98         )
L99         if len(view) > max_rows:
L100             view = view.iloc[:max_rows]
L101         logger.info("===== DF_Z DUMP START =====")
L102         logger.info("\n%s", view.to_string(max_rows=None, max_cols=None))
L103         logger.info("===== DF_Z DUMP END =====")
L104     except Exception as exc:
L105         logger.warning("df_z dump failed: %s", exc)
L106
L107 def _safe_div(a, b):
L108     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L109     except Exception: return np.nan
L110
L111 def _safe_last(series: pd.Series, default=np.nan):
L112     try: return float(series.iloc[-1])
L113     except Exception: return default
L114
L115 D_WEIGHTS_EFF = None  # 出力表示互換のため
L116
L117 # ---- Scorer 本体 -------------------------------------------------------------
L118 class Scorer:
L119     """
L120     - factor.py からは `aggregate_scores(ib, cfg)` を呼ぶだけでOK。
L121     - cfg は必須（factor.PipelineConfig を渡す）。
L122     - 旧カラム名を自動リネームして新スキーマに吸収します。
L123     """
L124
L125     # === 先頭で旧→新カラム名マップ（移行用） ===
L126     EPS_RENAME = {"eps_ttm":"EPS_TTM", "eps_q_recent":"EPS_Q_LastQ"}
L127     FCF_RENAME = {"fcf_ttm":"FCF_TTM"}
L128
L129     # === スキーマ簡易チェック（最低限） ===
L130     @staticmethod
L131     def _validate_ib_for_scorer(ib: Any):
L132         miss = [a for a in ["tickers","bench","data","px","spx","tickers_bulk","info","eps_df","fcf_df","returns"] if not hasattr(ib,a) or getattr(ib,a) is None]
L133         if miss: raise ValueError(f"InputBundle is missing required attributes for Scorer: {miss}")
L134         if any(c in ib.eps_df.columns for c in Scorer.EPS_RENAME): ib.eps_df.rename(columns=Scorer.EPS_RENAME, inplace=True)
L135         if any(c in ib.fcf_df.columns for c in Scorer.FCF_RENAME): ib.fcf_df.rename(columns=Scorer.FCF_RENAME, inplace=True)
L136         need_eps, need_fcf = {"EPS_TTM","EPS_Q_LastQ"},{"FCF_TTM"}
L137         if not need_eps.issubset(ib.eps_df.columns): raise ValueError(f"eps_df must contain columns {need_eps} (accepts old names via auto-rename). Got: {list(ib.eps_df.columns)}")
L138         if not need_fcf.issubset(ib.fcf_df.columns): raise ValueError(f"fcf_df must contain columns {need_fcf} (accepts old names via auto-rename). Got: {list(ib.fcf_df.columns)}")
L139
L140     # ----（Scorer専用）テクニカル・指標系 ----
L141     @staticmethod
L142     def trend(s: pd.Series):
L143         if len(s)<200: return np.nan
L144         sma50, sma150, sma200 = s.rolling(50).mean().iloc[-1], s.rolling(150).mean().iloc[-1], s.rolling(200).mean().iloc[-1]
L145         prev200, p = s.rolling(200).mean().iloc[-21], s.iloc[-1]
L146         lo_52 = s[-252:].min() if len(s)>=252 else s.min(); hi_52 = s[-252:].max() if len(s)>=252 else s.max()
L147         rng = (hi_52 - lo_52) if hi_52>lo_52 else np.nan
L148         clip = lambda x,lo,hi: (np.nan if pd.isna(x) else max(lo,min(hi,x)))
L149         a = clip(p/(s.rolling(50).mean().iloc[-1]) - 1, -0.5, 0.5)
L150         b = clip(sma50/sma150 - 1, -0.5, 0.5)
L151         c = clip(sma150/sma200 - 1, -0.5, 0.5)
L152         d = clip(sma200/prev200 - 1, -0.2, 0.2)
L153         e = clip((p - lo_52) / (rng if rng and rng>0 else np.nan) - 0.5, -0.5, 0.5)
L154         parts = [0.0 if pd.isna(x) else x for x in (a,b,c,d,e)]
L155         return 0.30*parts[0] + 0.20*parts[1] + 0.15*parts[2] + 0.15*parts[3] + 0.20*parts[4]
L156
L157     @staticmethod
L158     def rs(s, b):
L159         n, nb = len(s), len(b)
L160         if n<60 or nb<60: return np.nan
L161         L12 = 252 if n>=252 and nb>=252 else min(n,nb)-1; L1 = 22 if n>=22 and nb>=22 else max(5, min(n,nb)//3)
L162         r12, r1, br12, br1 = s.iloc[-1]/s.iloc[-L12]-1, s.iloc[-1]/s.iloc[-L1]-1, b.iloc[-1]/b.iloc[-L12]-1, b.iloc[-1]/b.iloc[-L1]-1
L163         return (r12 - br12)*0.7 + (r1 - br1)*0.3
L164
L165     @staticmethod
L166     def tr_str(s):
L167         if s is None:
L168             return np.nan
L169         s = s.ffill(limit=2).dropna()
L170         if len(s) < 50:
L171             return np.nan
L172         ma50 = s.rolling(50, min_periods=50).mean()
L173         last_ma = ma50.iloc[-1]
L174         last_px = s.iloc[-1]
L175         return float(last_px/last_ma - 1.0) if pd.notna(last_ma) and pd.notna(last_px) else np.nan
L176
L177     @staticmethod
L178     def rs_line_slope(s: pd.Series, b: pd.Series, win: int) -> float:
L179         r = (s/b).dropna()
L180         if len(r) < win: return np.nan
L181         y, x = np.log(r.iloc[-win:]), np.arange(win, dtype=float)
L182         try: return float(np.polyfit(x, y, 1)[0])
L183         except Exception: return np.nan
L184
L185     @staticmethod
L186     def ev_fallback(info_t: dict, tk: yf.Ticker) -> float:
L187         ev = info_t.get('enterpriseValue', np.nan)
L188         if pd.notna(ev) 
```