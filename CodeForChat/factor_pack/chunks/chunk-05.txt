```text
  val = pd.to_numeric([v for (_d, v) in pairs_e], errors="coerce")
L978                     s = pd.Series(val, index=idx).sort_index()
L979                     entry["SEC_EPS_Q_SERIES"] = s
L980                 else:
L981                     entry["SEC_EPS_Q_SERIES"] = m.get("eps_q_series") or []
L982
L983             r = entry.get("SEC_REV_Q_SERIES")
L984             e = entry.get("SEC_EPS_Q_SERIES")
L985             # 年次は直近3件（約3年）だけ保持。重み分岐の nY 判定は従来通り。
L986             try:
L987                 if hasattr(r, "index") and isinstance(r.index, pd.DatetimeIndex):
L988                     y = r.resample("Y").sum().dropna()
L989                     entry["SEC_REV_Y_SERIES"] = y.tail(3)
L990                 else:
L991                     entry["SEC_REV_Y_SERIES"] = []
L992             except Exception:
L993                 entry["SEC_REV_Y_SERIES"] = []
L994             ry = entry.get("SEC_REV_Y_SERIES")
L995             if _has_entries(r):
L996                 have_rev += 1
L997             if _has_entries(e):
L998                 have_eps += 1
L999             lr = _brief_len(r)
L1000             le = _brief_len(e)
L1001             rev_lens.append(lr)
L1002             eps_lens.append(le)
L1003             rev_y_lens.append(_brief_len(ry))
L1004             if len(samples) < 8:
L1005                 try:
L1006                     rd = getattr(r, "index", [])[-1] if lr > 0 else None
L1007                     rv = float(r.iloc[-1]) if lr > 0 else None
L1008                     ed = getattr(e, "index", [])[-1] if le > 0 else None
L1009                     ev = float(e.iloc[-1]) if le > 0 else None
L1010                     samples.append((t, lr, str(rd) if rd is not None else "-", rv, le, str(ed) if ed is not None else "-", ev))
L1011                 except Exception:
L1012                     samples.append((t, lr, "-", None, le, "-", None))
L1013
L1014         logger.info("[SEC] series attach: rev_q=%d/%d, eps_q=%d/%d", have_rev, len(tickers), have_eps, len(tickers))
L1015         logger.info(
L1016             "[SEC_SERIES] rev_q=%d (<=12), eps_q=%d (<=12), rev_y=%d (<=3)",
L1017             max(rev_lens) if rev_lens else 0,
L1018             max(eps_lens) if eps_lens else 0,
L1019             max(rev_y_lens) if rev_y_lens else 0,
L1020         )
L1021
L1022         if rev_lens:
L1023             rev_lens_sorted = sorted(rev_lens)
L1024             eps_lens_sorted = sorted(eps_lens)
L1025             _log(
L1026                 "SEC_SERIES",
L1027                 f"rev_len min/med/max={rev_lens_sorted[0]}/{rev_lens_sorted[len(rev_lens)//2]}/{rev_lens_sorted[-1]} "
L1028                 f"eps_len min/med/max={eps_lens_sorted[0]}/{eps_lens_sorted[len(eps_lens)//2]}/{eps_lens_sorted[-1]}",
L1029             )
L1030         for (t, lr, rd, rv, le, ed, ev) in samples:
L1031             _log("SEC_SERIES_SMP", f"{t}  rev_len={lr} last=({rd},{rv})  eps_len={le} last=({ed},{ev})")
L1032         eps_df = self._build_eps_df(tickers, tickers_bulk, info, sec_map=sec_map)
L1033         # index 重複があると .loc[t, col] が Series になり代入時に ValueError を誘発する
L1034         if not eps_df.index.is_unique:
L1035             eps_df = eps_df[~eps_df.index.duplicated(keep="last")]
L1036         eps_df = eps_df.assign(
L1037             EPS_TTM=eps_df["eps_ttm"],
L1038             EPS_TTM_PREV=eps_df.get("eps_ttm_prev", np.nan),
L1039             EPS_Q_LastQ=eps_df["eps_q_recent"],
L1040             EPS_Q_Prev=eps_df.get("eps_q_prev", np.nan),
L1041             REV_TTM=eps_df["rev_ttm"],
L1042             REV_TTM_PREV=eps_df.get("rev_ttm_prev", np.nan),
L1043             REV_Q_LastQ=eps_df["rev_q_recent"],
L1044             REV_Q_Prev=eps_df.get("rev_q_prev", np.nan),
L1045             EPS_A_LATEST=eps_df.get("eps_annual_latest", np.nan),
L1046             EPS_A_PREV=eps_df.get("eps_annual_prev", np.nan),
L1047             REV_A_LATEST=eps_df.get("rev_annual_latest", np.nan),
L1048             REV_A_PREV=eps_df.get("rev_annual_prev", np.nan),
L1049             EPS_A_CAGR3=eps_df.get("eps_cagr3", np.nan),
L1050             REV_A_CAGR3=eps_df.get("rev_cagr3", np.nan),
L1051         )
L1052         missing_logs = pd.DataFrame()
L1053         # ここで非NaN件数をサマリ表示（欠損状況の即時把握用）
L1054         try:
L1055             n = len(eps_df)
L1056             c_eps = int(eps_df["EPS_TTM"].notna().sum())
L1057             c_rev = int(eps_df["REV_TTM"].notna().sum())
L1058             print(f"[SEC] eps_ttm non-NaN: {c_eps}/{n}  rev_ttm non-NaN: {c_rev}/{n}")
L1059         except Exception:
L1060             pass
L1061         fcf_df = self.compute_fcf_with_fallback(tickers, finnhub_api_key=self.api_key)
L1062         _tlog("eps/fcf prep done")
L1063         returns = px[tickers].pct_change()
L1064         _tlog("price prep/returns done")
L1065         return dict(cand=cand_f, tickers=tickers, data=data, px=px, spx=spx, tickers_bulk=tickers_bulk, info=info, eps_df=eps_df, fcf_df=fcf_df, returns=returns, missing_logs=missing_logs)
L1066
L1067 # === Selector：相関低減・選定（スコア＆リターンだけ読む） ===
L1068 class Selector:
L1069     # ---- DRRS helpers（Selector専用） ----
L1070     @staticmethod
L1071     def _z_np(X: np.ndarray) -> np.ndarray:
L1072         X = np.asarray(X, dtype=np.float32)
L1073         m = np.nanmean(X, axis=0, keepdims=True)
L1074         s = np.nanstd(X, axis=0, keepdims=True)
L1075         # 分母0/全NaN列の安全化：std==0 を 1 に置換（z=0に収束）
L1076         s = np.where(np.isfinite(s) & (s > 0), s, 1.0).astype(np.float32)
L1077         with np.errstate(invalid="ignore", divide="ignore"):
L1078             Z = (np.nan_to_num(X) - np.nan_to_num(m)) / s
L1079         return np.nan_to_num(Z)
L1080
L1081     @classmethod
L1082     def residual_corr(cls, R: np.ndarray, n_pc: int=3, shrink: float=0.1) -> np.ndarray:
L1083         Z = cls._z_np(R); U,S,_ = np.linalg.svd(Z, full_matrices=False); F = U[:,:n_pc]*S[:n_pc]; B = np.linalg.lstsq(F, Z, rcond=None)[0]
L1084         E = Z - F@B; C = np.corrcoef(E, rowvar=False)
L1085         off = C - np.diag(np.diag(C)); iu = np.triu_indices_from(off,1); avg_abs = np.nanmean(np.abs(off[iu])) if iu[0].size else 0.0
L1086         shrink_eff = float(np.clip(shrink + 0.5*avg_abs, 0.1, 0.6)); N = C.shape[0]
L1087         return (1.0 - shrink_eff)*C + shrink_eff*np.eye(N, dtype=C.dtype)
L1088
L1089     @classmethod
L1090     def rrqr_like_det(cls, R: np.ndarray, score: np.ndarray, k: int, gamma: float=1.0):
L1091         Z, w = cls._z_np(R), (score-score.min())/(np.ptp(score)+1e-12); X = Z*(1.0 + gamma*w)
L1092         N, k = X.shape[1], max(0, min(k, X.shape[1]))
L1093         if k==0: return []
L1094         S, selected, Rres = [], np.zeros(N, dtype=bool), X.copy()
L1095         for _ in range(k):
L1096             norms = (Rres*Rres).sum(axis=0); cand = np.where(~selected)[0]
L1097             j = sorted(cand, key=lambda c:(-norms[c], -w[c], c))[0]
L1098             S.append(j); selected[j]=True; u = X[:,j:j+1]; u/=(np.linalg.norm(u)+1e-12); Rres = Rres - u @ (u.T @ Rres)
L1099         return sorted(S)
L1100
L1101     @staticmethod
L1102     def _obj(corrM: np.ndarray, score: np.ndarray, idx, lam: float) -> float:
L1103         idx = list(idx); P = corrM[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L1104         return float(s[idx].sum() - lam*((P.sum()-np.trace(P))/2.0))
L1105
L1106     @classmethod
L1107     def swap_local_det(cls, corrM: np.ndarray, score: np.ndarray, idx, lam: float=0.6, max_pass: int=15):
L1108         S, best, improved, passes = sorted(idx), cls._obj(corrM, score, idx, lam), True, 0
L1109         while improved and passes<max_pass:
L1110             improved, passes = False, passes+1
L1111             for i,out in enumerate(list(S)):
L1112                 for inn in range(len(score)):
L1113                     if inn in S: continue
L1114                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj(corrM, score, cand, lam)
L1115                     if v>best+1e-10: S, best, improved = cand, v, True; break
L1116                 if improved: break
L1117         return S, best
L1118
L1119     @staticmethod
L1120     def _obj_with_cross(C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float, mu: float) -> float:
L1121         idx = list(idx); P = C_within[np.ix_(idx, idx)]; s = (score-score.mean())/(score.std()+1e-9)
L1122         within = (P.sum()-np.trace(P))/2.0; cross = 0.0
L1123         if C_cross is not None and C_cross.size>0: cross = C_cross[idx,:].sum()
L1124         return float(s[idx].sum() - lam*within - mu*cross)
L1125
L1126     @classmethod
L1127     def swap_local_det_cross(cls, C_within: np.ndarray, C_cross: np.ndarray|None, score: np.ndarray, idx, lam: float=0.6, mu: float=0.3, max_pass: int=15):
L1128         S, best, improved, passes, N = sorted(idx), cls._obj_with_cross(C_within,C_cross,score,idx,lam,mu), True, 0, len(score)
L1129         while improved and passes<max_pass:
L1130             improved, passes = False, passes+1
L1131             for i,out in enumerate(list(S)):
L1132                 for inn in range(N):
L1133                     if inn in S: continue
L1134                     cand = sorted(S[:i]+[inn]+S[i+1:]); v = cls._obj_with_cross(C_within,C_cross,score,cand,lam,mu)
L1135                     if v>best+1e-10: S, best, improved = cand, v, True; break
L1136                 if improved: break
L1137         return S, best
L1138
L1139     @staticmethod
L1140     def avg_corr(C: np.ndarray, idx) -> float:
L1141         k = len(idx); P = C[np.ix_(idx, idx)]
L1142         return float((P.sum()-np.trace(P))/(k*(k-1)+1e-12))
L1143
L1144     @classmethod
L1145     def select_bucket_drrs(cls, returns_df: pd.DataFrame, score_ser: pd.Series, pool_tickers: list[str], k: int, *, n_pc: int, gamma: float, lam: float, lookback: int, shrink: float=0.10, g_fixed_tickers: list[str]|None=None, mu: float=0.0):
L1146         g_fixed = [t for t in (g_fixed_tickers or []) if t in returns_df.columns]
L1147         union = [t for t in pool_tickers if t in returns_df.columns]
L1148         for t in g_fixed:
L1149             if t not in union: union.append(t)
L1150         Rdf_all = returns_df[union]
L1151         Rdf_all = Rdf_all.iloc[-lookback:] if len(Rdf_all) >= lookback else Rdf_all
L1152         _thresh = max(1, int(0.8 * len(Rdf_all)))
L1153         Rdf_all = Rdf_all.dropna(axis=1, thresh=_thresh)
L1154         Rdf_all = Rdf_all.dropna()
L1155         pool_eff, g_eff = (
L1156             [t for t in pool_tickers if t in Rdf_all.columns],
L1157             [t for t in g_fixed if t in Rdf_all.columns],
L1158         )
L1159         if len(pool_eff)==0: return dict(idx=[], tickers=[], avg_res_corr=np.nan, sum_score=0.0, objective=-np.inf)
L1160         score = score_ser.reindex(pool_eff).to_numpy(dtype=np.float32)
L1161         C_all = cls.residual_corr(Rdf_all.to_numpy(), n_pc=n_pc, shrink=shrink)
L1162         col_pos = {c:i for i,c in enumerate(Rdf_all.columns)}; pool_pos = [col_pos[t] for t in pool_eff]
L1163         C_within, C_cross = C_all[np.ix_(pool_pos,pool_pos)], None
L1164         if len(g_eff)>0 and mu>0.0:
L1165             g_pos = [col_pos[t] for t in g_eff]; C_cross = C_all[np.ix_(pool_pos,g_pos)]
L1166         R_pool = Rdf_all[pool_eff].to_numpy(); S0 = cls.rrqr_like_det(R_pool, score, k, gamma=gamma)
L1167         S, Jn = (cls.swap_local_det_cross(C_within, C_cross, score, S0, lam=lam, mu=mu, max_pass=15) if C_cross is not None else cls.swap_local_det(C_within, score, S0, lam=lam, max_pass=15))
L1168         selected_tickers = [pool_eff[i] for i in S]
L1169         return dict(idx=S, tickers=selected_tickers, avg_res_corr=cls.avg_corr(C_within,S), sum_score=float(score[S].sum()), objective=float(Jn))
L1170
L1171     # ---- 選定（スコア Series / returns だけを受ける）----
L1172 # === Output：出力整形と送信（表示・Slack） ===
L1173 class Output:
L1174
L1175     def __init__(self, debug=None):
L1176         # self.debug は使わない（互換のため引数は受けるが無視）
L1177         self.miss_df = self.g_table = self.d_table = self.io_table = self.df_metrics_fmt = se
```