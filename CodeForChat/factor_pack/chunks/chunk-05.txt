```text
ual_corr(R, n_pc=3, shrink=DRRS_SHRINK)
L895                 RESID_rho = float((C_resid.sum()-np.trace(C_resid))/(C_resid.shape[0]*(C_resid.shape[0]-1)))
L896             else: RAW_rho = RESID_rho = np.nan
L897             divy = ttm_div_yield_portfolio(ticks); metrics[name] = {'RET':ann_ret,'VOL':ann_vol,'SHP':sharpe,'MDD':drawdown,'RAWÏ':RAW_rho,'RESIDÏ':RESID_rho,'DIVY':divy}
L898         df_metrics = pd.DataFrame(metrics).T; df_metrics_pct = df_metrics.copy(); self.df_metrics = df_metrics
L899         for col in ['RET','VOL','MDD','DIVY']: df_metrics_pct[col] = df_metrics_pct[col]*100
L900         cols_order = ['RET','VOL','SHP','MDD','RAWÏ','RESIDÏ','DIVY']; df_metrics_pct = df_metrics_pct.reindex(columns=cols_order)
L901         def _fmt_row(s):
L902             return pd.Series({'RET':f"{s['RET']:.1f}%",'VOL':f"{s['VOL']:.1f}%",'SHP':f"{s['SHP']:.1f}",'MDD':f"{s['MDD']:.1f}%",'RAWÏ':(f"{s['RAWÏ']:.2f}" if pd.notna(s['RAWÏ']) else "NaN"),'RESIDÏ':(f"{s['RESIDÏ']:.2f}" if pd.notna(s['RESIDÏ']) else "NaN"),'DIVY':f"{s['DIVY']:.1f}%"})
L903         self.df_metrics_fmt = df_metrics_pct.apply(_fmt_row, axis=1); print("Performance Comparison:"); print(self.df_metrics_fmt.to_string())
L904         # === è¿½åŠ : GSC+DSC ãŒä½ã„é † TOP10 ===
L905         try:
L906             all_scores = pd.DataFrame({'GSC': df_z['GSC'], 'DSC': df_z['DSC']}).copy()
L907             all_scores['G_plus_D'] = all_scores['GSC'] + all_scores['DSC']
L908             all_scores = all_scores.dropna(subset=['G_plus_D'])
L909             self.low10_table = all_scores.sort_values('G_plus_D', ascending=True).head(10).round(3)
L910             print("Low Score Candidates (GSC+DSC bottom 10):")
L911             print(self.low10_table.to_string())
L912         except Exception as e:
L913             print(f"[warn] low-score ranking failed: {e}")
L914             self.low10_table = None
L915         self.debug_text = ""
L916         if debug_mode:
L917             logger.info("debug_mode=True: df_z dump handled in scorer; skipping factor-side debug output")
L918         else:
L919             logger.debug(
L920                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L921                 debug_mode, True
L922             )
L923         self._debug_logged = True
L924
L925     # --- Slacké€ä¿¡ï¼ˆå…ƒ notify_slack ã®ãƒ­ã‚¸ãƒƒã‚¯ãã®ã¾ã¾ï¼‰ ---
L926     def notify_slack(self):
L927         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L928
L929         if not SLACK_WEBHOOK_URL:
L930             print("âš ï¸ SLACK_WEBHOOK_URL not set (main report skipped)")
L931             return
L932
L933         def _filter_suffix_from(spec: dict, group: str) -> str:
L934             g = spec.get(group, {})
L935             parts = [str(m) for m in g.get("pre_mask", [])]
L936             for k, v in (g.get("pre_filter", {}) or {}).items():
L937                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L938                 name = {"beta": "Î²"}.get(base, base)
L939                 try:
L940                     val = f"{float(v):g}"
L941                 except Exception:
L942                     val = str(v)
L943                 parts.append(f"{name}{op}{val}")
L944             return "" if not parts else " / filter:" + " & ".join(parts)
L945
L946         def _inject_filter_suffix(title: str, group: str) -> str:
L947             suf = _filter_suffix_from(FILTER_SPEC, group)
L948             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L949
L950         def _blk(title, tbl, fmt=None, drop=()):
L951             if tbl is None or getattr(tbl, 'empty', False):
L952                 return f"{title}\n(é¸å®šãªã—)\n"
L953             if drop and hasattr(tbl, 'columns'):
L954                 keep = [c for c in tbl.columns if c not in drop]
L955                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L956             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L957
L958         message = "ğŸ“ˆ ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–ã®çµæœ\n"
L959         if self.miss_df is not None and not self.miss_df.empty:
L960             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L961         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L962         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L963         message += "Changes\n" + ("(å¤‰æ›´ãªã—)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L964         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L965
L966         try:
L967             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L968             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L969             if r is not None:
L970                 r.raise_for_status()
L971         except Exception as e:
L972             print(f"[ERR] main_post_failed: {e}")
L973
L974 def _infer_g_universe(feature_df, selected12=None, near5=None):
L975     try:
L976         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L977         if out: return out
L978     except Exception:
L979         pass
L980     base = set()
L981     for lst in (selected12 or []), (near5 or []):
L982         for x in (lst or []): base.add(x)
L983     return list(base) if base else list(feature_df.index)
L984
L985 def _fmt_with_fire_mark(tickers, feature_df):
L986     out = []
L987     for t in tickers or []:
L988         try:
L989             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L990             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L991             out.append(f"{t}{' ğŸ”¥' if (br or pb) else ''}")
L992         except Exception:
L993             out.append(t)
L994     return out
L995
L996 def _label_recent_event(t, feature_df):
L997     try:
L998         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L999         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L1000         if   br and not pb: return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼‰"
L1001         elif pb and not br: return f"{t}ï¼ˆæŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L1002         elif br and pb:     return f"{t}ï¼ˆãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®š {dbr}ï¼æŠ¼ã—ç›®åç™º {dpb}ï¼‰"
L1003     except Exception:
L1004         pass
L1005     return t
L1006
L1007 # === ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–ï¼šG/Då…±é€šãƒ•ãƒ­ãƒ¼ï¼ˆå‡ºåŠ›ã¯ä¸å¤‰ï¼‰ ===
L1008
L1009 def io_build_input_bundle() -> InputBundle:
L1010     """
L1011     æ—¢å­˜ã®ã€ãƒ‡ãƒ¼ã‚¿å–å¾—â†’å‰å‡¦ç†ã€ã‚’å®Ÿè¡Œã—ã€InputBundle ã‚’è¿”ã™ã€‚
L1012     å‡¦ç†å†…å®¹ãƒ»åˆ—åãƒ»ä¸¸ã‚ãƒ»ä¾‹å¤–ãƒ»ãƒ­ã‚°æ–‡è¨€ã¯ç¾è¡Œã©ãŠã‚Šï¼ˆå¤‰æ›´ç¦æ­¢ï¼‰ã€‚
L1013     """
L1014     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L1015     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L1016
L1017 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L1018               n_target: int) -> tuple[list, float, float, float]:
L1019     """
L1020     G/Dã‚’åŒä¸€æ‰‹é †ã§å‡¦ç†ï¼šæ¡ç‚¹â†’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼â†’é¸å®šï¼ˆç›¸é–¢ä½æ¸›è¾¼ã¿ï¼‰ã€‚
L1021     æˆ»ã‚Šå€¤ï¼š(pick, avg_res_corr, sum_score, objective)
L1022     JSONä¿å­˜ã¯æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚­ãƒ¼åãƒ»ä¸¸ã‚æ¡ãƒ»é †åºï¼‰ã‚’è¸è¥²ã€‚
L1023     """
L1024     sc.cfg = cfg
L1025
L1026     if hasattr(sc, "score_build_features"):
L1027         feat = sc.score_build_features(inb)
L1028         if not hasattr(sc, "_feat_logged"):
L1029             T.log("features built (scorer)")
L1030             sc._feat_logged = True
L1031         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L1032     else:
L1033         fb = sc.aggregate_scores(inb, cfg)
L1034         if not hasattr(sc, "_feat_logged"):
L1035             T.log("features built (scorer)")
L1036             sc._feat_logged = True
L1037         sc._feat = fb
L1038         agg = fb.g_score if group == "G" else fb.d_score_all
L1039         if group == "D" and hasattr(fb, "df"):
L1040             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L1041
L1042     if hasattr(sc, "filter_candidates"):
L1043         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1044
L1045     selector = Selector()
L1046     if hasattr(sc, "select_diversified"):
L1047         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1048             selector=selector, prev_tickers=None,
L1049             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1050             cross_mu=cfg.drrs.cross_mu_gd)
L1051     else:
L1052         if group == "G":
L1053             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1054             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1055                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1056                 lam=cfg.drrs.G.get("lam", 0.68),
L1057                 lookback=cfg.drrs.G.get("lookback", 252),
L1058                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1059         else:
L1060             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1061             g_fixed = getattr(sc, "_top_G", None)
L1062             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1063                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1064                 lam=cfg.drrs.D.get("lam", 0.85),
L1065                 lookback=cfg.drrs.D.get("lookback", 504),
L1066                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1067                 mu=cfg.drrs.cross_mu_gd)
L1068         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1069         sum_sc = res["sum_score"]; obj = res["objective"]
L1070         if group == "D":
L1071             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1072             T.log("selection finalized (G/D)")
L1073     try:
L1074         inc = [t for t in exist if t in agg.index]
L1075         pick = _sticky_keep_current(
L1076             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1077             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1078         )
L1079     except Exception as _e:
L1080         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1081     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L1082     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L1083     try:
L1084         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1085         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1086         setattr(sc, f"_near_{group}", near10)
L1087         setattr(sc, f"_agg_{group}", agg)
L1088     except Exception:
L1089         pass
L1090
L1091     if group == "D":
L1092         T.log("save done")
L1093     if group == "G":
L1094         sc._top_G = pick
L1095     return pick, avg_r, sum_sc, obj
L1096
L1097 def run_pipeline() -> SelectionBundle:
L1098     """
L1099     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1100     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1101     """
L1102     inb = io_build_input_bundle()
L1103     cfg = PipelineConfig(
L1104         weights=WeightsConfig(g=g_weights, d=D_weights),
L1105         drrs=DRRSParams(
L1106             corrM=corrM, shrink=DRRS_SHRINK,
L1107             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1108         ),
L1109         price_max=CAND_PRICE_MAX,
L1110         debug_mode=debug_mode
L1111     )
L1112     sc = Scorer()
L1113     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1114     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1115     alpha = Scorer.spx_to_alpha(inb.spx)
L1116     sectors = {t:(inb.info
```