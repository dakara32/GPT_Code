```text
  logger.debug(
L841                 "skip debug log: debug_mode=%s debug_text_empty=%s",
L842                 debug_mode, not bool((self.debug_text or '').strip())
L843             )
L844             self._debug_logged = True
L845
L846     # --- Slack送信（元 notify_slack のロジックそのまま） ---
L847     def notify_slack(self):
L848         SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L849
L850         if not SLACK_WEBHOOK_URL:
L851             print("⚠️ SLACK_WEBHOOK_URL not set (main report skipped)")
L852             return
L853
L854         def _filter_suffix_from(spec: dict, group: str) -> str:
L855             g = spec.get(group, {})
L856             parts = [str(m) for m in g.get("pre_mask", [])]
L857             for k, v in (g.get("pre_filter", {}) or {}).items():
L858                 base, op = (k[:-4], "<") if k.endswith("_max") else ((k[:-4], ">") if k.endswith("_min") else (k, "="))
L859                 name = {"beta": "β"}.get(base, base)
L860                 try:
L861                     val = f"{float(v):g}"
L862                 except Exception:
L863                     val = str(v)
L864                 parts.append(f"{name}{op}{val}")
L865             return "" if not parts else " / filter:" + " & ".join(parts)
L866
L867         def _inject_filter_suffix(title: str, group: str) -> str:
L868             suf = _filter_suffix_from(FILTER_SPEC, group)
L869             return f"{title[:-1]}{suf}]" if suf and title.endswith("]") else (title + suf)
L870
L871         def _blk(title, tbl, fmt=None, drop=()):
L872             if tbl is None or getattr(tbl, 'empty', False):
L873                 return f"{title}\n(選定なし)\n"
L874             if drop and hasattr(tbl, 'columns'):
L875                 keep = [c for c in tbl.columns if c not in drop]
L876                 tbl, fmt = tbl[keep], {k: v for k, v in (fmt or {}).items() if k in keep}
L877             return f"{title}\n```{tbl.to_string(formatters=fmt)}```\n"
L878
L879         message = "📈 ファクター分散最適化の結果\n"
L880         if self.miss_df is not None and not self.miss_df.empty:
L881             message += "Missing Data\n```" + self.miss_df.to_string(index=False) + "```\n"
L882         message += _blk(_inject_filter_suffix(self.g_title, "G"), self.g_table, self.g_formatters, drop=("TRD",))
L883         message += _blk(_inject_filter_suffix(self.d_title, "D"), self.d_table, self.d_formatters)
L884         message += "Changes\n" + ("(変更なし)\n" if self.io_table is None or getattr(self.io_table, 'empty', False) else f"```{self.io_table.to_string(index=False)}```\n")
L885         message += "Performance Comparison:\n```" + self.df_metrics_fmt.to_string() + "```"
L886
L887         try:
L888             r = requests.post(SLACK_WEBHOOK_URL, json={"text": message})
L889             print(f"[DBG] main_post status={getattr(r, 'status_code', None)} size={len(message)}")
L890             if r is not None:
L891                 r.raise_for_status()
L892         except Exception as e:
L893             print(f"[ERR] main_post_failed: {e}")
L894
L895 def _infer_g_universe(feature_df, selected12=None, near5=None):
L896     try:
L897         out = feature_df.index[feature_df['group'].astype(str).str.upper().eq('G')].tolist()
L898         if out: return out
L899     except Exception:
L900         pass
L901     base = set()
L902     for lst in (selected12 or []), (near5 or []):
L903         for x in (lst or []): base.add(x)
L904     return list(base) if base else list(feature_df.index)
L905
L906 def _fmt_with_fire_mark(tickers, feature_df):
L907     out = []
L908     for t in tickers or []:
L909         try:
L910             br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"])
L911             pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"])
L912             out.append(f"{t}{' 🔥' if (br or pb) else ''}")
L913         except Exception:
L914             out.append(t)
L915     return out
L916
L917 def _label_recent_event(t, feature_df):
L918     try:
L919         br = bool(feature_df.at[t, "G_BREAKOUT_recent_5d"]); dbr = str(feature_df.at[t, "G_BREAKOUT_last_date"]) if br else ""
L920         pb = bool(feature_df.at[t, "G_PULLBACK_recent_5d"]); dpb = str(feature_df.at[t, "G_PULLBACK_last_date"]) if pb else ""
L921         if   br and not pb: return f"{t}（ブレイクアウト確定 {dbr}）"
L922         elif pb and not br: return f"{t}（押し目反発 {dpb}）"
L923         elif br and pb:     return f"{t}（ブレイクアウト確定 {dbr}／押し目反発 {dpb}）"
L924     except Exception:
L925         pass
L926     return t
L927
L928 # === パイプライン可視化：G/D共通フロー（出力は不変） ===
L929
L930 def io_build_input_bundle() -> InputBundle:
L931     """
L932     既存の『データ取得→前処理』を実行し、InputBundle を返す。
L933     処理内容・列名・丸め・例外・ログ文言は現行どおり（変更禁止）。
L934     """
L935     state = Input(cand=cand, exist=exist, bench=bench, price_max=CAND_PRICE_MAX, finnhub_api_key=FINNHUB_API_KEY).prepare_data()
L936     return InputBundle(cand=state["cand"], tickers=state["tickers"], bench=bench, data=state["data"], px=state["px"], spx=state["spx"], tickers_bulk=state["tickers_bulk"], info=state["info"], eps_df=state["eps_df"], fcf_df=state["fcf_df"], returns=state["returns"])
L937
L938 def run_group(sc: Scorer, group: str, inb: InputBundle, cfg: PipelineConfig,
L939               n_target: int) -> tuple[list, float, float, float]:
L940     """
L941     G/Dを同一手順で処理：採点→フィルター→選定（相関低減込み）。
L942     戻り値：(pick, avg_res_corr, sum_score, objective)
L943     JSON保存は既存フォーマット（キー名・丸め桁・順序）を踏襲。
L944     """
L945     sc.cfg = cfg
L946
L947     if hasattr(sc, "score_build_features"):
L948         feat = sc.score_build_features(inb)
L949         if not hasattr(sc, "_feat_logged"):
L950             T.log("features built (scorer)")
L951             sc._feat_logged = True
L952         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L953     else:
L954         fb = sc.aggregate_scores(inb, cfg)
L955         if not hasattr(sc, "_feat_logged"):
L956             T.log("features built (scorer)")
L957             sc._feat_logged = True
L958         sc._feat = fb
L959         agg = fb.g_score if group == "G" else fb.d_score_all
L960         if group == "D" and hasattr(fb, "df"):
L961             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L962
L963     if hasattr(sc, "filter_candidates"):
L964         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L965
L966     selector = Selector()
L967     if hasattr(sc, "select_diversified"):
L968         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L969             selector=selector, prev_tickers=None,
L970             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L971             cross_mu=cfg.drrs.cross_mu_gd)
L972     else:
L973         if group == "G":
L974             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L975             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L976                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L977                 lam=cfg.drrs.G.get("lam", 0.68),
L978                 lookback=cfg.drrs.G.get("lookback", 252),
L979                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L980         else:
L981             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L982             g_fixed = getattr(sc, "_top_G", None)
L983             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L984                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L985                 lam=cfg.drrs.D.get("lam", 0.85),
L986                 lookback=cfg.drrs.D.get("lookback", 504),
L987                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L988                 mu=cfg.drrs.cross_mu_gd)
L989         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L990         sum_sc = res["sum_score"]; obj = res["objective"]
L991         if group == "D":
L992             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L993             T.log("selection finalized (G/D)")
L994     try:
L995         inc = [t for t in exist if t in agg.index]
L996         pick = _sticky_keep_current(
L997             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L998             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L999         )
L1000     except Exception as _e:
L1001         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1002     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L1003     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L1004     try:
L1005         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1006         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1007         setattr(sc, f"_near_{group}", near10)
L1008         setattr(sc, f"_agg_{group}", agg)
L1009     except Exception:
L1010         pass
L1011
L1012     if group == "D":
L1013         T.log("save done")
L1014     if group == "G":
L1015         sc._top_G = pick
L1016     return pick, avg_r, sum_sc, obj
L1017
L1018 def run_pipeline() -> SelectionBundle:
L1019     """
L1020     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L1021     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L1022     """
L1023     inb = io_build_input_bundle()
L1024     cfg = PipelineConfig(weights=WeightsConfig(g=g_weights, d=D_weights),
L1025         drrs=DRRSParams(corrM=corrM, shrink=DRRS_SHRINK,
L1026                          G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD),
L1027         price_max=CAND_PRICE_MAX)
L1028     sc = Scorer()
L1029     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1030     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L1031     alpha = Scorer.spx_to_alpha(inb.spx)
L1032     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1033     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1034     sc._top_G = top_G
L1035     try:
L1036         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L1037         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1038     except Exception:
L1039         pass
L1040     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1041     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1042     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1043     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1044     fb = getattr(sc, "_feat", None)
L1045     near_G = getattr(sc, "_near_G", [])
L1046     selected12 = list(top_G)
L1047     df = fb.df if fb is not None else pd.DataFrame()
L1048     guni = _infer_g_universe(df, selected12, near_G)
L1049     try:
L1050         fire_recent = [t for t in guni
L1051                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1052                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1053     except Exception: fire_recent = []
L1054
L1055     lines = [
L1056         "【G枠レポート｜週次モニタ（直近5営業日）】",
L1057         "【凡例】🔥=直近5営業日内に「ブレイクアウト確定」または「押し目反発」を検知",
L1058         f"選定{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"選定{N_G}: なし",
L1059         f"次点10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "次点10: なし",]
L1060
L1061     if fire_recent:
L1062         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1063         lines.append(f"過去5営業日の検知: {fire_list}")
L1064     else:
L1065         lines.append("過去5営業日の検知: なし")
L1066
L1067     try:
L1068         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1069         if webhook:
L1070             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1071     except Exception:
L1072         pass
L1073
L1074     out = Output()
L1075     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1076     try: ou
```