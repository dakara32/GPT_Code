```text
     sc.cfg = cfg
L856
L857     if hasattr(sc, "score_build_features"):
L858         feat = sc.score_build_features(inb)
L859         if not hasattr(sc, "_feat_logged"):
L860             T.log("features built (scorer)")
L861             sc._feat_logged = True
L862         agg = sc.score_aggregate(feat, group, cfg) if hasattr(sc, "score_aggregate") else feat
L863     else:
L864         fb = sc.aggregate_scores(inb, cfg)
L865         if not hasattr(sc, "_feat_logged"):
L866             T.log("features built (scorer)")
L867             sc._feat_logged = True
L868         sc._feat = fb
L869         agg = fb.g_score if group == "G" else fb.d_score_all
L870         if group == "D" and hasattr(fb, "df"):
L871             agg = agg[fb.df['BETA'] < D_BETA_MAX]
L872
L873     if hasattr(sc, "filter_candidates"):
L874         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L875
L876     selector = Selector()
L877     if hasattr(sc, "select_diversified"):
L878         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L879             selector=selector, prev_tickers=None,
L880             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L881             cross_mu=cfg.drrs.cross_mu_gd)
L882     else:
L883         if group == "G":
L884             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L885             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L886                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L887                 lam=cfg.drrs.G.get("lam", 0.68),
L888                 lookback=cfg.drrs.G.get("lookback", 252),
L889                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L890         else:
L891             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L892             g_fixed = getattr(sc, "_top_G", None)
L893             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L894                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L895                 lam=cfg.drrs.D.get("lam", 0.85),
L896                 lookback=cfg.drrs.D.get("lookback", 504),
L897                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L898                 mu=cfg.drrs.cross_mu_gd)
L899         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L900         sum_sc = res["sum_score"]; obj = res["objective"]
L901         if group == "D":
L902             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L903             T.log("selection finalized (G/D)")
L904     try:
L905         inc = [t for t in exist if t in agg.index]
L906         pick = _sticky_keep_current(
L907             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L908             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L909         )
L910     except Exception as _e:
L911         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L912     # --- Near-Miss: æƒœã—ãã‚‚é¸ã°ã‚Œãªã‹ã£ãŸä¸Šä½10ã‚’ä¿æŒï¼ˆSlackè¡¨ç¤ºç”¨ï¼‰ ---
L913     # 5) Near-Miss ã¨æœ€çµ‚é›†è¨ˆSeriesã‚’ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ã€‚è¨ˆç®—ã¸å½±éŸ¿ãªã—ï¼‰
L914     try:
L915         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L916         near10 = list(pool.sort_values(ascending=False).head(10).index)
L917         setattr(sc, f"_near_{group}", near10)
L918         setattr(sc, f"_agg_{group}", agg)
L919     except Exception:
L920         pass
L921
L922     if group == "D":
L923         T.log("save done")
L924     if group == "G":
L925         sc._top_G = pick
L926     return pick, avg_r, sum_sc, obj
L927
L928 def run_pipeline() -> SelectionBundle:
L929     """
L930     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L931     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L932     """
L933     inb = io_build_input_bundle()
L934     cfg = PipelineConfig(
L935         weights=WeightsConfig(g=g_weights, d=D_weights),
L936         drrs=DRRSParams(
L937             corrM=corrM, shrink=DRRS_SHRINK,
L938             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L939         ),
L940         price_max=CAND_PRICE_MAX,
L941         debug_mode=debug_mode
L942     )
L943     sc = Scorer()
L944     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L945     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False).index)
L946     alpha = Scorer.spx_to_alpha(inb.spx)
L947     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L948     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L949     sc._top_G = top_G
L950     try:
L951         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).sort_values(ascending=False)
L952         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L953     except Exception:
L954         pass
L955     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L956     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L957     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L958     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L959     fb = getattr(sc, "_feat", None)
L960     near_G = getattr(sc, "_near_G", [])
L961     selected12 = list(top_G)
L962     df = fb.df if fb is not None else pd.DataFrame()
L963     guni = _infer_g_universe(df, selected12, near_G)
L964     try:
L965         fire_recent = [t for t in guni
L966                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L967                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L968     except Exception: fire_recent = []
L969
L970     lines = [
L971         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L972         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L973         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L974         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L975
L976     if fire_recent:
L977         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L978         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L979     else:
L980         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L981
L982     try:
L983         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L984         if webhook:
L985             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L986     except Exception:
L987         pass
L988
L989     out = Output()
L990     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L991     try: out._sc = sc
L992     except Exception: pass
L993     if hasattr(sc, "_feat"):
L994         try:
L995             fb = sc._feat
L996             out.miss_df = fb.missing_logs
L997             out.display_results(
L998                 exist=exist,
L999                 bench=bench,
L1000                 df_z=fb.df_z,
L1001                 g_score=fb.g_score,
L1002                 d_score_all=fb.d_score_all,
L1003                 init_G=top_G,
L1004                 init_D=top_D,
L1005                 top_G=top_G,
L1006                 top_D=top_D,
L1007                 df_full_z=getattr(fb, "df_full_z", None),
L1008                 prev_G=getattr(sc, "_prev_G", exist),
L1009                 prev_D=getattr(sc, "_prev_D", exist),
L1010             )
L1011         except Exception:
L1012             pass
L1013     out.notify_slack()
L1014     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1015               "sum_score": sumG, "objective": objG},
L1016         resD={"tickers": top_D, "avg_res_corr": avgD,
L1017               "sum_score": sumD, "objective": objD},
L1018         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1019
L1020     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1021     try:
L1022         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1023               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1024               .sort_values("G_plus_D")
L1025               .head(10)
L1026               .round(3))
L1027         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1028         _post_slack({"text": f"```{low_msg}```"})
L1029     except Exception as _e:
L1030         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1031
L1032     return sb
L1033
L1034 if __name__ == "__main__":
L1035     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #
L26 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L27 # =============================================================================
L28
L29 import logging
L30 import os, sys, warnings
L31 import requests
L32 import numpy as np
L33 import pandas as pd
L34 import yfinance as yf
L35 from typing import Any, TYPE_CHECKING
L36 from scipy.stats import zscore
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L40
L41 logger = logging.getLogger(__name__)
L42
L43 # ---- Dividend Helpers -------------------------------------------------------
L44 def _last_close(t, price_map=None):
L45     if price_map and (c := price_map.get(t)) is not None: return float(c)
L46     try:
L47         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L48         return float(h.iloc[-1]) if len(h) else np.nan
L49     except Exception:
L50         return np.nan
L51
L52 def _ttm_div_sum(t, lookback_days=400):
L53     try:
L54         div = yf.Ticker(t).dividends
L55         if div is None or len(div) == 0: return 0.0
L56         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L57         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L58         return ttm if ttm > 0 else float(div.tail(4).sum())
L59     except Exception:
L60         return 0.0
L61
L62 def ttm_div_yield_portfolio(tickers, price_map=None):
L63     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L64     return float(np.mean(ys)) if ys else 0.0
L65
L66 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L67 def winsorize_s(s: pd.Series, p=0.02):
L68     if s is None or s.dropna().empty: return s
L69     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L70
L71 def robust_z(s: pd.Series, p=0.02):
L72     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L73
L74 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L75     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L76     if s is None:
L77         return pd.Series(dtype=float)
L78     v = pd.to_numeric(s, errors="coerce")
L79     m = np.nanmedian(v)
L80     mad = np.nanmedian(np.abs(v - m))
L81     z = (v - m) / (1
```