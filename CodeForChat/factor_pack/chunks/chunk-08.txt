```text
an(skipna=True)),
L1643                     float(beta_raw.std(skipna=True, ddof=0)),
L1644                 )
L1645             except Exception:
L1646                 pass
L1647
L1648     if hasattr(sc, "filter_candidates"):
L1649         agg = agg[sc.filter_candidates(inb, agg, group, cfg)]
L1650
L1651     if isinstance(agg, pd.Series):
L1652         agg = _as_numeric_series(agg)
L1653
L1654     selector = Selector()
L1655     if hasattr(sc, "select_diversified"):
L1656         pick, avg_r, sum_sc, obj = sc.select_diversified(agg, group, cfg, n_target,
L1657             selector=selector, prev_tickers=None,
L1658             corrM=cfg.drrs.corrM, shrink=cfg.drrs.shrink,
L1659             cross_mu=cfg.drrs.cross_mu_gd)
L1660     else:
L1661         if group == "G":
L1662             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1663             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1664                 n_pc=cfg.drrs.G.get("n_pc", 3), gamma=cfg.drrs.G.get("gamma", 1.2),
L1665                 lam=cfg.drrs.G.get("lam", 0.68),
L1666                 lookback=cfg.drrs.G.get("lookback", 252),
L1667                 shrink=cfg.drrs.shrink, g_fixed_tickers=None, mu=0.0)
L1668         else:
L1669             init = agg.nlargest(min(cfg.drrs.corrM, len(agg))).index.tolist()
L1670             g_fixed = getattr(sc, "_top_G", None)
L1671             res = selector.select_bucket_drrs(returns_df=inb.returns, score_ser=agg, pool_tickers=init, k=n_target,
L1672                 n_pc=cfg.drrs.D.get("n_pc", 4), gamma=cfg.drrs.D.get("gamma", 0.8),
L1673                 lam=cfg.drrs.D.get("lam", 0.85),
L1674                 lookback=cfg.drrs.D.get("lookback", 504),
L1675                 shrink=cfg.drrs.shrink, g_fixed_tickers=g_fixed,
L1676                 mu=cfg.drrs.cross_mu_gd)
L1677         pick = res["tickers"]; avg_r = res["avg_res_corr"]
L1678         sum_sc = res["sum_score"]; obj = res["objective"]
L1679         if group == "D":
L1680             _, pick = _disjoint_keepG(getattr(sc, "_top_G", []), pick, init)
L1681             T.log("selection finalized (G/D)")
L1682     try:
L1683         inc = [t for t in exist if t in agg.index]
L1684         pick = _sticky_keep_current(
L1685             agg=agg, pick=pick, incumbents=inc, n_target=n_target,
L1686             delta_z=SWAP_DELTA_Z, keep_buffer=SWAP_KEEP_BUFFER
L1687         )
L1688     except Exception as _e:
L1689         print(f"[warn] sticky_keep_current skipped: {str(_e)}")
L1690     # --- Near-Miss: 惜しくも選ばれなかった上位10を保持（Slack表示用） ---
L1691     # 5) Near-Miss と最終集計Seriesを保持（表示専用。計算へ影響なし）
L1692     try:
L1693         pool = agg.drop(index=[t for t in pick if t in agg.index], errors="ignore")
L1694         near10 = list(pool.sort_values(ascending=False).head(10).index)
L1695         setattr(sc, f"_near_{group}", near10)
L1696         setattr(sc, f"_agg_{group}", agg)
L1697     except Exception:
L1698         pass
L1699
L1700     if group == "D":
L1701         T.log("save done")
L1702     if group == "G":
L1703         sc._top_G = pick
L1704     return pick, avg_r, sum_sc, obj
L1705
L1706 def run_pipeline() -> SelectionBundle:
L1707     """
L1708     G/D共通フローの入口。I/Oはここだけで実施し、計算はScorerに委譲。
L1709     Slack文言・丸め・順序は既存の Output を用いて変更しない。
L1710     """
L1711     inb = io_build_input_bundle()
L1712     cfg = PipelineConfig(
L1713         weights=WeightsConfig(g=g_weights, d=D_weights),
L1714         drrs=DRRSParams(
L1715             corrM=corrM, shrink=DRRS_SHRINK,
L1716             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1717         ),
L1718         price_max=CAND_PRICE_MAX,
L1719         debug_mode=debug_mode
L1720     )
L1721     sc = Scorer()
L1722     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1723     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False).index)
L1724     alpha = Scorer.spx_to_alpha(inb.spx)
L1725     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1726     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1727     sc._top_G = top_G
L1728     try:
L1729         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False)
L1730         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1731     except Exception:
L1732         pass
L1733     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1734     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1735     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1736     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1737     fb = getattr(sc, "_feat", None)
L1738     out = Output()
L1739     # 表示側から選定時の集計へアクセスできるように保持（表示専用・副作用なし）
L1740     try:
L1741         out._sc = sc
L1742     except Exception:
L1743         pass
L1744     if hasattr(sc, "_feat"):
L1745         try:
L1746             fb = sc._feat
L1747             out.miss_df = fb.missing_logs
L1748             out.display_results(
L1749                 exist=exist,
L1750                 bench=bench,
L1751                 df_raw=fb.df,
L1752                 df_z=fb.df_z,
L1753                 g_score=fb.g_score,
L1754                 d_score_all=fb.d_score_all,
L1755                 init_G=top_G,
L1756                 init_D=top_D,
L1757                 top_G=top_G,
L1758                 top_D=top_D,
L1759                 df_full_z=getattr(fb, "df_full_z", None),
L1760                 prev_G=getattr(sc, "_prev_G", exist),
L1761                 prev_D=getattr(sc, "_prev_D", exist),
L1762             )
L1763             try:
L1764                 DBG_COLS = ["GSC", "GROWTH_F", "MOM", "VOL", "DBGRW.GROWTH_F", "DBGRW.MOM", "DBGRW.VOL"]
L1765                 cols = [c for c in DBG_COLS if c in fb.df_z.columns]
L1766                 idx = [t for t in top_G if t in fb.df_z.index]
L1767                 out.debug_table = fb.df_z.loc[idx, cols].round(2) if idx and cols else None
L1768             except Exception:
L1769                 out.debug_table = None
L1770         except Exception:
L1771             pass
L1772     out.notify_slack()
L1773     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1774               "sum_score": sumG, "objective": objG},
L1775         resD={"tickers": top_D, "avg_res_corr": avgD,
L1776               "sum_score": sumD, "objective": objD},
L1777         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1778
L1779     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1780     try:
L1781         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1782               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1783               .sort_values("G_plus_D")
L1784               .head(10)
L1785               .round(3))
L1786         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1787         _post_slack({"text": f"```{low_msg}```"})
L1788     except Exception as _e:
L1789         _post_slack({"text": f"```Low Score Candidates: 作成失敗: {_e}```"})
L1790
L1791     return sb
L1792
L1793 if __name__ == "__main__":
L1794     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ファクター/指標の生成と合成スコア算出を担う純粋層
L5 #
L6 # 【このファイルだけ読めば分かるポイント】
L7 # - 入力(InputBundle)は「価格/出来高/ベンチ/基本情報/EPS/FCF/リターン」を含むDTO
L8 # - 出力(FeatureBundle)は「raw特徴量 df」「標準化 df_z」「G/D スコア」「欠損ログ」
L9 # - 重み等のコンフィグ(PipelineConfig)は factor から渡す（cfg 必須）
L10 # - 旧カラム名は Scorer 内で自動リネームして受け入れ（後方互換）
L11 #   例) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # 【I/O契約（Scorerが参照するInputBundleフィールド）】
L14 #   - cand: List[str]    … 候補銘柄（単体実行では未使用）
L15 #   - tickers: List[str] … 対象銘柄リスト
L16 #   - bench: str         … ベンチマークティッカー（例 '^GSPC'）
L17 #   - data: pd.DataFrame … yfinance download結果 ('Close','Volume' 等の階層列)
L18 #   - px: pd.DataFrame   … data['Close'] 相当（終値）
L19 #   - spx: pd.Series     … ベンチマークの終値
L20 #   - tickers_bulk: object         … yfinance.Tickers
L21 #   - info: Dict[str, dict]        … yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         … 必須列: EPS_TTM, EPS_Q_LastQ（旧名も可）
L23 #   - fcf_df: pd.DataFrame         … 必須列: FCF_TTM（旧名も可）
L24 #   - returns: pd.DataFrame        … px[tickers].pct_change() 相当
L25 #   - missing_logs: pd.DataFrame   … 補完後の欠損ログ
L26 #
L27 # ※入出力の形式・例外文言は既存実装を変えません（安全な短縮のみ）
L28 # =============================================================================
L29
L30 import json, logging, os, requests, sys, warnings
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36 from datetime import datetime as _dt
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # 実行時importなし（循環回避）
L40
L41 logger = logging.getLogger(__name__)
L42
L43
L44 def _log(stage, msg):
L45     try:
L46         print(f"[DBG][{_dt.utcnow().isoformat(timespec='seconds')}Z][{stage}] {msg}")
L47     except Exception:
L48         print(f"[DBG][{stage}] {msg}")
L49
L50
L51 # ---- Dividend Helpers -------------------------------------------------------
L52 def _last_close(t, price_map=None):
L53     if price_map and (c := price_map.get(t)) is not None: return float(c)
L54     try:
L55         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L56         return float(h.iloc[-1]) if len(h) else np.nan
L57     except Exception:
L58         return np.nan
L59
L60 def _ttm_div_sum(t, lookback_days=400):
L61     try:
L62         div = yf.Ticker(t).dividends
L63         if div is None or len(div) == 0: return 0.0
L64         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L65         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L66         return ttm if ttm > 0 else float(div.tail(4).sum())
L67     except Exception:
L68         return 0.0
L69
L70 def ttm_div_yield_portfolio(tickers, price_map=None):
L71     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L72     return float(np.mean(ys)) if ys else 0.0
L73
L74 # ---- 簡易ユーティリティ（安全な短縮のみ） -----------------------------------
L75 def _as_numeric_series(s: pd.Series) -> pd.Series:
L76     """Series を float dtype に強制変換し、index を保持する。"""
L77     if s is None:
L78         return pd.Series(dtype=float)
L79     v = pd.to_numeric(s, errors="coerce")
L80     return pd.Series(v.values, index=getattr(s, "index", None), dtype=float, name=getattr(s, "name", None))
L81
L82
L83 def _plain_zscore_series(s: pd.Series) -> pd.Series:
L84     v = pd.to_numeric(s, errors="coerce")
L85     mean = v.mean(skipna=True)
L86     std = v.std(skipna=True, ddof=0)
L87     if not np.isfinite(std) or std == 0:
L88         return pd.Series(index=v.index, dtype=float)
L89     out = (v - mean) / std
L90     return pd.Series(out.values, index=v.index, dtype=float)
L91
L92
L93 def _scalar(x):
L94     """
L95     入力を安全に float スカラへ変換する。
L96
L97     許容する入力パターン:
L98       - pandas.Series: 非NaNの最後の値を採用
L99       - numpy スカラ/配列: 最後の要素を採用
L100       - その他の数値っぽい値: float へ変換
L101
L102     変換できない場合は np.nan を返す。
L103     """
L104
L105     if x is None:
L106         return np.nan
L107
L108     # pandas.Series の場合は非NaNの最後の値を採用
L109     if isinstance(x, pd.Series):
L110         s = pd.to_numeric(x, errors="coerce").dropna()
L111         return float(s.iloc[-1]) if not s.empty else np.nan
L112
L113     # numpy スカラ (item() を持つ) ※文字列は除外
L114     if hasattr(x, "item") and not isinstance(x, (str, bytes)):
L115         try:
L116             return float(x.item())
L117         except Exception:
L118             pass
L119
L120     # 配列様のオブジェクト
L121     try:
L122        
```