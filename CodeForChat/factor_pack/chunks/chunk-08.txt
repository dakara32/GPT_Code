```text
        T.log("save done")
L1616     if group == "G":
L1617         sc._top_G = pick
L1618     return pick, avg_r, sum_sc, obj
L1619
L1620 def run_pipeline() -> SelectionBundle:
L1621     """
L1622     G/Då…±é€šãƒ•ãƒ­ãƒ¼ã®å…¥å£ã€‚I/Oã¯ã“ã“ã ã‘ã§å®Ÿæ–½ã—ã€è¨ˆç®—ã¯Scorerã«å§”è­²ã€‚
L1623     Slackæ–‡è¨€ãƒ»ä¸¸ã‚ãƒ»é †åºã¯æ—¢å­˜ã® Output ã‚’ç”¨ã„ã¦å¤‰æ›´ã—ãªã„ã€‚
L1624     """
L1625     inb = io_build_input_bundle()
L1626     cfg = PipelineConfig(
L1627         weights=WeightsConfig(g=g_weights, d=D_weights),
L1628         drrs=DRRSParams(
L1629             corrM=corrM, shrink=DRRS_SHRINK,
L1630             G=DRRS_G, D=DRRS_D, cross_mu_gd=CROSS_MU_GD
L1631         ),
L1632         price_max=CAND_PRICE_MAX,
L1633         debug_mode=debug_mode
L1634     )
L1635     sc = Scorer()
L1636     top_G, avgG, sumG, objG = run_group(sc, "G", inb, cfg, N_G)
L1637     poolG = list(getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False).index)
L1638     alpha = Scorer.spx_to_alpha(inb.spx)
L1639     sectors = {t:(inb.info.get(t,{}).get("sector") or "U") for t in poolG}; scores = {t:Scorer.g_score.get(t,0.0) for t in poolG}
L1640     top_G = Scorer.pick_top_softcap(scores, sectors, N=N_G, cap=2, alpha=alpha, hard=5)
L1641     sc._top_G = top_G
L1642     try:
L1643         aggG = getattr(sc, "_agg_G", pd.Series(dtype=float)).dropna().sort_values(ascending=False)
L1644         sc._near_G = [t for t in aggG.index if t not in set(top_G)][:10]
L1645     except Exception:
L1646         pass
L1647     base = sum(Scorer.g_score.get(t,0.0) for t in poolG[:N_G])
L1648     effs = sum(Scorer.g_score.get(t,0.0) for t in top_G)
L1649     print(f"[soft_cap2] score_cost={(base-effs)/max(1e-9,abs(base)):.2%}, alpha={alpha:.3f}")
L1650     top_D, avgD, sumD, objD = run_group(sc, "D", inb, cfg, N_D)
L1651     poolD = list(getattr(sc, "_agg_D", pd.Series(dtype=float)).dropna().sort_values(ascending=False).index)
L1652     fb = getattr(sc, "_feat", None)
L1653     near_G = getattr(sc, "_near_G", [])
L1654     selected12 = list(top_G)
L1655     df = fb.df if fb is not None else pd.DataFrame()
L1656     guni = _infer_g_universe(df, selected12, near_G)
L1657     try:
L1658         fire_recent = [t for t in guni
L1659                        if (str(df.at[t, "G_BREAKOUT_recent_5d"]) == "True") or
L1660                           (str(df.at[t, "G_PULLBACK_recent_5d"]) == "True")]
L1661     except Exception: fire_recent = []
L1662
L1663     lines = [
L1664         "ã€Gæ ãƒ¬ãƒãƒ¼ãƒˆï½œé€±æ¬¡ãƒ¢ãƒ‹ã‚¿ï¼ˆç›´è¿‘5å–¶æ¥­æ—¥ï¼‰ã€‘",
L1665         "ã€å‡¡ä¾‹ã€‘ğŸ”¥=ç›´è¿‘5å–¶æ¥­æ—¥å†…ã«ã€Œãƒ–ãƒ¬ã‚¤ã‚¯ã‚¢ã‚¦ãƒˆç¢ºå®šã€ã¾ãŸã¯ã€ŒæŠ¼ã—ç›®åç™ºã€ã‚’æ¤œçŸ¥",
L1666         f"é¸å®š{N_G}: {', '.join(_fmt_with_fire_mark(selected12, df))}" if selected12 else f"é¸å®š{N_G}: ãªã—",
L1667         f"æ¬¡ç‚¹10: {', '.join(_fmt_with_fire_mark(near_G, df))}" if near_G else "æ¬¡ç‚¹10: ãªã—",]
L1668
L1669     if fire_recent:
L1670         fire_list = ", ".join([_label_recent_event(t, df) for t in fire_recent])
L1671         lines.append(f"éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: {fire_list}")
L1672     else:
L1673         lines.append("éå»5å–¶æ¥­æ—¥ã®æ¤œçŸ¥: ãªã—")
L1674
L1675     try:
L1676         webhook = os.environ.get("SLACK_WEBHOOK_URL", "")
L1677         if webhook:
L1678             requests.post(webhook, json={"text": "\n".join([s for s in lines if s != ""])}, timeout=10)
L1679     except Exception:
L1680         pass
L1681
L1682     out = Output()
L1683     # è¡¨ç¤ºå´ã‹ã‚‰é¸å®šæ™‚ã®é›†è¨ˆã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ä¿æŒï¼ˆè¡¨ç¤ºå°‚ç”¨ãƒ»å‰¯ä½œç”¨ãªã—ï¼‰
L1684     try:
L1685         out._sc = sc
L1686     except Exception:
L1687         pass
L1688     if hasattr(sc, "_feat"):
L1689         try:
L1690             fb = sc._feat
L1691             out.miss_df = fb.missing_logs
L1692             out.display_results(
L1693                 exist=exist,
L1694                 bench=bench,
L1695                 df_z=fb.df_z,
L1696                 g_score=fb.g_score,
L1697                 d_score_all=fb.d_score_all,
L1698                 init_G=top_G,
L1699                 init_D=top_D,
L1700                 top_G=top_G,
L1701                 top_D=top_D,
L1702                 df_full_z=getattr(fb, "df_full_z", None),
L1703                 prev_G=getattr(sc, "_prev_G", exist),
L1704                 prev_D=getattr(sc, "_prev_D", exist),
L1705             )
L1706             try:
L1707                 DBG_COLS = ["GSC", "GROWTH_F", "MOM", "VOL", "DBGRW.GROWTH_F", "DBGRW.MOM", "DBGRW.VOL"]
L1708                 cols = [c for c in DBG_COLS if c in fb.df_z.columns]
L1709                 idx = [t for t in top_G if t in fb.df_z.index]
L1710                 out.debug_table = fb.df_z.loc[idx, cols].round(2) if idx and cols else None
L1711             except Exception:
L1712                 out.debug_table = None
L1713         except Exception:
L1714             pass
L1715     out.notify_slack()
L1716     sb = SelectionBundle(resG={"tickers": top_G, "avg_res_corr": avgG,
L1717               "sum_score": sumG, "objective": objG},
L1718         resD={"tickers": top_D, "avg_res_corr": avgD,
L1719               "sum_score": sumD, "objective": objD},
L1720         top_G=top_G, top_D=top_D, init_G=top_G, init_D=top_D)
L1721
L1722     # --- Low Score Candidates (GSC+DSC bottom 10) : send before debug dump ---
L1723     try:
L1724         _low_df = (pd.DataFrame({"GSC": fb.g_score, "DSC": fb.d_score_all})
L1725               .assign(G_plus_D=lambda x: x["GSC"] + x["DSC"])
L1726               .sort_values("G_plus_D")
L1727               .head(10)
L1728               .round(3))
L1729         low_msg = "Low Score Candidates (GSC+DSC bottom 10)\n" + _low_df.to_string(index=True, index_names=False)
L1730         _post_slack({"text": f"```{low_msg}```"})
L1731     except Exception as _e:
L1732         _post_slack({"text": f"```Low Score Candidates: ä½œæˆå¤±æ•—: {_e}```"})
L1733
L1734     return sb
L1735
L1736 if __name__ == "__main__":
L1737     run_pipeline()
```

## <scorer.py>
```text
L1 # scorer.py
L2 # kawatest
L3 # =============================================================================
L4 # Scorer: ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼/æŒ‡æ¨™ã®ç”Ÿæˆã¨åˆæˆã‚¹ã‚³ã‚¢ç®—å‡ºã‚’æ‹…ã†ç´”ç²‹å±¤
L5 #
L6 # ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘èª­ã‚ã°åˆ†ã‹ã‚‹ãƒã‚¤ãƒ³ãƒˆã€‘
L7 # - å…¥åŠ›(InputBundle)ã¯ã€Œä¾¡æ ¼/å‡ºæ¥é«˜/ãƒ™ãƒ³ãƒ/åŸºæœ¬æƒ…å ±/EPS/FCF/ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’å«ã‚€DTO
L8 # - å‡ºåŠ›(FeatureBundle)ã¯ã€Œrawç‰¹å¾´é‡ dfã€ã€Œæ¨™æº–åŒ– df_zã€ã€ŒG/D ã‚¹ã‚³ã‚¢ã€ã€Œæ¬ æãƒ­ã‚°ã€
L9 # - é‡ã¿ç­‰ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°(PipelineConfig)ã¯ factor ã‹ã‚‰æ¸¡ã™ï¼ˆcfg å¿…é ˆï¼‰
L10 # - æ—§ã‚«ãƒ©ãƒ åã¯ Scorer å†…ã§è‡ªå‹•ãƒªãƒãƒ¼ãƒ ã—ã¦å—ã‘å…¥ã‚Œï¼ˆå¾Œæ–¹äº’æ›ï¼‰
L11 #   ä¾‹) eps_ttm -> EPS_TTM, eps_q_recent -> EPS_Q_LastQ, fcf_ttm -> FCF_TTM
L12 #
L13 # ã€I/Oå¥‘ç´„ï¼ˆScorerãŒå‚ç…§ã™ã‚‹InputBundleãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰ã€‘
L14 #   - cand: List[str]    â€¦ å€™è£œéŠ˜æŸ„ï¼ˆå˜ä½“å®Ÿè¡Œã§ã¯æœªä½¿ç”¨ï¼‰
L15 #   - tickers: List[str] â€¦ å¯¾è±¡éŠ˜æŸ„ãƒªã‚¹ãƒˆ
L16 #   - bench: str         â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚£ãƒƒã‚«ãƒ¼ï¼ˆä¾‹ '^GSPC'ï¼‰
L17 #   - data: pd.DataFrame â€¦ yfinance downloadçµæœ ('Close','Volume' ç­‰ã®éšå±¤åˆ—)
L18 #   - px: pd.DataFrame   â€¦ data['Close'] ç›¸å½“ï¼ˆçµ‚å€¤ï¼‰
L19 #   - spx: pd.Series     â€¦ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµ‚å€¤
L20 #   - tickers_bulk: object         â€¦ yfinance.Tickers
L21 #   - info: Dict[str, dict]        â€¦ yfinance info per ticker
L22 #   - eps_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: EPS_TTM, EPS_Q_LastQï¼ˆæ—§åã‚‚å¯ï¼‰
L23 #   - fcf_df: pd.DataFrame         â€¦ å¿…é ˆåˆ—: FCF_TTMï¼ˆæ—§åã‚‚å¯ï¼‰
L24 #   - returns: pd.DataFrame        â€¦ px[tickers].pct_change() ç›¸å½“
L25 #   - missing_logs: pd.DataFrame   â€¦ è£œå®Œå¾Œã®æ¬ æãƒ­ã‚°
L26 #
L27 # â€»å…¥å‡ºåŠ›ã®å½¢å¼ãƒ»ä¾‹å¤–æ–‡è¨€ã¯æ—¢å­˜å®Ÿè£…ã‚’å¤‰ãˆã¾ã›ã‚“ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰
L28 # =============================================================================
L29
L30 import json, logging, os, requests, sys, warnings
L31 import numpy as np
L32 import pandas as pd
L33 import yfinance as yf
L34 from typing import Any, TYPE_CHECKING
L35 from scipy.stats import zscore
L36 from datetime import datetime as _dt
L37
L38 if TYPE_CHECKING:
L39     from factor import PipelineConfig  # type: ignore  # å®Ÿè¡Œæ™‚importãªã—ï¼ˆå¾ªç’°å›é¿ï¼‰
L40
L41 logger = logging.getLogger(__name__)
L42
L43
L44 def _log(stage, msg):
L45     try:
L46         print(f"[DBG][{_dt.utcnow().isoformat(timespec='seconds')}Z][{stage}] {msg}")
L47     except Exception:
L48         print(f"[DBG][{stage}] {msg}")
L49
L50
L51 # ---- Dividend Helpers -------------------------------------------------------
L52 def _last_close(t, price_map=None):
L53     if price_map and (c := price_map.get(t)) is not None: return float(c)
L54     try:
L55         h = yf.Ticker(t).history(period="5d")["Close"].dropna()
L56         return float(h.iloc[-1]) if len(h) else np.nan
L57     except Exception:
L58         return np.nan
L59
L60 def _ttm_div_sum(t, lookback_days=400):
L61     try:
L62         div = yf.Ticker(t).dividends
L63         if div is None or len(div) == 0: return 0.0
L64         cutoff = pd.Timestamp.utcnow().tz_localize(None) - pd.Timedelta(days=lookback_days)
L65         ttm = float(div[div.index.tz_localize(None) >= cutoff].sum())
L66         return ttm if ttm > 0 else float(div.tail(4).sum())
L67     except Exception:
L68         return 0.0
L69
L70 def ttm_div_yield_portfolio(tickers, price_map=None):
L71     ys = [(lambda c, s: (s/c) if (np.isfinite(c) and c>0 and s>0) else 0.0)(_last_close(t, price_map), _ttm_div_sum(t)) for t in tickers]
L72     return float(np.mean(ys)) if ys else 0.0
L73
L74 # ---- ç°¡æ˜“ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆå®‰å…¨ãªçŸ­ç¸®ã®ã¿ï¼‰ -----------------------------------
L75 def _as_numeric_series(s: pd.Series) -> pd.Series:
L76     """Series ã‚’ float dtype ã«å¼·åˆ¶å¤‰æ›ã—ã€index ã‚’ä¿æŒã™ã‚‹ã€‚"""
L77     if s is None:
L78         return pd.Series(dtype=float)
L79     v = pd.to_numeric(s, errors="coerce")
L80     return pd.Series(v.values, index=getattr(s, "index", None), dtype=float, name=getattr(s, "name", None))
L81
L82
L83 def _scalar(x):
L84     """
L85     å…¥åŠ›ã‚’å®‰å…¨ã« float ã‚¹ã‚«ãƒ©ã¸å¤‰æ›ã™ã‚‹ã€‚
L86
L87     è¨±å®¹ã™ã‚‹å…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³:
L88       - pandas.Series: éNaNã®æœ€å¾Œã®å€¤ã‚’æ¡ç”¨
L89       - numpy ã‚¹ã‚«ãƒ©/é…åˆ—: æœ€å¾Œã®è¦ç´ ã‚’æ¡ç”¨
L90       - ãã®ä»–ã®æ•°å€¤ã£ã½ã„å€¤: float ã¸å¤‰æ›
L91
L92     å¤‰æ›ã§ããªã„å ´åˆã¯ np.nan ã‚’è¿”ã™ã€‚
L93     """
L94
L95     if x is None:
L96         return np.nan
L97
L98     # pandas.Series ã®å ´åˆã¯éNaNã®æœ€å¾Œã®å€¤ã‚’æ¡ç”¨
L99     if isinstance(x, pd.Series):
L100         s = pd.to_numeric(x, errors="coerce").dropna()
L101         return float(s.iloc[-1]) if not s.empty else np.nan
L102
L103     # numpy ã‚¹ã‚«ãƒ© (item() ã‚’æŒã¤) â€»æ–‡å­—åˆ—ã¯é™¤å¤–
L104     if hasattr(x, "item") and not isinstance(x, (str, bytes)):
L105         try:
L106             return float(x.item())
L107         except Exception:
L108             pass
L109
L110     # é…åˆ—æ§˜ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
L111     try:
L112         arr = np.asarray(x, dtype=float).ravel()
L113         return float(arr[-1]) if arr.size else np.nan
L114     except Exception:
L115         pass
L116
L117     # æœ€å¾Œã«ç´ ç›´ã« float å¤‰æ›ã‚’è©¦ã™
L118     try:
L119         return float(x)
L120     except Exception:
L121         return np.nan
L122
L123
L124 def winsorize_s(s: pd.Series, p=0.02):
L125     if s is None or s.dropna().empty: return s
L126     lo, hi = np.nanpercentile(s.astype(float), [100*p, 100*(1-p)]); return s.clip(lo, hi)
L127
L128 def robust_z(s: pd.Series, p=0.02):
L129     s2 = winsorize_s(s,p); return np.nan_to_num(zscore(s2.fillna(s2.mean())))
L130
L131 def robust_z_keepnan(s: pd.Series) -> pd.Series:
L132     """robust_z variant that preserves NaNs and falls back to rank-z when needed."""
L133     if s is None:
L134         return pd.Series(dtype=float)
L135     v = pd.to_numeric(s, errors="coerce")
L136     m = np.nanmedian(v)
L137     mad = np.nanmedian(np.abs(v - m))
L138     z = (v - m) / (1.4826 * mad + 1e-9)
L139     if np.nanstd(z) < 1e-9:
L140         r = v.rank(method="average", na_option="keep")
L141         z = (r - np.nanmean(r)) / (np.nanstd(r) + 1e-9)
L142     return pd.Series(z, index=v.index, dtype=float)
L143
L144
L145 def _safe_div(a, b):
L146     try: return np.nan if (b is None or float(b)==0 or pd.isna(b)) else float(a)/float(b)
L147     except Exception: return np.nan
L148
L149 def _safe_last(series: pd.Series, default=np.nan):
L150     try: return float(series.iloc[-1])
L151     except Exception: return default
L152
L153
L154 def _ensure_series(x):
L155     if x is None:
L156         return pd.Series(dtype=float)
L157     if isinstance(x, pd.Series):
L158         return x.dropna()
L159     if isinstance(x, (list, tuple)):
L160         if len(x) and isinstance(x[0], (tuple, list)) and len(x[0]) == 2:
L161             dt = pd.to_datetime([d for d, _ in x], errors="coerce")
L162             v = pd.to_numeric([_v for _, _v in x], errors="coerce")
L163             return pd.Series(v, index=dt).dropna()
L164         return pd.Series(
```