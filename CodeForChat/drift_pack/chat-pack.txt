# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-26 18:42:19 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import json
L6 import time
L7 from pathlib import Path
L8 import csv
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L12 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸš¨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21 AUDIT_PRINT_MAX = int(os.environ.get("AUDIT_PRINT_MAX", "20"))  # stdout ã«æµã™æœ¬æ—¥ã®æ˜ç´°ã®æœ€å¤§è¡Œæ•°
L22
L23
L24 def _state_file():
L25     return str(Path(RESULTS_DIR) / "breadth_state.json")
L26
L27
L28 def load_mode(default="NORMAL"):
L29     try:
L30         m = json.loads(open(_state_file()).read()).get("mode", default)
L31         return m if m in ("EMERG","CAUTION","NORMAL") else default
L32     except Exception:
L33         return default
L34
L35
L36 def save_mode(mode: str):
L37     try:
L38         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L39     except Exception:
L40         pass
L41
L42
L43 def _read_csv_list(fname):
L44     p = Path(__file__).with_name(fname)
L45     if not p.exists(): return []
L46     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L47
L48
L49 def _load_universe():
L50     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L51     exist = _read_csv_list("current_tickers.csv")
L52     cand  = _read_csv_list("candidate_tickers.csv")
L53     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L54     cand_keep = []
L55     for t in cand:
L56         try:
L57             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L58         except Exception:
L59             px = float("inf")
L60         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L61             cand_keep.append(t)
L62     tickers = sorted(set(exist + cand_keep))
L63     return exist, cand_keep, tickers
L64
L65
L66 def _fetch_prices_600d(tickers):
L67     data = yf.download(
L68         tickers + [BENCH],
L69         period="600d",
L70         auto_adjust=True,
L71         progress=False,
L72         threads=False,
L73     )
L74     close = data["Close"]
L75     px = close.dropna(how="all", axis=1).ffill(limit=2)
L76     spx = close[BENCH].reindex(px.index).ffill()
L77     return px, spx
L78
L79
L80 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L81     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L82     import numpy as np, pandas as pd
L83     if px is None or px.empty:
L84         return pd.Series(dtype=int)
L85     px = px.dropna(how="all", axis=1)
L86     if win_days and win_days > 0:
L87         px = px.tail(win_days)
L88     if px.empty:
L89         return pd.Series(dtype=int)
L90     # æ¬ æå¸å
L91     px = px.ffill(limit=2)
L92     spx = spx.reindex(px.index).ffill()
L93
L94     ma50  = px.rolling(50,  min_periods=50).mean()
L95     ma150 = px.rolling(150, min_periods=150).mean()
L96     ma200 = px.rolling(200, min_periods=200).mean()
L97
L98     tt = (px > ma150)
L99     tt &= (px > ma200)
L100     tt &= (ma150 > ma200)
L101     tt &= (ma200 - ma200.shift(21) > 0)
L102     tt &= (ma50  > ma150)
L103     tt &= (ma50  > ma200)
L104     tt &= (px    > ma50)
L105
L106     lo252 = px.rolling(252, min_periods=252).min()
L107     hi252 = px.rolling(252, min_periods=252).max()
L108     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L109     tt &= (px >= (0.75 * hi252))
L110
L111     r12  = px.divide(px.shift(252)).sub(1.0)
L112     br12 = spx.divide(spx.shift(252)).sub(1.0)
L113     r1   = px.divide(px.shift(22)).sub(1.0)
L114     br1  = spx.divide(spx.shift(22)).sub(1.0)
L115     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L116     tt &= (rs >= 0.10)
L117
L118     return tt.fillna(False).sum(axis=1).astype(int)
L119
L120
L121 def build_breadth_header():
L122     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L123     exist, cand, tickers = _load_universe()
L124     if not tickers:
L125         return "", "NORMAL", 0
L126     px, spx = _fetch_prices_600d(tickers)
L127     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L128     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L129     if C_ts.empty:
L130         return "", "NORMAL", 0
L131     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L132     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L133     C_full = int(C_ts.iloc[-1])
L134
L135     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L136     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L137     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L138
L139     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L140     N_G = config.N_G
L141     th_in_rec   = max(N_G, q05)
L142     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L143     th_norm_rec = max(3*N_G, q60)
L144
L145     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L146     if use_calib:
L147         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L148     else:
L149         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L150         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L151         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L152         th_src = "æ‰‹å‹•"
L153
L154     prev = load_mode("NORMAL")
L155     if   prev == "EMERG":
L156         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L157     elif prev == "CAUTION":
L158         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L159     else:
L160         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L161     save_mode(mode)
L162
L163     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L164     eff_days = len(base)
L165
L166     lead_lines = [
L167         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L168         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L169         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L170         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L171         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L172         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L173         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L174         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L175         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L176         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L177     ]
L178     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L179
L180
L181 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L182     growth = []
L183     for row in portfolio:
L184         bucket = str(row.get("bucket", "")).strip().upper()
L185         if bucket == "G":
L186             sym = str(row.get("symbol", "")).strip().upper()
L187             if sym:
L188                 growth.append(sym)
L189     return sorted(set(growth))
L190
L191
L192 def _combine_modes(mode_a: str, mode_b: str) -> str:
L193     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L194     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L195     for mode, rank in MODE_RANK.items():
L196         if rank == max(a, b):
L197             return mode
L198     return "NORMAL"
L199
L200
L201 def _format_mode(mode: str) -> str:
L202     upper = (mode or "NORMAL").upper()
L203     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L204
L205
L206 def _ts_mode_growth_5d(g_syms: list[str], ref_mode: str) -> tuple[str, int, set[str]]:
L207     """ç›´è¿‘5å–¶æ¥­æ—¥ã‚’æ ªä¾¡ç›´æ¥æ–¹å¼ã§ä¸€æ‹¬åˆ¤å®šï¼ˆLow vs 60D Highï¼‰ã€‚"""
L208
L209     if not g_syms:
L210         print("âš ï¸ audit: GéŠ˜æŸ„ãƒªã‚¹ãƒˆãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L211         return "NORMAL", 0, set()
L212
L213     try:
L214         df = yf.download(
L215             g_syms,
L216             period="100d",
L217             interval="1d",
L218             auto_adjust=False,
L219             progress=False,
L220         )
L221     except Exception as e:
L222         print(f"âš ï¸ audit: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L223         return "NORMAL", 0, set()
L224
L225     if not isinstance(df, pd.DataFrame) or df.empty:
L226         print("âš ï¸ audit: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L227         return "NORMAL", 0, set()
L228
L229     try:
L230         hi_all = df["High"] if "High" in df.columns else None
L231         lo_all = df["Low"] if "Low" in df.columns else None
L232     except Exception as e:
L233         print(f"âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L234         hi_all = lo_all = None
L235
L236     if hi_all is None or lo_all is None:
L237         print("âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã‚‹ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L238         return "NORMAL", 0, set()
L239
L240     if isinstance(hi_all, pd.Series):
L241         hi_all = hi_all.to_frame(name=g_syms[0])
L242     if isinstance(lo_all, pd.Series):
L243         lo_all = lo_all.to_frame(name=g_syms[0])
L244
L245     if hi_all.empty or lo_all.empty:
L246         print("âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L247         return "NORMAL", 0, set()
L248
L249     roll_hi = hi_all.rolling(60, min_periods=20).max()
L250     last5_hi = roll_hi.tail(5)
L251     last5_lo = lo_all.tail(5).reindex(last5_hi.index)
L252
L253     if last5_hi.empty or last5_lo.empty:
L254         print("âš ï¸ audit: ç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã‚ãšã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L255         return "NORMAL", 0, set()
L256
L257     base = float(config.TS_BASE_BY_MODE.get((ref_mode or "NORMAL").upper(), 0.15))
L258     uniq_hits: set[str] = set()
L259     today_hits: set[str] = set()
L260
L261     rows_today_printed = 0
L262     today_reason_flags: list[str] = []
L263     last_day = last5_hi.index[-1]
L264
L265     for dt in last5_hi.index:
L266         hi_row = last5_hi.loc[dt]
L267         lo_row = last5_lo.loc[dt]
L268         for sym in g_syms:
L269             rh = float(hi_row.get(sym, float("nan"))) if hasattr(hi_row, "get") else float("nan")
L270             lt = float(lo_row.get(sym, float("nan"))) if hasattr(lo_row, "get") else float("nan")
L271
L272             if not (pd.notna(rh) and rh > 0):
L273                 if dt == last_day:
L274                     today_reason_flags.append("H60æ¬ æ")
L275                 continue
L276             if not (pd.notna(lt) and lt > 0):
L277                 if dt == last_day:
L278                     today_reason_flags.append("Lowæ¬ æ")
L279                 continue
L280
L281             threshold = rh * (1.0 - base)
L282             breach = int(lt <= threshold)
L283             if breach:
L284                 uniq_hits.add(sym)
L285                 if dt == last_day:
L286                     today_hits.add(sym)
L287
L288             if dt == last_day and rows_today_printed < AUDIT_PRINT_MAX:
L289                 print(
L290                     "ğŸ“ audit: ä»Šæ—¥ã®æ˜ç´° "
L291                     f"{dt.date().isoformat()} {sym} High60={rh:.6g} Low={lt:.6g} "
L292                     f"baseTS={base:.3f} é˜ˆå€¤={threshold:.6g} åˆ¤å®š={breach}"
L293                 )
L294                 rows_today_printed += 1
L295
L296     print(
L297         "ğŸ“ audit: 5Dãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°={0} / ä»Šæ—¥ãƒ’ãƒƒãƒˆä¸€è¦§={1}".format(
L298             len(uniq_hits), sorted(today_hits) if today_hits else []
L299         )
L300     )
L301
L302     if rows_today_printed == 0:
L303         reason = "ã€".join(sorted(set(today_reason_flags))) or "ãƒ‡ãƒ¼ã‚¿æ¬ æã¾ãŸã¯éŠ˜æŸ„ãªã—"
L304         print(f"âš ï¸ audit: ä»Šæ—¥ã®æ˜ç´°ãŒç©ºã§ã™ï¼ˆç†ç”±ã®ãƒ’ãƒ³ãƒˆ: {reason}ï¼‰")
L305
L306     k5 = len(uniq_hits)
L307     mode1 = "EMERG" if k5 >= 8 else "CAUTION" if k5 >= 6 else "NORMAL"
L308     return mode1, k5, today_hits
L309 # Debug flag
L310 debug_mode = False  # set to True for detailed output
L311
L312 # --- Finnhub settings & helper ---
L313 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L314 if not FINNHUB_API_KEY:
L315     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L316
L317 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L318 call_times = []
L319
L320
L321 def finnhub_get(endpoint, params):
L322     """Call Finnhub API with basic rate limiting."""
L323     now = time.time()
L324     cutoff = now - 60
L325     while call_times and call_times[0] < cutoff:
L326         call_times.pop(0)
L327     if len(call_times) >= RATE_LIMIT:
L328         sleep_time = 60 - (now - call_times[0])
L329         time.sleep(sleep_time)
L330     params = {**params, "token": FINNHUB_API_KEY}
L331     try:
L332         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L333         resp.raise_for_status()
L334         data = resp.json()
L335     except requests.exceptions.JSONDecodeError as e:
L336         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L337         return {}
L338     except Exception as e:
L339         print(f"âš ï¸ Finnhub API error: {e}")
L340         return {}
L341     call_times.append(time.time())
L342     return data
L343
L344
L345 def fetch_price(symbol):
L346     try:
L347         data = finnhub_get("quote", {"symbol": symbol})
L348         price = data.get("c")
L349         return float(price) if price not in (None, 0) else float("nan")
L350     except Exception:
L351         return float("nan")
L352
L353
L354 def fetch_vix_ma5():
L355     """Retrieve VIX 5-day moving average via yfinance."""
L356     try:
L357         vix = (
L358             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L359             .dropna()
L360             .tail(5)
L361         )
L362         if len(vix) < 5:
L363             return float("nan")
L364         return vix.mean().item()
L365     except Exception:
L366         return float("nan")
L367
L368
L369
L370 # === Minervini-like sell signals ===
L371 def _yf_df(sym, period="6mo"):
L372     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L373     try:
L374         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L375         if df is None or df.empty:
L376             return None
L377         return df.dropna().assign(
L378             ma20=lambda d: d["Close"].rolling(20).mean(),
L379             ma50=lambda d: d["Close"].rolling(50).mean(),
L380             vol50=lambda d: d["Volume"].rolling(50).mean(),
L381         )
L382     except Exception:
L383         return None
L384
L385
L386 def _scalar(row, col):
L387     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L388     try:
L389         v = row[col]
L390         if hasattr(v, "item"):
L391             try:
L392                 v = v.item()
L393             except Exception:
L394                 pass
L395         return v
L396     except Exception:
L397         return float("nan")
L398
L399
L400 def _is_strict_down(seq):
L401     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L402     try:
L403         xs = [float(x) for x in seq]
L404         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L405             return False
L406         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L407     except Exception:
L408         return False
L409
L410
L411 def _signals_for_day(df, idx):
L412     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L413     try:
L414         sig = []
L415         d = df.loc[idx]
L416         close = _scalar(d, "Close")
L417         ma20 = _scalar(d, "ma20")
L418         ma50 = _scalar(d, "ma50")
L419         vol = _scalar(d, "Volume")
L420         vol50 = _scalar(d, "vol50")
L421
L422         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L423             sig.append("20DMAâ†“")
L424
L425         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L426             sig.append("50DMAâ†“(å¤§å•†ã„)")
L427
L428         last4 = df.loc[:idx].tail(4)
L429         last10 = df.loc[:idx].tail(10)
L430
L431         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L432         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L433         if lows_desc or reds > 5:
L434             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L435
L436         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L437         if ups >= 7:
L438             sig.append("ä¸Šã’åé‡(>70%)")
L439
L440         last15 = df.loc[:idx].tail(15)
L441         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L442         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L443             sig.append("+25%/15æ—¥å†…")
L444
L445         if len(df.loc[:idx]) >= 2:
L446             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L447             t1_high = _scalar(t1, "High")
L448             t0_open = _scalar(t0, "Open")
L449             t0_close = _scalar(t0, "Close")
L450             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L451                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L452                     sig.append("GUâ†’é™°ç·š")
L453         return sig
L454     except Exception:
L455         return []
L456
L457
L458 def scan_sell_signals(symbols, lookback_days=5):
L459     """
L460     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L461     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L462     """
L463     out = {}
L464     for s in symbols:
L465         df = _yf_df(s)
L466         if df is None or len(df) < 60:
L467             continue
L468         alerts = []
L469         for idx in df.tail(lookback_days).index:
L470             tags = _signals_for_day(df, idx)
L471             if tags:
L472                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L473         if alerts:
L474             out[s] = alerts
L475     return out
L476
L477
L478 def load_portfolio():
L479     tickers_path = Path(__file__).with_name("current_tickers.csv")
L480     with tickers_path.open() as f:
L481         rows = [row for row in csv.reader(f) if row and row[0].strip()]
L482     n = len(rows)
L483     portfolio = []
L484     for row in rows:
L485         sym = row[0].strip().upper()
L486         qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
L487         bucket = row[2].strip().upper() if len(row) > 2 else ""
L488         entry = {
L489             "symbol": sym,
L490             "shares": qty,
L491             "target_ratio": 1 / n if n else 0.0,
L492             "bucket": bucket,
L493         }
L494         portfolio.append(entry)
L495     return portfolio
L496
L497
L498 def compute_threshold():
L499     vix_ma5 = fetch_vix_ma5()
L500     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L501     return vix_ma5, drift_threshold
L502
L503
L504 def compute_threshold_by_mode(mode: str):
L505     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L506     m = (mode or "NORMAL").upper()
L507     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L508     drift_map = config.DRIFT_THRESHOLD_BY_MODE
L509     return cash_map.get(m, 0.10), drift_map.get(m, 12)
L510
L511
L512 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L513     """
L514     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L515     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L516     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L517     """
L518     m = (mode or "NORMAL").upper()
L519     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L520     now  = config.COUNTS_BY_MODE.get(m, base)
L521     cash_slots = max(0, base["G"] - now["G"])
L522     return now["G"], now["D"], cash_slots
L523
L524
L525 def build_dataframe(portfolio):
L526     for stock in portfolio:
L527         price = fetch_price(stock["symbol"])
L528         stock["price"] = price
L529         stock["value"] = price * stock["shares"]
L530
L531     df = pd.DataFrame(portfolio)
L532     total_value = df["value"].sum()
L533     df["current_ratio"] = df["value"] / total_value
L534     df["drift"] = df["current_ratio"] - df["target_ratio"]
L535     df["drift_abs"] = df["drift"].abs()
L536     total_drift_abs = df["drift_abs"].sum()
L537     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L538     df["adjustable"] = (
L539         (df["adjusted_ratio"] * total_value) >= df["price"]
L540     ) & df["price"].notna() & df["price"].gt(0)
L541     return df, total_value, total_drift_abs
L542
L543
L544 def simulate(df, total_value, total_drift_abs, drift_threshold):
L545     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L546     if alert:
L547         df["trade_shares"] = df.apply(
L548             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L549             if r["adjustable"] and r["price"] > 0 else 0,
L550             axis=1,
L551         )
L552         df["new_shares"] = df["shares"] + df["trade_shares"]
L553         df["new_value"] = df["new_shares"] * df["price"]
L554         new_total_value = df["new_value"].sum()
L555         df["simulated_ratio"] = df["new_value"] / new_total_value
L556         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L557         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L558     else:
L559         df["trade_shares"] = np.nan
L560         df["new_shares"] = np.nan
L561         df["new_value"] = np.nan
L562         new_total_value = np.nan
L563         df["simulated_ratio"] = np.nan
L564         df["simulated_drift_abs"] = np.nan
L565         simulated_total_drift_abs = np.nan
L566     return df, alert, new_total_value, simulated_total_drift_abs
L567
L568
L569 def prepare_summary(df, total_drift_abs, alert):
L570     summary = {
L571         "symbol": "åˆè¨ˆ",
L572         "shares": df["shares"].sum(),
L573         "value": df["value"].sum(),
L574         "current_ratio": np.nan,
L575         "drift_abs": total_drift_abs,
L576     }
L577     if alert:
L578         summary["trade_shares"] = np.nan
L579     # Sort details by evaluation value descending before appending summary
L580     df = df.sort_values(by="value", ascending=False)
L581     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L582     if alert:
L583         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L584         df_small = df[cols].copy()
L585         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L586     else:
L587         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L588         df_small = df[cols].copy()
L589         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L590     return df_small
L591
L592
L593 def currency(x):
L594     return f"${x:,.0f}" if pd.notnull(x) else ""
L595
L596
L597 def formatters_for(alert):
L598     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L599     if alert:
L600         formatters["Î”qty"] = "{:.0f}".format
L601     return formatters
L602
L603
L604 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L605     header = (
L606         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L607         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L608         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L609     )
L610     if alert:
L611         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L612         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L613     else:
L614         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L615     # â˜… è¿½è¨˜: TSãƒ«ãƒ¼ãƒ«ï¼ˆG/Då…±é€šï¼‰ã¨æ¨å¥¨ä¿æœ‰æ•°
L616     # TS(åŸºæœ¬)ã‚’ãƒ¢ãƒ¼ãƒ‰ã§å‹•çš„è¡¨ç¤ºã€‚æ®µéšTSã¯ã€ŒåŸºæœ¬ã‹ã‚‰ -3/-6/-8 ptã€å›ºå®šã€‚
L617     base_ts = config.TS_BASE_BY_MODE.get(mode.upper(), config.TS_BASE_BY_MODE["NORMAL"])
L618     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L619     ts_line = f"*ğŸ›¡ TS:* åŸºæœ¬ -{base_ts*100:.0f}% / +30%â†’-{max(base_ts*100 - d1, 0):.0f}% / +60%â†’-{max(base_ts*100 - d2, 0):.0f}% / +100%â†’-{max(base_ts*100 - d3, 0):.0f}%\n"
L620     header += ts_line
L621     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(mode)
L622     cash_pct = cash_slots * (100 / (config.TOTAL_TARGETS))  # 1æ =ç·æ•°åˆ†å‰²ã®%ï¼ˆ20éŠ˜æŸ„ãªã‚‰5%ï¼‰
L623     header += f"*ğŸ“‹ æ¨å¥¨ä¿æœ‰æ•°:* G {g_cnt} / D {d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}æ  â‰’ {cash_pct:.0f}%ï¼‰\n"
L624     return header
L625
L626
L627 def send_slack(text):
L628     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L629     if not SLACK_WEBHOOK_URL:
L630         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L631     payload = {"text": text}
L632     try:
L633         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L634         resp.raise_for_status()
L635         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L636     except Exception as e:
L637         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L638
L639
L640 def send_debug(debug_text):
L641     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L642     if not SLACK_WEBHOOK_URL:
L643         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L644     debug_payload = {"text": "```" + debug_text + "```"}
L645     try:
L646         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L647         resp.raise_for_status()
L648         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L649     except Exception as e:
L650         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L651
L652
L653 def main():
L654     portfolio = load_portfolio()
L655     symbols = [r["symbol"] for r in portfolio]
L656     g_syms = _load_growth_symbols(portfolio)
L657     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L658
L659     breadth_block, breadth_mode, breadth_score = build_breadth_header()
L660     ts_mode, k5, today_hits = _ts_mode_growth_5d(g_syms, breadth_mode)
L661     combo_mode = _combine_modes(ts_mode, breadth_mode)
L662
L663     cash_ratio, drift_threshold = compute_threshold_by_mode(breadth_mode)
L664
L665     df, total_value, total_drift_abs = build_dataframe(portfolio)
L666     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L667         df, total_value, total_drift_abs, drift_threshold
L668     )
L669     df_small = prepare_summary(df, total_drift_abs, alert)
L670     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L671         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L672         if col_sym:
L673             alert_keys = {str(k) for k in sell_alerts.keys()}
L674             df_small[col_sym] = df_small[col_sym].astype(str)
L675             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L676             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L677             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L678     formatters = formatters_for(alert)
L679     header_core = build_header(
L680         breadth_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L681     )
L682
L683     g_count = len(g_syms)
L684     hits_line = "ãªã—" if not today_hits else ", ".join(sorted(today_hits))
L685     summary_lines = [
L686         f"â‘  Growth TS: {_format_mode(ts_mode)} ï¼ˆ5Dãƒ¦ãƒ‹ãƒ¼ã‚¯: {k5} / G={g_count}ï¼‰",
L687         f"ãƒ»å½“æ—¥ãƒ’ãƒƒãƒˆ: {hits_line}",
L688         f"â‘¡ Breadth: {_format_mode(breadth_mode)} ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}ï¼‰",
L689         f"ç·åˆï¼ˆORæ‚ªåŒ–/ANDå›å¾©ï¼‰: {_format_mode(combo_mode)}",
L690     ]
L691     prepend_block = "\n".join(summary_lines)
L692
L693     if breadth_block:
L694         if breadth_block.startswith("```"):
L695             inner = breadth_block[len("```") :]
L696             if inner.startswith("\n"):
L697                 inner = inner[1:]
L698             if inner.endswith("```"):
L699                 inner = inner[: -len("```")]
L700             inner = inner.strip("\n")
L701             inner_lines = [line for line in inner.splitlines() if "ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in line]
L702             cleaned_inner = "\n".join(inner_lines)
L703             if cleaned_inner:
L704                 new_inner = prepend_block + "\n" + cleaned_inner
L705             else:
L706                 new_inner = prepend_block
L707             breadth_block = "```\n" + new_inner + "\n```"
L708         else:
L709             lines = [line for line in breadth_block.splitlines() if "ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in line]
L710             cleaned_block = "\n".join(lines)
L711             breadth_block = prepend_block + ("\n" + cleaned_block if cleaned_block else "")
L712         header = breadth_block + "\n" + header_core
L713     else:
L714         header = prepend_block + "\n" + header_core
L715     if sell_alerts:
L716         def fmt_pair(date_tags):
L717             date, tags = date_tags
L718             return f"{date}:" + "ãƒ»".join(tags)
L719         listed = []
L720         for t, arr in sell_alerts.items():
L721             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L722         hits = ", ".join(listed)
L723         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L724             header = header.replace(
L725                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L726                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L727             )
L728         else:
L729             header += f"\nğŸŸ¥ {hits}"
L730     table_text = df_small.to_string(formatters=formatters, index=False)
L731     send_slack(header + "\n```" + table_text + "```")
L732
L733     if debug_mode:
L734         debug_cols = [
L735             "symbol",
L736             "shares",
L737             "price",
L738             "value",
L739             "current_ratio",
L740             "drift",
L741             "drift_abs",
L742             "adjusted_ratio",
L743             "adjustable",
L744             "trade_shares",
L745             "new_shares",
L746             "new_value",
L747             "simulated_ratio",
L748             "simulated_drift_abs",
L749         ]
L750         debug_text = (
L751             "=== DEBUG: full dataframe ===\n"
L752             + df[debug_cols].to_string()
L753             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L754             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L755         )
L756         print("\n" + debug_text)
L757         send_debug(debug_text)
L758
L759
L760 if __name__ == "__main__":
L761     main()
L762
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚³ãƒ³ãƒœï¼šå…ˆå°æ ªTS Ã— ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰*
L20
L21 ### â‘  å…ˆå°æ ªTSã‚·ã‚°ãƒŠãƒ«ï¼ˆGrowthã®ã¿ï¼‰
L22 - å¯¾è±¡ï¼ˆGrowthã®å®šç¾©ï¼‰ï¼šå½“æ—¥ä¿æœ‰éŠ˜æŸ„ã®ã†ã¡ **Î² â‰¥ -0.6** ã‚’ Growth ã¨ã¿ãªã™ï¼ˆDefenseã¯ç„¡è¦–ï¼‰
L23 - åˆ¤å®šï¼šç›´è¿‘60æ—¥é«˜å€¤ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰åˆ¥åŸºæœ¬TSå¹…ï¼ˆNORMAL:-15% / CAUTION:-13% / EMERG:-10%ï¼‰ä»¥ä¸Šã®ä¸‹è½ã‚’ã€ŒTSæŠµè§¦ã€ã¨ã¿ãªã™
L24 - é›†è¨ˆï¼šç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æŠµè§¦éŠ˜æŸ„æ•°
L25   - 8éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =EMERG
L26   - 6éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =CAUTION
L27   - ãã‚Œæœªæº€ â†’ â‘ =NORMAL
L28 - è£œè¶³ï¼šåŒä¸€æ—¥ã«è¤‡æ•°å›å®Ÿè¡Œã—ãŸå ´åˆã¯ã€**åŒæ—¥ä¸Šæ›¸ã**ã§ç®¡ç†
L29
L30 ### â‘¡ ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼ˆtrend_template åˆæ ¼æœ¬æ•°ï¼‰
L31 - current+candidate å…¨ä½“ã§ trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„æ•°ï¼ˆåŸºæº– N_G=12ï¼‰
L32 - é–¾å€¤ï¼šéå»600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰è‡ªå‹•æ¡ç”¨ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L33   - ç·Šæ€¥å…¥ã‚Š: max(q05, 12æœ¬)
L34   - ç·Šæ€¥è§£é™¤: max(q20, 18æœ¬)
L35   - é€šå¸¸å¾©å¸°: max(q60, 36æœ¬)
L36 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L37
L38 ### ã‚³ãƒ³ãƒœãƒ«ãƒ¼ãƒ«
L39 - **æ‚ªåŒ–ï¼ˆãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L40   final_mode = max(modeâ‘ , modeâ‘¡)
L41   - ä¾‹ï¼šâ‘ =CAUTION, â‘¡=NORMAL â†’ final=CAUTION
L42   - ä¾‹ï¼šâ‘ =EMERG, â‘¡=CAUTION â†’ final=EMERG
L43
L44 - **å›å¾©ï¼ˆã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L45   final_mode ã‚’1æ®µéšä¸‹ã’ã‚‹ã«ã¯ã€modeâ‘  ã¨ modeâ‘¡ ãŒã¨ã‚‚ã«ä¸‹ä½ãƒ¢ãƒ¼ãƒ‰ã«æƒã£ãŸå ´åˆã®ã¿
L46   - ä¾‹ï¼šEMERGâ†’CAUTION ã¯ â‘ =CAUTION **ã‹ã¤** â‘¡=CAUTION
L47   - ä¾‹ï¼šCAUTIONâ†’NORMAL ã¯ â‘ =NORMAL **ã‹ã¤** â‘¡=NORMAL
L48
L49 > ç›´æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚ºï¼š**ã€Œæ‚ªåŒ–ã¯ã©ã¡ã‚‰ã‹èµ¤ã§èµ¤ã€å›å¾©ã¯ä¸¡æ–¹é’ã§é’ã€**
L50
L51 ---
L52
L53 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®šï¼ˆç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆãƒ»ä¿æœ‰æ•°ï¼‰
L54
L55 | ãƒ¢ãƒ¼ãƒ‰       | ç¾é‡‘æ¯”ç‡ | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤      | åŸºæœ¬TSå¹… | Growthæ æ•° | Defenseæ æ•° | è£œè¶³ |
L56 |--------------|----------|-------------------|----------|------------|-------------|------|
L57 | **NORMAL**   | 10%      | 12%               | -15%     | 12         | 8           | ãƒ•ãƒ«20éŠ˜æŸ„ï¼ˆç¾é‡‘åŒ–æ ãªã—ï¼‰ |
L58 | **CAUTION**  | 20%      | 14%               | -13%     | 10         | 8           | Gã‚’2æ å¤–ã—=ç¾é‡‘åŒ–10% |
L59 | **EMERG**    | 30%      | ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ | -10%     | 8          | 8           | Gã‚’4æ å¤–ã—=ç¾é‡‘åŒ–20% |
L60
L61 - å«ã¿ç›Šåˆ°é”æ™‚ã®TSã‚¿ã‚¤ãƒˆåŒ–ï¼š+30% â†’ -3ptã€+60% â†’ -6ptã€+100% â†’ -8pt
L62 - å«ã¿ç›Š +100% é”æˆæ™‚ã¯50%ã‚’åˆ©ç¢ºã—ã€æ®‹ã‚Šã¯ãƒ•ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ -15%TS ã§ä¿æœ‰ç¶™ç¶š
L63 - TSç™ºå‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã¯å»ƒæ­¢ï¼ˆç¿Œæ—¥ä»¥é™ã™ãã«å†INå¯ï¼‰
L64
L65 ---
L66
L67 ## æ–°è¦è²·ä»˜
L68 - **æ–°è¦INã¯ç­‰åˆ†æ¯”ç‡ï¼ˆ=5%ï¼‰ã®åŠåˆ†ã¾ã§**ã‚’ä¸Šé™ã€‚  
L69 - è¿½åŠ è£œå……ã‚„åŠæˆ»ã—è²·ä»˜ã‚‚åŒã˜ä¸Šé™ã«å¾“ã†ã€‚
L70
L71 ---
L72
L73 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
L74 1. **ç¾é‡‘æ¯”ç‡ â‰¤ é–¾å€¤**ï¼šéé‡é‡éŠ˜æŸ„ã‚’å£²å´ã—ã€ä¸è¶³éŠ˜æŸ„ã‚’è£œå……ã€‚  
L75 2. **ç¾é‡‘æ¯”ç‡ > é–¾å€¤**ï¼š**å£²å´ã¯è¡Œã‚ãš**ã€ç¾é‡‘ã§ãƒ‰ãƒªãƒ•ãƒˆä¸è¶³éŠ˜æŸ„ã‚’è²·ä»˜ï¼ˆç¾é‡‘æ¯”ç‡ã‚’é–¾å€¤ä»¥ä¸‹ã¸æˆ»ã™ã“ã¨ã‚’å„ªå…ˆï¼‰ã€‚  
L76 3. **å…±é€š**ï¼šãƒªãƒãƒ©ãƒ³ã‚¹å¾Œã¯å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã€‚EMERGã§ã¯ã€Œãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ã€ã€20éŠ˜æŸ„Ã—5%å…¨æˆ»ã—ã®ã¿è¨±å®¹ã€‚
L77
L78 ---
L79
L80 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †
L81 - ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€Growthæ æ•°ã ã‘èª¿æ•´ï¼š  
L82   1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã—ã€`current_tickers.csv` ã‹ã‚‰è¡Œå‰Šé™¤ï¼ˆ=ç¾é‡‘åŒ–ï¼‰ã€‚  
L83   2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**ã€‚  
L84   3. **NORMALå¾©å¸°æ™‚ã®è£œå……**ï¼š`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰ï¼‰ã€‚ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚  
L85 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦å‡ç­‰æ¯”ç‡ã‚’å†è¨ˆç®—ã€‚
L86
L87 ---
L88
L89 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L90 - **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦æ—¥æ¬¡ã§ã‚¹ã‚³ã‚¢é›†è¨ˆ**ã—ã€**ã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰IN/OUT**ã‚’æ±ºå®šã€‚  
L91 - å‚è€ƒï¼šOxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€Alpha Investorã€Motley Foolã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã€‚  
L92 - å¹´é–“NISAæ ã¯Growthç¾¤ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ï¼ˆé•·æœŸä¿æŒã«å›ºåŸ·ã—ãªã„ï¼‰ã€‚
L93
L94 ---
L95
L96 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L97 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ  
L98 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
