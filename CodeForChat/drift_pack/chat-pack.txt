# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-26 17:01:10 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L12 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸš¨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21
L22 def _state_file():
L23     return str(Path(RESULTS_DIR) / "breadth_state.json")
L24
L25
L26 def load_mode(default="NORMAL"):
L27     try:
L28         m = json.loads(open(_state_file()).read()).get("mode", default)
L29         return m if m in ("EMERG","CAUTION","NORMAL") else default
L30     except Exception:
L31         return default
L32
L33
L34 def save_mode(mode: str):
L35     try:
L36         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L37     except Exception:
L38         pass
L39
L40
L41 def _read_csv_list(fname):
L42     p = Path(__file__).with_name(fname)
L43     if not p.exists(): return []
L44     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L45
L46
L47 def _load_universe():
L48     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L49     exist = _read_csv_list("current_tickers.csv")
L50     cand  = _read_csv_list("candidate_tickers.csv")
L51     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L52     cand_keep = []
L53     for t in cand:
L54         try:
L55             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L56         except Exception:
L57             px = float("inf")
L58         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L59             cand_keep.append(t)
L60     tickers = sorted(set(exist + cand_keep))
L61     return exist, cand_keep, tickers
L62
L63
L64 def _fetch_prices_600d(tickers):
L65     data = yf.download(
L66         tickers + [BENCH],
L67         period="600d",
L68         auto_adjust=True,
L69         progress=False,
L70         threads=False,
L71     )
L72     close = data["Close"]
L73     px = close.dropna(how="all", axis=1).ffill(limit=2)
L74     spx = close[BENCH].reindex(px.index).ffill()
L75     return px, spx
L76
L77
L78 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L79     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L80     import numpy as np, pandas as pd
L81     if px is None or px.empty:
L82         return pd.Series(dtype=int)
L83     px = px.dropna(how="all", axis=1)
L84     if win_days and win_days > 0:
L85         px = px.tail(win_days)
L86     if px.empty:
L87         return pd.Series(dtype=int)
L88     # æ¬ æå¸å
L89     px = px.ffill(limit=2)
L90     spx = spx.reindex(px.index).ffill()
L91
L92     ma50  = px.rolling(50,  min_periods=50).mean()
L93     ma150 = px.rolling(150, min_periods=150).mean()
L94     ma200 = px.rolling(200, min_periods=200).mean()
L95
L96     tt = (px > ma150)
L97     tt &= (px > ma200)
L98     tt &= (ma150 > ma200)
L99     tt &= (ma200 - ma200.shift(21) > 0)
L100     tt &= (ma50  > ma150)
L101     tt &= (ma50  > ma200)
L102     tt &= (px    > ma50)
L103
L104     lo252 = px.rolling(252, min_periods=252).min()
L105     hi252 = px.rolling(252, min_periods=252).max()
L106     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L107     tt &= (px >= (0.75 * hi252))
L108
L109     r12  = px.divide(px.shift(252)).sub(1.0)
L110     br12 = spx.divide(spx.shift(252)).sub(1.0)
L111     r1   = px.divide(px.shift(22)).sub(1.0)
L112     br1  = spx.divide(spx.shift(22)).sub(1.0)
L113     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L114     tt &= (rs >= 0.10)
L115
L116     return tt.fillna(False).sum(axis=1).astype(int)
L117
L118
L119 def build_breadth_header():
L120     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L121     exist, cand, tickers = _load_universe()
L122     if not tickers:
L123         return "", "NORMAL", 0
L124     px, spx = _fetch_prices_600d(tickers)
L125     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L126     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L127     if C_ts.empty:
L128         return "", "NORMAL", 0
L129     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L130     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L131     C_full = int(C_ts.iloc[-1])
L132
L133     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L134     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L135     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L136
L137     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L138     N_G = config.N_G
L139     th_in_rec   = max(N_G, q05)
L140     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L141     th_norm_rec = max(3*N_G, q60)
L142
L143     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L144     if use_calib:
L145         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L146     else:
L147         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L148         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L149         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L150         th_src = "æ‰‹å‹•"
L151
L152     prev = load_mode("NORMAL")
L153     if   prev == "EMERG":
L154         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L155     elif prev == "CAUTION":
L156         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L157     else:
L158         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L159     save_mode(mode)
L160
L161     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L162     eff_days = len(base)
L163
L164     lead_lines = [
L165         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L166         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L167         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L168         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L169         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L170         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L171         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L172         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L173         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L174         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L175     ]
L176     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L177
L178
L179 TS_LOG_FILE = Path(RESULTS_DIR) / "ts_signal_log.csv"
L180
L181
L182 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L183     growth = []
L184     for row in portfolio:
L185         bucket = str(row.get("bucket", "")).strip().upper()
L186         if bucket == "G":
L187             sym = str(row.get("symbol", "")).strip().upper()
L188             if sym:
L189                 growth.append(sym)
L190     return sorted(set(growth))
L191
L192
L193 def _upsert_ts_hits(date_str: str, hits: set[str]):
L194     df = None
L195     if TS_LOG_FILE.exists():
L196         try:
L197             df = pd.read_csv(TS_LOG_FILE)
L198         except Exception:
L199             df = None
L200     if df is None or not isinstance(df, pd.DataFrame):
L201         df = pd.DataFrame(columns=["date", "symbol"])
L202     df = df[df["date"] != date_str]
L203     if hits:
L204         add = pd.DataFrame({"date": date_str, "symbol": sorted({h.upper() for h in hits})})
L205         df = pd.concat([df, add], ignore_index=True)
L206     df = df.sort_values(["date", "symbol"])
L207     df.to_csv(TS_LOG_FILE, index=False)
L208
L209
L210 def _count_unique_hits_5d(today_utc: pd.Timestamp) -> int:
L211     if not TS_LOG_FILE.exists():
L212         return 0
L213     try:
L214         df = pd.read_csv(TS_LOG_FILE)
L215     except Exception:
L216         return 0
L217     if df.empty or "date" not in df.columns or "symbol" not in df.columns:
L218         return 0
L219     try:
L220         df["date"] = pd.to_datetime(df["date"], utc=True)
L221     except Exception:
L222         return 0
L223     today = today_utc.normalize()
L224     start = today - pd.offsets.BDay(4)
L225     mask = (df["date"] >= start) & (df["date"] <= today)
L226     if not mask.any():
L227         return 0
L228     return int(df.loc[mask, "symbol"].str.upper().nunique())
L229
L230
L231 def _combine_modes(mode_a: str, mode_b: str) -> str:
L232     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L233     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L234     for mode, rank in MODE_RANK.items():
L235         if rank == max(a, b):
L236             return mode
L237     return "NORMAL"
L238
L239
L240 def _format_mode(mode: str) -> str:
L241     upper = (mode or "NORMAL").upper()
L242     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L243
L244
L245 def _build_status_block(ts_mode: str, k5: int, ts_hits: list[str], breadth_mode: str, breadth_score: int, combo_mode: str) -> str:
L246     hits_line = "ãªã—" if not ts_hits else ", ".join(sorted(ts_hits))
L247     lines = [
L248         f"*â‘  Growth TS:* {_format_mode(ts_mode)}ï¼ˆ5Dãƒ¦ãƒ‹ãƒ¼ã‚¯: {k5}éŠ˜æŸ„ï¼‰",
L249         f"  ãƒ»å½“æ—¥ãƒ’ãƒƒãƒˆ: {hits_line}",
L250         f"*â‘¡ Breadth:* {_format_mode(breadth_mode)}ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}æœ¬ï¼‰",
L251         f"*ç·åˆï¼ˆORæ‚ªåŒ–/ANDå›å¾©ï¼‰:* {_format_mode(combo_mode)}",
L252     ]
L253     return "\n".join(lines)
L254
L255
L256 def _ts_mode_growth_eod(g_syms: list[str], ref_mode: str) -> tuple[str, int, list[str]]:
L257     now_utc = pd.Timestamp.today(tz="UTC")
L258     if not g_syms:
L259         k = _count_unique_hits_5d(now_utc)
L260         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L261         return mode1, k, []
L262     try:
L263         df = yf.download(
L264             g_syms,
L265             period="90d",
L266             interval="1d",
L267             auto_adjust=False,
L268             progress=False,
L269             group_by="column",
L270         )
L271     except Exception:
L272         df = None
L273     if not isinstance(df, pd.DataFrame) or df.empty:
L274         k = _count_unique_hits_5d(now_utc)
L275         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L276         return mode1, k, []
L277     try:
L278         hi = df["High"] if "High" in df.columns else None
L279         lo = df["Low"] if "Low" in df.columns else None
L280     except Exception:
L281         hi = lo = None
L282     if hi is None or lo is None:
L283         k = _count_unique_hits_5d(now_utc)
L284         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L285         return mode1, k, []
L286     if isinstance(hi, pd.Series):
L287         hi = hi.to_frame(name=g_syms[0])
L288     if isinstance(lo, pd.Series):
L289         lo = lo.to_frame(name=g_syms[0])
L290     try:
L291         roll_hi = hi.rolling(60, min_periods=20).max().tail(1).iloc[0]
L292         low_today = lo.tail(1).iloc[0]
L293     except Exception:
L294         k = _count_unique_hits_5d(now_utc)
L295         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L296         return mode1, k, []
L297     base = float(config.TS_BASE_BY_MODE.get((ref_mode or "NORMAL").upper(), 0.15))
L298     hits = set()
L299     for s in g_syms:
L300         rh = float(roll_hi.get(s, float("nan")))
L301         lt = float(low_today.get(s, float("nan")))
L302         if pd.notna(rh) and rh > 0 and pd.notna(lt) and lt > 0:
L303             if lt <= rh * (1.0 - base):
L304                 hits.add(s)
L305     today = now_utc.date().isoformat()
L306     _upsert_ts_hits(today, hits)
L307     k = _count_unique_hits_5d(now_utc)
L308     mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L309     return mode1, k, sorted(hits)
L310 # Debug flag
L311 debug_mode = False  # set to True for detailed output
L312
L313 # --- Finnhub settings & helper ---
L314 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L315 if not FINNHUB_API_KEY:
L316     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L317
L318 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L319 call_times = []
L320
L321
L322 def finnhub_get(endpoint, params):
L323     """Call Finnhub API with basic rate limiting."""
L324     now = time.time()
L325     cutoff = now - 60
L326     while call_times and call_times[0] < cutoff:
L327         call_times.pop(0)
L328     if len(call_times) >= RATE_LIMIT:
L329         sleep_time = 60 - (now - call_times[0])
L330         time.sleep(sleep_time)
L331     params = {**params, "token": FINNHUB_API_KEY}
L332     try:
L333         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L334         resp.raise_for_status()
L335         data = resp.json()
L336     except requests.exceptions.JSONDecodeError as e:
L337         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L338         return {}
L339     except Exception as e:
L340         print(f"âš ï¸ Finnhub API error: {e}")
L341         return {}
L342     call_times.append(time.time())
L343     return data
L344
L345
L346 def fetch_price(symbol):
L347     try:
L348         data = finnhub_get("quote", {"symbol": symbol})
L349         price = data.get("c")
L350         return float(price) if price not in (None, 0) else float("nan")
L351     except Exception:
L352         return float("nan")
L353
L354
L355 def fetch_vix_ma5():
L356     """Retrieve VIX 5-day moving average via yfinance."""
L357     try:
L358         vix = (
L359             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L360             .dropna()
L361             .tail(5)
L362         )
L363         if len(vix) < 5:
L364             return float("nan")
L365         return vix.mean().item()
L366     except Exception:
L367         return float("nan")
L368
L369
L370
L371 # === Minervini-like sell signals ===
L372 def _yf_df(sym, period="6mo"):
L373     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L374     try:
L375         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L376         if df is None or df.empty:
L377             return None
L378         return df.dropna().assign(
L379             ma20=lambda d: d["Close"].rolling(20).mean(),
L380             ma50=lambda d: d["Close"].rolling(50).mean(),
L381             vol50=lambda d: d["Volume"].rolling(50).mean(),
L382         )
L383     except Exception:
L384         return None
L385
L386
L387 def _scalar(row, col):
L388     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L389     try:
L390         v = row[col]
L391         if hasattr(v, "item"):
L392             try:
L393                 v = v.item()
L394             except Exception:
L395                 pass
L396         return v
L397     except Exception:
L398         return float("nan")
L399
L400
L401 def _is_strict_down(seq):
L402     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L403     try:
L404         xs = [float(x) for x in seq]
L405         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L406             return False
L407         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L408     except Exception:
L409         return False
L410
L411
L412 def _signals_for_day(df, idx):
L413     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L414     try:
L415         sig = []
L416         d = df.loc[idx]
L417         close = _scalar(d, "Close")
L418         ma20 = _scalar(d, "ma20")
L419         ma50 = _scalar(d, "ma50")
L420         vol = _scalar(d, "Volume")
L421         vol50 = _scalar(d, "vol50")
L422
L423         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L424             sig.append("20DMAâ†“")
L425
L426         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L427             sig.append("50DMAâ†“(å¤§å•†ã„)")
L428
L429         last4 = df.loc[:idx].tail(4)
L430         last10 = df.loc[:idx].tail(10)
L431
L432         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L433         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L434         if lows_desc or reds > 5:
L435             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L436
L437         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L438         if ups >= 7:
L439             sig.append("ä¸Šã’åé‡(>70%)")
L440
L441         last15 = df.loc[:idx].tail(15)
L442         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L443         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L444             sig.append("+25%/15æ—¥å†…")
L445
L446         if len(df.loc[:idx]) >= 2:
L447             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L448             t1_high = _scalar(t1, "High")
L449             t0_open = _scalar(t0, "Open")
L450             t0_close = _scalar(t0, "Close")
L451             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L452                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L453                     sig.append("GUâ†’é™°ç·š")
L454         return sig
L455     except Exception:
L456         return []
L457
L458
L459 def scan_sell_signals(symbols, lookback_days=5):
L460     """
L461     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L462     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L463     """
L464     out = {}
L465     for s in symbols:
L466         df = _yf_df(s)
L467         if df is None or len(df) < 60:
L468             continue
L469         alerts = []
L470         for idx in df.tail(lookback_days).index:
L471             tags = _signals_for_day(df, idx)
L472             if tags:
L473                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L474         if alerts:
L475             out[s] = alerts
L476     return out
L477
L478
L479 def load_portfolio():
L480     tickers_path = Path(__file__).with_name("current_tickers.csv")
L481     with tickers_path.open() as f:
L482         rows = [row for row in csv.reader(f) if row and row[0].strip()]
L483     n = len(rows)
L484     portfolio = []
L485     for row in rows:
L486         sym = row[0].strip().upper()
L487         qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
L488         bucket = row[2].strip().upper() if len(row) > 2 else ""
L489         entry = {
L490             "symbol": sym,
L491             "shares": qty,
L492             "target_ratio": 1 / n if n else 0.0,
L493             "bucket": bucket,
L494         }
L495         portfolio.append(entry)
L496     return portfolio
L497
L498
L499 def compute_threshold():
L500     vix_ma5 = fetch_vix_ma5()
L501     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L502     return vix_ma5, drift_threshold
L503
L504
L505 def compute_threshold_by_mode(mode: str):
L506     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L507     m = (mode or "NORMAL").upper()
L508     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L509     drift_map = config.DRIFT_THRESHOLD_BY_MODE
L510     return cash_map.get(m, 0.10), drift_map.get(m, 12)
L511
L512
L513 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L514     """
L515     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L516     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L517     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L518     """
L519     m = (mode or "NORMAL").upper()
L520     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L521     now  = config.COUNTS_BY_MODE.get(m, base)
L522     cash_slots = max(0, base["G"] - now["G"])
L523     return now["G"], now["D"], cash_slots
L524
L525
L526 def build_dataframe(portfolio):
L527     for stock in portfolio:
L528         price = fetch_price(stock["symbol"])
L529         stock["price"] = price
L530         stock["value"] = price * stock["shares"]
L531
L532     df = pd.DataFrame(portfolio)
L533     total_value = df["value"].sum()
L534     df["current_ratio"] = df["value"] / total_value
L535     df["drift"] = df["current_ratio"] - df["target_ratio"]
L536     df["drift_abs"] = df["drift"].abs()
L537     total_drift_abs = df["drift_abs"].sum()
L538     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L539     df["adjustable"] = (
L540         (df["adjusted_ratio"] * total_value) >= df["price"]
L541     ) & df["price"].notna() & df["price"].gt(0)
L542     return df, total_value, total_drift_abs
L543
L544
L545 def simulate(df, total_value, total_drift_abs, drift_threshold):
L546     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L547     if alert:
L548         df["trade_shares"] = df.apply(
L549             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L550             if r["adjustable"] and r["price"] > 0 else 0,
L551             axis=1,
L552         )
L553         df["new_shares"] = df["shares"] + df["trade_shares"]
L554         df["new_value"] = df["new_shares"] * df["price"]
L555         new_total_value = df["new_value"].sum()
L556         df["simulated_ratio"] = df["new_value"] / new_total_value
L557         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L558         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L559     else:
L560         df["trade_shares"] = np.nan
L561         df["new_shares"] = np.nan
L562         df["new_value"] = np.nan
L563         new_total_value = np.nan
L564         df["simulated_ratio"] = np.nan
L565         df["simulated_drift_abs"] = np.nan
L566         simulated_total_drift_abs = np.nan
L567     return df, alert, new_total_value, simulated_total_drift_abs
L568
L569
L570 def prepare_summary(df, total_drift_abs, alert):
L571     summary = {
L572         "symbol": "åˆè¨ˆ",
L573         "shares": df["shares"].sum(),
L574         "value": df["value"].sum(),
L575         "current_ratio": np.nan,
L576         "drift_abs": total_drift_abs,
L577     }
L578     if alert:
L579         summary["trade_shares"] = np.nan
L580     # Sort details by evaluation value descending before appending summary
L581     df = df.sort_values(by="value", ascending=False)
L582     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L583     if alert:
L584         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L585         df_small = df[cols].copy()
L586         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L587     else:
L588         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L589         df_small = df[cols].copy()
L590         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L591     return df_small
L592
L593
L594 def currency(x):
L595     return f"${x:,.0f}" if pd.notnull(x) else ""
L596
L597
L598 def formatters_for(alert):
L599     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L600     if alert:
L601         formatters["Î”qty"] = "{:.0f}".format
L602     return formatters
L603
L604
L605 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L606     header = (
L607         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L608         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L609         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L610     )
L611     if alert:
L612         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L613         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L614     else:
L615         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L616     # â˜… è¿½è¨˜: TSãƒ«ãƒ¼ãƒ«ï¼ˆG/Då…±é€šï¼‰ã¨æ¨å¥¨ä¿æœ‰æ•°
L617     # TS(åŸºæœ¬)ã‚’ãƒ¢ãƒ¼ãƒ‰ã§å‹•çš„è¡¨ç¤ºã€‚æ®µéšTSã¯ã€ŒåŸºæœ¬ã‹ã‚‰ -3/-6/-8 ptã€å›ºå®šã€‚
L618     base_ts = config.TS_BASE_BY_MODE.get(mode.upper(), config.TS_BASE_BY_MODE["NORMAL"])
L619     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L620     ts_line = f"*ğŸ›¡ TS:* åŸºæœ¬ -{base_ts*100:.0f}% / +30%â†’-{max(base_ts*100 - d1, 0):.0f}% / +60%â†’-{max(base_ts*100 - d2, 0):.0f}% / +100%â†’-{max(base_ts*100 - d3, 0):.0f}%\n"
L621     header += ts_line
L622     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(mode)
L623     cash_pct = cash_slots * (100 / (config.TOTAL_TARGETS))  # 1æ =ç·æ•°åˆ†å‰²ã®%ï¼ˆ20éŠ˜æŸ„ãªã‚‰5%ï¼‰
L624     header += f"*ğŸ“‹ æ¨å¥¨ä¿æœ‰æ•°:* G {g_cnt} / D {d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}æ  â‰’ {cash_pct:.0f}%ï¼‰\n"
L625     return header
L626
L627
L628 def send_slack(text):
L629     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L630     if not SLACK_WEBHOOK_URL:
L631         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L632     payload = {"text": text}
L633     try:
L634         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L635         resp.raise_for_status()
L636         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L637     except Exception as e:
L638         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L639
L640
L641 def send_debug(debug_text):
L642     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L643     if not SLACK_WEBHOOK_URL:
L644         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L645     debug_payload = {"text": "```" + debug_text + "```"}
L646     try:
L647         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L648         resp.raise_for_status()
L649         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L650     except Exception as e:
L651         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L652
L653
L654 def main():
L655     portfolio = load_portfolio()
L656     symbols = [r["symbol"] for r in portfolio]
L657     g_syms = _load_growth_symbols(portfolio)
L658     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L659
L660     breadth_block, breadth_mode, breadth_score = build_breadth_header()
L661     ts_mode, k5, ts_hits = _ts_mode_growth_eod(g_syms, breadth_mode)
L662     combo_mode = _combine_modes(ts_mode, breadth_mode)
L663
L664     cash_ratio, drift_threshold = compute_threshold_by_mode(breadth_mode)
L665
L666     df, total_value, total_drift_abs = build_dataframe(portfolio)
L667     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L668         df, total_value, total_drift_abs, drift_threshold
L669     )
L670     df_small = prepare_summary(df, total_drift_abs, alert)
L671     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L672         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L673         if col_sym:
L674             alert_keys = {str(k) for k in sell_alerts.keys()}
L675             df_small[col_sym] = df_small[col_sym].astype(str)
L676             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L677             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L678             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L679     formatters = formatters_for(alert)
L680     header_core = build_header(
L681         breadth_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L682     )
L683     status_block = _build_status_block(ts_mode, k5, ts_hits, breadth_mode, breadth_score, combo_mode)
L684     header = header_core + "\n" + status_block
L685     if breadth_block:
L686         header = breadth_block + "\n" + header
L687     if sell_alerts:
L688         def fmt_pair(date_tags):
L689             date, tags = date_tags
L690             return f"{date}:" + "ãƒ»".join(tags)
L691         listed = []
L692         for t, arr in sell_alerts.items():
L693             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L694         hits = ", ".join(listed)
L695         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L696             header = header.replace(
L697                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L698                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L699             )
L700         else:
L701             header += f"\nğŸŸ¥ {hits}"
L702     table_text = df_small.to_string(formatters=formatters, index=False)
L703     send_slack(header + "\n```" + table_text + "```")
L704
L705     if debug_mode:
L706         debug_cols = [
L707             "symbol",
L708             "shares",
L709             "price",
L710             "value",
L711             "current_ratio",
L712             "drift",
L713             "drift_abs",
L714             "adjusted_ratio",
L715             "adjustable",
L716             "trade_shares",
L717             "new_shares",
L718             "new_value",
L719             "simulated_ratio",
L720             "simulated_drift_abs",
L721         ]
L722         debug_text = (
L723             "=== DEBUG: full dataframe ===\n"
L724             + df[debug_cols].to_string()
L725             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L726             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L727         )
L728         print("\n" + debug_text)
L729         send_debug(debug_text)
L730
L731
L732 if __name__ == "__main__":
L733     main()
L734
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚³ãƒ³ãƒœï¼šå…ˆå°æ ªTS Ã— ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰*
L20
L21 ### â‘  å…ˆå°æ ªTSã‚·ã‚°ãƒŠãƒ«ï¼ˆGrowthã®ã¿ï¼‰
L22 - å¯¾è±¡ï¼ˆGrowthã®å®šç¾©ï¼‰ï¼šå½“æ—¥ä¿æœ‰éŠ˜æŸ„ã®ã†ã¡ **Î² â‰¥ -0.6** ã‚’ Growth ã¨ã¿ãªã™ï¼ˆDefenseã¯ç„¡è¦–ï¼‰
L23 - åˆ¤å®šï¼šç›´è¿‘60æ—¥é«˜å€¤ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰åˆ¥åŸºæœ¬TSå¹…ï¼ˆNORMAL:-15% / CAUTION:-13% / EMERG:-10%ï¼‰ä»¥ä¸Šã®ä¸‹è½ã‚’ã€ŒTSæŠµè§¦ã€ã¨ã¿ãªã™
L24 - é›†è¨ˆï¼šç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æŠµè§¦éŠ˜æŸ„æ•°
L25   - 8éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =EMERG
L26   - 6éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =CAUTION
L27   - ãã‚Œæœªæº€ â†’ â‘ =NORMAL
L28 - è£œè¶³ï¼šåŒä¸€æ—¥ã«è¤‡æ•°å›å®Ÿè¡Œã—ãŸå ´åˆã¯ã€**åŒæ—¥ä¸Šæ›¸ã**ã§ç®¡ç†
L29
L30 ### â‘¡ ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼ˆtrend_template åˆæ ¼æœ¬æ•°ï¼‰
L31 - current+candidate å…¨ä½“ã§ trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„æ•°ï¼ˆåŸºæº– N_G=12ï¼‰
L32 - é–¾å€¤ï¼šéå»600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰è‡ªå‹•æ¡ç”¨ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L33   - ç·Šæ€¥å…¥ã‚Š: max(q05, 12æœ¬)
L34   - ç·Šæ€¥è§£é™¤: max(q20, 18æœ¬)
L35   - é€šå¸¸å¾©å¸°: max(q60, 36æœ¬)
L36 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L37
L38 ### ã‚³ãƒ³ãƒœãƒ«ãƒ¼ãƒ«
L39 - **æ‚ªåŒ–ï¼ˆãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L40   final_mode = max(modeâ‘ , modeâ‘¡)
L41   - ä¾‹ï¼šâ‘ =CAUTION, â‘¡=NORMAL â†’ final=CAUTION
L42   - ä¾‹ï¼šâ‘ =EMERG, â‘¡=CAUTION â†’ final=EMERG
L43
L44 - **å›å¾©ï¼ˆã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L45   final_mode ã‚’1æ®µéšä¸‹ã’ã‚‹ã«ã¯ã€modeâ‘  ã¨ modeâ‘¡ ãŒã¨ã‚‚ã«ä¸‹ä½ãƒ¢ãƒ¼ãƒ‰ã«æƒã£ãŸå ´åˆã®ã¿
L46   - ä¾‹ï¼šEMERGâ†’CAUTION ã¯ â‘ =CAUTION **ã‹ã¤** â‘¡=CAUTION
L47   - ä¾‹ï¼šCAUTIONâ†’NORMAL ã¯ â‘ =NORMAL **ã‹ã¤** â‘¡=NORMAL
L48
L49 > ç›´æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚ºï¼š**ã€Œæ‚ªåŒ–ã¯ã©ã¡ã‚‰ã‹èµ¤ã§èµ¤ã€å›å¾©ã¯ä¸¡æ–¹é’ã§é’ã€**
L50
L51 ---
L52
L53 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®šï¼ˆç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆãƒ»ä¿æœ‰æ•°ï¼‰
L54
L55 | ãƒ¢ãƒ¼ãƒ‰       | ç¾é‡‘æ¯”ç‡ | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤      | åŸºæœ¬TSå¹… | Growthæ æ•° | Defenseæ æ•° | è£œè¶³ |
L56 |--------------|----------|-------------------|----------|------------|-------------|------|
L57 | **NORMAL**   | 10%      | 12%               | -15%     | 12         | 8           | ãƒ•ãƒ«20éŠ˜æŸ„ï¼ˆç¾é‡‘åŒ–æ ãªã—ï¼‰ |
L58 | **CAUTION**  | 20%      | 14%               | -13%     | 10         | 8           | Gã‚’2æ å¤–ã—=ç¾é‡‘åŒ–10% |
L59 | **EMERG**    | 30%      | ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ | -10%     | 8          | 8           | Gã‚’4æ å¤–ã—=ç¾é‡‘åŒ–20% |
L60
L61 - å«ã¿ç›Šåˆ°é”æ™‚ã®TSã‚¿ã‚¤ãƒˆåŒ–ï¼š+30% â†’ -3ptã€+60% â†’ -6ptã€+100% â†’ -8pt
L62 - å«ã¿ç›Š +100% é”æˆæ™‚ã¯50%ã‚’åˆ©ç¢ºã—ã€æ®‹ã‚Šã¯ãƒ•ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ -15%TS ã§ä¿æœ‰ç¶™ç¶š
L63 - TSç™ºå‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã¯å»ƒæ­¢ï¼ˆç¿Œæ—¥ä»¥é™ã™ãã«å†INå¯ï¼‰
L64
L65 ---
L66
L67 ## æ–°è¦è²·ä»˜
L68 - **æ–°è¦INã¯ç­‰åˆ†æ¯”ç‡ï¼ˆ=5%ï¼‰ã®åŠåˆ†ã¾ã§**ã‚’ä¸Šé™ã€‚  
L69 - è¿½åŠ è£œå……ã‚„åŠæˆ»ã—è²·ä»˜ã‚‚åŒã˜ä¸Šé™ã«å¾“ã†ã€‚
L70
L71 ---
L72
L73 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
L74 1. **ç¾é‡‘æ¯”ç‡ â‰¤ é–¾å€¤**ï¼šéé‡é‡éŠ˜æŸ„ã‚’å£²å´ã—ã€ä¸è¶³éŠ˜æŸ„ã‚’è£œå……ã€‚  
L75 2. **ç¾é‡‘æ¯”ç‡ > é–¾å€¤**ï¼š**å£²å´ã¯è¡Œã‚ãš**ã€ç¾é‡‘ã§ãƒ‰ãƒªãƒ•ãƒˆä¸è¶³éŠ˜æŸ„ã‚’è²·ä»˜ï¼ˆç¾é‡‘æ¯”ç‡ã‚’é–¾å€¤ä»¥ä¸‹ã¸æˆ»ã™ã“ã¨ã‚’å„ªå…ˆï¼‰ã€‚  
L76 3. **å…±é€š**ï¼šãƒªãƒãƒ©ãƒ³ã‚¹å¾Œã¯å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã€‚EMERGã§ã¯ã€Œãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ã€ã€20éŠ˜æŸ„Ã—5%å…¨æˆ»ã—ã®ã¿è¨±å®¹ã€‚
L77
L78 ---
L79
L80 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †
L81 - ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€Growthæ æ•°ã ã‘èª¿æ•´ï¼š  
L82   1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã—ã€`current_tickers.csv` ã‹ã‚‰è¡Œå‰Šé™¤ï¼ˆ=ç¾é‡‘åŒ–ï¼‰ã€‚  
L83   2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**ã€‚  
L84   3. **NORMALå¾©å¸°æ™‚ã®è£œå……**ï¼š`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰ï¼‰ã€‚ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚  
L85 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦å‡ç­‰æ¯”ç‡ã‚’å†è¨ˆç®—ã€‚
L86
L87 ---
L88
L89 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L90 - **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦æ—¥æ¬¡ã§ã‚¹ã‚³ã‚¢é›†è¨ˆ**ã—ã€**ã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰IN/OUT**ã‚’æ±ºå®šã€‚  
L91 - å‚è€ƒï¼šOxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€Alpha Investorã€Motley Foolã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã€‚  
L92 - å¹´é–“NISAæ ã¯Growthç¾¤ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ï¼ˆé•·æœŸä¿æŒã«å›ºåŸ·ã—ãªã„ï¼‰ã€‚
L93
L94 ---
L95
L96 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L97 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ  
L98 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
