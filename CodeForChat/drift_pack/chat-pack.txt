# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-19 22:06:30 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 # --- breadth utilities (factor parity) ---
L12 BENCH = "^GSPC"
L13 CAND_PRICE_MAX = 450.0
L14 RESULTS_DIR = "results"
L15 os.makedirs(RESULTS_DIR, exist_ok=True)
L16
L17
L18 def _state_file():
L19     return str(Path(RESULTS_DIR) / "breadth_state.json")
L20
L21
L22 def load_mode(default="NORMAL"):
L23     try:
L24         m = json.loads(open(_state_file()).read()).get("mode", default)
L25         return m if m in ("EMERG","CAUTION","NORMAL") else default
L26     except Exception:
L27         return default
L28
L29
L30 def save_mode(mode: str):
L31     try:
L32         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L33     except Exception:
L34         pass
L35
L36
L37 def _read_csv_list(fname):
L38     p = Path(__file__).with_name(fname)
L39     if not p.exists(): return []
L40     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L41
L42
L43 def _load_universe():
L44     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L45     exist = _read_csv_list("current_tickers.csv")
L46     cand  = _read_csv_list("candidate_tickers.csv")
L47     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L48     cand_keep = []
L49     for t in cand:
L50         try:
L51             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L52         except Exception:
L53             px = float("inf")
L54         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L55             cand_keep.append(t)
L56     tickers = sorted(set(exist + cand_keep))
L57     return exist, cand_keep, tickers
L58
L59
L60 def _fetch_prices_600d(tickers):
L61     data = yf.download(
L62         tickers + [BENCH],
L63         period="600d",
L64         auto_adjust=True,
L65         progress=False,
L66         threads=False,
L67     )
L68     close = data["Close"]
L69     px = close.dropna(how="all", axis=1).ffill(limit=2)
L70     spx = close[BENCH].reindex(px.index).ffill()
L71     return px, spx
L72
L73
L74 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L75     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L76     import numpy as np, pandas as pd
L77     if px is None or px.empty:
L78         return pd.Series(dtype=int)
L79     px = px.dropna(how="all", axis=1)
L80     if win_days and win_days > 0:
L81         px = px.tail(win_days)
L82     if px.empty:
L83         return pd.Series(dtype=int)
L84     # æ¬ æå¸å
L85     px = px.ffill(limit=2)
L86     spx = spx.reindex(px.index).ffill()
L87
L88     ma50  = px.rolling(50,  min_periods=50).mean()
L89     ma150 = px.rolling(150, min_periods=150).mean()
L90     ma200 = px.rolling(200, min_periods=200).mean()
L91
L92     tt = (px > ma150)
L93     tt &= (px > ma200)
L94     tt &= (ma150 > ma200)
L95     tt &= (ma200 - ma200.shift(21) > 0)
L96     tt &= (ma50  > ma150)
L97     tt &= (ma50  > ma200)
L98     tt &= (px    > ma50)
L99
L100     lo252 = px.rolling(252, min_periods=252).min()
L101     hi252 = px.rolling(252, min_periods=252).max()
L102     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L103     tt &= (px >= (0.75 * hi252))
L104
L105     r12  = px.divide(px.shift(252)).sub(1.0)
L106     br12 = spx.divide(spx.shift(252)).sub(1.0)
L107     r1   = px.divide(px.shift(22)).sub(1.0)
L108     br1  = spx.divide(spx.shift(22)).sub(1.0)
L109     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L110     tt &= (rs >= 0.10)
L111
L112     return tt.fillna(False).sum(axis=1).astype(int)
L113
L114
L115 def build_breadth_header():
L116     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L117     exist, cand, tickers = _load_universe()
L118     if not tickers:
L119         return "", "NORMAL", 0
L120     px, spx = _fetch_prices_600d(tickers)
L121     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L122     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L123     if C_ts.empty:
L124         return "", "NORMAL", 0
L125     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L126     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L127     C_full = int(C_ts.iloc[-1])
L128
L129     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L130     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L131     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L132
L133     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L134     N_G = config.N_G
L135     th_in_rec   = max(N_G, q05)
L136     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L137     th_norm_rec = max(3*N_G, q60)
L138
L139     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L140     if use_calib:
L141         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L142     else:
L143         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L144         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L145         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L146         th_src = "æ‰‹å‹•"
L147
L148     prev = load_mode("NORMAL")
L149     if   prev == "EMERG":
L150         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L151     elif prev == "CAUTION":
L152         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L153     else:
L154         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L155     save_mode(mode)
L156
L157     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L158     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L159     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L160     eff_days = len(base)
L161
L162     lead_lines = [
L163         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L164         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L165         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L166         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L167         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L168         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L169         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L170         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L171         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L172         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L173     ]
L174     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L175 # Debug flag
L176 debug_mode = False  # set to True for detailed output
L177
L178 # --- Finnhub settings & helper ---
L179 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L180 if not FINNHUB_API_KEY:
L181     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L182
L183 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L184 call_times = []
L185
L186
L187 def finnhub_get(endpoint, params):
L188     """Call Finnhub API with basic rate limiting."""
L189     now = time.time()
L190     cutoff = now - 60
L191     while call_times and call_times[0] < cutoff:
L192         call_times.pop(0)
L193     if len(call_times) >= RATE_LIMIT:
L194         sleep_time = 60 - (now - call_times[0])
L195         time.sleep(sleep_time)
L196     params = {**params, "token": FINNHUB_API_KEY}
L197     try:
L198         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L199         resp.raise_for_status()
L200         data = resp.json()
L201     except requests.exceptions.JSONDecodeError as e:
L202         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L203         return {}
L204     except Exception as e:
L205         print(f"âš ï¸ Finnhub API error: {e}")
L206         return {}
L207     call_times.append(time.time())
L208     return data
L209
L210
L211 def fetch_price(symbol):
L212     try:
L213         data = finnhub_get("quote", {"symbol": symbol})
L214         price = data.get("c")
L215         return float(price) if price not in (None, 0) else float("nan")
L216     except Exception:
L217         return float("nan")
L218
L219
L220 def fetch_vix_ma5():
L221     """Retrieve VIX 5-day moving average via yfinance."""
L222     try:
L223         vix = (
L224             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L225             .dropna()
L226             .tail(5)
L227         )
L228         if len(vix) < 5:
L229             return float("nan")
L230         return vix.mean().item()
L231     except Exception:
L232         return float("nan")
L233
L234
L235
L236 # === Minervini-like sell signals ===
L237 def _yf_df(sym, period="6mo"):
L238     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L239     try:
L240         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L241         if df is None or df.empty:
L242             return None
L243         return df.dropna().assign(
L244             ma20=lambda d: d["Close"].rolling(20).mean(),
L245             ma50=lambda d: d["Close"].rolling(50).mean(),
L246             vol50=lambda d: d["Volume"].rolling(50).mean(),
L247         )
L248     except Exception:
L249         return None
L250
L251
L252 def _scalar(row, col):
L253     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L254     try:
L255         v = row[col]
L256         if hasattr(v, "item"):
L257             try:
L258                 v = v.item()
L259             except Exception:
L260                 pass
L261         return v
L262     except Exception:
L263         return float("nan")
L264
L265
L266 def _is_strict_down(seq):
L267     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L268     try:
L269         xs = [float(x) for x in seq]
L270         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L271             return False
L272         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L273     except Exception:
L274         return False
L275
L276
L277 def _signals_for_day(df, idx):
L278     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L279     try:
L280         sig = []
L281         d = df.loc[idx]
L282         close = _scalar(d, "Close")
L283         ma20 = _scalar(d, "ma20")
L284         ma50 = _scalar(d, "ma50")
L285         vol = _scalar(d, "Volume")
L286         vol50 = _scalar(d, "vol50")
L287
L288         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L289             sig.append("20DMAâ†“")
L290
L291         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L292             sig.append("50DMAâ†“(å¤§å•†ã„)")
L293
L294         last4 = df.loc[:idx].tail(4)
L295         last10 = df.loc[:idx].tail(10)
L296
L297         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L298         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L299         if lows_desc or reds > 5:
L300             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L301
L302         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L303         if ups >= 7:
L304             sig.append("ä¸Šã’åé‡(>70%)")
L305
L306         last15 = df.loc[:idx].tail(15)
L307         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L308         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L309             sig.append("+25%/15æ—¥å†…")
L310
L311         if len(df.loc[:idx]) >= 2:
L312             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L313             t1_high = _scalar(t1, "High")
L314             t0_open = _scalar(t0, "Open")
L315             t0_close = _scalar(t0, "Close")
L316             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L317                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L318                     sig.append("GUâ†’é™°ç·š")
L319         return sig
L320     except Exception:
L321         return []
L322
L323
L324 def scan_sell_signals(symbols, lookback_days=5):
L325     """
L326     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L327     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L328     """
L329     out = {}
L330     for s in symbols:
L331         df = _yf_df(s)
L332         if df is None or len(df) < 60:
L333             continue
L334         alerts = []
L335         for idx in df.tail(lookback_days).index:
L336             tags = _signals_for_day(df, idx)
L337             if tags:
L338                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L339         if alerts:
L340             out[s] = alerts
L341     return out
L342
L343
L344 def load_portfolio():
L345     tickers_path = Path(__file__).with_name("current_tickers.csv")
L346     with tickers_path.open() as f:
L347         reader = list(csv.reader(f))
L348     return [
L349         {"symbol": sym.strip().upper(), "shares": int(qty), "target_ratio": 1 / len(reader)}
L350         for sym, qty in reader
L351     ]
L352
L353
L354 def compute_threshold():
L355     vix_ma5 = fetch_vix_ma5()
L356     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L357     return vix_ma5, drift_threshold
L358
L359
L360 def compute_threshold_by_mode(mode: str):
L361     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L362     m = (mode or "NORMAL").upper()
L363     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L364     drift_map = config.DRIFT_THRESHOLD_BY_MODE
L365     return cash_map.get(m, 0.10), drift_map.get(m, 12)
L366
L367
L368 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L369     """
L370     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L371     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L372     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L373     """
L374     m = (mode or "NORMAL").upper()
L375     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L376     now  = config.COUNTS_BY_MODE.get(m, base)
L377     cash_slots = max(0, base["G"] - now["G"])
L378     return now["G"], now["D"], cash_slots
L379
L380
L381 def build_dataframe(portfolio):
L382     for stock in portfolio:
L383         price = fetch_price(stock["symbol"])
L384         stock["price"] = price
L385         stock["value"] = price * stock["shares"]
L386
L387     df = pd.DataFrame(portfolio)
L388     total_value = df["value"].sum()
L389     df["current_ratio"] = df["value"] / total_value
L390     df["drift"] = df["current_ratio"] - df["target_ratio"]
L391     df["drift_abs"] = df["drift"].abs()
L392     total_drift_abs = df["drift_abs"].sum()
L393     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L394     df["adjustable"] = (
L395         (df["adjusted_ratio"] * total_value) >= df["price"]
L396     ) & df["price"].notna() & df["price"].gt(0)
L397     return df, total_value, total_drift_abs
L398
L399
L400 def simulate(df, total_value, total_drift_abs, drift_threshold):
L401     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L402     if alert:
L403         df["trade_shares"] = df.apply(
L404             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L405             if r["adjustable"] and r["price"] > 0 else 0,
L406             axis=1,
L407         )
L408         df["new_shares"] = df["shares"] + df["trade_shares"]
L409         df["new_value"] = df["new_shares"] * df["price"]
L410         new_total_value = df["new_value"].sum()
L411         df["simulated_ratio"] = df["new_value"] / new_total_value
L412         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L413         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L414     else:
L415         df["trade_shares"] = np.nan
L416         df["new_shares"] = np.nan
L417         df["new_value"] = np.nan
L418         new_total_value = np.nan
L419         df["simulated_ratio"] = np.nan
L420         df["simulated_drift_abs"] = np.nan
L421         simulated_total_drift_abs = np.nan
L422     return df, alert, new_total_value, simulated_total_drift_abs
L423
L424
L425 def prepare_summary(df, total_drift_abs, alert):
L426     summary = {
L427         "symbol": "åˆè¨ˆ",
L428         "shares": df["shares"].sum(),
L429         "value": df["value"].sum(),
L430         "current_ratio": np.nan,
L431         "drift_abs": total_drift_abs,
L432     }
L433     if alert:
L434         summary["trade_shares"] = np.nan
L435     # Sort details by evaluation value descending before appending summary
L436     df = df.sort_values(by="value", ascending=False)
L437     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L438     if alert:
L439         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L440         df_small = df[cols].copy()
L441         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L442     else:
L443         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L444         df_small = df[cols].copy()
L445         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L446     return df_small
L447
L448
L449 def currency(x):
L450     return f"${x:,.0f}" if pd.notnull(x) else ""
L451
L452
L453 def formatters_for(alert):
L454     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L455     if alert:
L456         formatters["Î”qty"] = "{:.0f}".format
L457     return formatters
L458
L459
L460 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L461     header = (
L462         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L463         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L464         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L465     )
L466     if alert:
L467         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L468         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L469     else:
L470         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L471     # â˜… è¿½è¨˜: TSãƒ«ãƒ¼ãƒ«ï¼ˆG/Då…±é€šï¼‰ã¨æ¨å¥¨ä¿æœ‰æ•°
L472     # TS(åŸºæœ¬)ã‚’ãƒ¢ãƒ¼ãƒ‰ã§å‹•çš„è¡¨ç¤ºã€‚æ®µéšTSã¯ã€ŒåŸºæœ¬ã‹ã‚‰ -3/-6/-8 ptã€å›ºå®šã€‚
L473     base_ts = config.TS_BASE_BY_MODE.get(mode.upper(), config.TS_BASE_BY_MODE["NORMAL"])
L474     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L475     ts_line = f"*ğŸ›¡ TS:* åŸºæœ¬ -{base_ts*100:.0f}% / +30%â†’-{max(base_ts*100 - d1, 0):.0f}% / +60%â†’-{max(base_ts*100 - d2, 0):.0f}% / +100%â†’-{max(base_ts*100 - d3, 0):.0f}%\n"
L476     header += ts_line
L477     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(mode)
L478     cash_pct = cash_slots * (100 / (config.TOTAL_TARGETS))  # 1æ =ç·æ•°åˆ†å‰²ã®%ï¼ˆ20éŠ˜æŸ„ãªã‚‰5%ï¼‰
L479     header += f"*ğŸ“‹ æ¨å¥¨ä¿æœ‰æ•°:* G {g_cnt} / D {d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}æ  â‰’ {cash_pct:.0f}%ï¼‰\n"
L480     return header
L481
L482
L483 def send_slack(text):
L484     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L485     if not SLACK_WEBHOOK_URL:
L486         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L487     payload = {"text": text}
L488     try:
L489         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L490         resp.raise_for_status()
L491         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L492     except Exception as e:
L493         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L494
L495
L496 def send_debug(debug_text):
L497     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L498     if not SLACK_WEBHOOK_URL:
L499         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L500     debug_payload = {"text": "```" + debug_text + "```"}
L501     try:
L502         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L503         resp.raise_for_status()
L504         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L505     except Exception as e:
L506         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L507
L508
L509 def main():
L510     portfolio = load_portfolio()
L511     symbols = [r["symbol"] for r in portfolio]
L512     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L513
L514     breadth_block, mode, _C = build_breadth_header()
L515
L516     cash_ratio, drift_threshold = compute_threshold_by_mode(mode)
L517
L518     df, total_value, total_drift_abs = build_dataframe(portfolio)
L519     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L520         df, total_value, total_drift_abs, drift_threshold
L521     )
L522     df_small = prepare_summary(df, total_drift_abs, alert)
L523     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L524         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L525         if col_sym:
L526             alert_keys = {str(k) for k in sell_alerts.keys()}
L527             df_small[col_sym] = df_small[col_sym].astype(str)
L528             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L529             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L530             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L531     formatters = formatters_for(alert)
L532     header = build_header(
L533         mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L534     )
L535     if breadth_block:
L536         header = breadth_block + "\n" + header
L537     if sell_alerts:
L538         def fmt_pair(date_tags):
L539             date, tags = date_tags
L540             return f"{date}:" + "ãƒ»".join(tags)
L541         listed = []
L542         for t, arr in sell_alerts.items():
L543             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L544         hits = ", ".join(listed)
L545         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L546             header = header.replace(
L547                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L548                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L549             )
L550         else:
L551             header += f"\nğŸŸ¥ {hits}"
L552     table_text = df_small.to_string(formatters=formatters, index=False)
L553     send_slack(header + "\n```" + table_text + "```")
L554
L555     if debug_mode:
L556         debug_cols = [
L557             "symbol",
L558             "shares",
L559             "price",
L560             "value",
L561             "current_ratio",
L562             "drift",
L563             "drift_abs",
L564             "adjusted_ratio",
L565             "adjustable",
L566             "trade_shares",
L567             "new_shares",
L568             "new_value",
L569             "simulated_ratio",
L570             "simulated_drift_abs",
L571         ]
L572         debug_text = (
L573             "=== DEBUG: full dataframe ===\n"
L574             + df[debug_cols].to_string()
L575             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L576             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L577         )
L578         print("\n" + debug_text)
L579         send_debug(debug_text)
L580
L581
L582 if __name__ == "__main__":
L583     main()
L584
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**ï¼ˆNORMAL åŸºæº–ï¼‰
L7
L8 ## Barbell Growth-Defenseæ–¹é‡
L9 - Growthæ  **12éŠ˜æŸ„**ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L10 - Defenseæ  **8éŠ˜æŸ„**ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L11 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L12
L13 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L14 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**ï¼ˆåŸºæº– N_G=12ï¼‰
L15 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L16   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L17   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= ceil(1.5Ã—12)ï¼‰
L18   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L19 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L20
L21 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L22  - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23  - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **14%**
L24  - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ20Ã—5%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L25
L26 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨â€œä¿æœ‰éŠ˜æŸ„æ•°â€ï¼ˆMMFâ‰’ç¾é‡‘ï¼‰
L27 *å„æ =5%ï¼ˆ20éŠ˜æŸ„å‡ç­‰ï¼‰ã€‚ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œæ™‚ã¯**Gã®æ æ•°ã®ã¿**èª¿æ•´ã—ã€å¤–ã—ãŸæ ã¯ç¾é‡‘ã¨ã—ã¦ä¿æŒã€‚*
L28
L29 - **NORMAL:** G **12** / D **8** / ç¾é‡‘åŒ–æ  **0**  
L30 - **CAUTION:** G **10** / D **8** / ç¾é‡‘åŒ–æ  **2**ï¼ˆ= 10%ï¼‰  
L31 - **EMERG:** G **8**  / D **8** / ç¾é‡‘åŒ–æ  **4**ï¼ˆ= 20%ï¼‰  
L32
L33 > å®Ÿé‹ç”¨ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚è§£é™¤æ™‚ã¯factorä¸Šä½ã‹ã‚‰è£œå……ã€‚
L34
L35 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—
L36 - **åŸºæœ¬TS (ãƒ¢ãƒ¼ãƒ‰åˆ¥):** NORMAL **15%** / CAUTION **13%** / EMERG **10%**
L37 - å«ã¿ç›ŠãŒ **+30% / +60% / +100%** åˆ°é”ã§ã€åŸºæœ¬ã‹ã‚‰ **-3pt / -6pt / -8pt** å¼•ãä¸Šã’
L38 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L39
L40 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰æ‰‹é †
L41 ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã§**ã‚¢ãƒ©ãƒ¼ãƒˆ**ãŒå‡ºãŸå ´åˆï¼ˆåˆè¨ˆ|drift| ãŒãƒ¢ãƒ¼ãƒ‰é–¾å€¤ã‚’è¶…éã€EMERGé™¤ãï¼‰ã€ç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãã§ä¸‹è¨˜ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
L42
L43 1. **å£²å´ï¼ˆå¿…é ˆï¼‰**  
L44    Slackãƒ†ãƒ¼ãƒ–ãƒ«ã® **Î”qty ãŒãƒã‚¤ãƒŠã‚¹ã®éŠ˜æŸ„ã‚’å£²å´** ã™ã‚‹ï¼ˆå¯„ä»˜ãæˆè¡Œæ¨å¥¨ï¼‰ã€‚  
L45    ã“ã‚Œã¯ã€ŒåŠæˆ»ã—ã€è¨ˆç®—ã«åŸºã¥ãéé‡é‡ã®å‰Šæ¸›ã‚’æ„å‘³ã™ã‚‹ã€‚
L46
L47 2. **è³¼å…¥ï¼ˆä»»æ„ãƒ»åŠæˆ»ã—ç›®å®‰ï¼‰**  
L48    åŠæˆ»ã—å¾Œã®åˆè¨ˆ|drift|ã‚’**ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å€¤ï¼ˆSlackãƒ˜ãƒƒãƒ€ã«è¡¨ç¤ºï¼‰**ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ã‚’ç›®å®‰ã«ã€  
L49    **ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—**ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ï¼ˆÎ”qtyãŒãƒ—ãƒ©ã‚¹ã®éŠ˜æŸ„ã‚’å„ªå…ˆã—ã¦ã‚‚ã‚ˆã„ï¼‰ã€‚
L50
L51 3. **ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ã®å†è¨­å®šï¼ˆå¿…é ˆï¼‰**  
L52    ã™ã¹ã¦ã®ä¿æœ‰éŠ˜æŸ„ã«ã¤ã„ã¦ã€æœ€æ–°ã®è©•ä¾¡é¡ã«åˆã‚ã›ã¦TSã‚’**å†ç™ºæ³¨ï¼æ›´æ–°**ã™ã‚‹ã€‚  
L53    ãƒ«ãƒ¼ãƒ«ã¯ä¸‹è¨˜ï¼ˆåˆ©ç›Šåˆ°é”ã§æ®µéšçš„ã«ã‚¿ã‚¤ãƒˆåŒ–ï¼‰ï¼š  
L54    - **åŸºæœ¬TS:** -15%  
L55    - **+30% åˆ°é” â†’ TS -12%**  
L56    - **+60% åˆ°é” â†’ TS -9%**  
L57    - **+100% åˆ°é” â†’ TS -7%**  
L58    â€»ã‚¹ãƒˆãƒƒãƒ—ä¾¡æ ¼ã®å¼•ãä¸Šã’ã¯è¨±å¯ã€**å¼•ãä¸‹ã’ã¯ä¸å¯**ï¼ˆåˆ©ç›Šä¿å…¨ã®åŸå‰‡ï¼‰ã€‚
L59
L60 4. **ä¾‹å¤–ï¼ˆEMERGãƒ¢ãƒ¼ãƒ‰ï¼‰**  
L61    ç·Šæ€¥(EMERG)ã§ã¯**ãƒ‰ãƒªãƒ•ãƒˆç”±æ¥ã®å£²è²·ã¯åœæ­¢ï¼ˆâˆï¼‰**ã€‚20éŠ˜æŸ„Ã—å„5%ã¸ã®**å…¨æˆ»ã—**ã®ã¿è¨±å®¹ã€‚
L62
L63 5. **å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°**
L64    - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L65    - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
L66
L67 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †ï¼ˆè¶…ã‚·ãƒ³ãƒ—ãƒ«ï¼‰
L68 ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€**Gã®æ æ•°ã ã‘**ã‚’èª¿æ•´ã™ã‚‹ï¼š
L69 1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰  
L70    - â­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã™ã€‚  
L71    - **`current_tickers.csv` ã‹ã‚‰å¤–ã™GéŠ˜æŸ„ã®è¡Œã‚’å‰Šé™¤**ï¼ˆï¼ãã®æ ã¯ç¾é‡‘åŒ–ï¼‰ã€‚
L72 2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**  
L73    - å¤–ã—ãŸæ ã¯ç¾é‡‘ï¼ˆã¾ãŸã¯MMFç›¸å½“ï¼‰ã§ãƒ—ãƒ¼ãƒ«ã€‚  
L74 3. **å¾©å¸°æ™‚ã®è£œå……**ï¼ˆNORMALã¸ï¼‰  
L75    - **`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ **ï¼ˆfactorä¸Šä½ã‹ã‚‰ï¼‰ã€‚  
L76    - ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚
L77
L78 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦è‡ªå‹•ã§å‡ç­‰æ¯”ç‡ãŒå†è¨ˆç®—ã•ã‚Œã‚‹ã€‚
L79
L80 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L81 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L82 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L83
L84 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L85 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L86
L87 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L88 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L89 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
