# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-27 16:29:02 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ç¾é‡‘æ¯”ç‡
L18 CASH_RATIO_BY_MODE = {
L19     "NORMAL": 0.10,  # 10%
L20     "CAUTION": 0.20,  # 20%
L21     "EMERG": 0.30,  # 30%
L22 }
L23
L24 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L25 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L26 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L27 TS_STEP_DELTAS_PT = (3, 6, 8)
L28
L29 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L30 N_G = COUNTS_BASE["G"]
L31 N_D = COUNTS_BASE["D"]
L32
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import json
L6 import time
L7 from pathlib import Path
L8 import csv
L9 import config
L10
L11 # --- Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã—ãã„å€¤ï¼ˆGrowthã®å¹³å‡DDåŸºæº–ï¼‰---
L12 CD_CAUTION = 0.10   # -10% ã§è­¦æˆ’
L13 CD_EMERG = 0.15   # -15% ã§ç·Šæ€¥
L14
L15 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L16 # Slacké€šçŸ¥ç”¨ã®ãƒ¢ãƒ¼ãƒ‰ã‚¢ã‚¤ã‚³ãƒ³
L17 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸ”´"}
L18 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L19
L20 # --- breadth utilities (factor parity) ---
L21 BENCH = "^GSPC"
L22 CAND_PRICE_MAX = 450.0
L23 RESULTS_DIR = "results"
L24 os.makedirs(RESULTS_DIR, exist_ok=True)
L25
L26
L27 def _state_file():
L28     """Return path to JSON storing the latest breadth/final mode state."""
L29
L30     return str(Path(RESULTS_DIR) / "current_mode.json")
L31
L32
L33 def _load_state_dict() -> dict:
L34     p = Path(_state_file())
L35     if not p.exists():
L36         return {}
L37     try:
L38         data = json.loads(p.read_text(encoding="utf-8") or "{}")
L39         return data if isinstance(data, dict) else {}
L40     except Exception:
L41         return {}
L42
L43
L44 def _save_state_dict(state: dict):
L45     # å¸¸ã« {"mode": "<...>"} ã®1ã‚­ãƒ¼ã«åœ§ç¸®ã—ã¦ä¿å­˜
L46     m = (state.get("mode") or state.get("final_mode") or state.get("breadth_mode") or "NORMAL")
L47     m = str(m).upper().strip()
L48     Path(_state_file()).write_text(
L49         json.dumps({"mode": m}, ensure_ascii=False, indent=2),
L50         encoding="utf-8",
L51     )
L52
L53
L54 def load_breadth_mode(default: str = "NORMAL") -> str:
L55     state = _load_state_dict()
L56     mode = state.get("breadth_mode", state.get("mode", default))
L57     return mode if mode in MODE_RANK else default
L58
L59
L60 def save_breadth_mode(mode: str):
L61     return  # å‚è€ƒå€¤ã®ãŸã‚ä¿å­˜ã—ãªã„ï¼ˆno-opï¼‰
L62
L63
L64 def load_final_mode(default: str = "NORMAL") -> str:
L65     state = _load_state_dict()
L66     mode = state.get("final_mode", state.get("mode", default))
L67     return mode if mode in MODE_RANK else default
L68
L69
L70 def save_final_mode(mode: str):
L71     """çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ mode ã®ã¿ã‚’ä¿å­˜ï¼ˆG-CDã§æ±ºå®šï¼‰"""
L72     m = (mode or "NORMAL").upper().strip()
L73     Path(_state_file()).write_text(
L74         json.dumps({"mode": m}, ensure_ascii=False, indent=2),
L75         encoding="utf-8",
L76     )
L77
L78
L79 def _read_csv_list(fname):
L80     p = Path(__file__).with_name(fname)
L81     if not p.exists(): return []
L82     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L83
L84
L85 # leaders.csv èª­ã¿è¾¼ã¿ï¼ˆresults/leaders.csv, 1åˆ—æƒ³å®šï¼‰
L86 def _read_leaders_symbols() -> list[str]:
L87     p = Path(__file__).with_name("results").joinpath("leaders.csv")
L88     df = pd.read_csv(p, header=None)
L89     return sorted(set(df.iloc[:,0].astype(str).str.strip().str.upper().tolist()))
L90
L91 def _load_universe():
L92     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L93     exist = _read_csv_list("current_tickers.csv")
L94     cand  = _read_csv_list("candidate_tickers.csv")
L95     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L96     cand_keep = []
L97     for t in cand:
L98         try:
L99             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L100         except Exception:
L101             px = float("inf")
L102         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L103             cand_keep.append(t)
L104     tickers = sorted(set(exist + cand_keep))
L105     return exist, cand_keep, tickers
L106
L107
L108 def _fetch_prices_600d(tickers):
L109     data = yf.download(
L110         tickers + [BENCH],
L111         period="600d",
L112         auto_adjust=True,
L113         progress=False,
L114         threads=False,
L115     )
L116     close = data["Close"]
L117     px = close.dropna(how="all", axis=1).ffill(limit=2)
L118     spx = close[BENCH].reindex(px.index).ffill()
L119     return px, spx
L120
L121
L122 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L123     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L124     import numpy as np, pandas as pd
L125     if px is None or px.empty:
L126         return pd.Series(dtype=int)
L127     px = px.dropna(how="all", axis=1)
L128     if win_days and win_days > 0:
L129         px = px.tail(win_days)
L130     if px.empty:
L131         return pd.Series(dtype=int)
L132     # æ¬ æå¸å
L133     px = px.ffill(limit=2)
L134     spx = spx.reindex(px.index).ffill()
L135
L136     ma50  = px.rolling(50,  min_periods=50).mean()
L137     ma150 = px.rolling(150, min_periods=150).mean()
L138     ma200 = px.rolling(200, min_periods=200).mean()
L139
L140     tt = (px > ma150)
L141     tt &= (px > ma200)
L142     tt &= (ma150 > ma200)
L143     tt &= (ma200 - ma200.shift(21) > 0)
L144     tt &= (ma50  > ma150)
L145     tt &= (ma50  > ma200)
L146     tt &= (px    > ma50)
L147
L148     lo252 = px.rolling(252, min_periods=252).min()
L149     hi252 = px.rolling(252, min_periods=252).max()
L150     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L151     tt &= (px >= (0.75 * hi252))
L152
L153     r12  = px.divide(px.shift(252)).sub(1.0)
L154     br12 = spx.divide(spx.shift(252)).sub(1.0)
L155     r1   = px.divide(px.shift(22)).sub(1.0)
L156     br1  = spx.divide(spx.shift(22)).sub(1.0)
L157     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L158     tt &= (rs >= 0.10)
L159
L160     return tt.fillna(False).sum(axis=1).astype(int)
L161
L162
L163 def build_breadth_header():
L164     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L165     exist, cand, tickers = _load_universe()
L166     if not tickers:
L167         return "", "NORMAL", 0
L168     px, spx = _fetch_prices_600d(tickers)
L169     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L170     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L171     if C_ts.empty:
L172         return "", "NORMAL", 0
L173     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L174     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L175     C_full = int(C_ts.iloc[-1])
L176
L177     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L178     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L179     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L180
L181     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L182     N_G = config.N_G
L183     th_in_rec   = max(N_G, q05)
L184     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L185     th_norm_rec = max(3*N_G, q60)
L186
L187     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L188     if use_calib:
L189         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L190     else:
L191         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L192         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L193         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L194         th_src = "æ‰‹å‹•"
L195
L196     prev = load_breadth_mode("NORMAL")
L197     if   prev == "EMERG":
L198         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L199     elif prev == "CAUTION":
L200         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L201     else:
L202         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L203     save_breadth_mode(mode)
L204
L205     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L206     eff_days = len(base)
L207
L208     lead_lines = [
L209         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L210         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L211         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L212         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L213         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L214         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L215         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L216         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L217         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L218         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L219     ]
L220     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L221
L222
L223 def _format_mode(mode: str) -> str:
L224     upper = (mode or "NORMAL").upper()
L225     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L226
L227
L228 def _gcd_mode_today(g_syms: list[str]) -> tuple[str, float]:
L229     """
L230     ç¾åœ¨ã®Growthç¾¤ã«ã¤ã„ã¦ã€Low_today / Peak60(High) ã®ç­‰åŠ é‡å¹³å‡ã‹ã‚‰ G-CD(%) ã‚’ç®—å‡ºã—ã€ãƒ¢ãƒ¼ãƒ‰ã‚’è¿”ã™ã€‚
L231     æˆ»ã‚Šå€¤: (gcd_mode, gcd_pct)  â€»gcd_pctã¯æ­£ã®%ï¼ˆä¾‹ 11.3 ã¯ -11.3%ã®ä¸‹è½ï¼‰
L232     """
L233
L234     if not g_syms:
L235         print("ğŸ“ audit[G-CD details]: GéŠ˜æŸ„ãŒç©ºã®ãŸã‚ç®—å‡ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
L236         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L237         return "NORMAL", 0.0
L238
L239     try:
L240         df = yf.download(
L241             g_syms,
L242             period="100d",
L243             interval="1d",
L244             auto_adjust=False,
L245             progress=False,
L246         )
L247     except Exception as e:
L248         print(f"âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L249         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L250         return "NORMAL", 0.0
L251
L252     if not isinstance(df, pd.DataFrame) or df.empty:
L253         print("âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L254         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L255         return "NORMAL", 0.0
L256
L257     hi_all = df.get("High") if isinstance(df, pd.DataFrame) else None
L258     lo_all = df.get("Low") if isinstance(df, pd.DataFrame) else None
L259     if hi_all is None or lo_all is None:
L260         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã¾ã™")
L261         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L262         return "NORMAL", 0.0
L263
L264     if isinstance(hi_all, pd.Series):
L265         hi_all = hi_all.to_frame(name=g_syms[0])
L266     if isinstance(lo_all, pd.Series):
L267         lo_all = lo_all.to_frame(name=g_syms[0])
L268
L269     if hi_all.empty or lo_all.empty:
L270         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L271         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L272         return "NORMAL", 0.0
L273
L274     peak60 = hi_all.rolling(60, min_periods=20).max().tail(1).iloc[0]
L275     low_today = lo_all.tail(1).iloc[0]
L276
L277     details: list[tuple[str, float, float, float, float]] = []
L278     for sym in g_syms:
L279         p = float(peak60.get(sym, float("nan"))) if hasattr(peak60, "get") else float("nan")
L280         lt = float(low_today.get(sym, float("nan"))) if hasattr(low_today, "get") else float("nan")
L281         if pd.notna(p) and p > 0 and pd.notna(lt) and lt > 0:
L282             ratio = lt / p
L283             ddpct = (1.0 - ratio) * 100.0
L284             details.append((sym, p, lt, ratio, ddpct))
L285
L286     if not details:
L287         print("âš ï¸ audit[G-CD details]: æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
L288         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L289         return "NORMAL", 0.0
L290
L291     details.sort(key=lambda x: x[4], reverse=True)
L292     today = pd.Timestamp.today(tz="America/New_York").date().isoformat()
L293     print(f"ğŸ“ audit[G-CD details] {today}  G={len(g_syms)}")
L294     print("  SYMBOL        Peak60(H)     Low(T)     ratio    DD%")
L295     for sym, peak, low, ratio, ddpct in details:
L296         print(f"  {sym:<8}  {peak:>12.6g}  {low:>10.6g}   {ratio:>6.3f}  {ddpct:>6.2f}")
L297
L298     avg_ratio = float(np.mean([r for _, _, _, r, _ in details]))
L299     gcd_pct = max(0.0, (1.0 - avg_ratio) * 100.0)
L300     mode = "EMERG" if gcd_pct >= CD_EMERG * 100 else "CAUTION" if gcd_pct >= CD_CAUTION * 100 else "NORMAL"
L301     print(
L302         f"ğŸ“ audit[G-CD summary]: avg_low/peak60={avg_ratio:.4f}  drawdown={gcd_pct:.2f}%  => {mode}"
L303     )
L304     return mode, gcd_pct
L305 # Debug flag
L306 debug_mode = False  # set to True for detailed output
L307
L308 # --- Finnhub settings & helper ---
L309 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L310 if not FINNHUB_API_KEY:
L311     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L312
L313 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L314 call_times = []
L315
L316
L317 def finnhub_get(endpoint, params):
L318     """Call Finnhub API with basic rate limiting."""
L319     now = time.time()
L320     cutoff = now - 60
L321     while call_times and call_times[0] < cutoff:
L322         call_times.pop(0)
L323     if len(call_times) >= RATE_LIMIT:
L324         sleep_time = 60 - (now - call_times[0])
L325         time.sleep(sleep_time)
L326     params = {**params, "token": FINNHUB_API_KEY}
L327     try:
L328         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L329         resp.raise_for_status()
L330         data = resp.json()
L331     except requests.exceptions.JSONDecodeError as e:
L332         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L333         return {}
L334     except Exception as e:
L335         print(f"âš ï¸ Finnhub API error: {e}")
L336         return {}
L337     call_times.append(time.time())
L338     return data
L339
L340
L341 def fetch_price(symbol):
L342     try:
L343         data = finnhub_get("quote", {"symbol": symbol})
L344         price = data.get("c")
L345         return float(price) if price not in (None, 0) else float("nan")
L346     except Exception:
L347         return float("nan")
L348
L349
L350 def fetch_vix_ma5():
L351     """Retrieve VIX 5-day moving average via yfinance."""
L352     try:
L353         vix = (
L354             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L355             .dropna()
L356             .tail(5)
L357         )
L358         if len(vix) < 5:
L359             return float("nan")
L360         return vix.mean().item()
L361     except Exception:
L362         return float("nan")
L363
L364
L365
L366 # === Minervini-like sell signals ===
L367 def _yf_df(sym, period="6mo"):
L368     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L369     try:
L370         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L371         if df is None or df.empty:
L372             return None
L373         return df.dropna().assign(
L374             ma20=lambda d: d["Close"].rolling(20).mean(),
L375             ma50=lambda d: d["Close"].rolling(50).mean(),
L376             vol50=lambda d: d["Volume"].rolling(50).mean(),
L377         )
L378     except Exception:
L379         return None
L380
L381
L382 def _scalar(row, col):
L383     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L384     try:
L385         v = row[col]
L386         if hasattr(v, "item"):
L387             try:
L388                 v = v.item()
L389             except Exception:
L390                 pass
L391         return v
L392     except Exception:
L393         return float("nan")
L394
L395
L396 def _is_strict_down(seq):
L397     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L398     try:
L399         xs = [float(x) for x in seq]
L400         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L401             return False
L402         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L403     except Exception:
L404         return False
L405
L406
L407 def _signals_for_day(df, idx):
L408     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L409     try:
L410         sig = []
L411         d = df.loc[idx]
L412         close = _scalar(d, "Close")
L413         ma20 = _scalar(d, "ma20")
L414         ma50 = _scalar(d, "ma50")
L415         vol = _scalar(d, "Volume")
L416         vol50 = _scalar(d, "vol50")
L417
L418         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L419             sig.append("20DMAâ†“")
L420
L421         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L422             sig.append("50DMAâ†“(å¤§å•†ã„)")
L423
L424         last4 = df.loc[:idx].tail(4)
L425         last10 = df.loc[:idx].tail(10)
L426
L427         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L428         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L429         if lows_desc or reds > 5:
L430             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L431
L432         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L433         if ups >= 7:
L434             sig.append("ä¸Šã’åé‡(>70%)")
L435
L436         last15 = df.loc[:idx].tail(15)
L437         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L438         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L439             sig.append("+25%/15æ—¥å†…")
L440
L441         if len(df.loc[:idx]) >= 2:
L442             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L443             t1_high = _scalar(t1, "High")
L444             t0_open = _scalar(t0, "Open")
L445             t0_close = _scalar(t0, "Close")
L446             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L447                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L448                     sig.append("GUâ†’é™°ç·š")
L449         return sig
L450     except Exception:
L451         return []
L452
L453
L454 def scan_sell_signals(symbols, lookback_days=5):
L455     """
L456     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L457     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L458     """
L459     out = {}
L460     for s in symbols:
L461         df = _yf_df(s)
L462         if df is None or len(df) < 60:
L463             continue
L464         alerts = []
L465         for idx in df.tail(lookback_days).index:
L466             tags = _signals_for_day(df, idx)
L467             if tags:
L468                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L469         if alerts:
L470             out[s] = alerts
L471     return out
L472
L473
L474 def load_portfolio():
L475     tickers_path = Path(__file__).with_name("current_tickers.csv")
L476     with tickers_path.open() as f:
L477         rows = [row for row in csv.reader(f) if row and row[0].strip()]
L478     n = len(rows)
L479     portfolio = []
L480     for row in rows:
L481         sym = row[0].strip().upper()
L482         qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
L483         bucket = row[2].strip().upper() if len(row) > 2 else ""
L484         entry = {
L485             "symbol": sym,
L486             "shares": qty,
L487             "target_ratio": 1 / n if n else 0.0,
L488             "bucket": bucket,
L489         }
L490         portfolio.append(entry)
L491     return portfolio
L492
L493
L494 def compute_threshold():
L495     vix_ma5 = fetch_vix_ma5()
L496     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L497     return vix_ma5, drift_threshold
L498
L499
L500 def compute_threshold_by_mode(mode: str):
L501     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L502     m = (mode or "NORMAL").upper()
L503     cash_ratio = config.CASH_RATIO_BY_MODE.get(
L504         m, config.CASH_RATIO_BY_MODE.get("NORMAL", 0.10)
L505     )
L506     drift_threshold = config.DRIFT_THRESHOLD_BY_MODE.get(
L507         m, config.DRIFT_THRESHOLD_BY_MODE.get("NORMAL", 12)
L508     )
L509     return cash_ratio, drift_threshold
L510
L511
L512 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L513     """
L514     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L515     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L516     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L517     """
L518     m = (mode or "NORMAL").upper()
L519     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L520     now  = config.COUNTS_BY_MODE.get(m, base)
L521     cash_slots = max(0, base["G"] - now["G"])
L522     return now["G"], now["D"], cash_slots
L523
L524
L525 def _mode_tail_line(final_mode: str) -> str:
L526     """â‘ ãƒ–ãƒ­ãƒƒã‚¯å†…ã®â€œã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šâ€ã‚’æ”¹è¡Œï¼‹ã‚¢ã‚¤ã‚³ãƒ³ã§æ•´å½¢ï¼ˆğŸ“Šã¯è¡¨ç¤ºã—ãªã„ï¼‰"""
L527     fm = (final_mode or "NORMAL").upper()
L528     base_ts = config.TS_BASE_BY_MODE.get(fm, config.TS_BASE_BY_MODE.get("NORMAL", 0.15))
L529     ts_base_pct = int(round(base_ts * 100))
L530     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L531     step30 = max(ts_base_pct - d1, 0)
L532     step60 = max(ts_base_pct - d2, 0)
L533     step100 = max(ts_base_pct - d3, 0)
L534     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(fm)
L535     cash_pct = config.CASH_RATIO_BY_MODE.get(fm, config.CASH_RATIO_BY_MODE.get("NORMAL", 0.10)) * 100
L536     return "\n".join([
L537         "ã€”ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šã€•",
L538         f"ğŸ¯ TSåŸºæœ¬: -{ts_base_pct}ï¼…ï¼ˆ+30%â†’-{step30}ï¼…ï¼+60%â†’-{step60}ï¼…ï¼+100%â†’-{step100}ï¼…ï¼‰",
L539         f"ğŸ§© æ¨å¥¨ä¿æœ‰: G{g_cnt}ãƒ»D{d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}ï¼‰",
L540         f"ğŸ’¼ æ¨å¥¨ç¾é‡‘æ¯”ç‡: {cash_pct:.0f}ï¼…",
L541     ])
L542
L543
L544 def build_dataframe(portfolio):
L545     for stock in portfolio:
L546         price = fetch_price(stock["symbol"])
L547         stock["price"] = price
L548         stock["value"] = price * stock["shares"]
L549
L550     df = pd.DataFrame(portfolio)
L551     total_value = df["value"].sum()
L552     df["current_ratio"] = df["value"] / total_value
L553     df["drift"] = df["current_ratio"] - df["target_ratio"]
L554     df["drift_abs"] = df["drift"].abs()
L555     total_drift_abs = df["drift_abs"].sum()
L556     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L557     df["adjustable"] = (
L558         (df["adjusted_ratio"] * total_value) >= df["price"]
L559     ) & df["price"].notna() & df["price"].gt(0)
L560     return df, total_value, total_drift_abs
L561
L562
L563 def simulate(df, total_value, total_drift_abs, drift_threshold):
L564     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L565     if alert:
L566         df["trade_shares"] = df.apply(
L567             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L568             if r["adjustable"] and r["price"] > 0 else 0,
L569             axis=1,
L570         )
L571         df["new_shares"] = df["shares"] + df["trade_shares"]
L572         df["new_value"] = df["new_shares"] * df["price"]
L573         new_total_value = df["new_value"].sum()
L574         df["simulated_ratio"] = df["new_value"] / new_total_value
L575         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L576         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L577     else:
L578         df["trade_shares"] = np.nan
L579         df["new_shares"] = np.nan
L580         df["new_value"] = np.nan
L581         new_total_value = np.nan
L582         df["simulated_ratio"] = np.nan
L583         df["simulated_drift_abs"] = np.nan
L584         simulated_total_drift_abs = np.nan
L585     return df, alert, new_total_value, simulated_total_drift_abs
L586
L587
L588 def prepare_summary(df, total_drift_abs, alert):
L589     summary = {
L590         "symbol": "åˆè¨ˆ",
L591         "shares": df["shares"].sum(),
L592         "value": df["value"].sum(),
L593         "current_ratio": np.nan,
L594         "drift_abs": total_drift_abs,
L595     }
L596     if alert:
L597         summary["trade_shares"] = np.nan
L598     # Sort details by evaluation value descending before appending summary
L599     df = df.sort_values(by="value", ascending=False)
L600     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L601     if alert:
L602         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L603         df_small = df[cols].copy()
L604         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L605     else:
L606         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L607         df_small = df[cols].copy()
L608         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L609     return df_small
L610
L611
L612 def currency(x):
L613     return f"${x:,.0f}" if pd.notnull(x) else ""
L614
L615
L616 def formatters_for(alert):
L617     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L618     if alert:
L619         formatters["Î”qty"] = "{:.0f}".format
L620     return formatters
L621
L622
L623 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L624     # ä¸‹æ®µãƒ˜ãƒƒãƒ€ï¼šğŸ“Šã¨ğŸ“‰ã®ã¿ï¼ˆğŸ’¼ã¯â‘ ã¸é›†ç´„æ¸ˆã¿ï¼‰
L625     header  = f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(int(drift_threshold)) + '%'}\n"
L626     header += f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L627     if alert:
L628         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L629         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L630     else:
L631         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L632     return header
L633
L634
L635 def send_slack(text):
L636     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L637     if not SLACK_WEBHOOK_URL:
L638         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L639     payload = {"text": text}
L640     try:
L641         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L642         resp.raise_for_status()
L643         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L644     except Exception as e:
L645         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L646
L647
L648 def send_debug(debug_text):
L649     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L650     if not SLACK_WEBHOOK_URL:
L651         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L652     debug_payload = {"text": "```" + debug_text + "```"}
L653     try:
L654         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L655         resp.raise_for_status()
L656         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L657     except Exception as e:
L658         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L659
L660
L661 def main():
L662     portfolio = load_portfolio()
L663     symbols = [r["symbol"] for r in portfolio]
L664     # Gé›†åˆã¯ leaders.csv ã‚’ä½¿ç”¨ï¼ˆå­˜åœ¨å‰æï¼‰
L665     g_syms = _read_leaders_symbols()
L666     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L667
L668     breadth_block, breadth_mode, breadth_score = build_breadth_header()
L669     gcd_mode, gcd_pct = _gcd_mode_today(g_syms)
L670
L671     # ãƒ¢ãƒ¼ãƒ‰ã¯ Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDD ã®ã¿ã§æ±ºå®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
L672     final_mode = gcd_mode
L673     save_final_mode(final_mode)
L674
L675     cash_ratio, drift_threshold = compute_threshold_by_mode(final_mode)
L676
L677     df, total_value, total_drift_abs = build_dataframe(portfolio)
L678     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L679         df, total_value, total_drift_abs, drift_threshold
L680     )
L681     df_small = prepare_summary(df, total_drift_abs, alert)
L682     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L683         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L684         if col_sym:
L685             alert_keys = {str(k) for k in sell_alerts.keys()}
L686             df_small[col_sym] = df_small[col_sym].astype(str)
L687             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L688             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L689             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L690     formatters = formatters_for(alert)
L691     header_core = build_header(
L692         final_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L693     )
L694
L695     # --- Slacké€ä¿¡ï¼šâ‘ ï¼ˆåˆ¤å®šï¼‹ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šï¼‰ã¨â‘¡ï¼ˆBreadthè©³ç´°ï¼‰ã‚’ç¢ºå®Ÿã«äºŒåˆ†å‰² ---
L696     me_g = MODE_EMOJIS.get(gcd_mode, "")
L697     me_b = MODE_EMOJIS.get(breadth_mode, "")
L698     block_gcd = (
L699         f"â‘  Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDD: -{gcd_pct:.1f}%"
L700         f"ï¼ˆåŸºæº–: C={CD_CAUTION*100:.0f}% / E={CD_EMERG*100:.0f}%ï¼‰ åˆ¤å®š: {me_g} {gcd_mode}"
L701     )
L702     # â‘ ãƒ–ãƒ­ãƒƒã‚¯ï¼šã“ã“ã¾ã§ï¼‹ã“ã®ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆğŸ“Šã¯ã“ã“ã«å‡ºã•ãªã„ï¼‰
L703     first_block = "```\n" + block_gcd + "\n" + _mode_tail_line(final_mode) + "\n```"
L704
L705     # â‘¡ãƒ–ãƒ­ãƒƒã‚¯ï¼šBreadthã®ã¿ï¼ˆâ€œç·åˆï¼ˆå‚è€ƒè¡¨ç¤ºï¼‰â€ã¯å»ƒæ­¢ï¼‰
L706     block_breadth = f"â‘¡ Breadth: {me_b} {breadth_mode}ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}ï¼‰"
L707     # breadth_block ã®ä¸­èº«ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹é™¤å»ï¼‹é‡è¤‡è¡Œã‚’é™¤å»ï¼‰
L708     breadth_details = ""
L709     if breadth_block:
L710         inner = breadth_block
L711         if inner.startswith("```"):
L712             inner = inner[len("```"):]
L713             if inner.startswith("\n"):
L714                 inner = inner[1:]
L715             if inner.endswith("```"):
L716                 inner = inner[:-3]
L717         # â‘¡ã‚¿ã‚¤ãƒˆãƒ«ã§æ—¢å‡ºã®è¡Œã¯å‰Šé™¤
L718         inner_lines = [ln for ln in inner.splitlines() if ("ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in ln and "ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°" not in ln)]
L719         breadth_details = "\n".join(inner_lines).strip()
L720     second_body = block_breadth + ("\n" + breadth_details if breadth_details else "")
L721     second_block = "```\n" + second_body.strip() + "\n```"
L722
L723     # é€£ç¶šã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒçµåˆã•ã‚Œãªã„ã‚ˆã†ç©ºè¡Œã‚’1è¡Œè¿½åŠ 
L724     header = first_block + "\n\n" + second_block + "\n" + header_core
L725     if sell_alerts:
L726         def fmt_pair(date_tags):
L727             date, tags = date_tags
L728             return f"{date}:" + "ãƒ»".join(tags)
L729         listed = []
L730         for t, arr in sell_alerts.items():
L731             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L732         hits = ", ".join(listed)
L733         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L734             header = header.replace(
L735                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L736                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L737             )
L738         else:
L739             header += f"\nğŸŸ¥ {hits}"
L740     table_text = df_small.to_string(formatters=formatters, index=False)
L741     send_slack(header + "\n```" + table_text + "```")
L742
L743     if debug_mode:
L744         debug_cols = [
L745             "symbol",
L746             "shares",
L747             "price",
L748             "value",
L749             "current_ratio",
L750             "drift",
L751             "drift_abs",
L752             "adjusted_ratio",
L753             "adjustable",
L754             "trade_shares",
L755             "new_shares",
L756             "new_value",
L757             "simulated_ratio",
L758             "simulated_drift_abs",
L759         ]
L760         debug_text = (
L761             "=== DEBUG: full dataframe ===\n"
L762             + df[debug_cols].to_string()
L763             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L764             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L765         )
L766         print("\n" + debug_text)
L767         send_debug(debug_text)
L768
L769
L770 if __name__ == "__main__":
L771     main()
L772
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 permissions:
L13   contents: write
L14
L15 jobs:
L16   build-and-report:
L17     runs-on: ubuntu-latest
L18
L19     steps:
L20       - name: Debug start
L21         run: echo 'ğŸš€ DEBUGstarted'
L22               
L23       - name: Checkout repository
L24         uses: actions/checkout@v4
L25         with:
L26           fetch-depth: 0
L27
L28       - name: Setup Python
L29         uses: actions/setup-python@v4
L30         with:
L31           python-version: '3.x'
L32
L33       - name: Install dependencies
L34         run: pip install -r requirements.txt
L35
L36       - name: Prepare results directory
L37         run: mkdir -p results
L38
L39       - name: Run drift.py
L40         env:
L41           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L42           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L43         run: python drift.py
L44
L45       - name: Commit results if changed
L46         if: ${{ github.event_name != 'pull_request' }}
L47         run: |
L48           git config user.name  "github-actions[bot]"
L49           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L50           git add results/ || true
L51           if git diff --cached --quiet; then
L52             echo "No changes to commit."
L53             exit 0
L54           fi
L55           git pull --rebase --autostash origin "${GITHUB_REF_NAME:-$GITHUB_REF}" || true
L56           git commit -m "ci: update results [skip ci]"
L57           git push origin HEAD:${GITHUB_REF_NAME:-$GITHUB_REF}
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆGã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã¿ï¼Breadthã¯å‚è€ƒæŒ‡æ¨™ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰ã€‚GãŒå…ˆè¡Œã—ã¦è‰¯åŒ–ã™ã‚Œã°1æ®µéšå›å¾©*
L20
L21 ### â‘  Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDï¼ˆGrowthã®ã¿ãƒ»**æœ€çµ‚ãƒ¢ãƒ¼ãƒ‰ã¯ã“ã‚Œã§æ±ºå®š**ï¼‰
L22 - å¯¾è±¡ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ã†ã¡ `bucket = "G"` ã®éŠ˜æŸ„ã‚’ Growth ç¾¤ã¨ã—ã¦é›†è¨ˆ
L23 - ç®—å‡ºï¼šå„GéŠ˜æŸ„ã® `Low_today / Peak60(High)` ã‚’ç­‰åŠ é‡å¹³å‡ã—ã€`1 - å¹³å‡` ã‚’%è¡¨ç¤ºï¼ˆæ­£ã®å€¤ãŒä¸‹è½å¹…ï¼‰
L24 - ã—ãã„å€¤ï¼š**CAUTION = 10% / EMERG = 15%**
L25 - ãƒ­ã‚°ï¼šSlackã¨ã¯åˆ¥ã«ã€æ¨™æº–å‡ºåŠ›ã¸éŠ˜æŸ„åˆ¥ã® Peak60ãƒ»Lowãƒ»æ¯”ç‡ãƒ»DD% ã‚’é™é †ã§è¨˜éŒ²
L26
L27 ### â‘¡ ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼ˆtrend_template åˆæ ¼æœ¬æ•°ï¼‰â€»**å‚è€ƒè¡¨ç¤ºã®ã¿**
L28 - current+candidate å…¨ä½“ã§ trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„æ•°ï¼ˆåŸºæº– N_G=12ï¼‰
L29 - é–¾å€¤ï¼šéå»600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰è‡ªå‹•æ¡ç”¨ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L30   - ç·Šæ€¥å…¥ã‚Š: max(q05, 12æœ¬)
L31   - ç·Šæ€¥è§£é™¤: max(q20, 18æœ¬)
L32   - é€šå¸¸å¾©å¸°: max(q60, 36æœ¬)
L33 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L34
L35 > ãƒ¡ãƒ¢ï¼šBreadthã¯å¸‚å ´ã®ä½“æ¸©è¨ˆã¨ã—ã¦ä½µè¨˜ã™ã‚‹ãŒã€**ãƒ¢ãƒ¼ãƒ‰ã®æ±ºå®šã¯Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã¿**ã€‚
L36
L37 ---
L38
L39 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®šï¼ˆç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆãƒ»ä¿æœ‰æ•°ï¼‰
L40
L41 | ãƒ¢ãƒ¼ãƒ‰       | ç¾é‡‘æ¯”ç‡ | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤      | åŸºæœ¬TSå¹… | Growthæ æ•° | Defenseæ æ•° | è£œè¶³ |
L42 |--------------|----------|-------------------|----------|------------|-------------|------|
L43 | **NORMAL**   | 10%      | 12%               | -15%     | 12         | 8           | ãƒ•ãƒ«20éŠ˜æŸ„ï¼ˆç¾é‡‘åŒ–æ ãªã—ï¼‰ |
L44 | **CAUTION**  | 20%      | 14%               | -13%     | 10         | 8           | Gã‚’2æ å¤–ã—=ç¾é‡‘åŒ–10% + è¿½åŠ 10% |
L45 | **EMERG**    | 30%      | ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ | -10%     | 8          | 8           | Gã‚’4æ å¤–ã—=ç¾é‡‘åŒ–20% + è¿½åŠ 10% |
L46
L47 - å«ã¿ç›Šåˆ°é”æ™‚ã®TSã‚¿ã‚¤ãƒˆåŒ–ï¼š+30% â†’ -3ptã€+60% â†’ -6ptã€+100% â†’ -8pt
L48 - å«ã¿ç›Š +100% é”æˆæ™‚ã¯50%ã‚’åˆ©ç¢ºã—ã€æ®‹ã‚Šã¯ãƒ•ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ -15%TS ã§ä¿æœ‰ç¶™ç¶š
L49 - TSç™ºå‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã¯å»ƒæ­¢ï¼ˆç¿Œæ—¥ä»¥é™ã™ãã«å†INå¯ï¼‰
L50
L51 <!-- å†—é•·ãªå®šæ•°ç®¡ç†ã®æ³¨è¨˜ã¯å‰Šé™¤ã€‚å®Ÿè£…ã¯ config.py ã«æº–æ‹ ã€‚ -->
L52
L53 ---
L54
L55 ## æ–°è¦è²·ä»˜
L56 - **æ–°è¦INã¯ç­‰åˆ†æ¯”ç‡ï¼ˆ=5%ï¼‰ã®åŠåˆ†ã¾ã§**ã‚’ä¸Šé™ã€‚  
L57 - è¿½åŠ è£œå……ã‚„åŠæˆ»ã—è²·ä»˜ã‚‚åŒã˜ä¸Šé™ã«å¾“ã†ã€‚
L58
L59 ---
L60
L61 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
L62 1. **ç¾é‡‘æ¯”ç‡ â‰¤ é–¾å€¤**ï¼šéé‡é‡éŠ˜æŸ„ã‚’å£²å´ã—ã€ä¸è¶³éŠ˜æŸ„ã‚’è£œå……ã€‚  
L63 2. **ç¾é‡‘æ¯”ç‡ > é–¾å€¤**ï¼š**å£²å´ã¯è¡Œã‚ãš**ã€ç¾é‡‘ã§ãƒ‰ãƒªãƒ•ãƒˆä¸è¶³éŠ˜æŸ„ã‚’è²·ä»˜ï¼ˆç¾é‡‘æ¯”ç‡ã‚’é–¾å€¤ä»¥ä¸‹ã¸æˆ»ã™ã“ã¨ã‚’å„ªå…ˆï¼‰ã€‚  
L64 3. **å…±é€š**ï¼šãƒªãƒãƒ©ãƒ³ã‚¹å¾Œã¯å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã€‚EMERGã§ã¯ã€Œãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ã€ã€20éŠ˜æŸ„Ã—5%å…¨æˆ»ã—ã®ã¿è¨±å®¹ã€‚
L65
L66 ---
L67
L68 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †
L69 - ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€Growthæ æ•°ã ã‘èª¿æ•´ï¼š  
L70   1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã—ã€`current_tickers.csv` ã‹ã‚‰è¡Œå‰Šé™¤ï¼ˆ=ç¾é‡‘åŒ–ï¼‰ã€‚  
L71   2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**ã€‚  
L72   3. **NORMALå¾©å¸°æ™‚ã®è£œå……**ï¼š`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰ï¼‰ã€‚ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚  
L73 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦å‡ç­‰æ¯”ç‡ã‚’å†è¨ˆç®—ã€‚
L74
L75 ---
L76
L77 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L78 - **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦æ—¥æ¬¡ã§ã‚¹ã‚³ã‚¢é›†è¨ˆ**ã—ã€**ã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰IN/OUT**ã‚’æ±ºå®šã€‚  
L79 - å‚è€ƒï¼šOxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€Alpha Investorã€Motley Foolã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã€‚  
L80 - å¹´é–“NISAæ ã¯Growthç¾¤ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ï¼ˆé•·æœŸä¿æŒã«å›ºåŸ·ã—ãªã„ï¼‰ã€‚
L81
L82 ---
L83
L84 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L85 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ  
L86 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
