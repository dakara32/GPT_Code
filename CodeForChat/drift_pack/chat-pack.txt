# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9
L10 # Debug flag
L11 debug_mode = False  # set to True for detailed output
L12
L13 # --- Finnhub settings & helper ---
L14 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L15 if not FINNHUB_API_KEY:
L16     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L17
L18 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L19 call_times = []
L20
L21
L22 def finnhub_get(endpoint, params):
L23     """Call Finnhub API with basic rate limiting."""
L24     now = time.time()
L25     cutoff = now - 60
L26     while call_times and call_times[0] < cutoff:
L27         call_times.pop(0)
L28     if len(call_times) >= RATE_LIMIT:
L29         sleep_time = 60 - (now - call_times[0])
L30         time.sleep(sleep_time)
L31     params = {**params, "token": FINNHUB_API_KEY}
L32     try:
L33         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L34         resp.raise_for_status()
L35         data = resp.json()
L36     except requests.exceptions.JSONDecodeError as e:
L37         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L38         return {}
L39     except Exception as e:
L40         print(f"âš ï¸ Finnhub API error: {e}")
L41         return {}
L42     call_times.append(time.time())
L43     return data
L44
L45
L46 def fetch_price(symbol):
L47     try:
L48         data = finnhub_get("quote", {"symbol": symbol})
L49         price = data.get("c")
L50         return float(price) if price not in (None, 0) else float("nan")
L51     except Exception:
L52         return float("nan")
L53
L54
L55 def fetch_vix_ma5():
L56     """Retrieve VIX 5-day moving average via yfinance."""
L57     try:
L58         vix = (
L59             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L60             .dropna()
L61             .tail(5)
L62         )
L63         if len(vix) < 5:
L64             return float("nan")
L65         return vix.mean().item()
L66     except Exception:
L67         return float("nan")
L68
L69
L70 # --- BEGIN: breadth port ---
L71 RESULTS_DIR = "results"
L72 os.makedirs(RESULTS_DIR, exist_ok=True)
L73
L74
L75 def _breadth_state_file():
L76     return os.path.join(RESULTS_DIR, "breadth_state.json")
L77
L78
L79 def load_mode(default="NORMAL"):
L80     try:
L81         with open(_breadth_state_file(), "r") as f:
L82             m = json.load(f).get("mode", default)
L83         return m if m in ("EMERG", "CAUTION", "NORMAL") else default
L84     except Exception:
L85         return default
L86
L87
L88 def save_mode(mode: str):
L89     try:
L90         with open(_breadth_state_file(), "w") as f:
L91             json.dump({"mode": mode}, f)
L92     except Exception:
L93         pass
L94
L95
L96 def _read_universe_for_breadth():
L97     """current + candidateï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰ã‚’åˆç®—ã—ã€ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
L98     cur = []
L99     try:
L100         with Path(__file__).with_name("current_tickers.csv").open() as f:
L101             cur = [r[0].strip().upper() for r in csv.reader(f) if r]
L102     except Exception:
L103         pass
L104     cand = []
L105     cand_path = Path(__file__).with_name("candidate_tickers.csv")
L106     if cand_path.exists():
L107         try:
L108             with cand_path.open() as f:
L109                 cand = [r[0].strip().upper() for r in csv.reader(f) if r]
L110         except Exception:
L111             pass
L112     # ç©ºã‚„é‡è¤‡ã‚’é™¤å»
L113     uni = sorted({t for t in (cur + cand) if t and t != "^GSPC"})
L114     return uni
L115
L116
L117 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L118     """
L119     scorer.py / Scorer.trend_template_breadth_series ã‚’ç§»æ¤ã€‚
L120     å„å–¶æ¥­æ—¥ã® trend_template åˆæ ¼â€œæœ¬æ•°â€=C ã‚’è¿”ã™ï¼ˆint Seriesï¼‰ã€‚
L121     """
L122     if px is None or px.empty:
L123         return pd.Series(dtype=int)
L124     px = px.dropna(how="all", axis=1)
L125     if win_days and win_days > 0:
L126         px = px.tail(win_days)
L127     if px.empty:
L128         return pd.Series(dtype=int)
L129     spx = spx.reindex(px.index).ffill()
L130
L131     ma50 = px.rolling(50).mean()
L132     ma150 = px.rolling(150).mean()
L133     ma200 = px.rolling(200).mean()
L134
L135     tt = (px > ma150)
L136     tt &= (px > ma200)
L137     tt &= (ma150 > ma200)
L138     tt &= (ma200 - ma200.shift(21) > 0)
L139     tt &= (ma50 > ma150)
L140     tt &= (ma50 > ma200)
L141     tt &= (px > ma50)
L142
L143     lo252 = px.rolling(252).min()
L144     hi252 = px.rolling(252).max()
L145     tt &= (px.divide(lo252).sub(1.0) >= 0.30)  # P_OVER_LOW52 >= 0.30
L146     tt &= (px >= (0.75 * hi252))  # NEAR_52W_HIGH >= -0.25
L147
L148     r12 = px.divide(px.shift(252)).sub(1.0)
L149     br12 = spx.divide(spx.shift(252)).sub(1.0)
L150     r1 = px.divide(px.shift(22)).sub(1.0)
L151     br1 = spx.divide(spx.shift(22)).sub(1.0)
L152     rs = 0.7 * (r12.sub(br12, axis=0)) + 0.3 * (r1.sub(br1, axis=0))
L153     tt &= (rs >= 0.10)
L154
L155     return tt.fillna(False).sum(axis=1).astype(int)
L156
L157
L158 def build_breadth_lead_lines() -> tuple[list[str], str]:
L159     """
L160     æ—§ factor._build_breadth_lead_lines ã¨åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã€‚
L161     ãƒ˜ãƒƒãƒ€ã®å„è¡Œ(list[str])ã¨æ±ºå®šãƒ¢ãƒ¼ãƒ‰("EMERG"/"CAUTION"/"NORMAL")ã‚’è¿”ã™ã€‚
L162     """
L163     bench = "^GSPC"
L164     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L165     warmup = int(os.getenv("BREADTH_WARMUP_DAYS", "252"))
L166     use_calib = (
L167         os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L168     )
L169
L170     tickers = _read_universe_for_breadth()
L171     if not tickers:
L172         raise RuntimeError("breadth: universe empty")
L173
L174     data = yf.download(tickers + [bench], period=f"{win}d", auto_adjust=True, progress=False)
L175     px, spx = data["Close"][tickers], data["Close"][bench]
L176
L177     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L178     if C_ts.empty:
L179         raise RuntimeError("breadth series empty")
L180     base = C_ts.iloc[warmup:] if len(C_ts) > warmup else C_ts
L181     C_full = int(C_ts.iloc[-1])
L182
L183     # åˆ†ä½
L184     q05 = int(
L185         np.nan_to_num(
L186             base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN", "0.05"))),
L187             nan=0.0,
L188         )
L189     )
L190     q20 = int(
L191         np.nan_to_num(
L192             base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))),
L193             nan=0.0,
L194         )
L195     )
L196     q60 = int(
L197         np.nan_to_num(
L198             base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT", "0.60"))),
L199             nan=0.0,
L200         )
L201     )
L202
L203     # è‡ªå‹•/æ‰‹å‹•ã®ã—ãã„å€¤
L204     N_G = 12
L205     th_in_rec = max(N_G, q05)
L206     th_out_rec = max(int(np.ceil(1.5 * N_G)), q20)
L207     th_norm_rec = max(3 * N_G, q60)
L208     if use_calib:
L209         th_in, th_out, th_norm, th_src = (
L210             th_in_rec,
L211             th_out_rec,
L212             th_norm_rec,
L213             "è‡ªå‹•",
L214         )
L215     else:
L216         th_in = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L217         th_out = int(os.getenv("GTT_EMERG_OUT", str(int(1.5 * N_G))))
L218         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3 * N_G)))
L219         th_src = "æ‰‹å‹•"
L220
L221     # ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹
L222     prev = load_mode("NORMAL")
L223     if prev == "EMERG":
L224         mode = (
L225             "EMERG"
L226             if (C_full < th_out)
L227             else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L228         )
L229     elif prev == "CAUTION":
L230         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L231     else:
L232         mode = (
L233             "EMERG"
L234             if (C_full < th_in)
L235             else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L236         )
L237     save_mode(mode)
L238
L239     _MODE_JA = {"EMERG": "ç·Šæ€¥", "CAUTION": "è­¦æˆ’", "NORMAL": "é€šå¸¸"}
L240     _MODE_EMOJI = {"EMERG": "ğŸš¨", "CAUTION": "âš ï¸", "NORMAL": "ğŸŸ¢"}
L241     mode_ja, emoji = _MODE_JA.get(mode, mode), _MODE_EMOJI.get(mode, "â„¹ï¸")
L242     eff_days = len(base)
L243
L244     lead_lines = [
L245         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L246         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L247         f"ã—ãã„å€¤ï¼ˆ{th_src}ï¼‰",
L248         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L249         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L250         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L251         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L252         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L253         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L254         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L255     ]
L256     return lead_lines, mode
L257
L258
L259 def build_breadth_header_block() -> str:
L260     """Slack å…ˆé ­ã«å·®ã—è¾¼ã‚€ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯æ–‡å­—åˆ—ã‚’è¿”ã™ã€‚å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã€‚"""
L261     try:
L262         lines, _mode = build_breadth_lead_lines()
L263         return "```" + "\n".join(lines) + "```"
L264     except Exception:
L265         return ""
L266
L267
L268 # --- END: breadth port ---
L269
L270 # === Minervini-like sell signals ===
L271 def _yf_df(sym, period="6mo"):
L272     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L273     try:
L274         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L275         if df is None or df.empty:
L276             return None
L277         return df.dropna().assign(
L278             ma20=lambda d: d["Close"].rolling(20).mean(),
L279             ma50=lambda d: d["Close"].rolling(50).mean(),
L280             vol50=lambda d: d["Volume"].rolling(50).mean(),
L281         )
L282     except Exception:
L283         return None
L284
L285
L286 def _scalar(row, col):
L287     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L288     try:
L289         v = row[col]
L290         if hasattr(v, "item"):
L291             try:
L292                 v = v.item()
L293             except Exception:
L294                 pass
L295         return v
L296     except Exception:
L297         return float("nan")
L298
L299
L300 def _is_strict_down(seq):
L301     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L302     try:
L303         xs = [float(x) for x in seq]
L304         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L305             return False
L306         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L307     except Exception:
L308         return False
L309
L310
L311 def _signals_for_day(df, idx):
L312     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L313     try:
L314         sig = []
L315         d = df.loc[idx]
L316         close = _scalar(d, "Close")
L317         open_ = _scalar(d, "Open")
L318         ma20 = _scalar(d, "ma20")
L319         ma50 = _scalar(d, "ma50")
L320         vol = _scalar(d, "Volume")
L321         vol50 = _scalar(df.iloc[-1], "vol50")
L322         if any(pd.isna(x) for x in (close, open_, vol, vol50)):
L323             return sig
L324         if pd.notna(ma20) and close < ma20:
L325             sig.append("20DMAâ†“")
L326         if pd.notna(ma50) and close < ma50 and vol > 1.5 * vol50:
L327             sig.append("50DMAâ†“(å¤§å•†ã„)")
L328
L329         last4 = df.loc[:idx].tail(4)
L330         lows_desc = _is_strict_down(last4["Low"].tolist())
L331         last10 = df.loc[:idx].tail(10)
L332         reds = int((last10["Close"] < last10["Open"]).sum())
L333         if lows_desc or reds > 5:
L334             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L335
L336         ups = int((last10["Close"] > last10["Open"]).sum())
L337         if ups >= 7:
L338             sig.append("ä¸Šã’åé‡(>70%)")
L339
L340         last15 = df.loc[:idx].tail(15)
L341         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L342         if pd.notna(base0) and base0 != 0 and (close / base0 - 1) >= 0.25:
L343             sig.append("+25%/15æ—¥å†…")
L344
L345         if len(df.loc[:idx]) >= 2:
L346             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L347             t1_high = _scalar(t1, "High")
L348             t0_open = _scalar(t0, "Open")
L349             t0_close = _scalar(t0, "Close")
L350             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L351                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L352                     sig.append("GUâ†’é™°ç·š")
L353         return sig
L354     except Exception:
L355         return []
L356
L357
L358 def scan_sell_signals(symbols, lookback_days=5):
L359     """
L360     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L361     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L362     """
L363     out = {}
L364     for s in symbols:
L365         df = _yf_df(s)
L366         if df is None or len(df) < 60:
L367             continue
L368         alerts = []
L369         for idx in df.tail(lookback_days).index:
L370             tags = _signals_for_day(df, idx)
L371             if tags:
L372                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L373         if alerts:
L374             out[s] = alerts
L375     return out
L376
L377
L378 def load_portfolio():
L379     tickers_path = Path(__file__).with_name("current_tickers.csv")
L380     with tickers_path.open() as f:
L381         reader = list(csv.reader(f))
L382     return [
L383         {"symbol": sym.strip().upper(), "shares": int(qty), "target_ratio": 1 / len(reader)}
L384         for sym, qty in reader
L385     ]
L386
L387
L388 def compute_threshold():
L389     vix_ma5 = fetch_vix_ma5()
L390     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L391     return vix_ma5, drift_threshold
L392
L393
L394 def build_dataframe(portfolio):
L395     for stock in portfolio:
L396         price = fetch_price(stock["symbol"])
L397         stock["price"] = price
L398         stock["value"] = price * stock["shares"]
L399
L400     df = pd.DataFrame(portfolio)
L401     total_value = df["value"].sum()
L402     df["current_ratio"] = df["value"] / total_value
L403     df["drift"] = df["current_ratio"] - df["target_ratio"]
L404     df["drift_abs"] = df["drift"].abs()
L405     total_drift_abs = df["drift_abs"].sum()
L406     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L407     df["adjustable"] = (
L408         (df["adjusted_ratio"] * total_value) >= df["price"]
L409     ) & df["price"].notna() & df["price"].gt(0)
L410     return df, total_value, total_drift_abs
L411
L412
L413 def simulate(df, total_value, total_drift_abs, drift_threshold):
L414     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L415     if alert:
L416         df["trade_shares"] = df.apply(
L417             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L418             if r["adjustable"] and r["price"] > 0 else 0,
L419             axis=1,
L420         )
L421         df["new_shares"] = df["shares"] + df["trade_shares"]
L422         df["new_value"] = df["new_shares"] * df["price"]
L423         new_total_value = df["new_value"].sum()
L424         df["simulated_ratio"] = df["new_value"] / new_total_value
L425         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L426         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L427     else:
L428         df["trade_shares"] = np.nan
L429         df["new_shares"] = np.nan
L430         df["new_value"] = np.nan
L431         new_total_value = np.nan
L432         df["simulated_ratio"] = np.nan
L433         df["simulated_drift_abs"] = np.nan
L434         simulated_total_drift_abs = np.nan
L435     return df, alert, new_total_value, simulated_total_drift_abs
L436
L437
L438 def prepare_summary(df, total_drift_abs, alert):
L439     summary = {
L440         "symbol": "åˆè¨ˆ",
L441         "shares": df["shares"].sum(),
L442         "value": df["value"].sum(),
L443         "current_ratio": np.nan,
L444         "drift_abs": total_drift_abs,
L445     }
L446     if alert:
L447         summary["trade_shares"] = np.nan
L448     # Sort details by evaluation value descending before appending summary
L449     df = df.sort_values(by="value", ascending=False)
L450     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L451     if alert:
L452         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L453         df_small = df[cols].copy()
L454         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L455     else:
L456         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L457         df_small = df[cols].copy()
L458         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L459     return df_small
L460
L461
L462 def currency(x):
L463     return f"${x:,.0f}" if pd.notnull(x) else ""
L464
L465
L466 def formatters_for(alert):
L467     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L468     if alert:
L469         formatters["Î”qty"] = "{:.0f}".format
L470     return formatters
L471
L472
L473 def build_header(vix_ma5, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L474     header = (
L475         f"*ğŸ“ˆ VIX MA5:* {vix_ma5:.2f}\n"
L476         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(é«˜VIX)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L477         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L478     )
L479     if alert:
L480         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L481         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L482     else:
L483         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L484     return header
L485
L486
L487 def send_slack(text):
L488     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L489     if not SLACK_WEBHOOK_URL:
L490         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L491     payload = {"text": text}
L492     try:
L493         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L494         resp.raise_for_status()
L495         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L496     except Exception as e:
L497         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L498
L499
L500 def send_debug(debug_text):
L501     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L502     if not SLACK_WEBHOOK_URL:
L503         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L504     debug_payload = {"text": "```" + debug_text + "```"}
L505     try:
L506         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L507         resp.raise_for_status()
L508         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L509     except Exception as e:
L510         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L511
L512
L513 def main():
L514     portfolio = load_portfolio()
L515     symbols = [r["symbol"] for r in portfolio]
L516     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L517     vix_ma5, drift_threshold = compute_threshold()
L518     df, total_value, total_drift_abs = build_dataframe(portfolio)
L519     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L520         df, total_value, total_drift_abs, drift_threshold
L521     )
L522     df_small = prepare_summary(df, total_drift_abs, alert)
L523     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L524         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L525         if col_sym:
L526             df_small.insert(0, "âš ", df_small[col_sym].apply(lambda x: "ğŸ”´" if x in sell_alerts else ""))
L527     formatters = formatters_for(alert)
L528     header = build_header(
L529         vix_ma5, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L530     )
L531     if sell_alerts:
L532         def fmt_pair(date_tags):
L533             date, tags = date_tags
L534             return f"{date}:" + "ãƒ»".join(tags)
L535         listed = []
L536         for t, arr in sell_alerts.items():
L537             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L538         hits = ", ".join(listed)
L539         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L540             header = header.replace(
L541                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L542                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L543             )
L544         else:
L545             header += f"\nğŸŸ¥ {hits}"
L546     table_text = df_small.to_string(formatters=formatters, index=False)
L547     breadth_head = build_breadth_header_block()
L548     send_slack((breadth_head + "\n" if breadth_head else "") + header + "\n```" + table_text + "```")
L549
L550     if debug_mode:
L551         debug_cols = [
L552             "symbol",
L553             "shares",
L554             "price",
L555             "value",
L556             "current_ratio",
L557             "drift",
L558             "drift_abs",
L559             "adjusted_ratio",
L560             "adjustable",
L561             "trade_shares",
L562             "new_shares",
L563             "new_value",
L564             "simulated_ratio",
L565             "simulated_drift_abs",
L566         ]
L567         debug_text = (
L568             "=== DEBUG: full dataframe ===\n"
L569             + df[debug_cols].to_string()
L570             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L571             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L572         )
L573         print("\n" + debug_text)
L574         send_debug(debug_text)
L575
L576
L577 if __name__ == "__main__":
L578     main()
L579
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 25éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š4%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6
L7 ## Barbell Growth-Defenseæ–¹é‡
L8 - Growthæ 12éŠ˜æŸ„ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L9 - Defenseæ 13éŠ˜æŸ„ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L10 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L11
L12 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L13 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**
L14 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L15   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L16   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= 1.5Ã—N_Gï¼‰
L17   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L18 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯18æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯36æœ¬ä»¥ä¸Šï¼‰
L19
L20 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L21 - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **10%**
L22 - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23 - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ25Ã—4%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L24
L25 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ï¼ˆçµ±ä¸€ï¼‰
L26 - G/D å…±é€šã® **åŸºæœ¬TS=15%**
L27 - å«ã¿ç›ŠãŒ **+20% / +40% / +60%** åˆ°é”ã§ TS ã‚’ **12% / 9% / 7%** ã«æ®µéšå¼•ãä¸Šã’
L28 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L29
L30 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L31 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L32 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L33
L34 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L35 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L36
L37 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L38 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L39 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 25éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ãƒ»VIXæƒ…å ±ã‚’å–å¾—ã—ã€ç¾æ³æ¯”ç‡ã¨èª¿æ•´æ¡ˆã‚’è¨ˆç®—ã€‚
L6
L7 ## å®šæ•°ãƒ»è¨­å®š
L8 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L9 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L10 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L11
L12 ## ä¸»ãªé–¢æ•°
L13 ### finnhub_get
L14 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L15
L16 ### fetch_price
L17 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L18
L19 ### fetch_vix_ma5
L20 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã—ã€ç›´è¿‘5å–¶æ¥­æ—¥ã®ç§»å‹•å¹³å‡ã‚’ç®—å‡ºã€‚
L21
L22 ### load_portfolio
L23 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L24
L25 ### compute_threshold
L26 - VIX MA5ã«å¿œã˜ã¦ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’10%/12%/é«˜VIXãƒ¢ãƒ¼ãƒ‰(âˆ)ã«è¨­å®šã€‚
L27
L28 ### build_dataframe
L29 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L30
L31 ### simulate
L32 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L33
L34 ### prepare_summary
L35 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L36
L37 ### formatters_for / currency
L38 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L39
L40 ### build_header
L41 - VIXãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚
L42
L43 ### send_slack / send_debug
L44 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L45
L46 ### main
L47 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L48
L49 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L50 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L51 2. `compute_threshold` ã§VIX MA5ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L52 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L53 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L54 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L55 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
