# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-26 17:30:11 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L12 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸš¨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21 LOG_PATH = Path(RESULTS_DIR) / "ts_signal_log.csv"
L22 AUDIT_PATH = Path(RESULTS_DIR) / "ts_eod_audit.csv"
L23
L24
L25 def _state_file():
L26     return str(Path(RESULTS_DIR) / "breadth_state.json")
L27
L28
L29 def load_mode(default="NORMAL"):
L30     try:
L31         m = json.loads(open(_state_file()).read()).get("mode", default)
L32         return m if m in ("EMERG","CAUTION","NORMAL") else default
L33     except Exception:
L34         return default
L35
L36
L37 def save_mode(mode: str):
L38     try:
L39         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L40     except Exception:
L41         pass
L42
L43
L44 def _read_csv_list(fname):
L45     p = Path(__file__).with_name(fname)
L46     if not p.exists(): return []
L47     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L48
L49
L50 def _load_universe():
L51     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L52     exist = _read_csv_list("current_tickers.csv")
L53     cand  = _read_csv_list("candidate_tickers.csv")
L54     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L55     cand_keep = []
L56     for t in cand:
L57         try:
L58             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L59         except Exception:
L60             px = float("inf")
L61         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L62             cand_keep.append(t)
L63     tickers = sorted(set(exist + cand_keep))
L64     return exist, cand_keep, tickers
L65
L66
L67 def _fetch_prices_600d(tickers):
L68     data = yf.download(
L69         tickers + [BENCH],
L70         period="600d",
L71         auto_adjust=True,
L72         progress=False,
L73         threads=False,
L74     )
L75     close = data["Close"]
L76     px = close.dropna(how="all", axis=1).ffill(limit=2)
L77     spx = close[BENCH].reindex(px.index).ffill()
L78     return px, spx
L79
L80
L81 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L82     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L83     import numpy as np, pandas as pd
L84     if px is None or px.empty:
L85         return pd.Series(dtype=int)
L86     px = px.dropna(how="all", axis=1)
L87     if win_days and win_days > 0:
L88         px = px.tail(win_days)
L89     if px.empty:
L90         return pd.Series(dtype=int)
L91     # æ¬ æå¸å
L92     px = px.ffill(limit=2)
L93     spx = spx.reindex(px.index).ffill()
L94
L95     ma50  = px.rolling(50,  min_periods=50).mean()
L96     ma150 = px.rolling(150, min_periods=150).mean()
L97     ma200 = px.rolling(200, min_periods=200).mean()
L98
L99     tt = (px > ma150)
L100     tt &= (px > ma200)
L101     tt &= (ma150 > ma200)
L102     tt &= (ma200 - ma200.shift(21) > 0)
L103     tt &= (ma50  > ma150)
L104     tt &= (ma50  > ma200)
L105     tt &= (px    > ma50)
L106
L107     lo252 = px.rolling(252, min_periods=252).min()
L108     hi252 = px.rolling(252, min_periods=252).max()
L109     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L110     tt &= (px >= (0.75 * hi252))
L111
L112     r12  = px.divide(px.shift(252)).sub(1.0)
L113     br12 = spx.divide(spx.shift(252)).sub(1.0)
L114     r1   = px.divide(px.shift(22)).sub(1.0)
L115     br1  = spx.divide(spx.shift(22)).sub(1.0)
L116     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L117     tt &= (rs >= 0.10)
L118
L119     return tt.fillna(False).sum(axis=1).astype(int)
L120
L121
L122 def build_breadth_header():
L123     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L124     exist, cand, tickers = _load_universe()
L125     if not tickers:
L126         return "", "NORMAL", 0
L127     px, spx = _fetch_prices_600d(tickers)
L128     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L129     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L130     if C_ts.empty:
L131         return "", "NORMAL", 0
L132     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L133     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L134     C_full = int(C_ts.iloc[-1])
L135
L136     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L137     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L138     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L139
L140     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L141     N_G = config.N_G
L142     th_in_rec   = max(N_G, q05)
L143     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L144     th_norm_rec = max(3*N_G, q60)
L145
L146     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L147     if use_calib:
L148         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L149     else:
L150         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L151         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L152         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L153         th_src = "æ‰‹å‹•"
L154
L155     prev = load_mode("NORMAL")
L156     if   prev == "EMERG":
L157         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L158     elif prev == "CAUTION":
L159         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L160     else:
L161         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L162     save_mode(mode)
L163
L164     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L165     eff_days = len(base)
L166
L167     lead_lines = [
L168         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L169         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L170         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L171         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L172         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L173         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L174         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L175         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L176         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L177         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L178     ]
L179     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L180
L181
L182 def _ensure_log_header():
L183     if not LOG_PATH.exists():
L184         LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
L185         with open(LOG_PATH, "w", newline="") as f:
L186             f.write("date,symbol,breach\n")
L187
L188
L189 def _ensure_audit_header():
L190     AUDIT_PATH.parent.mkdir(parents=True, exist_ok=True)
L191     if not AUDIT_PATH.exists():
L192         with open(AUDIT_PATH, "w", newline="") as f:
L193             f.write("date,symbol,high60,low_today,baseTS,threshold,breach\n")
L194
L195
L196 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L197     growth = []
L198     for row in portfolio:
L199         bucket = str(row.get("bucket", "")).strip().upper()
L200         if bucket == "G":
L201             sym = str(row.get("symbol", "")).strip().upper()
L202             if sym:
L203                 growth.append(sym)
L204     return sorted(set(growth))
L205
L206
L207 def _upsert_ts_hits(date_str: str, hits: set[str]):
L208     _ensure_log_header()
L209     try:
L210         df = pd.read_csv(LOG_PATH)
L211     except Exception:
L212         df = pd.DataFrame(columns=["date", "symbol", "breach"])
L213     if df.empty:
L214         df = pd.DataFrame(columns=["date", "symbol", "breach"])
L215     df = df[df["date"] != date_str]
L216     if hits:
L217         add = pd.DataFrame(
L218             {
L219                 "date": date_str,
L220                 "symbol": sorted({h.upper() for h in hits}),
L221                 "breach": 1,
L222             }
L223         )
L224         df = pd.concat([df, add], ignore_index=True)
L225     df = df.sort_values(["date", "symbol"])
L226     df.to_csv(LOG_PATH, index=False)
L227
L228
L229 def _count_unique_hits_5d(today_utc: pd.Timestamp) -> int:
L230     if not LOG_PATH.exists():
L231         return 0
L232     try:
L233         df = pd.read_csv(LOG_PATH)
L234     except Exception:
L235         return 0
L236     if df.empty or "date" not in df.columns or "symbol" not in df.columns:
L237         return 0
L238     if "breach" in df.columns:
L239         try:
L240             df = df[df["breach"].astype(int) == 1]
L241         except Exception:
L242             df = df[df["breach"] == 1]
L243     try:
L244         df["date"] = pd.to_datetime(df["date"], utc=True)
L245     except Exception:
L246         return 0
L247     today = today_utc.normalize()
L248     start = today - pd.offsets.BDay(4)
L249     mask = (df["date"] >= start) & (df["date"] <= today)
L250     if not mask.any():
L251         return 0
L252     return int(df.loc[mask, "symbol"].str.upper().nunique())
L253
L254
L255 def _combine_modes(mode_a: str, mode_b: str) -> str:
L256     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L257     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L258     for mode, rank in MODE_RANK.items():
L259         if rank == max(a, b):
L260             return mode
L261     return "NORMAL"
L262
L263
L264 def _format_mode(mode: str) -> str:
L265     upper = (mode or "NORMAL").upper()
L266     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L267
L268
L269 def _ts_mode_growth_eod(g_syms: list[str], ref_mode: str) -> tuple[str, int, list[str]]:
L270     now_utc = pd.Timestamp.today(tz="UTC")
L271     if not g_syms:
L272         k = _count_unique_hits_5d(now_utc)
L273         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L274         return mode1, k, []
L275
L276     try:
L277         df = yf.download(
L278             g_syms,
L279             period="90d",
L280             interval="1d",
L281             auto_adjust=False,
L282             progress=False,
L283             group_by="column",
L284         )
L285     except Exception:
L286         df = None
L287
L288     hi = lo = None
L289     if isinstance(df, pd.DataFrame) and not df.empty:
L290         try:
L291             hi = df["High"] if "High" in df.columns else None
L292             lo = df["Low"] if "Low" in df.columns else None
L293         except Exception:
L294             hi = lo = None
L295         if isinstance(hi, pd.Series):
L296             hi = hi.to_frame(name=g_syms[0])
L297         if isinstance(lo, pd.Series):
L298             lo = lo.to_frame(name=g_syms[0])
L299
L300     if hi is None or lo is None or hi.empty or lo.empty:
L301         roll_hi = pd.Series(dtype=float)
L302         low_today = pd.Series(dtype=float)
L303     else:
L304         try:
L305             roll_hi = hi.rolling(60, min_periods=20).max().tail(1).iloc[0]
L306             low_today = lo.tail(1).iloc[0]
L307         except Exception:
L308             roll_hi = pd.Series(dtype=float)
L309             low_today = pd.Series(dtype=float)
L310
L311     base = float(config.TS_BASE_BY_MODE.get((ref_mode or "NORMAL").upper(), 0.15))
L312     hits = set()
L313     audit_rows = []
L314     today = now_utc.date().isoformat()
L315     _ensure_audit_header()
L316
L317     def _fmt(val: float) -> str:
L318         if pd.isna(val):
L319             return ""
L320         return f"{float(val):.6g}"
L321
L322     for s in g_syms:
L323         rh = float(roll_hi.get(s, float("nan"))) if hasattr(roll_hi, "get") else float("nan")
L324         lt = float(low_today.get(s, float("nan"))) if hasattr(low_today, "get") else float("nan")
L325         threshold = float("nan")
L326         breach = 0
L327         if pd.notna(rh) and rh > 0 and pd.notna(lt) and lt > 0:
L328             threshold = rh * (1.0 - base)
L329             breach = int(lt <= threshold)
L330             if breach:
L331                 hits.add(s)
L332         audit_rows.append(
L333             {
L334                 "date": today,
L335                 "symbol": s,
L336                 "high60": _fmt(rh),
L337                 "low_today": _fmt(lt),
L338                 "baseTS": f"{base:.3f}",
L339                 "threshold": _fmt(threshold),
L340                 "breach": str(breach),
L341             }
L342         )
L343
L344     if audit_rows:
L345         with open(AUDIT_PATH, "a", newline="") as f:
L346             writer = csv.DictWriter(
L347                 f,
L348                 fieldnames=["date", "symbol", "high60", "low_today", "baseTS", "threshold", "breach"],
L349             )
L350             writer.writerows(audit_rows)
L351
L352     _upsert_ts_hits(today, hits)
L353     k = _count_unique_hits_5d(now_utc)
L354     mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L355     return mode1, k, sorted(hits)
L356 # Debug flag
L357 debug_mode = False  # set to True for detailed output
L358
L359 # --- Finnhub settings & helper ---
L360 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L361 if not FINNHUB_API_KEY:
L362     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L363
L364 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L365 call_times = []
L366
L367
L368 def finnhub_get(endpoint, params):
L369     """Call Finnhub API with basic rate limiting."""
L370     now = time.time()
L371     cutoff = now - 60
L372     while call_times and call_times[0] < cutoff:
L373         call_times.pop(0)
L374     if len(call_times) >= RATE_LIMIT:
L375         sleep_time = 60 - (now - call_times[0])
L376         time.sleep(sleep_time)
L377     params = {**params, "token": FINNHUB_API_KEY}
L378     try:
L379         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L380         resp.raise_for_status()
L381         data = resp.json()
L382     except requests.exceptions.JSONDecodeError as e:
L383         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L384         return {}
L385     except Exception as e:
L386         print(f"âš ï¸ Finnhub API error: {e}")
L387         return {}
L388     call_times.append(time.time())
L389     return data
L390
L391
L392 def fetch_price(symbol):
L393     try:
L394         data = finnhub_get("quote", {"symbol": symbol})
L395         price = data.get("c")
L396         return float(price) if price not in (None, 0) else float("nan")
L397     except Exception:
L398         return float("nan")
L399
L400
L401 def fetch_vix_ma5():
L402     """Retrieve VIX 5-day moving average via yfinance."""
L403     try:
L404         vix = (
L405             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L406             .dropna()
L407             .tail(5)
L408         )
L409         if len(vix) < 5:
L410             return float("nan")
L411         return vix.mean().item()
L412     except Exception:
L413         return float("nan")
L414
L415
L416
L417 # === Minervini-like sell signals ===
L418 def _yf_df(sym, period="6mo"):
L419     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L420     try:
L421         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L422         if df is None or df.empty:
L423             return None
L424         return df.dropna().assign(
L425             ma20=lambda d: d["Close"].rolling(20).mean(),
L426             ma50=lambda d: d["Close"].rolling(50).mean(),
L427             vol50=lambda d: d["Volume"].rolling(50).mean(),
L428         )
L429     except Exception:
L430         return None
L431
L432
L433 def _scalar(row, col):
L434     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L435     try:
L436         v = row[col]
L437         if hasattr(v, "item"):
L438             try:
L439                 v = v.item()
L440             except Exception:
L441                 pass
L442         return v
L443     except Exception:
L444         return float("nan")
L445
L446
L447 def _is_strict_down(seq):
L448     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L449     try:
L450         xs = [float(x) for x in seq]
L451         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L452             return False
L453         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L454     except Exception:
L455         return False
L456
L457
L458 def _signals_for_day(df, idx):
L459     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L460     try:
L461         sig = []
L462         d = df.loc[idx]
L463         close = _scalar(d, "Close")
L464         ma20 = _scalar(d, "ma20")
L465         ma50 = _scalar(d, "ma50")
L466         vol = _scalar(d, "Volume")
L467         vol50 = _scalar(d, "vol50")
L468
L469         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L470             sig.append("20DMAâ†“")
L471
L472         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L473             sig.append("50DMAâ†“(å¤§å•†ã„)")
L474
L475         last4 = df.loc[:idx].tail(4)
L476         last10 = df.loc[:idx].tail(10)
L477
L478         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L479         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L480         if lows_desc or reds > 5:
L481             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L482
L483         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L484         if ups >= 7:
L485             sig.append("ä¸Šã’åé‡(>70%)")
L486
L487         last15 = df.loc[:idx].tail(15)
L488         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L489         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L490             sig.append("+25%/15æ—¥å†…")
L491
L492         if len(df.loc[:idx]) >= 2:
L493             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L494             t1_high = _scalar(t1, "High")
L495             t0_open = _scalar(t0, "Open")
L496             t0_close = _scalar(t0, "Close")
L497             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L498                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L499                     sig.append("GUâ†’é™°ç·š")
L500         return sig
L501     except Exception:
L502         return []
L503
L504
L505 def scan_sell_signals(symbols, lookback_days=5):
L506     """
L507     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L508     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L509     """
L510     out = {}
L511     for s in symbols:
L512         df = _yf_df(s)
L513         if df is None or len(df) < 60:
L514             continue
L515         alerts = []
L516         for idx in df.tail(lookback_days).index:
L517             tags = _signals_for_day(df, idx)
L518             if tags:
L519                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L520         if alerts:
L521             out[s] = alerts
L522     return out
L523
L524
L525 def load_portfolio():
L526     tickers_path = Path(__file__).with_name("current_tickers.csv")
L527     with tickers_path.open() as f:
L528         rows = [row for row in csv.reader(f) if row and row[0].strip()]
L529     n = len(rows)
L530     portfolio = []
L531     for row in rows:
L532         sym = row[0].strip().upper()
L533         qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
L534         bucket = row[2].strip().upper() if len(row) > 2 else ""
L535         entry = {
L536             "symbol": sym,
L537             "shares": qty,
L538             "target_ratio": 1 / n if n else 0.0,
L539             "bucket": bucket,
L540         }
L541         portfolio.append(entry)
L542     return portfolio
L543
L544
L545 def compute_threshold():
L546     vix_ma5 = fetch_vix_ma5()
L547     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L548     return vix_ma5, drift_threshold
L549
L550
L551 def compute_threshold_by_mode(mode: str):
L552     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L553     m = (mode or "NORMAL").upper()
L554     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L555     drift_map = config.DRIFT_THRESHOLD_BY_MODE
L556     return cash_map.get(m, 0.10), drift_map.get(m, 12)
L557
L558
L559 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L560     """
L561     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L562     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L563     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L564     """
L565     m = (mode or "NORMAL").upper()
L566     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L567     now  = config.COUNTS_BY_MODE.get(m, base)
L568     cash_slots = max(0, base["G"] - now["G"])
L569     return now["G"], now["D"], cash_slots
L570
L571
L572 def build_dataframe(portfolio):
L573     for stock in portfolio:
L574         price = fetch_price(stock["symbol"])
L575         stock["price"] = price
L576         stock["value"] = price * stock["shares"]
L577
L578     df = pd.DataFrame(portfolio)
L579     total_value = df["value"].sum()
L580     df["current_ratio"] = df["value"] / total_value
L581     df["drift"] = df["current_ratio"] - df["target_ratio"]
L582     df["drift_abs"] = df["drift"].abs()
L583     total_drift_abs = df["drift_abs"].sum()
L584     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L585     df["adjustable"] = (
L586         (df["adjusted_ratio"] * total_value) >= df["price"]
L587     ) & df["price"].notna() & df["price"].gt(0)
L588     return df, total_value, total_drift_abs
L589
L590
L591 def simulate(df, total_value, total_drift_abs, drift_threshold):
L592     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L593     if alert:
L594         df["trade_shares"] = df.apply(
L595             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L596             if r["adjustable"] and r["price"] > 0 else 0,
L597             axis=1,
L598         )
L599         df["new_shares"] = df["shares"] + df["trade_shares"]
L600         df["new_value"] = df["new_shares"] * df["price"]
L601         new_total_value = df["new_value"].sum()
L602         df["simulated_ratio"] = df["new_value"] / new_total_value
L603         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L604         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L605     else:
L606         df["trade_shares"] = np.nan
L607         df["new_shares"] = np.nan
L608         df["new_value"] = np.nan
L609         new_total_value = np.nan
L610         df["simulated_ratio"] = np.nan
L611         df["simulated_drift_abs"] = np.nan
L612         simulated_total_drift_abs = np.nan
L613     return df, alert, new_total_value, simulated_total_drift_abs
L614
L615
L616 def prepare_summary(df, total_drift_abs, alert):
L617     summary = {
L618         "symbol": "åˆè¨ˆ",
L619         "shares": df["shares"].sum(),
L620         "value": df["value"].sum(),
L621         "current_ratio": np.nan,
L622         "drift_abs": total_drift_abs,
L623     }
L624     if alert:
L625         summary["trade_shares"] = np.nan
L626     # Sort details by evaluation value descending before appending summary
L627     df = df.sort_values(by="value", ascending=False)
L628     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L629     if alert:
L630         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L631         df_small = df[cols].copy()
L632         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L633     else:
L634         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L635         df_small = df[cols].copy()
L636         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L637     return df_small
L638
L639
L640 def currency(x):
L641     return f"${x:,.0f}" if pd.notnull(x) else ""
L642
L643
L644 def formatters_for(alert):
L645     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L646     if alert:
L647         formatters["Î”qty"] = "{:.0f}".format
L648     return formatters
L649
L650
L651 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L652     header = (
L653         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L654         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L655         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L656     )
L657     if alert:
L658         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L659         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L660     else:
L661         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L662     # â˜… è¿½è¨˜: TSãƒ«ãƒ¼ãƒ«ï¼ˆG/Då…±é€šï¼‰ã¨æ¨å¥¨ä¿æœ‰æ•°
L663     # TS(åŸºæœ¬)ã‚’ãƒ¢ãƒ¼ãƒ‰ã§å‹•çš„è¡¨ç¤ºã€‚æ®µéšTSã¯ã€ŒåŸºæœ¬ã‹ã‚‰ -3/-6/-8 ptã€å›ºå®šã€‚
L664     base_ts = config.TS_BASE_BY_MODE.get(mode.upper(), config.TS_BASE_BY_MODE["NORMAL"])
L665     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L666     ts_line = f"*ğŸ›¡ TS:* åŸºæœ¬ -{base_ts*100:.0f}% / +30%â†’-{max(base_ts*100 - d1, 0):.0f}% / +60%â†’-{max(base_ts*100 - d2, 0):.0f}% / +100%â†’-{max(base_ts*100 - d3, 0):.0f}%\n"
L667     header += ts_line
L668     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(mode)
L669     cash_pct = cash_slots * (100 / (config.TOTAL_TARGETS))  # 1æ =ç·æ•°åˆ†å‰²ã®%ï¼ˆ20éŠ˜æŸ„ãªã‚‰5%ï¼‰
L670     header += f"*ğŸ“‹ æ¨å¥¨ä¿æœ‰æ•°:* G {g_cnt} / D {d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}æ  â‰’ {cash_pct:.0f}%ï¼‰\n"
L671     return header
L672
L673
L674 def send_slack(text):
L675     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L676     if not SLACK_WEBHOOK_URL:
L677         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L678     payload = {"text": text}
L679     try:
L680         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L681         resp.raise_for_status()
L682         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L683     except Exception as e:
L684         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L685
L686
L687 def send_debug(debug_text):
L688     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L689     if not SLACK_WEBHOOK_URL:
L690         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L691     debug_payload = {"text": "```" + debug_text + "```"}
L692     try:
L693         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L694         resp.raise_for_status()
L695         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L696     except Exception as e:
L697         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L698
L699
L700 def main():
L701     portfolio = load_portfolio()
L702     symbols = [r["symbol"] for r in portfolio]
L703     g_syms = _load_growth_symbols(portfolio)
L704     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L705
L706     breadth_block, breadth_mode, breadth_score = build_breadth_header()
L707     ts_mode, k5, ts_hits = _ts_mode_growth_eod(g_syms, breadth_mode)
L708     combo_mode = _combine_modes(ts_mode, breadth_mode)
L709
L710     cash_ratio, drift_threshold = compute_threshold_by_mode(breadth_mode)
L711
L712     df, total_value, total_drift_abs = build_dataframe(portfolio)
L713     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L714         df, total_value, total_drift_abs, drift_threshold
L715     )
L716     df_small = prepare_summary(df, total_drift_abs, alert)
L717     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L718         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L719         if col_sym:
L720             alert_keys = {str(k) for k in sell_alerts.keys()}
L721             df_small[col_sym] = df_small[col_sym].astype(str)
L722             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L723             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L724             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L725     formatters = formatters_for(alert)
L726     header_core = build_header(
L727         breadth_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L728     )
L729
L730     g_count = len(g_syms)
L731     hits_line = "ãªã—" if not ts_hits else ", ".join(sorted(ts_hits))
L732     summary_lines = [
L733         f"â‘  Growth TS: {_format_mode(ts_mode)} ï¼ˆ5Dãƒ¦ãƒ‹ãƒ¼ã‚¯: {k5} / G={g_count}ï¼‰",
L734         f"ãƒ»å½“æ—¥ãƒ’ãƒƒãƒˆ: {hits_line}",
L735         f"â‘¡ Breadth: {_format_mode(breadth_mode)} ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}ï¼‰",
L736         f"ç·åˆï¼ˆORæ‚ªåŒ–/ANDå›å¾©ï¼‰: {_format_mode(combo_mode)}",
L737     ]
L738     prepend_block = "\n".join(summary_lines)
L739
L740     if breadth_block:
L741         if breadth_block.startswith("```"):
L742             remainder = breadth_block[len("```") :]
L743             if remainder.startswith("\n"):
L744                 remainder = remainder[1:]
L745             breadth_block = "```\n" + prepend_block + "\n" + remainder
L746         else:
L747             breadth_block = prepend_block + "\n" + breadth_block
L748         header = breadth_block + "\n" + header_core
L749     else:
L750         header = prepend_block + "\n" + header_core
L751     if sell_alerts:
L752         def fmt_pair(date_tags):
L753             date, tags = date_tags
L754             return f"{date}:" + "ãƒ»".join(tags)
L755         listed = []
L756         for t, arr in sell_alerts.items():
L757             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L758         hits = ", ".join(listed)
L759         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L760             header = header.replace(
L761                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L762                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L763             )
L764         else:
L765             header += f"\nğŸŸ¥ {hits}"
L766     table_text = df_small.to_string(formatters=formatters, index=False)
L767     send_slack(header + "\n```" + table_text + "```")
L768
L769     if debug_mode:
L770         debug_cols = [
L771             "symbol",
L772             "shares",
L773             "price",
L774             "value",
L775             "current_ratio",
L776             "drift",
L777             "drift_abs",
L778             "adjusted_ratio",
L779             "adjustable",
L780             "trade_shares",
L781             "new_shares",
L782             "new_value",
L783             "simulated_ratio",
L784             "simulated_drift_abs",
L785         ]
L786         debug_text = (
L787             "=== DEBUG: full dataframe ===\n"
L788             + df[debug_cols].to_string()
L789             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L790             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L791         )
L792         print("\n" + debug_text)
L793         send_debug(debug_text)
L794
L795
L796 if __name__ == "__main__":
L797     main()
L798
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚³ãƒ³ãƒœï¼šå…ˆå°æ ªTS Ã— ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰*
L20
L21 ### â‘  å…ˆå°æ ªTSã‚·ã‚°ãƒŠãƒ«ï¼ˆGrowthã®ã¿ï¼‰
L22 - å¯¾è±¡ï¼ˆGrowthã®å®šç¾©ï¼‰ï¼šå½“æ—¥ä¿æœ‰éŠ˜æŸ„ã®ã†ã¡ **Î² â‰¥ -0.6** ã‚’ Growth ã¨ã¿ãªã™ï¼ˆDefenseã¯ç„¡è¦–ï¼‰
L23 - åˆ¤å®šï¼šç›´è¿‘60æ—¥é«˜å€¤ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰åˆ¥åŸºæœ¬TSå¹…ï¼ˆNORMAL:-15% / CAUTION:-13% / EMERG:-10%ï¼‰ä»¥ä¸Šã®ä¸‹è½ã‚’ã€ŒTSæŠµè§¦ã€ã¨ã¿ãªã™
L24 - é›†è¨ˆï¼šç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æŠµè§¦éŠ˜æŸ„æ•°
L25   - 8éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =EMERG
L26   - 6éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =CAUTION
L27   - ãã‚Œæœªæº€ â†’ â‘ =NORMAL
L28 - è£œè¶³ï¼šåŒä¸€æ—¥ã«è¤‡æ•°å›å®Ÿè¡Œã—ãŸå ´åˆã¯ã€**åŒæ—¥ä¸Šæ›¸ã**ã§ç®¡ç†
L29
L30 ### â‘¡ ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼ˆtrend_template åˆæ ¼æœ¬æ•°ï¼‰
L31 - current+candidate å…¨ä½“ã§ trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„æ•°ï¼ˆåŸºæº– N_G=12ï¼‰
L32 - é–¾å€¤ï¼šéå»600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰è‡ªå‹•æ¡ç”¨ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L33   - ç·Šæ€¥å…¥ã‚Š: max(q05, 12æœ¬)
L34   - ç·Šæ€¥è§£é™¤: max(q20, 18æœ¬)
L35   - é€šå¸¸å¾©å¸°: max(q60, 36æœ¬)
L36 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L37
L38 ### ã‚³ãƒ³ãƒœãƒ«ãƒ¼ãƒ«
L39 - **æ‚ªåŒ–ï¼ˆãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L40   final_mode = max(modeâ‘ , modeâ‘¡)
L41   - ä¾‹ï¼šâ‘ =CAUTION, â‘¡=NORMAL â†’ final=CAUTION
L42   - ä¾‹ï¼šâ‘ =EMERG, â‘¡=CAUTION â†’ final=EMERG
L43
L44 - **å›å¾©ï¼ˆã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L45   final_mode ã‚’1æ®µéšä¸‹ã’ã‚‹ã«ã¯ã€modeâ‘  ã¨ modeâ‘¡ ãŒã¨ã‚‚ã«ä¸‹ä½ãƒ¢ãƒ¼ãƒ‰ã«æƒã£ãŸå ´åˆã®ã¿
L46   - ä¾‹ï¼šEMERGâ†’CAUTION ã¯ â‘ =CAUTION **ã‹ã¤** â‘¡=CAUTION
L47   - ä¾‹ï¼šCAUTIONâ†’NORMAL ã¯ â‘ =NORMAL **ã‹ã¤** â‘¡=NORMAL
L48
L49 > ç›´æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚ºï¼š**ã€Œæ‚ªåŒ–ã¯ã©ã¡ã‚‰ã‹èµ¤ã§èµ¤ã€å›å¾©ã¯ä¸¡æ–¹é’ã§é’ã€**
L50
L51 ---
L52
L53 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®šï¼ˆç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆãƒ»ä¿æœ‰æ•°ï¼‰
L54
L55 | ãƒ¢ãƒ¼ãƒ‰       | ç¾é‡‘æ¯”ç‡ | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤      | åŸºæœ¬TSå¹… | Growthæ æ•° | Defenseæ æ•° | è£œè¶³ |
L56 |--------------|----------|-------------------|----------|------------|-------------|------|
L57 | **NORMAL**   | 10%      | 12%               | -15%     | 12         | 8           | ãƒ•ãƒ«20éŠ˜æŸ„ï¼ˆç¾é‡‘åŒ–æ ãªã—ï¼‰ |
L58 | **CAUTION**  | 20%      | 14%               | -13%     | 10         | 8           | Gã‚’2æ å¤–ã—=ç¾é‡‘åŒ–10% |
L59 | **EMERG**    | 30%      | ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ | -10%     | 8          | 8           | Gã‚’4æ å¤–ã—=ç¾é‡‘åŒ–20% |
L60
L61 - å«ã¿ç›Šåˆ°é”æ™‚ã®TSã‚¿ã‚¤ãƒˆåŒ–ï¼š+30% â†’ -3ptã€+60% â†’ -6ptã€+100% â†’ -8pt
L62 - å«ã¿ç›Š +100% é”æˆæ™‚ã¯50%ã‚’åˆ©ç¢ºã—ã€æ®‹ã‚Šã¯ãƒ•ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ -15%TS ã§ä¿æœ‰ç¶™ç¶š
L63 - TSç™ºå‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã¯å»ƒæ­¢ï¼ˆç¿Œæ—¥ä»¥é™ã™ãã«å†INå¯ï¼‰
L64
L65 ---
L66
L67 ## æ–°è¦è²·ä»˜
L68 - **æ–°è¦INã¯ç­‰åˆ†æ¯”ç‡ï¼ˆ=5%ï¼‰ã®åŠåˆ†ã¾ã§**ã‚’ä¸Šé™ã€‚  
L69 - è¿½åŠ è£œå……ã‚„åŠæˆ»ã—è²·ä»˜ã‚‚åŒã˜ä¸Šé™ã«å¾“ã†ã€‚
L70
L71 ---
L72
L73 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
L74 1. **ç¾é‡‘æ¯”ç‡ â‰¤ é–¾å€¤**ï¼šéé‡é‡éŠ˜æŸ„ã‚’å£²å´ã—ã€ä¸è¶³éŠ˜æŸ„ã‚’è£œå……ã€‚  
L75 2. **ç¾é‡‘æ¯”ç‡ > é–¾å€¤**ï¼š**å£²å´ã¯è¡Œã‚ãš**ã€ç¾é‡‘ã§ãƒ‰ãƒªãƒ•ãƒˆä¸è¶³éŠ˜æŸ„ã‚’è²·ä»˜ï¼ˆç¾é‡‘æ¯”ç‡ã‚’é–¾å€¤ä»¥ä¸‹ã¸æˆ»ã™ã“ã¨ã‚’å„ªå…ˆï¼‰ã€‚  
L76 3. **å…±é€š**ï¼šãƒªãƒãƒ©ãƒ³ã‚¹å¾Œã¯å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã€‚EMERGã§ã¯ã€Œãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ã€ã€20éŠ˜æŸ„Ã—5%å…¨æˆ»ã—ã®ã¿è¨±å®¹ã€‚
L77
L78 ---
L79
L80 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †
L81 - ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€Growthæ æ•°ã ã‘èª¿æ•´ï¼š  
L82   1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã—ã€`current_tickers.csv` ã‹ã‚‰è¡Œå‰Šé™¤ï¼ˆ=ç¾é‡‘åŒ–ï¼‰ã€‚  
L83   2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**ã€‚  
L84   3. **NORMALå¾©å¸°æ™‚ã®è£œå……**ï¼š`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰ï¼‰ã€‚ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚  
L85 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦å‡ç­‰æ¯”ç‡ã‚’å†è¨ˆç®—ã€‚
L86
L87 ---
L88
L89 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L90 - **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦æ—¥æ¬¡ã§ã‚¹ã‚³ã‚¢é›†è¨ˆ**ã—ã€**ã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰IN/OUT**ã‚’æ±ºå®šã€‚  
L91 - å‚è€ƒï¼šOxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€Alpha Investorã€Motley Foolã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã€‚  
L92 - å¹´é–“NISAæ ã¯Growthç¾¤ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ï¼ˆé•·æœŸä¿æŒã«å›ºåŸ·ã—ãªã„ï¼‰ã€‚
L93
L94 ---
L95
L96 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L97 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ  
L98 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
