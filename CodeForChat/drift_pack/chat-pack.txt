# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-26 18:24:45 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import json
L6 import time
L7 from pathlib import Path
L8 import config
L9
L10 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L11 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸš¨"}
L12 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L13
L14 # --- breadth utilities (factor parity) ---
L15 BENCH = "^GSPC"
L16 CAND_PRICE_MAX = 450.0
L17 RESULTS_DIR = "results"
L18 os.makedirs(RESULTS_DIR, exist_ok=True)
L19
L20 AUDIT_PRINT_MAX = int(os.environ.get("AUDIT_PRINT_MAX", "20"))  # stdout ã«æµã™æœ¬æ—¥ã®æ˜ç´°ã®æœ€å¤§è¡Œæ•°
L21
L22
L23 def _state_file():
L24     return str(Path(RESULTS_DIR) / "breadth_state.json")
L25
L26
L27 def load_mode(default="NORMAL"):
L28     try:
L29         m = json.loads(open(_state_file()).read()).get("mode", default)
L30         return m if m in ("EMERG","CAUTION","NORMAL") else default
L31     except Exception:
L32         return default
L33
L34
L35 def save_mode(mode: str):
L36     try:
L37         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L38     except Exception:
L39         pass
L40
L41
L42 def _read_csv_list(fname):
L43     p = Path(__file__).with_name(fname)
L44     if not p.exists(): return []
L45     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L46
L47
L48 def _load_universe():
L49     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L50     exist = _read_csv_list("current_tickers.csv")
L51     cand  = _read_csv_list("candidate_tickers.csv")
L52     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L53     cand_keep = []
L54     for t in cand:
L55         try:
L56             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L57         except Exception:
L58             px = float("inf")
L59         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L60             cand_keep.append(t)
L61     tickers = sorted(set(exist + cand_keep))
L62     return exist, cand_keep, tickers
L63
L64
L65 def _fetch_prices_600d(tickers):
L66     data = yf.download(
L67         tickers + [BENCH],
L68         period="600d",
L69         auto_adjust=True,
L70         progress=False,
L71         threads=False,
L72     )
L73     close = data["Close"]
L74     px = close.dropna(how="all", axis=1).ffill(limit=2)
L75     spx = close[BENCH].reindex(px.index).ffill()
L76     return px, spx
L77
L78
L79 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L80     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L81     import numpy as np, pandas as pd
L82     if px is None or px.empty:
L83         return pd.Series(dtype=int)
L84     px = px.dropna(how="all", axis=1)
L85     if win_days and win_days > 0:
L86         px = px.tail(win_days)
L87     if px.empty:
L88         return pd.Series(dtype=int)
L89     # æ¬ æå¸å
L90     px = px.ffill(limit=2)
L91     spx = spx.reindex(px.index).ffill()
L92
L93     ma50  = px.rolling(50,  min_periods=50).mean()
L94     ma150 = px.rolling(150, min_periods=150).mean()
L95     ma200 = px.rolling(200, min_periods=200).mean()
L96
L97     tt = (px > ma150)
L98     tt &= (px > ma200)
L99     tt &= (ma150 > ma200)
L100     tt &= (ma200 - ma200.shift(21) > 0)
L101     tt &= (ma50  > ma150)
L102     tt &= (ma50  > ma200)
L103     tt &= (px    > ma50)
L104
L105     lo252 = px.rolling(252, min_periods=252).min()
L106     hi252 = px.rolling(252, min_periods=252).max()
L107     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L108     tt &= (px >= (0.75 * hi252))
L109
L110     r12  = px.divide(px.shift(252)).sub(1.0)
L111     br12 = spx.divide(spx.shift(252)).sub(1.0)
L112     r1   = px.divide(px.shift(22)).sub(1.0)
L113     br1  = spx.divide(spx.shift(22)).sub(1.0)
L114     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L115     tt &= (rs >= 0.10)
L116
L117     return tt.fillna(False).sum(axis=1).astype(int)
L118
L119
L120 def build_breadth_header():
L121     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L122     exist, cand, tickers = _load_universe()
L123     if not tickers:
L124         return "", "NORMAL", 0
L125     px, spx = _fetch_prices_600d(tickers)
L126     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L127     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L128     if C_ts.empty:
L129         return "", "NORMAL", 0
L130     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L131     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L132     C_full = int(C_ts.iloc[-1])
L133
L134     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L135     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L136     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L137
L138     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L139     N_G = config.N_G
L140     th_in_rec   = max(N_G, q05)
L141     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L142     th_norm_rec = max(3*N_G, q60)
L143
L144     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L145     if use_calib:
L146         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L147     else:
L148         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L149         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L150         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L151         th_src = "æ‰‹å‹•"
L152
L153     prev = load_mode("NORMAL")
L154     if   prev == "EMERG":
L155         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L156     elif prev == "CAUTION":
L157         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L158     else:
L159         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L160     save_mode(mode)
L161
L162     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L163     eff_days = len(base)
L164
L165     lead_lines = [
L166         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L167         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L168         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L169         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L170         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L171         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L172         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L173         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L174         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L175         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L176     ]
L177     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L178
L179
L180 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L181     growth = []
L182     for row in portfolio:
L183         bucket = str(row.get("bucket", "")).strip().upper()
L184         if bucket == "G":
L185             sym = str(row.get("symbol", "")).strip().upper()
L186             if sym:
L187                 growth.append(sym)
L188     return sorted(set(growth))
L189
L190
L191 def _combine_modes(mode_a: str, mode_b: str) -> str:
L192     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L193     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L194     for mode, rank in MODE_RANK.items():
L195         if rank == max(a, b):
L196             return mode
L197     return "NORMAL"
L198
L199
L200 def _format_mode(mode: str) -> str:
L201     upper = (mode or "NORMAL").upper()
L202     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L203
L204
L205 def _ts_mode_growth_5d(g_syms: list[str], ref_mode: str) -> tuple[str, int, set[str]]:
L206     """ç›´è¿‘5å–¶æ¥­æ—¥ã‚’æ ªä¾¡ç›´æ¥æ–¹å¼ã§ä¸€æ‹¬åˆ¤å®šï¼ˆLow vs 60D Highï¼‰ã€‚"""
L207
L208     if not g_syms:
L209         print("âš ï¸ audit: GéŠ˜æŸ„ãƒªã‚¹ãƒˆãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L210         return "NORMAL", 0, set()
L211
L212     try:
L213         df = yf.download(
L214             g_syms,
L215             period="100d",
L216             interval="1d",
L217             auto_adjust=False,
L218             progress=False,
L219         )
L220     except Exception as e:
L221         print(f"âš ï¸ audit: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L222         return "NORMAL", 0, set()
L223
L224     if not isinstance(df, pd.DataFrame) or df.empty:
L225         print("âš ï¸ audit: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L226         return "NORMAL", 0, set()
L227
L228     try:
L229         hi_all = df["High"] if "High" in df.columns else None
L230         lo_all = df["Low"] if "Low" in df.columns else None
L231     except Exception as e:
L232         print(f"âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L233         hi_all = lo_all = None
L234
L235     if hi_all is None or lo_all is None:
L236         print("âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã‚‹ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L237         return "NORMAL", 0, set()
L238
L239     if isinstance(hi_all, pd.Series):
L240         hi_all = hi_all.to_frame(name=g_syms[0])
L241     if isinstance(lo_all, pd.Series):
L242         lo_all = lo_all.to_frame(name=g_syms[0])
L243
L244     if hi_all.empty or lo_all.empty:
L245         print("âš ï¸ audit: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L246         return "NORMAL", 0, set()
L247
L248     roll_hi = hi_all.rolling(60, min_periods=20).max()
L249     last5_hi = roll_hi.tail(5)
L250     last5_lo = lo_all.tail(5).reindex(last5_hi.index)
L251
L252     if last5_hi.empty or last5_lo.empty:
L253         print("âš ï¸ audit: ç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒæƒã‚ãšã€ä»Šæ—¥ã®æ˜ç´°ã‚’å‡ºåŠ›ã§ãã¾ã›ã‚“")
L254         return "NORMAL", 0, set()
L255
L256     base = float(config.TS_BASE_BY_MODE.get((ref_mode or "NORMAL").upper(), 0.15))
L257     uniq_hits: set[str] = set()
L258     today_hits: set[str] = set()
L259
L260     rows_today_printed = 0
L261     today_reason_flags: list[str] = []
L262     last_day = last5_hi.index[-1]
L263
L264     for dt in last5_hi.index:
L265         hi_row = last5_hi.loc[dt]
L266         lo_row = last5_lo.loc[dt]
L267         for sym in g_syms:
L268             rh = float(hi_row.get(sym, float("nan"))) if hasattr(hi_row, "get") else float("nan")
L269             lt = float(lo_row.get(sym, float("nan"))) if hasattr(lo_row, "get") else float("nan")
L270
L271             if not (pd.notna(rh) and rh > 0):
L272                 if dt == last_day:
L273                     today_reason_flags.append("H60æ¬ æ")
L274                 continue
L275             if not (pd.notna(lt) and lt > 0):
L276                 if dt == last_day:
L277                     today_reason_flags.append("Lowæ¬ æ")
L278                 continue
L279
L280             threshold = rh * (1.0 - base)
L281             breach = int(lt <= threshold)
L282             if breach:
L283                 uniq_hits.add(sym)
L284                 if dt == last_day:
L285                     today_hits.add(sym)
L286
L287             if dt == last_day and rows_today_printed < AUDIT_PRINT_MAX:
L288                 print(
L289                     "ğŸ“ audit: ä»Šæ—¥ã®æ˜ç´° "
L290                     f"{dt.date().isoformat()} {sym} High60={rh:.6g} Low={lt:.6g} "
L291                     f"baseTS={base:.3f} é˜ˆå€¤={threshold:.6g} åˆ¤å®š={breach}"
L292                 )
L293                 rows_today_printed += 1
L294
L295     print(
L296         "ğŸ“ audit: 5Dãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°={0} / ä»Šæ—¥ãƒ’ãƒƒãƒˆä¸€è¦§={1}".format(
L297             len(uniq_hits), sorted(today_hits) if today_hits else []
L298         )
L299     )
L300
L301     if rows_today_printed == 0:
L302         reason = "ã€".join(sorted(set(today_reason_flags))) or "ãƒ‡ãƒ¼ã‚¿æ¬ æã¾ãŸã¯éŠ˜æŸ„ãªã—"
L303         print(f"âš ï¸ audit: ä»Šæ—¥ã®æ˜ç´°ãŒç©ºã§ã™ï¼ˆç†ç”±ã®ãƒ’ãƒ³ãƒˆ: {reason}ï¼‰")
L304
L305     k5 = len(uniq_hits)
L306     mode1 = "EMERG" if k5 >= 8 else "CAUTION" if k5 >= 6 else "NORMAL"
L307     return mode1, k5, today_hits
L308 # Debug flag
L309 debug_mode = False  # set to True for detailed output
L310
L311 # --- Finnhub settings & helper ---
L312 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L313 if not FINNHUB_API_KEY:
L314     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L315
L316 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L317 call_times = []
L318
L319
L320 def finnhub_get(endpoint, params):
L321     """Call Finnhub API with basic rate limiting."""
L322     now = time.time()
L323     cutoff = now - 60
L324     while call_times and call_times[0] < cutoff:
L325         call_times.pop(0)
L326     if len(call_times) >= RATE_LIMIT:
L327         sleep_time = 60 - (now - call_times[0])
L328         time.sleep(sleep_time)
L329     params = {**params, "token": FINNHUB_API_KEY}
L330     try:
L331         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L332         resp.raise_for_status()
L333         data = resp.json()
L334     except requests.exceptions.JSONDecodeError as e:
L335         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L336         return {}
L337     except Exception as e:
L338         print(f"âš ï¸ Finnhub API error: {e}")
L339         return {}
L340     call_times.append(time.time())
L341     return data
L342
L343
L344 def fetch_price(symbol):
L345     try:
L346         data = finnhub_get("quote", {"symbol": symbol})
L347         price = data.get("c")
L348         return float(price) if price not in (None, 0) else float("nan")
L349     except Exception:
L350         return float("nan")
L351
L352
L353 def fetch_vix_ma5():
L354     """Retrieve VIX 5-day moving average via yfinance."""
L355     try:
L356         vix = (
L357             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L358             .dropna()
L359             .tail(5)
L360         )
L361         if len(vix) < 5:
L362             return float("nan")
L363         return vix.mean().item()
L364     except Exception:
L365         return float("nan")
L366
L367
L368
L369 # === Minervini-like sell signals ===
L370 def _yf_df(sym, period="6mo"):
L371     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L372     try:
L373         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L374         if df is None or df.empty:
L375             return None
L376         return df.dropna().assign(
L377             ma20=lambda d: d["Close"].rolling(20).mean(),
L378             ma50=lambda d: d["Close"].rolling(50).mean(),
L379             vol50=lambda d: d["Volume"].rolling(50).mean(),
L380         )
L381     except Exception:
L382         return None
L383
L384
L385 def _scalar(row, col):
L386     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L387     try:
L388         v = row[col]
L389         if hasattr(v, "item"):
L390             try:
L391                 v = v.item()
L392             except Exception:
L393                 pass
L394         return v
L395     except Exception:
L396         return float("nan")
L397
L398
L399 def _is_strict_down(seq):
L400     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L401     try:
L402         xs = [float(x) for x in seq]
L403         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L404             return False
L405         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L406     except Exception:
L407         return False
L408
L409
L410 def _signals_for_day(df, idx):
L411     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L412     try:
L413         sig = []
L414         d = df.loc[idx]
L415         close = _scalar(d, "Close")
L416         ma20 = _scalar(d, "ma20")
L417         ma50 = _scalar(d, "ma50")
L418         vol = _scalar(d, "Volume")
L419         vol50 = _scalar(d, "vol50")
L420
L421         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L422             sig.append("20DMAâ†“")
L423
L424         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L425             sig.append("50DMAâ†“(å¤§å•†ã„)")
L426
L427         last4 = df.loc[:idx].tail(4)
L428         last10 = df.loc[:idx].tail(10)
L429
L430         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L431         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L432         if lows_desc or reds > 5:
L433             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L434
L435         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L436         if ups >= 7:
L437             sig.append("ä¸Šã’åé‡(>70%)")
L438
L439         last15 = df.loc[:idx].tail(15)
L440         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L441         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L442             sig.append("+25%/15æ—¥å†…")
L443
L444         if len(df.loc[:idx]) >= 2:
L445             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L446             t1_high = _scalar(t1, "High")
L447             t0_open = _scalar(t0, "Open")
L448             t0_close = _scalar(t0, "Close")
L449             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L450                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L451                     sig.append("GUâ†’é™°ç·š")
L452         return sig
L453     except Exception:
L454         return []
L455
L456
L457 def scan_sell_signals(symbols, lookback_days=5):
L458     """
L459     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L460     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L461     """
L462     out = {}
L463     for s in symbols:
L464         df = _yf_df(s)
L465         if df is None or len(df) < 60:
L466             continue
L467         alerts = []
L468         for idx in df.tail(lookback_days).index:
L469             tags = _signals_for_day(df, idx)
L470             if tags:
L471                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L472         if alerts:
L473             out[s] = alerts
L474     return out
L475
L476
L477 def load_portfolio():
L478     tickers_path = Path(__file__).with_name("current_tickers.csv")
L479     with tickers_path.open() as f:
L480         rows = [row for row in csv.reader(f) if row and row[0].strip()]
L481     n = len(rows)
L482     portfolio = []
L483     for row in rows:
L484         sym = row[0].strip().upper()
L485         qty = int(row[1]) if len(row) > 1 and row[1].strip() else 0
L486         bucket = row[2].strip().upper() if len(row) > 2 else ""
L487         entry = {
L488             "symbol": sym,
L489             "shares": qty,
L490             "target_ratio": 1 / n if n else 0.0,
L491             "bucket": bucket,
L492         }
L493         portfolio.append(entry)
L494     return portfolio
L495
L496
L497 def compute_threshold():
L498     vix_ma5 = fetch_vix_ma5()
L499     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L500     return vix_ma5, drift_threshold
L501
L502
L503 def compute_threshold_by_mode(mode: str):
L504     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L505     m = (mode or "NORMAL").upper()
L506     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L507     drift_map = config.DRIFT_THRESHOLD_BY_MODE
L508     return cash_map.get(m, 0.10), drift_map.get(m, 12)
L509
L510
L511 def recommended_counts_by_mode(mode: str) -> tuple[int, int, int]:
L512     """
L513     ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ä¿æœ‰æ•° (G_count, D_count, cash_slots) ã‚’è¿”ã™ã€‚
L514     cash_slotsã¯ã€Œå¤–ã™Gæ ã®æ•°ã€ï¼ˆå„æ =5%ï¼‰ã€‚
L515     NORMAL: G12/D8/ç¾é‡‘åŒ–0, CAUTION: G10/D8/ç¾é‡‘åŒ–2, EMERG: G8/D8/ç¾é‡‘åŒ–4
L516     """
L517     m = (mode or "NORMAL").upper()
L518     base = config.COUNTS_BY_MODE.get("NORMAL", config.COUNTS_BASE)
L519     now  = config.COUNTS_BY_MODE.get(m, base)
L520     cash_slots = max(0, base["G"] - now["G"])
L521     return now["G"], now["D"], cash_slots
L522
L523
L524 def build_dataframe(portfolio):
L525     for stock in portfolio:
L526         price = fetch_price(stock["symbol"])
L527         stock["price"] = price
L528         stock["value"] = price * stock["shares"]
L529
L530     df = pd.DataFrame(portfolio)
L531     total_value = df["value"].sum()
L532     df["current_ratio"] = df["value"] / total_value
L533     df["drift"] = df["current_ratio"] - df["target_ratio"]
L534     df["drift_abs"] = df["drift"].abs()
L535     total_drift_abs = df["drift_abs"].sum()
L536     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L537     df["adjustable"] = (
L538         (df["adjusted_ratio"] * total_value) >= df["price"]
L539     ) & df["price"].notna() & df["price"].gt(0)
L540     return df, total_value, total_drift_abs
L541
L542
L543 def simulate(df, total_value, total_drift_abs, drift_threshold):
L544     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L545     if alert:
L546         df["trade_shares"] = df.apply(
L547             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L548             if r["adjustable"] and r["price"] > 0 else 0,
L549             axis=1,
L550         )
L551         df["new_shares"] = df["shares"] + df["trade_shares"]
L552         df["new_value"] = df["new_shares"] * df["price"]
L553         new_total_value = df["new_value"].sum()
L554         df["simulated_ratio"] = df["new_value"] / new_total_value
L555         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L556         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L557     else:
L558         df["trade_shares"] = np.nan
L559         df["new_shares"] = np.nan
L560         df["new_value"] = np.nan
L561         new_total_value = np.nan
L562         df["simulated_ratio"] = np.nan
L563         df["simulated_drift_abs"] = np.nan
L564         simulated_total_drift_abs = np.nan
L565     return df, alert, new_total_value, simulated_total_drift_abs
L566
L567
L568 def prepare_summary(df, total_drift_abs, alert):
L569     summary = {
L570         "symbol": "åˆè¨ˆ",
L571         "shares": df["shares"].sum(),
L572         "value": df["value"].sum(),
L573         "current_ratio": np.nan,
L574         "drift_abs": total_drift_abs,
L575     }
L576     if alert:
L577         summary["trade_shares"] = np.nan
L578     # Sort details by evaluation value descending before appending summary
L579     df = df.sort_values(by="value", ascending=False)
L580     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L581     if alert:
L582         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L583         df_small = df[cols].copy()
L584         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L585     else:
L586         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L587         df_small = df[cols].copy()
L588         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L589     return df_small
L590
L591
L592 def currency(x):
L593     return f"${x:,.0f}" if pd.notnull(x) else ""
L594
L595
L596 def formatters_for(alert):
L597     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L598     if alert:
L599         formatters["Î”qty"] = "{:.0f}".format
L600     return formatters
L601
L602
L603 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L604     header = (
L605         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L606         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L607         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L608     )
L609     if alert:
L610         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L611         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L612     else:
L613         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L614     # â˜… è¿½è¨˜: TSãƒ«ãƒ¼ãƒ«ï¼ˆG/Då…±é€šï¼‰ã¨æ¨å¥¨ä¿æœ‰æ•°
L615     # TS(åŸºæœ¬)ã‚’ãƒ¢ãƒ¼ãƒ‰ã§å‹•çš„è¡¨ç¤ºã€‚æ®µéšTSã¯ã€ŒåŸºæœ¬ã‹ã‚‰ -3/-6/-8 ptã€å›ºå®šã€‚
L616     base_ts = config.TS_BASE_BY_MODE.get(mode.upper(), config.TS_BASE_BY_MODE["NORMAL"])
L617     d1, d2, d3 = config.TS_STEP_DELTAS_PT
L618     ts_line = f"*ğŸ›¡ TS:* åŸºæœ¬ -{base_ts*100:.0f}% / +30%â†’-{max(base_ts*100 - d1, 0):.0f}% / +60%â†’-{max(base_ts*100 - d2, 0):.0f}% / +100%â†’-{max(base_ts*100 - d3, 0):.0f}%\n"
L619     header += ts_line
L620     g_cnt, d_cnt, cash_slots = recommended_counts_by_mode(mode)
L621     cash_pct = cash_slots * (100 / (config.TOTAL_TARGETS))  # 1æ =ç·æ•°åˆ†å‰²ã®%ï¼ˆ20éŠ˜æŸ„ãªã‚‰5%ï¼‰
L622     header += f"*ğŸ“‹ æ¨å¥¨ä¿æœ‰æ•°:* G {g_cnt} / D {d_cnt}ï¼ˆç¾é‡‘åŒ–æ  {cash_slots}æ  â‰’ {cash_pct:.0f}%ï¼‰\n"
L623     return header
L624
L625
L626 def send_slack(text):
L627     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L628     if not SLACK_WEBHOOK_URL:
L629         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L630     payload = {"text": text}
L631     try:
L632         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L633         resp.raise_for_status()
L634         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L635     except Exception as e:
L636         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L637
L638
L639 def send_debug(debug_text):
L640     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L641     if not SLACK_WEBHOOK_URL:
L642         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L643     debug_payload = {"text": "```" + debug_text + "```"}
L644     try:
L645         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L646         resp.raise_for_status()
L647         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L648     except Exception as e:
L649         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L650
L651
L652 def main():
L653     portfolio = load_portfolio()
L654     symbols = [r["symbol"] for r in portfolio]
L655     g_syms = _load_growth_symbols(portfolio)
L656     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L657
L658     breadth_block, breadth_mode, breadth_score = build_breadth_header()
L659     ts_mode, k5, today_hits = _ts_mode_growth_5d(g_syms, breadth_mode)
L660     combo_mode = _combine_modes(ts_mode, breadth_mode)
L661
L662     cash_ratio, drift_threshold = compute_threshold_by_mode(breadth_mode)
L663
L664     df, total_value, total_drift_abs = build_dataframe(portfolio)
L665     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L666         df, total_value, total_drift_abs, drift_threshold
L667     )
L668     df_small = prepare_summary(df, total_drift_abs, alert)
L669     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L670         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L671         if col_sym:
L672             alert_keys = {str(k) for k in sell_alerts.keys()}
L673             df_small[col_sym] = df_small[col_sym].astype(str)
L674             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L675             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L676             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L677     formatters = formatters_for(alert)
L678     header_core = build_header(
L679         breadth_mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L680     )
L681
L682     g_count = len(g_syms)
L683     hits_line = "ãªã—" if not today_hits else ", ".join(sorted(today_hits))
L684     summary_lines = [
L685         f"â‘  Growth TS: {_format_mode(ts_mode)} ï¼ˆ5Dãƒ¦ãƒ‹ãƒ¼ã‚¯: {k5} / G={g_count}ï¼‰",
L686         f"ãƒ»å½“æ—¥ãƒ’ãƒƒãƒˆ: {hits_line}",
L687         f"â‘¡ Breadth: {_format_mode(breadth_mode)} ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}ï¼‰",
L688         f"ç·åˆï¼ˆORæ‚ªåŒ–/ANDå›å¾©ï¼‰: {_format_mode(combo_mode)}",
L689     ]
L690     prepend_block = "\n".join(summary_lines)
L691
L692     if breadth_block:
L693         if breadth_block.startswith("```"):
L694             inner = breadth_block[len("```") :]
L695             if inner.startswith("\n"):
L696                 inner = inner[1:]
L697             if inner.endswith("```"):
L698                 inner = inner[: -len("```")]
L699             inner = inner.strip("\n")
L700             inner_lines = [line for line in inner.splitlines() if "ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in line]
L701             cleaned_inner = "\n".join(inner_lines)
L702             if cleaned_inner:
L703                 new_inner = prepend_block + "\n" + cleaned_inner
L704             else:
L705                 new_inner = prepend_block
L706             breadth_block = "```\n" + new_inner + "\n```"
L707         else:
L708             lines = [line for line in breadth_block.splitlines() if "ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰" not in line]
L709             cleaned_block = "\n".join(lines)
L710             breadth_block = prepend_block + ("\n" + cleaned_block if cleaned_block else "")
L711         header = breadth_block + "\n" + header_core
L712     else:
L713         header = prepend_block + "\n" + header_core
L714     if sell_alerts:
L715         def fmt_pair(date_tags):
L716             date, tags = date_tags
L717             return f"{date}:" + "ãƒ»".join(tags)
L718         listed = []
L719         for t, arr in sell_alerts.items():
L720             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L721         hits = ", ".join(listed)
L722         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L723             header = header.replace(
L724                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L725                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L726             )
L727         else:
L728             header += f"\nğŸŸ¥ {hits}"
L729     table_text = df_small.to_string(formatters=formatters, index=False)
L730     send_slack(header + "\n```" + table_text + "```")
L731
L732     if debug_mode:
L733         debug_cols = [
L734             "symbol",
L735             "shares",
L736             "price",
L737             "value",
L738             "current_ratio",
L739             "drift",
L740             "drift_abs",
L741             "adjusted_ratio",
L742             "adjustable",
L743             "trade_shares",
L744             "new_shares",
L745             "new_value",
L746             "simulated_ratio",
L747             "simulated_drift_abs",
L748         ]
L749         debug_text = (
L750             "=== DEBUG: full dataframe ===\n"
L751             + df[debug_cols].to_string()
L752             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L753             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L754         )
L755         print("\n" + debug_text)
L756         send_debug(debug_text)
L757
L758
L759 if __name__ == "__main__":
L760     main()
L761
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼ˆæ”¹è¨‚ç‰ˆï¼‰
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 20éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š5%ï¼‰  
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨  
L6 - **Growthæ  12éŠ˜æŸ„ / Defenseæ  8éŠ˜æŸ„**
L7
L8 ---
L9
L10 ## Barbell Growth-Defenseæ–¹é‡
L11 - **Growthæ ï¼ˆ12éŠ˜æŸ„ï¼‰**ï¼šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¿½ã†**ã‚¹ã‚¤ãƒ³ã‚°ãƒˆãƒ¬ãƒ¼ãƒ‰**ã€‚é«˜æˆé•·ãƒ»é«˜ãƒœãƒ©éŠ˜æŸ„ã§ãƒªã‚¿ãƒ¼ãƒ³æºæ³‰ã‚’ç‹™ã†ã€‚  
L12 - **Defenseæ ï¼ˆ8éŠ˜æŸ„ï¼‰**ï¼šå®‰å®šé‡è¦–ã®**ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‰ï¼ˆã‚„ã‚„é•·æœŸï¼‰**ã€‚ä½ãƒœãƒ©ãƒ»é«˜å“è³ªã§MDDã‚’æŠ‘åˆ¶ã€‚  
L13 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢ã‚’ç”Ÿã¿ã€**åŠæˆ»ã—ãƒªãƒãƒ©ãƒ³ã‚¹**ã§ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç²å¾—ã€‚
L14
L15 ---
L16
L17 ## ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šï¼ˆã‚³ãƒ³ãƒœï¼šå…ˆå°æ ªTS Ã— ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼‰
L18
L19 **è€ƒãˆæ–¹ï¼š** *æ‚ªåŒ–ã¯ã‚†ã‚‹ãï¼ˆORï¼‰ã€å›å¾©ã¯å³ã—ãï¼ˆANDï¼‰*
L20
L21 ### â‘  å…ˆå°æ ªTSã‚·ã‚°ãƒŠãƒ«ï¼ˆGrowthã®ã¿ï¼‰
L22 - å¯¾è±¡ï¼ˆGrowthã®å®šç¾©ï¼‰ï¼šå½“æ—¥ä¿æœ‰éŠ˜æŸ„ã®ã†ã¡ **Î² â‰¥ -0.6** ã‚’ Growth ã¨ã¿ãªã™ï¼ˆDefenseã¯ç„¡è¦–ï¼‰
L23 - åˆ¤å®šï¼šç›´è¿‘60æ—¥é«˜å€¤ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰åˆ¥åŸºæœ¬TSå¹…ï¼ˆNORMAL:-15% / CAUTION:-13% / EMERG:-10%ï¼‰ä»¥ä¸Šã®ä¸‹è½ã‚’ã€ŒTSæŠµè§¦ã€ã¨ã¿ãªã™
L24 - é›†è¨ˆï¼šç›´è¿‘5å–¶æ¥­æ—¥ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æŠµè§¦éŠ˜æŸ„æ•°
L25   - 8éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =EMERG
L26   - 6éŠ˜æŸ„ä»¥ä¸Š â†’ â‘ =CAUTION
L27   - ãã‚Œæœªæº€ â†’ â‘ =NORMAL
L28 - è£œè¶³ï¼šåŒä¸€æ—¥ã«è¤‡æ•°å›å®Ÿè¡Œã—ãŸå ´åˆã¯ã€**åŒæ—¥ä¸Šæ›¸ã**ã§ç®¡ç†
L29
L30 ### â‘¡ ãƒ–ãƒ¬ãƒƒãƒ‰ã‚¹ï¼ˆtrend_template åˆæ ¼æœ¬æ•°ï¼‰
L31 - current+candidate å…¨ä½“ã§ trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„æ•°ï¼ˆåŸºæº– N_G=12ï¼‰
L32 - é–¾å€¤ï¼šéå»600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰è‡ªå‹•æ¡ç”¨ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L33   - ç·Šæ€¥å…¥ã‚Š: max(q05, 12æœ¬)
L34   - ç·Šæ€¥è§£é™¤: max(q20, 18æœ¬)
L35   - é€šå¸¸å¾©å¸°: max(q60, 36æœ¬)
L36 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ï¼šå‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯23æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯45æœ¬ä»¥ä¸Šï¼‰
L37
L38 ### ã‚³ãƒ³ãƒœãƒ«ãƒ¼ãƒ«
L39 - **æ‚ªåŒ–ï¼ˆãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L40   final_mode = max(modeâ‘ , modeâ‘¡)
L41   - ä¾‹ï¼šâ‘ =CAUTION, â‘¡=NORMAL â†’ final=CAUTION
L42   - ä¾‹ï¼šâ‘ =EMERG, â‘¡=CAUTION â†’ final=EMERG
L43
L44 - **å›å¾©ï¼ˆã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼‰**ï¼š
L45   final_mode ã‚’1æ®µéšä¸‹ã’ã‚‹ã«ã¯ã€modeâ‘  ã¨ modeâ‘¡ ãŒã¨ã‚‚ã«ä¸‹ä½ãƒ¢ãƒ¼ãƒ‰ã«æƒã£ãŸå ´åˆã®ã¿
L46   - ä¾‹ï¼šEMERGâ†’CAUTION ã¯ â‘ =CAUTION **ã‹ã¤** â‘¡=CAUTION
L47   - ä¾‹ï¼šCAUTIONâ†’NORMAL ã¯ â‘ =NORMAL **ã‹ã¤** â‘¡=NORMAL
L48
L49 > ç›´æ„Ÿãƒ•ãƒ¬ãƒ¼ã‚ºï¼š**ã€Œæ‚ªåŒ–ã¯ã©ã¡ã‚‰ã‹èµ¤ã§èµ¤ã€å›å¾©ã¯ä¸¡æ–¹é’ã§é’ã€**
L50
L51 ---
L52
L53 ## ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®šï¼ˆç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆãƒ»ä¿æœ‰æ•°ï¼‰
L54
L55 | ãƒ¢ãƒ¼ãƒ‰       | ç¾é‡‘æ¯”ç‡ | ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤      | åŸºæœ¬TSå¹… | Growthæ æ•° | Defenseæ æ•° | è£œè¶³ |
L56 |--------------|----------|-------------------|----------|------------|-------------|------|
L57 | **NORMAL**   | 10%      | 12%               | -15%     | 12         | 8           | ãƒ•ãƒ«20éŠ˜æŸ„ï¼ˆç¾é‡‘åŒ–æ ãªã—ï¼‰ |
L58 | **CAUTION**  | 20%      | 14%               | -13%     | 10         | 8           | Gã‚’2æ å¤–ã—=ç¾é‡‘åŒ–10% |
L59 | **EMERG**    | 30%      | ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ | -10%     | 8          | 8           | Gã‚’4æ å¤–ã—=ç¾é‡‘åŒ–20% |
L60
L61 - å«ã¿ç›Šåˆ°é”æ™‚ã®TSã‚¿ã‚¤ãƒˆåŒ–ï¼š+30% â†’ -3ptã€+60% â†’ -6ptã€+100% â†’ -8pt
L62 - å«ã¿ç›Š +100% é”æˆæ™‚ã¯50%ã‚’åˆ©ç¢ºã—ã€æ®‹ã‚Šã¯ãƒ•ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒ³ã¨ã—ã¦ -15%TS ã§ä¿æœ‰ç¶™ç¶š
L63 - TSç™ºå‹•å¾Œã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã¯å»ƒæ­¢ï¼ˆç¿Œæ—¥ä»¥é™ã™ãã«å†INå¯ï¼‰
L64
L65 ---
L66
L67 ## æ–°è¦è²·ä»˜
L68 - **æ–°è¦INã¯ç­‰åˆ†æ¯”ç‡ï¼ˆ=5%ï¼‰ã®åŠåˆ†ã¾ã§**ã‚’ä¸Šé™ã€‚  
L69 - è¿½åŠ è£œå……ã‚„åŠæˆ»ã—è²·ä»˜ã‚‚åŒã˜ä¸Šé™ã«å¾“ã†ã€‚
L70
L71 ---
L72
L73 ## åŠæˆ»ã—ï¼ˆãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
L74 1. **ç¾é‡‘æ¯”ç‡ â‰¤ é–¾å€¤**ï¼šéé‡é‡éŠ˜æŸ„ã‚’å£²å´ã—ã€ä¸è¶³éŠ˜æŸ„ã‚’è£œå……ã€‚  
L75 2. **ç¾é‡‘æ¯”ç‡ > é–¾å€¤**ï¼š**å£²å´ã¯è¡Œã‚ãš**ã€ç¾é‡‘ã§ãƒ‰ãƒªãƒ•ãƒˆä¸è¶³éŠ˜æŸ„ã‚’è²·ä»˜ï¼ˆç¾é‡‘æ¯”ç‡ã‚’é–¾å€¤ä»¥ä¸‹ã¸æˆ»ã™ã“ã¨ã‚’å„ªå…ˆï¼‰ã€‚  
L76 3. **å…±é€š**ï¼šãƒªãƒãƒ©ãƒ³ã‚¹å¾Œã¯å…¨éŠ˜æŸ„ã®TSã‚’å†è¨­å®šã€‚EMERGã§ã¯ã€Œãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢ã€ã€20éŠ˜æŸ„Ã—5%å…¨æˆ»ã—ã®ã¿è¨±å®¹ã€‚
L77
L78 ---
L79
L80 ## ãƒ¢ãƒ¼ãƒ‰ç§»è¡Œã®å®Ÿå‹™æ‰‹é †
L81 - ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰ã€**MMFâ‰’ç¾é‡‘**ã¨ã—ã¦æ‰±ã„ã€Growthæ æ•°ã ã‘èª¿æ•´ï¼š  
L82   1. **Gã‚’å‰Šã‚‹**ï¼ˆCAUTION/EMERGï¼‰ï¼šâ­ï¸ä½ã‚¹ã‚³ã‚¢ã®Gã‹ã‚‰é †ã«å¤–ã—ã€`current_tickers.csv` ã‹ã‚‰è¡Œå‰Šé™¤ï¼ˆ=ç¾é‡‘åŒ–ï¼‰ã€‚  
L83   2. **ç¾é‡‘ã¨ã—ã¦ä¿æŒ**ã€‚  
L84   3. **NORMALå¾©å¸°æ™‚ã®è£œå……**ï¼š`current_tickers.csv` ã«éŠ˜æŸ„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰ï¼‰ã€‚ä»¥é™ã¯æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆ/TSãƒ«ãƒ¼ãƒ«ã«å¾“ã†ã€‚  
L85 > driftã¯ `target_ratio = 1/éŠ˜æŸ„æ•°` ã‚’è‡ªå‹•é©ç”¨ã€‚è¡Œæ•°ã«å¿œã˜ã¦å‡ç­‰æ¯”ç‡ã‚’å†è¨ˆç®—ã€‚
L86
L87 ---
L88
L89 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L90 - **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼åˆ†æ•£æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦æ—¥æ¬¡ã§ã‚¹ã‚³ã‚¢é›†è¨ˆ**ã—ã€**ã‚¹ã‚³ã‚¢ä¸Šä½ã‹ã‚‰IN/OUT**ã‚’æ±ºå®šã€‚  
L91 - å‚è€ƒï¼šOxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ã€Alpha Investorã€Motley Foolã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã€‚  
L92 - å¹´é–“NISAæ ã¯Growthç¾¤ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ï¼ˆé•·æœŸä¿æŒã«å›ºåŸ·ã—ãªã„ï¼‰ã€‚
L93
L94 ---
L95
L96 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L97 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ  
L98 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 20éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼ˆåŸºæº– N_G=12ï¼‰ï¼‰ã€‚
L6   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`
L7   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)` ï¼ˆceil(1.5*12)ï¼‰
L8   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)` ï¼ˆ3*12ï¼‰
L9
L10 ## å®šæ•°ãƒ»è¨­å®š
L11 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L12 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L13 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L14
L15 ## ä¸»ãªé–¢æ•°
L16 ### finnhub_get
L17 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L18
L19 ### fetch_price
L20 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L21
L22 ### fetch_vix_ma5
L23 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L24
L25 ### load_portfolio
L26 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L27
L28 ### compute_threshold_by_mode
L29 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ **12% / 14% / åœæ­¢(âˆ)** ã‚’è¿”ã™ï¼ˆ`config.py` ã‚’å‚ç…§ï¼‰ã€‚
L30
L31 ### build_dataframe
L32 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L33
L34 ### simulate
L35 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L36
L37 ### prepare_summary
L38 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L39
L40 ### formatters_for / currency
L41 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L42
L43 ### build_header
L44 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚TS(åŸºæœ¬)ã¯ãƒ¢ãƒ¼ãƒ‰åˆ¥ã« `config.py` ã‹ã‚‰å‹•çš„è¡¨ç¤ºã—ã€æ®µéšTSã¯ base ã‹ã‚‰ -3/-6/-8 ptã€‚
L45
L46 ### send_slack / send_debug
L47 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L48
L49 ### main
L50 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L51
L52 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L53 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L54 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L55 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L56 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L57 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L58 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
