# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9
L10 # --- breadth utilities (factor parity) ---
L11 BENCH = "^GSPC"
L12 CAND_PRICE_MAX = 450.0
L13 RESULTS_DIR = "results"
L14 os.makedirs(RESULTS_DIR, exist_ok=True)
L15
L16
L17 def _state_file():
L18     return str(Path(RESULTS_DIR) / "breadth_state.json")
L19
L20
L21 def load_mode(default="NORMAL"):
L22     try:
L23         m = json.loads(open(_state_file()).read()).get("mode", default)
L24         return m if m in ("EMERG","CAUTION","NORMAL") else default
L25     except Exception:
L26         return default
L27
L28
L29 def save_mode(mode: str):
L30     try:
L31         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L32     except Exception:
L33         pass
L34
L35
L36 def _read_csv_list(fname):
L37     p = Path(__file__).with_name(fname)
L38     if not p.exists(): return []
L39     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L40
L41
L42 def _load_universe():
L43     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L44     exist = _read_csv_list("current_tickers.csv")
L45     cand  = _read_csv_list("candidate_tickers.csv")
L46     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L47     cand_keep = []
L48     for t in cand:
L49         try:
L50             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L51         except Exception:
L52             px = float("inf")
L53         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L54             cand_keep.append(t)
L55     tickers = sorted(set(exist + cand_keep))
L56     return exist, cand_keep, tickers
L57
L58
L59 def _fetch_prices_600d(tickers):
L60     data = yf.download(tickers + [BENCH], period="600d", auto_adjust=True, progress=False)
L61     px   = data["Close"].dropna(how="all", axis=1)
L62     spx  = data["Close"][BENCH].dropna()
L63     return px, spx
L64
L65
L66 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L67     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L68     import numpy as np, pandas as pd
L69     if px is None or px.empty:
L70         return pd.Series(dtype=int)
L71     px = px.dropna(how="all", axis=1)
L72     if win_days and win_days > 0:
L73         px = px.tail(win_days)
L74     if px.empty:
L75         return pd.Series(dtype=int)
L76     spx = spx.reindex(px.index).ffill()
L77
L78     ma50  = px.rolling(50).mean()
L79     ma150 = px.rolling(150).mean()
L80     ma200 = px.rolling(200).mean()
L81
L82     tt = (px > ma150)
L83     tt &= (px > ma200)
L84     tt &= (ma150 > ma200)
L85     tt &= (ma200 - ma200.shift(21) > 0)
L86     tt &= (ma50  > ma150)
L87     tt &= (ma50  > ma200)
L88     tt &= (px    > ma50)
L89
L90     lo252 = px.rolling(252).min()
L91     hi252 = px.rolling(252).max()
L92     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L93     tt &= (px >= (0.75 * hi252))
L94
L95     r12  = px.divide(px.shift(252)).sub(1.0)
L96     br12 = spx.divide(spx.shift(252)).sub(1.0)
L97     r1   = px.divide(px.shift(22)).sub(1.0)
L98     br1  = spx.divide(spx.shift(22)).sub(1.0)
L99     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L100     tt &= (rs >= 0.10)
L101
L102     return tt.fillna(False).sum(axis=1).astype(int)
L103
L104
L105 def build_breadth_header():
L106     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L107     exist, cand, tickers = _load_universe()
L108     if not tickers:
L109         return "", "NORMAL", 0
L110     px, spx = _fetch_prices_600d(tickers)
L111     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L112     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L113     if C_ts.empty:
L114         return "", "NORMAL", 0
L115     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L116     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L117     C_full = int(C_ts.iloc[-1])
L118
L119     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L120     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L121     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L122
L123     N_G = 12
L124     th_in_rec   = max(N_G, q05)
L125     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L126     th_norm_rec = max(3*N_G, q60)
L127
L128     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L129     if use_calib:
L130         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L131     else:
L132         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L133         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L134         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L135         th_src = "æ‰‹å‹•"
L136
L137     prev = load_mode("NORMAL")
L138     if   prev == "EMERG":
L139         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L140     elif prev == "CAUTION":
L141         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L142     else:
L143         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L144     save_mode(mode)
L145
L146     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L147     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L148     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L149     eff_days = len(base)
L150
L151     lead_lines = [
L152         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L153         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L154         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L155         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L156         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L157         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L158         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L159         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L160         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L161         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L162     ]
L163     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L164 # Debug flag
L165 debug_mode = False  # set to True for detailed output
L166
L167 # --- Finnhub settings & helper ---
L168 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L169 if not FINNHUB_API_KEY:
L170     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L171
L172 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L173 call_times = []
L174
L175
L176 def finnhub_get(endpoint, params):
L177     """Call Finnhub API with basic rate limiting."""
L178     now = time.time()
L179     cutoff = now - 60
L180     while call_times and call_times[0] < cutoff:
L181         call_times.pop(0)
L182     if len(call_times) >= RATE_LIMIT:
L183         sleep_time = 60 - (now - call_times[0])
L184         time.sleep(sleep_time)
L185     params = {**params, "token": FINNHUB_API_KEY}
L186     try:
L187         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L188         resp.raise_for_status()
L189         data = resp.json()
L190     except requests.exceptions.JSONDecodeError as e:
L191         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L192         return {}
L193     except Exception as e:
L194         print(f"âš ï¸ Finnhub API error: {e}")
L195         return {}
L196     call_times.append(time.time())
L197     return data
L198
L199
L200 def fetch_price(symbol):
L201     try:
L202         data = finnhub_get("quote", {"symbol": symbol})
L203         price = data.get("c")
L204         return float(price) if price not in (None, 0) else float("nan")
L205     except Exception:
L206         return float("nan")
L207
L208
L209 def fetch_vix_ma5():
L210     """Retrieve VIX 5-day moving average via yfinance."""
L211     try:
L212         vix = (
L213             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L214             .dropna()
L215             .tail(5)
L216         )
L217         if len(vix) < 5:
L218             return float("nan")
L219         return vix.mean().item()
L220     except Exception:
L221         return float("nan")
L222
L223
L224
L225 # === Minervini-like sell signals ===
L226 def _yf_df(sym, period="6mo"):
L227     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L228     try:
L229         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L230         if df is None or df.empty:
L231             return None
L232         return df.dropna().assign(
L233             ma20=lambda d: d["Close"].rolling(20).mean(),
L234             ma50=lambda d: d["Close"].rolling(50).mean(),
L235             vol50=lambda d: d["Volume"].rolling(50).mean(),
L236         )
L237     except Exception:
L238         return None
L239
L240
L241 def _scalar(row, col):
L242     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L243     try:
L244         v = row[col]
L245         if hasattr(v, "item"):
L246             try:
L247                 v = v.item()
L248             except Exception:
L249                 pass
L250         return v
L251     except Exception:
L252         return float("nan")
L253
L254
L255 def _is_strict_down(seq):
L256     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L257     try:
L258         xs = [float(x) for x in seq]
L259         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L260             return False
L261         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L262     except Exception:
L263         return False
L264
L265
L266 def _signals_for_day(df, idx):
L267     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L268     try:
L269         sig = []
L270         d = df.loc[idx]
L271         close = _scalar(d, "Close")
L272         ma20 = _scalar(d, "ma20")
L273         ma50 = _scalar(d, "ma50")
L274         vol = _scalar(d, "Volume")
L275         vol50 = _scalar(d, "vol50")
L276
L277         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L278             sig.append("20DMAâ†“")
L279
L280         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L281             sig.append("50DMAâ†“(å¤§å•†ã„)")
L282
L283         last4 = df.loc[:idx].tail(4)
L284         last10 = df.loc[:idx].tail(10)
L285
L286         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L287         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L288         if lows_desc or reds > 5:
L289             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L290
L291         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L292         if ups >= 7:
L293             sig.append("ä¸Šã’åé‡(>70%)")
L294
L295         last15 = df.loc[:idx].tail(15)
L296         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L297         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L298             sig.append("+25%/15æ—¥å†…")
L299
L300         if len(df.loc[:idx]) >= 2:
L301             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L302             t1_high = _scalar(t1, "High")
L303             t0_open = _scalar(t0, "Open")
L304             t0_close = _scalar(t0, "Close")
L305             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L306                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L307                     sig.append("GUâ†’é™°ç·š")
L308         return sig
L309     except Exception:
L310         return []
L311
L312
L313 def scan_sell_signals(symbols, lookback_days=5):
L314     """
L315     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L316     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L317     """
L318     out = {}
L319     for s in symbols:
L320         df = _yf_df(s)
L321         if df is None or len(df) < 60:
L322             continue
L323         alerts = []
L324         for idx in df.tail(lookback_days).index:
L325             tags = _signals_for_day(df, idx)
L326             if tags:
L327                 alerts.append((idx.strftime("%Y-%m-%d"), tags))
L328         if alerts:
L329             out[s] = alerts
L330     return out
L331
L332
L333 def load_portfolio():
L334     tickers_path = Path(__file__).with_name("current_tickers.csv")
L335     with tickers_path.open() as f:
L336         reader = list(csv.reader(f))
L337     return [
L338         {"symbol": sym.strip().upper(), "shares": int(qty), "target_ratio": 1 / len(reader)}
L339         for sym, qty in reader
L340     ]
L341
L342
L343 def compute_threshold():
L344     vix_ma5 = fetch_vix_ma5()
L345     drift_threshold = 10 if vix_ma5 < 20 else 12 if vix_ma5 < 26 else float("inf")
L346     return vix_ma5, drift_threshold
L347
L348
L349 def compute_threshold_by_mode(mode: str):
L350     """ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’è¿”ã™ï¼ˆREADMEæº–æ‹ ï¼‰"""
L351     m = (mode or "NORMAL").upper()
L352     cash_map = {"NORMAL": 0.10, "CAUTION": 0.125, "EMERG": 0.20}
L353     drift_map = {"NORMAL": 10, "CAUTION": 12, "EMERG": float("inf")}
L354     return cash_map.get(m, 0.10), drift_map.get(m, 10)
L355
L356
L357 def build_dataframe(portfolio):
L358     for stock in portfolio:
L359         price = fetch_price(stock["symbol"])
L360         stock["price"] = price
L361         stock["value"] = price * stock["shares"]
L362
L363     df = pd.DataFrame(portfolio)
L364     total_value = df["value"].sum()
L365     df["current_ratio"] = df["value"] / total_value
L366     df["drift"] = df["current_ratio"] - df["target_ratio"]
L367     df["drift_abs"] = df["drift"].abs()
L368     total_drift_abs = df["drift_abs"].sum()
L369     df["adjusted_ratio"] = df["current_ratio"] - df["drift"] / 2
L370     df["adjustable"] = (
L371         (df["adjusted_ratio"] * total_value) >= df["price"]
L372     ) & df["price"].notna() & df["price"].gt(0)
L373     return df, total_value, total_drift_abs
L374
L375
L376 def simulate(df, total_value, total_drift_abs, drift_threshold):
L377     alert = drift_threshold != float("inf") and total_drift_abs * 100 > drift_threshold
L378     if alert:
L379         df["trade_shares"] = df.apply(
L380             lambda r: int(round(((r["adjusted_ratio"] * total_value) - r["value"]) / r["price"]))
L381             if r["adjustable"] and r["price"] > 0 else 0,
L382             axis=1,
L383         )
L384         df["new_shares"] = df["shares"] + df["trade_shares"]
L385         df["new_value"] = df["new_shares"] * df["price"]
L386         new_total_value = df["new_value"].sum()
L387         df["simulated_ratio"] = df["new_value"] / new_total_value
L388         df["simulated_drift_abs"] = (df["simulated_ratio"] - df["target_ratio"]).abs()
L389         simulated_total_drift_abs = df["simulated_drift_abs"].sum()
L390     else:
L391         df["trade_shares"] = np.nan
L392         df["new_shares"] = np.nan
L393         df["new_value"] = np.nan
L394         new_total_value = np.nan
L395         df["simulated_ratio"] = np.nan
L396         df["simulated_drift_abs"] = np.nan
L397         simulated_total_drift_abs = np.nan
L398     return df, alert, new_total_value, simulated_total_drift_abs
L399
L400
L401 def prepare_summary(df, total_drift_abs, alert):
L402     summary = {
L403         "symbol": "åˆè¨ˆ",
L404         "shares": df["shares"].sum(),
L405         "value": df["value"].sum(),
L406         "current_ratio": np.nan,
L407         "drift_abs": total_drift_abs,
L408     }
L409     if alert:
L410         summary["trade_shares"] = np.nan
L411     # Sort details by evaluation value descending before appending summary
L412     df = df.sort_values(by="value", ascending=False)
L413     df = pd.concat([df, pd.DataFrame([summary])], ignore_index=True)
L414     if alert:
L415         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs", "trade_shares"]
L416         df_small = df[cols].copy()
L417         df_small.columns = ["sym", "qty", "val", "now", "|d|", "Î”qty"]
L418     else:
L419         cols = ["symbol", "shares", "value", "current_ratio", "drift_abs"]
L420         df_small = df[cols].copy()
L421         df_small.columns = ["sym", "qty", "val", "now", "|d|"]
L422     return df_small
L423
L424
L425 def currency(x):
L426     return f"${x:,.0f}" if pd.notnull(x) else ""
L427
L428
L429 def formatters_for(alert):
L430     formatters = {"val": currency, "now": "{:.2%}".format, "|d|": "{:.2%}".format}
L431     if alert:
L432         formatters["Î”qty"] = "{:.0f}".format
L433     return formatters
L434
L435
L436 def build_header(mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs):
L437     header = (
L438         f"*ğŸ’¼ ç¾é‡‘ä¿æœ‰ç‡:* {cash_ratio*100:.1f}%\n"
L439         f"*ğŸ“Š ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤:* {'ğŸ”´(åœæ­¢)' if drift_threshold == float('inf') else str(drift_threshold)+'%'}\n"
L440         f"*ğŸ“‰ ç¾åœ¨ã®ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ:* {total_drift_abs * 100:.2f}%\n"
L441     )
L442     if alert:
L443         header += f"*ğŸ” åŠæˆ»ã—å¾Œãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆ(æƒ³å®š):* {simulated_total_drift_abs * 100:.2f}%\n"
L444         header += "ğŸš¨ *ã‚¢ãƒ©ãƒ¼ãƒˆ: ç™ºç”Ÿï¼ï¼ Î”qtyã®ãƒã‚¤ãƒŠã‚¹éŠ˜æŸ„ã‚’å£²å´ã€ä»»æ„ã®éŠ˜æŸ„ã‚’è²·ã„å¢—ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚Šã¾ã—ã‚‡ã†ï¼*\n"
L445     else:
L446         header += "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—\n"
L447     return header
L448
L449
L450 def send_slack(text):
L451     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L452     if not SLACK_WEBHOOK_URL:
L453         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L454     payload = {"text": text}
L455     try:
L456         resp = requests.post(SLACK_WEBHOOK_URL, json=payload)
L457         resp.raise_for_status()
L458         print("âœ… Slackï¼ˆWebhookï¼‰ã¸é€ä¿¡ã—ã¾ã—ãŸ")
L459     except Exception as e:
L460         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L461
L462
L463 def send_debug(debug_text):
L464     SLACK_WEBHOOK_URL = os.environ.get("SLACK_WEBHOOK_URL")
L465     if not SLACK_WEBHOOK_URL:
L466         raise ValueError("SLACK_WEBHOOK_URL not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L467     debug_payload = {"text": "```" + debug_text + "```"}
L468     try:
L469         resp = requests.post(SLACK_WEBHOOK_URL, json=debug_payload)
L470         resp.raise_for_status()
L471         print("âœ… Debugæƒ…å ±ã‚’Slackã«é€ä¿¡ã—ã¾ã—ãŸ")
L472     except Exception as e:
L473         print(f"âš ï¸ Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
L474
L475
L476 def main():
L477     portfolio = load_portfolio()
L478     symbols = [r["symbol"] for r in portfolio]
L479     sell_alerts = scan_sell_signals(symbols, lookback_days=5)
L480
L481     breadth_block, mode, _C = build_breadth_header()
L482
L483     cash_ratio, drift_threshold = compute_threshold_by_mode(mode)
L484
L485     df, total_value, total_drift_abs = build_dataframe(portfolio)
L486     df, alert, new_total_value, simulated_total_drift_abs = simulate(
L487         df, total_value, total_drift_abs, drift_threshold
L488     )
L489     df_small = prepare_summary(df, total_drift_abs, alert)
L490     if 'df_small' in locals() and isinstance(df_small, pd.DataFrame) and not df_small.empty:
L491         col_sym = "sym" if "sym" in df_small.columns else ("symbol" if "symbol" in df_small.columns else None)
L492         if col_sym:
L493             alert_keys = {str(k) for k in sell_alerts.keys()}
L494             df_small[col_sym] = df_small[col_sym].astype(str)
L495             df_small.insert(0, "âš ", df_small[col_sym].map(lambda x: "ğŸ”´" if x in alert_keys else ""))
L496             latest_tag = {s: " / ".join(sell_alerts[s][-1][1]) for s in sell_alerts}
L497             df_small.insert(1, "sig", df_small[col_sym].map(latest_tag).fillna(""))
L498     formatters = formatters_for(alert)
L499     header = build_header(
L500         mode, cash_ratio, drift_threshold, total_drift_abs, alert, simulated_total_drift_abs
L501     )
L502     if breadth_block:
L503         header = breadth_block + "\n" + header
L504     if sell_alerts:
L505         def fmt_pair(date_tags):
L506             date, tags = date_tags
L507             return f"{date}:" + "ãƒ»".join(tags)
L508         listed = []
L509         for t, arr in sell_alerts.items():
L510             listed.append(f"*{t}*ï¼ˆ" + ", ".join(fmt_pair(x) for x in arr) + "ï¼‰")
L511         hits = ", ".join(listed)
L512         if "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—" in header:
L513             header = header.replace(
L514                 "âœ… ã‚¢ãƒ©ãƒ¼ãƒˆãªã—",
L515                 f"âš ï¸ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ã‚ã‚Š: {len(sell_alerts)}éŠ˜æŸ„\nğŸŸ¥ {hits}",
L516             )
L517         else:
L518             header += f"\nğŸŸ¥ {hits}"
L519     table_text = df_small.to_string(formatters=formatters, index=False)
L520     send_slack(header + "\n```" + table_text + "```")
L521
L522     if debug_mode:
L523         debug_cols = [
L524             "symbol",
L525             "shares",
L526             "price",
L527             "value",
L528             "current_ratio",
L529             "drift",
L530             "drift_abs",
L531             "adjusted_ratio",
L532             "adjustable",
L533             "trade_shares",
L534             "new_shares",
L535             "new_value",
L536             "simulated_ratio",
L537             "simulated_drift_abs",
L538         ]
L539         debug_text = (
L540             "=== DEBUG: full dataframe ===\n"
L541             + df[debug_cols].to_string()
L542             + f"\n\ntotal_value={total_value}, new_total_value={new_total_value}\n"
L543             + f"total_drift_abs={total_drift_abs}, simulated_total_drift_abs={simulated_total_drift_abs}"
L544         )
L545         print("\n" + debug_text)
L546         send_debug(debug_text)
L547
L548
L549 if __name__ == "__main__":
L550     main()
L551
```

## <.github/workflows/daily-report.yml>
```text
L1 name: Daily Stock Report
L2
L3 on:
L4   push:
L5     branches: [ main ]
L6     paths-ignore:
L7       - 'CodeForChat/**'
L8   schedule:
L9     - cron: '30 23 * * 2-6'  # UTC 23:30 â†’ JST 08:30ï¼ˆç«ã€œåœŸï¼‰
L10   workflow_dispatch:
L11
L12 jobs:
L13   build-and-report:
L14     runs-on: ubuntu-latest
L15
L16     steps:
L17       - name: Debug start
L18         run: echo 'ğŸš€ DEBUGstarted'
L19               
L20       - name: Checkout repository
L21         uses: actions/checkout@v3
L22
L23       - name: Setup Python
L24         uses: actions/setup-python@v4
L25         with:
L26           python-version: '3.x'
L27
L28       - name: Install dependencies
L29         run: pip install -r requirements.txt
L30
L31       - name: Prepare results directory
L32         run: mkdir -p results
L33
L34       - name: Run drift.py
L35         env:
L36           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
L37           FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
L38         run: python drift.py
L39
L40       - name: Persist breadth_state.json
L41         if: always()
L42         run: |
L43           git config user.name  "github-actions[bot]"
L44           git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
L45           git add results/breadth_state.json || true
L46           git commit -m "chore: update breadth_state [skip ci]" || echo "no changes"
L47           git push || true
```

## <documents/README.md>
```text
L1 # é‹ç”¨ãƒ«ãƒ¼ãƒ«
L2
L3 ## åŸºæœ¬æ§‹æˆ
L4 - 25éŠ˜æŸ„ã‚’å‡ç­‰é…åˆ†ï¼ˆç¾é‡‘ã‚’é™¤ã1éŠ˜æŸ„ã‚ãŸã‚Š4%ï¼‰
L5 - moomooè¨¼åˆ¸ã§é‹ç”¨
L6
L7 ## Barbell Growth-Defenseæ–¹é‡
L8 - Growthæ 12éŠ˜æŸ„ï¼šé«˜æˆé•·ã§ä¹–é›¢æºã¨ãªã‚‹æ”»ã‚ã®éŠ˜æŸ„
L9 - Defenseæ 13éŠ˜æŸ„ï¼šä½ãƒœãƒ©ã§å®‰å®šæˆé•·ã—é…å½“ã‚’å¢—ã‚„ã™å®ˆã‚Šã®éŠ˜æŸ„
L10 - ã€ŒçŒ›çƒˆã«ä¼¸ã³ã‚‹æ”»ã‚ Ã— ç€å®Ÿã«ç¨¼ãç›¾ã€ã®çµ„åˆã›ã§ä¹–é›¢â†’åŠæˆ»ã—ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã‚’ç‹™ã†
L11
L12 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šï¼ˆtrend_template åˆæ ¼â€œæœ¬æ•°â€ã§åˆ¤å®šï¼‰
L13 - åˆæ ¼æœ¬æ•° = current+candidate å…¨ä½“ã®ã†ã¡ã€trend_template æ¡ä»¶ã‚’æº€ãŸã—ãŸéŠ˜æŸ„ã®**æœ¬æ•°(C)**
L14 - ã—ãã„å€¤ã¯éå»~600å–¶æ¥­æ—¥ã®åˆ†å¸ƒã‹ã‚‰**æ¯å›è‡ªå‹•æ¡ç”¨**ï¼ˆåˆ†ä½ç‚¹ã¨é‹ç”¨â€œåºŠâ€ã®maxï¼‰
L15   - ç·Šæ€¥å…¥ã‚Š: `max(q05, 12æœ¬)`ï¼ˆ= N_Gï¼‰
L16   - ç·Šæ€¥è§£é™¤: `max(q20, 18æœ¬)`ï¼ˆ= 1.5Ã—N_Gï¼‰
L17   - é€šå¸¸å¾©å¸°: `max(q60, 36æœ¬)`ï¼ˆ= 3Ã—N_Gï¼‰
L18 - ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹: å‰å›ãƒ¢ãƒ¼ãƒ‰ã«ä¾å­˜ï¼ˆEMERGâ†’è§£é™¤ã¯18æœ¬ä»¥ä¸Šã€CAUTIONâ†’é€šå¸¸ã¯36æœ¬ä»¥ä¸Šï¼‰
L19
L20 ## ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ç¾é‡‘ãƒ»ãƒ‰ãƒªãƒ•ãƒˆ
L21 - **é€šå¸¸(NORMAL)** : ç¾é‡‘ **10%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **10%**
L22 - **è­¦æˆ’(CAUTION)** : ç¾é‡‘ **12.5%** / ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ **12%**
L23 - **ç·Šæ€¥(EMERG)** : ç¾é‡‘ **20%** / **ãƒ‰ãƒªãƒ•ãƒˆå£²è²·åœæ­¢**ï¼ˆ25Ã—4%ã«å…¨æˆ»ã—ã®ã¿ï¼‰
L24
L25 ## ãƒˆãƒ¬ãƒ¼ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—ï¼ˆçµ±ä¸€ï¼‰
L26 - G/D å…±é€šã® **åŸºæœ¬TS=15%**
L27 - å«ã¿ç›ŠãŒ **+20% / +40% / +60%** åˆ°é”ã§ TS ã‚’ **12% / 9% / 7%** ã«æ®µéšå¼•ãä¸Šã’
L28 - TSç™ºå‹•ã§æ¸›å°‘ã—ãŸéŠ˜æŸ„ã¯ç¿Œæ—¥ä»¥é™ã«è£œå……ï¼ˆâ€»ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯è£œå……ã—ãªã„ï¼‰
L29
L30 ## å…¥æ›¿éŠ˜æŸ„é¸å®š
L31 - Oxfordã‚­ãƒ£ãƒ”ã‚¿ãƒ«ï¼ã‚¤ãƒ³ã‚«ãƒ ã€Alpha Investorã€Motley Fool Stock Advisorã€moomooã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ç­‰ã‚’å‚è€ƒã«chatGPTã§æ¤œè¨
L32 - å¹´é–“NISAæ ã¯Growthç¾¤ã®ä¸­ã‹ã‚‰ä½ãƒœãƒ©éŠ˜æŸ„ã‚’é¸å®šã—åˆ©ç”¨ã€‚é•·æœŸä¿æŒã«ã¯ã“ã ã‚ã‚‰ãªã„ã€‚
L33
L34 ## å†ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ï¼‰
L35 - TSãƒ’ãƒƒãƒˆå¾Œã®åŒéŠ˜æŸ„å†INã¯ **8å–¶æ¥­æ—¥** ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚’è¨­ã‘ã‚‹ï¼ˆæœŸé–“ä¸­ã¯å†INç¦æ­¢ï¼‰
L36
L37 ## å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚°
L38 - åˆ¤å®šï¼šç±³å›½å¸‚å ´çµ‚å€¤ç›´å¾Œ
L39 - åŸ·è¡Œï¼šç¿Œå–¶æ¥­æ—¥ã®ç±³å›½å¯„ä»˜ãæˆè¡Œ
```

## <documents/drift_design.md>
```text
L1 # drift.py è©³ç´°è¨­è¨ˆæ›¸
L2
L3 ## æ¦‚è¦
L4 - 25éŠ˜æŸ„ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‰ãƒªãƒ•ãƒˆã‚’æ—¥æ¬¡ç›£è¦–ã—ã€é–¾å€¤è¶…éæ™‚ã«åŠæˆ»ã—æ¡ˆã‚’Slacké€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
L5 - Finnhubã¨yfinanceã‹ã‚‰ä¾¡æ ¼ã‚’å–å¾—ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ã¯ trend_template æœ¬æ•°ã«åŸºã¥ãï¼‰ã€‚
L6
L7 ## å®šæ•°ãƒ»è¨­å®š
L8 - `FINNHUB_API_KEY` / `SLACK_WEBHOOK_URL` ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€‚
L9 - ç„¡æ–™æ ã‚’è€ƒæ…®ã—ãŸAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™: `RATE_LIMIT = 55`ã€‚
L10 - ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ç”¨ãƒ•ãƒ©ã‚° `debug_mode`ã€‚
L11
L12 ## ä¸»ãªé–¢æ•°
L13 ### finnhub_get
L14 - åŸºæœ¬çš„ãªãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãã§Finnhub APIã‚’å‘¼ã³å‡ºã—ã€JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸ã§è¿”ã™ã€‚
L15
L16 ### fetch_price
L17 - `quote` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§æ ªä¾¡ã‚’å–å¾—ã—ã€å¤±æ•—æ™‚ã¯ `NaN` ã‚’è¿”ã™ã€‚
L18
L19 ### fetch_vix_ma5
L20 - yfinanceã§VIXçµ‚å€¤ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã€‚å°†æ¥å†åˆ©ç”¨ã®ãŸã‚æ®‹ç½®ã€‚
L21
L22 ### load_portfolio
L23 - `current_tickers.csv` ã‹ã‚‰éŠ˜æŸ„ã¨ä¿æœ‰æ ªæ•°ã‚’èª­ã¿è¾¼ã¿ã€ç›®æ¨™æ¯”ç‡4%ã‚’ä»˜ä¸ã—ãŸãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚
L24
L25 ### compute_threshold_by_mode
L26 - ãƒ¢ãƒ¼ãƒ‰(NORMAL/CAUTION/EMERG) ã«å¿œã˜ã¦ 10% / 12% / åœæ­¢(âˆ) ã‚’è¿”ã™ã€‚
L27
L28 ### build_dataframe
L29 - å„éŠ˜æŸ„ã®è©•ä¾¡é¡ã‚„ç¾åœ¨æ¯”ç‡ã€ãƒ‰ãƒªãƒ•ãƒˆã€åŠæˆ»ã—å¾Œæ¯”ç‡(`adjusted_ratio`)ã‚’è¨ˆç®—ã—DataFrameåŒ–ã€‚
L30
L31 ### simulate
L32 - ãƒ‰ãƒªãƒ•ãƒˆåˆè¨ˆãŒé–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã€åŠæˆ»ã—å¾Œã®å£²è²·æ ªæ•°ã¨æ–°æ¯”ç‡ã‚’è©¦ç®—ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå¾Œãƒ‰ãƒªãƒ•ãƒˆã‚’è¿”ã™ã€‚
L33
L34 ### prepare_summary
L35 - è©•ä¾¡é¡é †ã«ä¸¦ã¹æ›¿ãˆãŸå¾Œã€åˆè¨ˆè¡Œã‚’ä»˜ä¸ã—ã¦Slackè¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã€‚
L36
L37 ### formatters_for / currency
L38 - é€šè²¨ãƒ»æ¯”ç‡ãƒ»æ ªæ•°ã®è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®šç¾©ã€‚
L39
L40 ### build_header
L41 - ç¾é‡‘ä¿æœ‰ç‡ãƒ»é–¾å€¤ãƒ»ãƒ‰ãƒªãƒ•ãƒˆå€¤ãŠã‚ˆã³ã‚¢ãƒ©ãƒ¼ãƒˆæœ‰ç„¡ã‚’Slackãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”¨ãƒ˜ãƒƒãƒ€ã«æ•´å½¢ã€‚
L42
L43 ### send_slack / send_debug
L44 - é€šå¸¸é€šçŸ¥ãŠã‚ˆã³ãƒ‡ãƒãƒƒã‚°è©³ç´°ã‚’Slack Webhookã¸é€ä¿¡ã€‚
L45
L46 ### main
L47 - ä¸Šè¨˜é–¢æ•°ã‚’é †ã«å‘¼ã³å‡ºã—ã€æ—¥æ¬¡ãƒ‰ãƒªãƒ•ãƒˆãƒã‚§ãƒƒã‚¯ã®ä¸€é€£å‡¦ç†ã‚’å®Ÿè¡Œã€‚
L48
L49 ## å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
L50 1. `load_portfolio` ã§ç¾ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’èª­ã¿è¾¼ã‚€ã€‚
L51 2. `build_breadth_header` ã§ãƒ¢ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€`compute_threshold_by_mode` ã§ç¾é‡‘ä¿æœ‰ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ã‚’æ±ºå®šã€‚
L52 3. `build_dataframe` ã§ç¾åœ¨æ¯”ç‡ã¨ãƒ‰ãƒªãƒ•ãƒˆã‚’è¨ˆç®—ã€‚
L53 4. `simulate` ã§é–¾å€¤è¶…éæ™‚ã®åŠæˆ»ã—æ¡ˆã‚’è©¦ç®—ã€‚
L54 5. `prepare_summary` ã¨ `build_header` ã§é€šçŸ¥æœ¬æ–‡ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ§‹ç¯‰ã€‚
L55 6. `send_slack` ã§çµæœã‚’é€ä¿¡ã€‚`debug_mode` ãŒTrueãªã‚‰ `send_debug` ã‚‚ä½µç”¨ã€‚
```
