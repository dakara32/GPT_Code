```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-27 09:05:54 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ç¾é‡‘æ¯”ç‡
L18 CASH_RATIO_BY_MODE = {
L19     "NORMAL": 0.10,  # 10%
L20     "CAUTION": 0.20,  # 20%
L21     "EMERG": 0.30,  # 30%
L22 }
L23
L24 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L25 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L26 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L27 TS_STEP_DELTAS_PT = (3, 6, 8)
L28
L29 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L30 N_G = COUNTS_BASE["G"]
L31 N_D = COUNTS_BASE["D"]
L32
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import json
L6 import time
L7 from pathlib import Path
L8 import csv
L9 import config
L10
L11 # --- Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã—ãã„å€¤ï¼ˆGrowthã®å¹³å‡DDåŸºæº–ï¼‰---
L12 CD_CAUTION = 0.10   # -10% ã§è­¦æˆ’
L13 CD_EMERG = 0.15   # -15% ã§ç·Šæ€¥
L14
L15 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L16 # Slacké€šçŸ¥ç”¨ã®ãƒ¢ãƒ¼ãƒ‰ã‚¢ã‚¤ã‚³ãƒ³
L17 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸ”´"}
L18 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L19
L20 # --- breadth utilities (factor parity) ---
L21 BENCH = "^GSPC"
L22 CAND_PRICE_MAX = 450.0
L23 RESULTS_DIR = "results"
L24 os.makedirs(RESULTS_DIR, exist_ok=True)
L25
L26 def _state_file():
L27     return str(Path(RESULTS_DIR) / "breadth_state.json")
L28
L29
L30 def _load_state_dict() -> dict:
L31     try:
L32         with open(_state_file()) as fh:
L33             data = json.load(fh)
L34         return data if isinstance(data, dict) else {}
L35     except Exception:
L36         return {}
L37
L38
L39 def _save_state_dict(state: dict):
L40     try:
L41         with open(_state_file(), "w") as fh:
L42             json.dump(state, fh)
L43     except Exception:
L44         pass
L45
L46
L47 def load_breadth_mode(default: str = "NORMAL") -> str:
L48     state = _load_state_dict()
L49     mode = state.get("breadth_mode", state.get("mode", default))
L50     return mode if mode in MODE_RANK else default
L51
L52
L53 def save_breadth_mode(mode: str):
L54     state = _load_state_dict()
L55     state["breadth_mode"] = mode
L56     _save_state_dict(state)
L57
L58
L59 def load_final_mode(default: str = "NORMAL") -> str:
L60     state = _load_state_dict()
L61     mode = state.get("final_mode", state.get("mode", default))
L62     return mode if mode in MODE_RANK else default
L63
L64
L65 def save_final_mode(mode: str):
L66     state = _load_state_dict()
L67     state["final_mode"] = mode
L68     state.setdefault("breadth_mode", state.get("breadth_mode", mode))
L69     state["mode"] = mode
L70     _save_state_dict(state)
L71
L72
L73 def _read_csv_list(fname):
L74     p = Path(__file__).with_name(fname)
L75     if not p.exists(): return []
L76     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L77
L78
L79 # leaders.csv èª­ã¿è¾¼ã¿ï¼ˆresults/leaders.csv, 1åˆ—æƒ³å®šï¼‰
L80 def _read_leaders_symbols() -> list[str]:
L81     p = Path(__file__).with_name("results").joinpath("leaders.csv")
L82     df = pd.read_csv(p, header=None)
L83     return sorted(set(df.iloc[:,0].astype(str).str.strip().str.upper().tolist()))
L84
L85 def _load_universe():
L86     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L87     exist = _read_csv_list("current_tickers.csv")
L88     cand  = _read_csv_list("candidate_tickers.csv")
L89     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L90     cand_keep = []
L91     for t in cand:
L92         try:
L93             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L94         except Exception:
L95             px = float("inf")
L96         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L97             cand_keep.append(t)
L98     tickers = sorted(set(exist + cand_keep))
L99     return exist, cand_keep, tickers
L100
L101
L102 def _fetch_prices_600d(tickers):
L103     data = yf.download(
L104         tickers + [BENCH],
L105         period="600d",
L106         auto_adjust=True,
L107         progress=False,
L108         threads=False,
L109     )
L110     close = data["Close"]
L111     px = close.dropna(how="all", axis=1).ffill(limit=2)
L112     spx = close[BENCH].reindex(px.index).ffill()
L113     return px, spx
L114
L115
L116 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L117     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L118     import numpy as np, pandas as pd
L119     if px is None or px.empty:
L120         return pd.Series(dtype=int)
L121     px = px.dropna(how="all", axis=1)
L122     if win_days and win_days > 0:
L123         px = px.tail(win_days)
L124     if px.empty:
L125         return pd.Series(dtype=int)
L126     # æ¬ æå¸å
L127     px = px.ffill(limit=2)
L128     spx = spx.reindex(px.index).ffill()
L129
L130     ma50  = px.rolling(50,  min_periods=50).mean()
L131     ma150 = px.rolling(150, min_periods=150).mean()
L132     ma200 = px.rolling(200, min_periods=200).mean()
L133
L134     tt = (px > ma150)
L135     tt &= (px > ma200)
L136     tt &= (ma150 > ma200)
L137     tt &= (ma200 - ma200.shift(21) > 0)
L138     tt &= (ma50  > ma150)
L139     tt &= (ma50  > ma200)
L140     tt &= (px    > ma50)
L141
L142     lo252 = px.rolling(252, min_periods=252).min()
L143     hi252 = px.rolling(252, min_periods=252).max()
L144     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L145     tt &= (px >= (0.75 * hi252))
L146
L147     r12  = px.divide(px.shift(252)).sub(1.0)
L148     br12 = spx.divide(spx.shift(252)).sub(1.0)
L149     r1   = px.divide(px.shift(22)).sub(1.0)
L150     br1  = spx.divide(spx.shift(22)).sub(1.0)
L151     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L152     tt &= (rs >= 0.10)
L153
L154     return tt.fillna(False).sum(axis=1).astype(int)
L155
L156
L157 def build_breadth_header():
L158     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L159     exist, cand, tickers = _load_universe()
L160     if not tickers:
L161         return "", "NORMAL", 0
L162     px, spx = _fetch_prices_600d(tickers)
L163     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L164     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L165     if C_ts.empty:
L166         return "", "NORMAL", 0
L167     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L168     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L169     C_full = int(C_ts.iloc[-1])
L170
L171     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L172     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L173     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L174
L175     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L176     N_G = config.N_G
L177     th_in_rec   = max(N_G, q05)
L178     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L179     th_norm_rec = max(3*N_G, q60)
L180
L181     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L182     if use_calib:
L183         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L184     else:
L185         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L186         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L187         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L188         th_src = "æ‰‹å‹•"
L189
L190     prev = load_breadth_mode("NORMAL")
L191     if   prev == "EMERG":
L192         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L193     elif prev == "CAUTION":
L194         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L195     else:
L196         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L197     save_breadth_mode(mode)
L198
L199     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L200     eff_days = len(base)
L201
L202     lead_lines = [
L203         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L204         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L205         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L206         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L207         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L208         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L209         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L210         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L211         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L212         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L213     ]
L214     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L215
L216
L217 def _format_mode(mode: str) -> str:
L218     upper = (mode or "NORMAL").upper()
L219     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L220
L221
L222 def _gcd_mode_today(g_syms: list[str]) -> tuple[str, float]:
L223     """
L224     ç¾åœ¨ã®Growthç¾¤ã«ã¤ã„ã¦ã€Low_today / Peak60(High) ã®ç­‰åŠ é‡å¹³å‡ã‹ã‚‰ G-CD(%) ã‚’ç®—å‡ºã—ã€ãƒ¢ãƒ¼ãƒ‰ã‚’è¿”ã™ã€‚
L225     æˆ»ã‚Šå€¤: (gcd_mode, gcd_pct)  â€»gcd_pctã¯æ­£ã®%ï¼ˆä¾‹ 11.3 ã¯ -11.3%ã®ä¸‹è½ï¼‰
L226     """
L227
L228     if not g_syms:
L229         print("ğŸ“ audit[G-CD details]: GéŠ˜æŸ„ãŒç©ºã®ãŸã‚ç®—å‡ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
L230         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L231         return "NORMAL", 0.0
L232
L233     try:
L234         df = yf.download(
L235             g_syms,
L236             period="100d",
L237             interval="1d",
L238             auto_adjust=False,
L239             progress=False,
L240         )
L241     except Exception as e:
L242         print(f"âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L243         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L244         return "NORMAL", 0.0
L245
L246     if not isinstance(df, pd.DataFrame) or df.empty:
L247         print("âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L248         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L249         return "NORMAL", 0.0
L250
L251     hi_all = df.get("High") if isinstance(df, pd.DataFrame) else None
L252     lo_all = df.get("Low") if isinstance(df, pd.DataFrame) else None
L253     if hi_all is None or lo_all is None:
L254         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã¾ã™")
L255         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L256         return "NORMAL", 0.0
L257
L258     if isinstance(hi_all, pd.Series):
L259         hi_all = hi_all.to_frame(name=g_syms[0])
L260     if isinstance(lo_all, pd.Series):
L261         lo_all = lo_all.to_frame(name=g_syms[0])
L262
L263     if hi_all.empty or lo_all.empty:
L264         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L265         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L266         return "NORMAL", 0.0
L267
L268     peak60 = hi_all.rolling(60, min_periods=20).max().tail(1).iloc[0]
L269     low_today = lo_all.tail(1).iloc[0]
L270
L271     details: list[tuple[str, float, float, float, float]] = []
L272     for sym in g_syms:
L273         p = float(peak60.get(sym, float("nan"))) if hasattr(peak60, "get") else float("nan")
L274         lt = float(low_today.get(sym, float("nan"))) if hasattr(low_today, "get") else float("nan")
L275         if pd.notna(p) and p > 0 and pd.notna(lt) and lt > 0:
L276             ratio = lt / p
L277             ddpct = (1.0 - ratio) * 100.0
L278             details.append((sym, p, lt, ratio, ddpct))
L279
L280     if not details:
L281         print("âš ï¸ audit[G-CD details]: æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
L282         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L283         return "NORMAL", 0.0
L284
L285     d
```