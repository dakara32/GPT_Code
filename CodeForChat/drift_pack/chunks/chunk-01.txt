```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 # --- breadth utilities (factor parity) ---
L12 BENCH = "^GSPC"
L13 CAND_PRICE_MAX = 450.0
L14 RESULTS_DIR = "results"
L15 os.makedirs(RESULTS_DIR, exist_ok=True)
L16
L17
L18 def _state_file():
L19     return str(Path(RESULTS_DIR) / "breadth_state.json")
L20
L21
L22 def load_mode(default="NORMAL"):
L23     try:
L24         m = json.loads(open(_state_file()).read()).get("mode", default)
L25         return m if m in ("EMERG","CAUTION","NORMAL") else default
L26     except Exception:
L27         return default
L28
L29
L30 def save_mode(mode: str):
L31     try:
L32         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L33     except Exception:
L34         pass
L35
L36
L37 def _read_csv_list(fname):
L38     p = Path(__file__).with_name(fname)
L39     if not p.exists(): return []
L40     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L41
L42
L43 def _load_universe():
L44     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L45     exist = _read_csv_list("current_tickers.csv")
L46     cand  = _read_csv_list("candidate_tickers.csv")
L47     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L48     cand_keep = []
L49     for t in cand:
L50         try:
L51             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L52         except Exception:
L53             px = float("inf")
L54         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L55             cand_keep.append(t)
L56     tickers = sorted(set(exist + cand_keep))
L57     return exist, cand_keep, tickers
L58
L59
L60 def _fetch_prices_600d(tickers):
L61     data = yf.download(tickers + [BENCH], period="600d", auto_adjust=True, progress=False)
L62     px   = data["Close"].dropna(how="all", axis=1)
L63     spx  = data["Close"][BENCH].dropna()
L64     return px, spx
L65
L66
L67 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L68     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L69     import numpy as np, pandas as pd
L70     if px is None or px.empty:
L71         return pd.Series(dtype=int)
L72     px = px.dropna(how="all", axis=1)
L73     if win_days and win_days > 0:
L74         px = px.tail(win_days)
L75     if px.empty:
L76         return pd.Series(dtype=int)
L77     spx = spx.reindex(px.index).ffill()
L78
L79     ma50  = px.rolling(50).mean()
L80     ma150 = px.rolling(150).mean()
L81     ma200 = px.rolling(200).mean()
L82
L83     tt = (px > ma150)
L84     tt &= (px > ma200)
L85     tt &= (ma150 > ma200)
L86     tt &= (ma200 - ma200.shift(21) > 0)
L87     tt &= (ma50  > ma150)
L88     tt &= (ma50  > ma200)
L89     tt &= (px    > ma50)
L90
L91     lo252 = px.rolling(252).min()
L92     hi252 = px.rolling(252).max()
L93     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L94     tt &= (px >= (0.75 * hi252))
L95
L96     r12  = px.divide(px.shift(252)).sub(1.0)
L97     br12 = spx.divide(spx.shift(252)).sub(1.0)
L98     r1   = px.divide(px.shift(22)).sub(1.0)
L99     br1  = spx.divide(spx.shift(22)).sub(1.0)
L100     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L101     tt &= (rs >= 0.10)
L102
L103     return tt.fillna(False).sum(axis=1).astype(int)
L104
L105
L106 def build_breadth_header():
L107     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L108     exist, cand, tickers = _load_universe()
L109     if not tickers:
L110         return "", "NORMAL", 0
L111     px, spx = _fetch_prices_600d(tickers)
L112     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L113     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L114     if C_ts.empty:
L115         return "", "NORMAL", 0
L116     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L117     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L118     C_full = int(C_ts.iloc[-1])
L119
L120     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L121     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L122     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L123
L124     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L125     N_G = config.N_G
L126     th_in_rec   = max(N_G, q05)
L127     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L128     th_norm_rec = max(3*N_G, q60)
L129
L130     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L131     if use_calib:
L132         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L133     else:
L134         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L135         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L136         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L137         th_src = "æ‰‹å‹•"
L138
L139     prev = load_mode("NORMAL")
L140     if   prev == "EMERG":
L141         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L142     elif prev == "CAUTION":
L143         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L144     else:
L145         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L146     save_mode(mode)
L147
L148     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L149     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L150     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L151     eff_days = len(base)
L152
L153     lead_lines = [
L154         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L155         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L156         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L157         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L158         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L159         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L160         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L161         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L162         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L163         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L164     ]
L165     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L166 # Debug flag
L167 debug_mode = False  # set to True for detailed output
L168
L169 # --- Finnhub settings & helper ---
L170 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L171 if not FINNHUB_API_KEY:
L172     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L173
L174 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L175 call_times = []
L176
L177
L178 def finnhub_get(endpoint, params):
L179     """Call Finnhub API with basic rate limiting."""
L180     now = time.time()
L181     cutoff = now - 60
L182     while call_times and call_times[0] < cutoff:
L183         call_times.pop(0)
L184     if len(call_times) >= RATE_LIMIT:
L185         sleep_time = 60 - (now - call_times[0])
L186         time.sleep(sleep_time)
L187     params = {**params, "token": FINNHUB_API_KEY}
L188     try:
L189         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L190         resp.raise_for_status()
L191         data = resp.json()
L192     except requests.exceptions.JSONDecodeError as e:
L193         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L194         return {}
L195     except Exception as e:
L196         print(f"âš ï¸ Finnhub API error: {e}")
L197         return {}
L198     call_times.append(time.time())
L199     return data
L200
L201
L202 def fetch_price(symbol):
L203     try:
L204         data = finnhub_get("quote", {"symbol": symbol})
L205         price = data.get("c")
L206         return float(price) if price not in (None, 0) else float("nan")
L207     except Exception:
L208         return float("nan")
L209
L210
L211 def fetch_vix_ma5():
L212     """Retrieve VIX 5-day moving average via yfinance."""
L213     try:
L214         vix = (
L215             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L216             .dropna()
L217             .tail(5)
L218         )
L219         if len(vix) < 5:
L220             return float("nan")
L221         return vix.mean().item()
L222     except Exception:
L223         return float("nan")
L224
L225
L226
L227 # === Minervini-like sell signals ===
L228 def _yf_df(sym, period="6mo"):
L229     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L230     try:
L231         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L232         if df is None or df.empty:
L233             return None
L234         return df.dropna().assign(
L235             ma20=lambda d: d["Close"].rolling(20).mean(),
L236             ma50=lambda d: d["Close"].rolling(50).mean(),
L237             vol50=lambda d: d["Volume"].rolling(50).mean(),
L238         )
L239     except Exception:
L240         return None
L241
L242
L243 def _scalar(row, col):
L244     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L245     try:
L246         v = row[col]
L247         if hasattr(v, "item"):
L248             try:
L249                 v = v.item()
L250             except Exception:
L251                 pass
L252         return v
L253     except Exception:
L254         return float("nan")
L255
L256
L257 def _is_strict_down(seq):
L258     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L259     try:
L260         xs = [float(x) for x in seq]
L261         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L262             return False
L263         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L264     except Exception:
L265         return False
L266
L267
L268 def _signals_for_day(df, idx):
L269     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L270     try:
L271         sig = []
L272         d = df.loc[idx]
L273         close = _scalar(d, "Close")
L274         ma20 = _scalar(d, "ma20")
L275         ma50 = _scalar(d, "ma50")
L276         vol = _scalar(d, "Volume")
L277         vol50 = _scalar(d, "vol50")
L278
L279         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L280             sig.append("20DMAâ†“")
L281
L282         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L283             sig.append("50DMAâ†“(å¤§å•†ã„)")
L284
L285         last4 = df.loc[:idx].tail(4)
L286         last10 = df.loc[:idx].tail(10)
L287
L288         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L289         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L290         if lows_desc or reds > 5:
L291             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L292
L293         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L294         if ups >= 7:
L295             sig.append("ä¸Šã’åé‡(>70%)")
L296
L297         last15 = df.loc[:idx].tail(15)
L298         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L299         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L300             sig.append("+25%/15æ—¥å†…")
L301
L302         if len(df.loc[:idx]) >= 2:
L303             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L304             t1_high = _scalar(t1, "High")
L305             t0_open = _scalar(t0, "Open")
L306             t0_close = _scalar(t0, "Close")
L307             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L308                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L309                     sig.append("GUâ†’é™°ç·š")
L310         return sig
L311     except Exception:
L312         return []
L313
L314
L315 def scan_sell_signals(symbols, lookback_days=5):
L316     """
L317     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L318     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L319     """
L320     out = {}
L
```