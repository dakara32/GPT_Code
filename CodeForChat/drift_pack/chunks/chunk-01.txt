```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9
L10 # --- breadth utilities (factor parity) ---
L11 BENCH = "^GSPC"
L12 CAND_PRICE_MAX = 450.0
L13 RESULTS_DIR = "results"
L14 os.makedirs(RESULTS_DIR, exist_ok=True)
L15
L16
L17 def _state_file():
L18     return str(Path(RESULTS_DIR) / "breadth_state.json")
L19
L20
L21 def load_mode(default="NORMAL"):
L22     try:
L23         m = json.loads(open(_state_file()).read()).get("mode", default)
L24         return m if m in ("EMERG","CAUTION","NORMAL") else default
L25     except Exception:
L26         return default
L27
L28
L29 def save_mode(mode: str):
L30     try:
L31         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L32     except Exception:
L33         pass
L34
L35
L36 def _read_csv_list(fname):
L37     p = Path(__file__).with_name(fname)
L38     if not p.exists(): return []
L39     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L40
L41
L42 def _load_universe():
L43     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L44     exist = _read_csv_list("current_tickers.csv")
L45     cand  = _read_csv_list("candidate_tickers.csv")
L46     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L47     cand_keep = []
L48     for t in cand:
L49         try:
L50             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L51         except Exception:
L52             px = float("inf")
L53         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L54             cand_keep.append(t)
L55     tickers = sorted(set(exist + cand_keep))
L56     return exist, cand_keep, tickers
L57
L58
L59 def _fetch_prices_600d(tickers):
L60     data = yf.download(tickers + [BENCH], period="600d", auto_adjust=True, progress=False)
L61     px   = data["Close"].dropna(how="all", axis=1)
L62     spx  = data["Close"][BENCH].dropna()
L63     return px, spx
L64
L65
L66 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L67     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L68     import numpy as np, pandas as pd
L69     if px is None or px.empty:
L70         return pd.Series(dtype=int)
L71     px = px.dropna(how="all", axis=1)
L72     if win_days and win_days > 0:
L73         px = px.tail(win_days)
L74     if px.empty:
L75         return pd.Series(dtype=int)
L76     spx = spx.reindex(px.index).ffill()
L77
L78     ma50  = px.rolling(50).mean()
L79     ma150 = px.rolling(150).mean()
L80     ma200 = px.rolling(200).mean()
L81
L82     tt = (px > ma150)
L83     tt &= (px > ma200)
L84     tt &= (ma150 > ma200)
L85     tt &= (ma200 - ma200.shift(21) > 0)
L86     tt &= (ma50  > ma150)
L87     tt &= (ma50  > ma200)
L88     tt &= (px    > ma50)
L89
L90     lo252 = px.rolling(252).min()
L91     hi252 = px.rolling(252).max()
L92     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L93     tt &= (px >= (0.75 * hi252))
L94
L95     r12  = px.divide(px.shift(252)).sub(1.0)
L96     br12 = spx.divide(spx.shift(252)).sub(1.0)
L97     r1   = px.divide(px.shift(22)).sub(1.0)
L98     br1  = spx.divide(spx.shift(22)).sub(1.0)
L99     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L100     tt &= (rs >= 0.10)
L101
L102     return tt.fillna(False).sum(axis=1).astype(int)
L103
L104
L105 def build_breadth_header():
L106     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L107     exist, cand, tickers = _load_universe()
L108     if not tickers:
L109         return "", "NORMAL", 0
L110     px, spx = _fetch_prices_600d(tickers)
L111     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L112     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L113     if C_ts.empty:
L114         return "", "NORMAL", 0
L115     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L116     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L117     C_full = int(C_ts.iloc[-1])
L118
L119     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L120     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L121     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L122
L123     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L124     N_G = 15
L125     th_in_rec   = max(N_G, q05)
L126     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L127     th_norm_rec = max(3*N_G, q60)
L128
L129     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L130     if use_calib:
L131         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L132     else:
L133         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L134         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L135         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L136         th_src = "æ‰‹å‹•"
L137
L138     prev = load_mode("NORMAL")
L139     if   prev == "EMERG":
L140         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L141     elif prev == "CAUTION":
L142         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L143     else:
L144         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L145     save_mode(mode)
L146
L147     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L148     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L149     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L150     eff_days = len(base)
L151
L152     lead_lines = [
L153         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L154         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L155         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L156         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L157         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L158         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L159         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L160         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L161         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L162         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L163     ]
L164     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L165 # Debug flag
L166 debug_mode = False  # set to True for detailed output
L167
L168 # --- Finnhub settings & helper ---
L169 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L170 if not FINNHUB_API_KEY:
L171     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L172
L173 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L174 call_times = []
L175
L176
L177 def finnhub_get(endpoint, params):
L178     """Call Finnhub API with basic rate limiting."""
L179     now = time.time()
L180     cutoff = now - 60
L181     while call_times and call_times[0] < cutoff:
L182         call_times.pop(0)
L183     if len(call_times) >= RATE_LIMIT:
L184         sleep_time = 60 - (now - call_times[0])
L185         time.sleep(sleep_time)
L186     params = {**params, "token": FINNHUB_API_KEY}
L187     try:
L188         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L189         resp.raise_for_status()
L190         data = resp.json()
L191     except requests.exceptions.JSONDecodeError as e:
L192         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L193         return {}
L194     except Exception as e:
L195         print(f"âš ï¸ Finnhub API error: {e}")
L196         return {}
L197     call_times.append(time.time())
L198     return data
L199
L200
L201 def fetch_price(symbol):
L202     try:
L203         data = finnhub_get("quote", {"symbol": symbol})
L204         price = data.get("c")
L205         return float(price) if price not in (None, 0) else float("nan")
L206     except Exception:
L207         return float("nan")
L208
L209
L210 def fetch_vix_ma5():
L211     """Retrieve VIX 5-day moving average via yfinance."""
L212     try:
L213         vix = (
L214             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L215             .dropna()
L216             .tail(5)
L217         )
L218         if len(vix) < 5:
L219             return float("nan")
L220         return vix.mean().item()
L221     except Exception:
L222         return float("nan")
L223
L224
L225
L226 # === Minervini-like sell signals ===
L227 def _yf_df(sym, period="6mo"):
L228     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L229     try:
L230         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L231         if df is None or df.empty:
L232             return None
L233         return df.dropna().assign(
L234             ma20=lambda d: d["Close"].rolling(20).mean(),
L235             ma50=lambda d: d["Close"].rolling(50).mean(),
L236             vol50=lambda d: d["Volume"].rolling(50).mean(),
L237         )
L238     except Exception:
L239         return None
L240
L241
L242 def _scalar(row, col):
L243     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L244     try:
L245         v = row[col]
L246         if hasattr(v, "item"):
L247             try:
L248                 v = v.item()
L249             except Exception:
L250                 pass
L251         return v
L252     except Exception:
L253         return float("nan")
L254
L255
L256 def _is_strict_down(seq):
L257     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L258     try:
L259         xs = [float(x) for x in seq]
L260         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L261             return False
L262         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L263     except Exception:
L264         return False
L265
L266
L267 def _signals_for_day(df, idx):
L268     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L269     try:
L270         sig = []
L271         d = df.loc[idx]
L272         close = _scalar(d, "Close")
L273         ma20 = _scalar(d, "ma20")
L274         ma50 = _scalar(d, "ma50")
L275         vol = _scalar(d, "Volume")
L276         vol50 = _scalar(d, "vol50")
L277
L278         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L279             sig.append("20DMAâ†“")
L280
L281         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L282             sig.append("50DMAâ†“(å¤§å•†ã„)")
L283
L284         last4 = df.loc[:idx].tail(4)
L285         last10 = df.loc[:idx].tail(10)
L286
L287         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L288         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L289         if lows_desc or reds > 5:
L290             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L291
L292         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L293         if ups >= 7:
L294             sig.append("ä¸Šã’åé‡(>70%)")
L295
L296         last15 = df.loc[:idx].tail(15)
L297         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L298         if pd.notna(base0) and pd.notna(close) and base0 != 0 and (close / base0 - 1) >= 0.25:
L299             sig.append("+25%/15æ—¥å†…")
L300
L301         if len(df.loc[:idx]) >= 2:
L302             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L303             t1_high = _scalar(t1, "High")
L304             t0_open = _scalar(t0, "Open")
L305             t0_close = _scalar(t0, "Close")
L306             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L307                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L308                     sig.append("GUâ†’é™°ç·š")
L309         return sig
L310     except Exception:
L311         return []
L312
L313
L314 def scan_sell_signals(symbols, lookback_days=5):
L315     """
L316     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L317     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L318     """
L319     out = {}
L320     for s in symbols:
L
```