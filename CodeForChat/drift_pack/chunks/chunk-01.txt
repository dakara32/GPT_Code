```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# 作成日時: 2025-09-26 18:03:28 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 TOTAL_TARGETS = 20
L3
L4 # 基準のバケット数（NORMAL）
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # モード別の推奨バケット数
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # モード別のドリフト閾値（%）
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # モード別のTS（基本幅, 小数=割合）
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "通常", "CAUTION": "警戒", "EMERG": "緊急"}
L12 MODE_EMOJIS = {"NORMAL": "🟢", "CAUTION": "⚠️", "EMERG": "🚨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21 AUDIT_PATH = Path(RESULTS_DIR) / "ts_eod_audit.csv"
L22
L23
L24 def _state_file():
L25     return str(Path(RESULTS_DIR) / "breadth_state.json")
L26
L27
L28 def load_mode(default="NORMAL"):
L29     try:
L30         m = json.loads(open(_state_file()).read()).get("mode", default)
L31         return m if m in ("EMERG","CAUTION","NORMAL") else default
L32     except Exception:
L33         return default
L34
L35
L36 def save_mode(mode: str):
L37     try:
L38         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L39     except Exception:
L40         pass
L41
L42
L43 def _read_csv_list(fname):
L44     p = Path(__file__).with_name(fname)
L45     if not p.exists(): return []
L46     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L47
L48
L49 def _load_universe():
L50     # exist + candidate を使用。candidate は価格上限で事前フィルタ
L51     exist = _read_csv_list("current_tickers.csv")
L52     cand  = _read_csv_list("candidate_tickers.csv")
L53     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L54     cand_keep = []
L55     for t in cand:
L56         try:
L57             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L58         except Exception:
L59             px = float("inf")
L60         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L61             cand_keep.append(t)
L62     tickers = sorted(set(exist + cand_keep))
L63     return exist, cand_keep, tickers
L64
L65
L66 def _fetch_prices_600d(tickers):
L67     data = yf.download(
L68         tickers + [BENCH],
L69         period="600d",
L70         auto_adjust=True,
L71         progress=False,
L72         threads=False,
L73     )
L74     close = data["Close"]
L75     px = close.dropna(how="all", axis=1).ffill(limit=2)
L76     spx = close[BENCH].reindex(px.index).ffill()
L77     return px, spx
L78
L79
L80 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L81     # scorer.py の実装をそのまま移植（ベクトル化版）
L82     import numpy as np, pandas as pd
L83     if px is None or px.empty:
L84         return pd.Series(dtype=int)
L85     px = px.dropna(how="all", axis=1)
L86     if win_days and win_days > 0:
L87         px = px.tail(win_days)
L88     if px.empty:
L89         return pd.Series(dtype=int)
L90     # 欠損吸収
L91     px = px.ffill(limit=2)
L92     spx = spx.reindex(px.index).ffill()
L93
L94     ma50  = px.rolling(50,  min_periods=50).mean()
L95     ma150 = px.rolling(150, min_periods=150).mean()
L96     ma200 = px.rolling(200, min_periods=200).mean()
L97
L98     tt = (px > ma150)
L99     tt &= (px > ma200)
L100     tt &= (ma150 > ma200)
L101     tt &= (ma200 - ma200.shift(21) > 0)
L102     tt &= (ma50  > ma150)
L103     tt &= (ma50  > ma200)
L104     tt &= (px    > ma50)
L105
L106     lo252 = px.rolling(252, min_periods=252).min()
L107     hi252 = px.rolling(252, min_periods=252).max()
L108     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L109     tt &= (px >= (0.75 * hi252))
L110
L111     r12  = px.divide(px.shift(252)).sub(1.0)
L112     br12 = spx.divide(spx.shift(252)).sub(1.0)
L113     r1   = px.divide(px.shift(22)).sub(1.0)
L114     br1  = spx.divide(spx.shift(22)).sub(1.0)
L115     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L116     tt &= (rs >= 0.10)
L117
L118     return tt.fillna(False).sum(axis=1).astype(int)
L119
L120
L121 def build_breadth_header():
L122     # factor._build_breadth_lead_lines と同一挙動
L123     exist, cand, tickers = _load_universe()
L124     if not tickers:
L125         return "", "NORMAL", 0
L126     px, spx = _fetch_prices_600d(tickers)
L127     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L128     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L129     if C_ts.empty:
L130         return "", "NORMAL", 0
L131     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L132     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L133     C_full = int(C_ts.iloc[-1])
L134
L135     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L136     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L137     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L138
L139     # G枠サイズ（Breadth基準）
L140     N_G = config.N_G
L141     th_in_rec   = max(N_G, q05)
L142     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L143     th_norm_rec = max(3*N_G, q60)
L144
L145     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L146     if use_calib:
L147         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "自動"
L148     else:
L149         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L150         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L151         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L152         th_src = "手動"
L153
L154     prev = load_mode("NORMAL")
L155     if   prev == "EMERG":
L156         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L157     elif prev == "CAUTION":
L158         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L159     else:
L160         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L161     save_mode(mode)
L162
L163     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "ℹ️")
L164     eff_days = len(base)
L165
L166     lead_lines = [
L167         f"{emoji} *現在モード: {mode_ja}*",
L168         f"テンプレ合格本数: *{C_full}本*",
L169         "しきい値（{0}）".format(th_src),
L170         f"  ・緊急入り: <{th_in}本",
L171         f"  ・緊急解除: ≥{th_out}本",
L172         f"  ・通常復帰: ≥{th_norm}本",
L173         f"参考指標（過去~{win}営業日, 有効={eff_days}日）",
L174         f"  ・下位5%: {q05}本",
L175         f"  ・下位20%: {q20}本",
L176         f"  ・60%分位: {q60}本",
L177     ]
L178     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L179
L180
L181 def _ensure_audit_header():
L182     AUDIT_PATH.parent.mkdir(parents=True, exist_ok=True)
L183     if not AUDIT_PATH.exists():
L184         with open(AUDIT_PATH, "w", newline="") as f:
L185             f.write("date,symbol,high60,low_today,baseTS,threshold,breach\n")
L186
L187
L188 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L189     growth = []
L190     for row in portfolio:
L191         bucket = str(row.get("bucket", "")).strip().upper()
L192         if bucket == "G":
L193             sym = str(row.get("symbol", "")).strip().upper()
L194             if sym:
L195                 growth.append(sym)
L196     return sorted(set(growth))
L197
L198
L199 def _combine_modes(mode_a: str, mode_b: str) -> str:
L200     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L201     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L202     for mode, rank in MODE_RANK.items():
L203         if rank == max(a, b):
L204             return mode
L205     return "NORMAL"
L206
L207
L208 def _format_mode(mode: str) -> str:
L209     upper = (mode or "NORMAL").upper()
L210     return f"{MODE_EMOJIS.get(upper, 'ℹ️')} {MODE_LABELS_JA.get(upper, upper)}"
L211
L212
L213 def _ts_mode_growth_5d(g_syms: list[str], ref_mode: str) -> tuple[str, int, set[str]]:
L214     """直近5営業日を株価直接方式で一括判定（Low vs 60D High）。"""
L215
L216     if not g_syms:
L217         return "NORMAL", 0, set()
L218
L219     try:
L220         df = yf.download(
L221             g_syms,
L222             period="100d",
L223             interval="1d",
L224             auto_adjust=False,
L225             progress=False,
L226         )
L227     except Exception:
L228         df = None
L229
L230     if not isinstance(df, pd.DataFrame) or df.empty:
L231         return "NORMAL", 0, set()
L232
L233     try:
L234         hi_all = df["High"] if "High" in df.columns else None
L235         lo_all = df["Low"] if "Low" in df.columns else None
L236     except Exception:
L237         hi_all = lo_all = None
L238
L239     if hi_all is None or lo_all is None:
L240         return "NORMAL", 0, set()
L241
L242     if isinstance(hi_all, pd.Series):
L243         hi_all = hi_all.to_frame(name=g_syms[0])
L244     if isinstance(lo_all, pd.Series):
L245         lo_all = lo_all.to_frame(name=g_syms[0])
L246
L247     if hi_all.empty or lo_all.empty:
L248         return "NORMAL", 0, set()
L249
L250     roll_hi = hi_all.rolling(60, min_periods=20).max()
L251     last5_hi = roll_hi.tail(5)
L252     last5_lo = lo_all.tail(5).reindex(last5_hi.index)
L253
L254     if last5_hi.empty or last5_lo.empty:
L255         return "NORMAL", 0, set()
L256
L257     base = float(config.TS_BASE_BY_MODE.get((ref_mode or "NORMAL").upper(), 0.15))
L258     uniq_hits: set[str] = set()
L259     today_hits: set[str] = set()
L260     _ensure_audit_header()
L261
L262     def _fmt(val: float) -> str:
L263         if pd.isna(val):
L264             return ""
L265         return f"{float(val):.6g}"
L266
L267     rows = []
L268     for dt in last5_hi.index:
L269         hi_row = last5_hi.loc[dt]
L270         lo_row = last5_lo.loc[dt]
L271         for sym in g_syms:
L272             rh = float(hi_row.get(sym, float("nan"))) if hasattr(hi_row, "get") else float("nan")
L273             lt = float(lo_row.get(sym, float("nan"))) if hasattr(lo_row, "get") else float("nan")
L274             threshold = float("nan")
L275             breach = 0
L276             if pd.notna(rh) and rh > 0 and pd.notna(lt) and lt > 0:
L277                 threshold = rh * (1.0 - base)
L278                 breach = int(lt <= threshold)
L279                 if breach:
L280                     uniq_hits.add(sym)
L281                     if dt == last5_hi.index[-1]:
L282                         today_hits.add(sym)
L283             rows.append(
L284                 {
L285                     "date": dt.date().isoformat() if hasattr(dt, "date") else str(dt),
L286                     "symbol": sym,
L287                     "high60": _fmt(rh),
L288                     "low_today": _fmt(lt),
L289                     "baseTS": f"{base:.3f}",
L290                     "threshold": _fmt(threshold),
L291                     "breach": str(breach),
L292                 }
L293             )
L294
L295     if rows:
L296         with open(AUDIT_PATH, "a", newline="") as f:
L297             writer = csv.DictWriter(
L298                 f,
L299                 fieldnames=["date", "symbol", "high60", "low_today", "baseTS", "threshold", "breach"],
L300        
```