```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-27 17:24:20 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ç¾é‡‘æ¯”ç‡
L18 CASH_RATIO_BY_MODE = {
L19     "NORMAL": 0.10,  # 10%
L20     "CAUTION": 0.20,  # 20%
L21     "EMERG": 0.30,  # 30%
L22 }
L23
L24 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L25 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L26 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L27 TS_STEP_DELTAS_PT = (3, 6, 8)
L28
L29 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L30 N_G = COUNTS_BASE["G"]
L31 N_D = COUNTS_BASE["D"]
L32
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import json
L6 import time
L7 from pathlib import Path
L8 import csv
L9 import config
L10
L11 # --- Gã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆDDã®ã—ãã„å€¤ï¼ˆGrowthã®å¹³å‡DDåŸºæº–ï¼‰---
L12 CD_CAUTION = 0.10   # -10% ã§è­¦æˆ’
L13 CD_EMERG = 0.15   # -15% ã§ç·Šæ€¥
L14
L15 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L16 # Slacké€šçŸ¥ç”¨ã®ãƒ¢ãƒ¼ãƒ‰ã‚¢ã‚¤ã‚³ãƒ³
L17 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸ”´"}
L18 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L19
L20 # --- breadth utilities (factor parity) ---
L21 BENCH = "^GSPC"
L22 CAND_PRICE_MAX = 450.0
L23 RESULTS_DIR = "results"
L24 os.makedirs(RESULTS_DIR, exist_ok=True)
L25
L26
L27 def _state_file():
L28     """Return path to JSON storing the latest breadth/final mode state."""
L29
L30     return str(Path(RESULTS_DIR) / "current_mode.json")
L31
L32
L33 def _load_state_dict() -> dict:
L34     p = Path(_state_file())
L35     if not p.exists():
L36         return {}
L37     try:
L38         data = json.loads(p.read_text(encoding="utf-8") or "{}")
L39         return data if isinstance(data, dict) else {}
L40     except Exception:
L41         return {}
L42
L43
L44 def _save_state_dict(state: dict):
L45     # å¸¸ã« {"mode": "<...>"} ã®1ã‚­ãƒ¼ã«åœ§ç¸®ã—ã¦ä¿å­˜
L46     m = (state.get("mode") or state.get("final_mode") or state.get("breadth_mode") or "NORMAL")
L47     m = str(m).upper().strip()
L48     Path(_state_file()).write_text(
L49         json.dumps({"mode": m}, ensure_ascii=False, indent=2),
L50         encoding="utf-8",
L51     )
L52
L53
L54 def load_breadth_mode(default: str = "NORMAL") -> str:
L55     state = _load_state_dict()
L56     mode = state.get("breadth_mode", state.get("mode", default))
L57     return mode if mode in MODE_RANK else default
L58
L59
L60 def save_breadth_mode(mode: str):
L61     return  # å‚è€ƒå€¤ã®ãŸã‚ä¿å­˜ã—ãªã„ï¼ˆno-opï¼‰
L62
L63
L64 def load_final_mode(default: str = "NORMAL") -> str:
L65     state = _load_state_dict()
L66     mode = state.get("final_mode", state.get("mode", default))
L67     return mode if mode in MODE_RANK else default
L68
L69
L70 def save_final_mode(mode: str):
L71     """çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯ mode ã®ã¿ã‚’ä¿å­˜ï¼ˆG-CDã§æ±ºå®šï¼‰"""
L72     m = (mode or "NORMAL").upper().strip()
L73     Path(_state_file()).write_text(
L74         json.dumps({"mode": m}, ensure_ascii=False, indent=2),
L75         encoding="utf-8",
L76     )
L77
L78
L79 def _read_csv_list(fname):
L80     p = Path(__file__).with_name(fname)
L81     if not p.exists(): return []
L82     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L83
L84
L85 # leaders.csv èª­ã¿è¾¼ã¿ï¼ˆresults/leaders.csv, 1åˆ—æƒ³å®šï¼‰
L86 def _read_leaders_symbols() -> list[str]:
L87     p = Path(__file__).with_name("results").joinpath("leaders.csv")
L88     df = pd.read_csv(p, header=None)
L89     return sorted(set(df.iloc[:,0].astype(str).str.strip().str.upper().tolist()))
L90
L91 def _load_universe():
L92     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L93     exist = _read_csv_list("current_tickers.csv")
L94     cand  = _read_csv_list("candidate_tickers.csv")
L95     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L96     cand_keep = []
L97     for t in cand:
L98         try:
L99             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L100         except Exception:
L101             px = float("inf")
L102         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L103             cand_keep.append(t)
L104     tickers = sorted(set(exist + cand_keep))
L105     return exist, cand_keep, tickers
L106
L107
L108 def _fetch_prices_600d(tickers):
L109     data = yf.download(
L110         tickers + [BENCH],
L111         period="600d",
L112         auto_adjust=True,
L113         progress=False,
L114         threads=False,
L115     )
L116     close = data["Close"]
L117     px = close.dropna(how="all", axis=1).ffill(limit=2)
L118     spx = close[BENCH].reindex(px.index).ffill()
L119     return px, spx
L120
L121
L122 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L123     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L124     import numpy as np, pandas as pd
L125     if px is None or px.empty:
L126         return pd.Series(dtype=int)
L127     px = px.dropna(how="all", axis=1)
L128     if win_days and win_days > 0:
L129         px = px.tail(win_days)
L130     if px.empty:
L131         return pd.Series(dtype=int)
L132     # æ¬ æå¸å
L133     px = px.ffill(limit=2)
L134     spx = spx.reindex(px.index).ffill()
L135
L136     ma50  = px.rolling(50,  min_periods=50).mean()
L137     ma150 = px.rolling(150, min_periods=150).mean()
L138     ma200 = px.rolling(200, min_periods=200).mean()
L139
L140     tt = (px > ma150)
L141     tt &= (px > ma200)
L142     tt &= (ma150 > ma200)
L143     tt &= (ma200 - ma200.shift(21) > 0)
L144     tt &= (ma50  > ma150)
L145     tt &= (ma50  > ma200)
L146     tt &= (px    > ma50)
L147
L148     lo252 = px.rolling(252, min_periods=252).min()
L149     hi252 = px.rolling(252, min_periods=252).max()
L150     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L151     tt &= (px >= (0.75 * hi252))
L152
L153     r12  = px.divide(px.shift(252)).sub(1.0)
L154     br12 = spx.divide(spx.shift(252)).sub(1.0)
L155     r1   = px.divide(px.shift(22)).sub(1.0)
L156     br1  = spx.divide(spx.shift(22)).sub(1.0)
L157     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L158     tt &= (rs >= 0.10)
L159
L160     return tt.fillna(False).sum(axis=1).astype(int)
L161
L162
L163 def build_breadth_header():
L164     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L165     exist, cand, tickers = _load_universe()
L166     if not tickers:
L167         return "", "NORMAL", 0
L168     px, spx = _fetch_prices_600d(tickers)
L169     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L170     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L171     if C_ts.empty:
L172         return "", "NORMAL", 0
L173     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L174     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L175     C_full = int(C_ts.iloc[-1])
L176
L177     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L178     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L179     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L180
L181     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L182     N_G = config.N_G
L183     th_in_rec   = max(N_G, q05)
L184     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L185     th_norm_rec = max(3*N_G, q60)
L186
L187     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L188     if use_calib:
L189         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L190     else:
L191         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L192         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L193         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L194         th_src = "æ‰‹å‹•"
L195
L196     prev = load_breadth_mode("NORMAL")
L197     if   prev == "EMERG":
L198         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L199     elif prev == "CAUTION":
L200         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L201     else:
L202         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L203     save_breadth_mode(mode)
L204
L205     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L206     eff_days = len(base)
L207
L208     lead_lines = [
L209         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L210         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L211         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L212         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L213         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L214         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L215         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L216         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L217         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L218         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L219     ]
L220     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L221
L222
L223 def _format_mode(mode: str) -> str:
L224     upper = (mode or "NORMAL").upper()
L225     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L226
L227
L228 def _gcd_mode_today(g_syms: list[str]) -> tuple[str, float]:
L229     """
L230     ç¾åœ¨ã®Growthç¾¤ã«ã¤ã„ã¦ã€Low_today / Peak60(High) ã®ç­‰åŠ é‡å¹³å‡ã‹ã‚‰ G-CD(%) ã‚’ç®—å‡ºã—ã€ãƒ¢ãƒ¼ãƒ‰ã‚’è¿”ã™ã€‚
L231     æˆ»ã‚Šå€¤: (gcd_mode, gcd_pct)  â€»gcd_pctã¯æ­£ã®%ï¼ˆä¾‹ 11.3 ã¯ -11.3%ã®ä¸‹è½ï¼‰
L232     """
L233
L234     if not g_syms:
L235         print("ğŸ“ audit[G-CD details]: GéŠ˜æŸ„ãŒç©ºã®ãŸã‚ç®—å‡ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“")
L236         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L237         return "NORMAL", 0.0
L238
L239     try:
L240         df = yf.download(
L241             g_syms,
L242             period="100d",
L243             interval="1d",
L244             auto_adjust=False,
L245             progress=False,
L246         )
L247     except Exception as e:
L248         print(f"âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})")
L249         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L250         return "NORMAL", 0.0
L251
L252     if not isinstance(df, pd.DataFrame) or df.empty:
L253         print("âš ï¸ audit[G-CD details]: æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L254         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L255         return "NORMAL", 0.0
L256
L257     hi_all = df.get("High") if isinstance(df, pd.DataFrame) else None
L258     lo_all = df.get("Low") if isinstance(df, pd.DataFrame) else None
L259     if hi_all is None or lo_all is None:
L260         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã¾ã™")
L261         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L262         return "NORMAL", 0.0
L263
L264     if isinstance(hi_all, pd.Series):
L265         hi_all = hi_all.to_frame(name=g_syms[0])
L266     if isinstance(lo_all, pd.Series):
L267         lo_all = lo_all.to_frame(name=g_syms[0])
L268
L269     if hi_all.empty or lo_all.empty:
L270         print("âš ï¸ audit[G-CD details]: High/Low ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ç®—å‡ºã§ãã¾ã›ã‚“")
L271         print("ğŸ“ audit[G-CD summary]: avg_low/peak60=1.0000  drawdown=0.00%  => NORMAL")
L272         return "NORMAL", 0.0
L273
L274     peak60 = hi_all.rolling(60, min_periods=20).max().tail(1).iloc[0]
L275     low_today = lo_all.tail(1).iloc[0]
L276
L277     details: list[tuple[str, float, float, float, float]] = []
L278     for sym in g_syms:
L279         p = float(peak60.get(sym, float("nan"))) if hasattr(peak60, "get") else float("nan")
L280         lt = float(low_today.get(sym, float("nan"))) if hasattr(low_today, "get") else float("nan")
L281         if pd.notna(p) and p > 0 and pd.notna(lt) and lt > 0:
L282             ratio = lt / p
L283             ddpct = (1.0 - r
```