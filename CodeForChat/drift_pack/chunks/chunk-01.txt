```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# 作成日時: 2025-09-26 17:30:11 (JST)
# 使い方: 下のチャンクを順に貼ればこのチャットで全体把握できます。
# 注記: 各ファイルは個別に L1.. で行番号付与。
---

## <config.py>
```text
L1 # 共通設定（factor / drift から参照）
L2 TOTAL_TARGETS = 20
L3
L4 # 基準のバケット数（NORMAL）
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # モード別の推奨バケット数
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # モード別のドリフト閾値（%）
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # モード別のTS（基本幅, 小数=割合）
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # 利益到達(+30/+60/+100%)時の段階タイト化（ポイント差）
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthの校正は N_G に連動（緊急解除=ceil(1.5*N_G), 通常復帰=3*N_G）
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "通常", "CAUTION": "警戒", "EMERG": "緊急"}
L12 MODE_EMOJIS = {"NORMAL": "🟢", "CAUTION": "⚠️", "EMERG": "🚨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21 LOG_PATH = Path(RESULTS_DIR) / "ts_signal_log.csv"
L22 AUDIT_PATH = Path(RESULTS_DIR) / "ts_eod_audit.csv"
L23
L24
L25 def _state_file():
L26     return str(Path(RESULTS_DIR) / "breadth_state.json")
L27
L28
L29 def load_mode(default="NORMAL"):
L30     try:
L31         m = json.loads(open(_state_file()).read()).get("mode", default)
L32         return m if m in ("EMERG","CAUTION","NORMAL") else default
L33     except Exception:
L34         return default
L35
L36
L37 def save_mode(mode: str):
L38     try:
L39         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L40     except Exception:
L41         pass
L42
L43
L44 def _read_csv_list(fname):
L45     p = Path(__file__).with_name(fname)
L46     if not p.exists(): return []
L47     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L48
L49
L50 def _load_universe():
L51     # exist + candidate を使用。candidate は価格上限で事前フィルタ
L52     exist = _read_csv_list("current_tickers.csv")
L53     cand  = _read_csv_list("candidate_tickers.csv")
L54     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L55     cand_keep = []
L56     for t in cand:
L57         try:
L58             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L59         except Exception:
L60             px = float("inf")
L61         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L62             cand_keep.append(t)
L63     tickers = sorted(set(exist + cand_keep))
L64     return exist, cand_keep, tickers
L65
L66
L67 def _fetch_prices_600d(tickers):
L68     data = yf.download(
L69         tickers + [BENCH],
L70         period="600d",
L71         auto_adjust=True,
L72         progress=False,
L73         threads=False,
L74     )
L75     close = data["Close"]
L76     px = close.dropna(how="all", axis=1).ffill(limit=2)
L77     spx = close[BENCH].reindex(px.index).ffill()
L78     return px, spx
L79
L80
L81 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L82     # scorer.py の実装をそのまま移植（ベクトル化版）
L83     import numpy as np, pandas as pd
L84     if px is None or px.empty:
L85         return pd.Series(dtype=int)
L86     px = px.dropna(how="all", axis=1)
L87     if win_days and win_days > 0:
L88         px = px.tail(win_days)
L89     if px.empty:
L90         return pd.Series(dtype=int)
L91     # 欠損吸収
L92     px = px.ffill(limit=2)
L93     spx = spx.reindex(px.index).ffill()
L94
L95     ma50  = px.rolling(50,  min_periods=50).mean()
L96     ma150 = px.rolling(150, min_periods=150).mean()
L97     ma200 = px.rolling(200, min_periods=200).mean()
L98
L99     tt = (px > ma150)
L100     tt &= (px > ma200)
L101     tt &= (ma150 > ma200)
L102     tt &= (ma200 - ma200.shift(21) > 0)
L103     tt &= (ma50  > ma150)
L104     tt &= (ma50  > ma200)
L105     tt &= (px    > ma50)
L106
L107     lo252 = px.rolling(252, min_periods=252).min()
L108     hi252 = px.rolling(252, min_periods=252).max()
L109     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L110     tt &= (px >= (0.75 * hi252))
L111
L112     r12  = px.divide(px.shift(252)).sub(1.0)
L113     br12 = spx.divide(spx.shift(252)).sub(1.0)
L114     r1   = px.divide(px.shift(22)).sub(1.0)
L115     br1  = spx.divide(spx.shift(22)).sub(1.0)
L116     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L117     tt &= (rs >= 0.10)
L118
L119     return tt.fillna(False).sum(axis=1).astype(int)
L120
L121
L122 def build_breadth_header():
L123     # factor._build_breadth_lead_lines と同一挙動
L124     exist, cand, tickers = _load_universe()
L125     if not tickers:
L126         return "", "NORMAL", 0
L127     px, spx = _fetch_prices_600d(tickers)
L128     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L129     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L130     if C_ts.empty:
L131         return "", "NORMAL", 0
L132     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L133     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L134     C_full = int(C_ts.iloc[-1])
L135
L136     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L137     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L138     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L139
L140     # G枠サイズ（Breadth基準）
L141     N_G = config.N_G
L142     th_in_rec   = max(N_G, q05)
L143     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L144     th_norm_rec = max(3*N_G, q60)
L145
L146     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L147     if use_calib:
L148         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "自動"
L149     else:
L150         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L151         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L152         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L153         th_src = "手動"
L154
L155     prev = load_mode("NORMAL")
L156     if   prev == "EMERG":
L157         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L158     elif prev == "CAUTION":
L159         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L160     else:
L161         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L162     save_mode(mode)
L163
L164     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "ℹ️")
L165     eff_days = len(base)
L166
L167     lead_lines = [
L168         f"{emoji} *現在モード: {mode_ja}*",
L169         f"テンプレ合格本数: *{C_full}本*",
L170         "しきい値（{0}）".format(th_src),
L171         f"  ・緊急入り: <{th_in}本",
L172         f"  ・緊急解除: ≥{th_out}本",
L173         f"  ・通常復帰: ≥{th_norm}本",
L174         f"参考指標（過去~{win}営業日, 有効={eff_days}日）",
L175         f"  ・下位5%: {q05}本",
L176         f"  ・下位20%: {q20}本",
L177         f"  ・60%分位: {q60}本",
L178     ]
L179     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L180
L181
L182 def _ensure_log_header():
L183     if not LOG_PATH.exists():
L184         LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
L185         with open(LOG_PATH, "w", newline="") as f:
L186             f.write("date,symbol,breach\n")
L187
L188
L189 def _ensure_audit_header():
L190     AUDIT_PATH.parent.mkdir(parents=True, exist_ok=True)
L191     if not AUDIT_PATH.exists():
L192         with open(AUDIT_PATH, "w", newline="") as f:
L193             f.write("date,symbol,high60,low_today,baseTS,threshold,breach\n")
L194
L195
L196 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L197     growth = []
L198     for row in portfolio:
L199         bucket = str(row.get("bucket", "")).strip().upper()
L200         if bucket == "G":
L201             sym = str(row.get("symbol", "")).strip().upper()
L202             if sym:
L203                 growth.append(sym)
L204     return sorted(set(growth))
L205
L206
L207 def _upsert_ts_hits(date_str: str, hits: set[str]):
L208     _ensure_log_header()
L209     try:
L210         df = pd.read_csv(LOG_PATH)
L211     except Exception:
L212         df = pd.DataFrame(columns=["date", "symbol", "breach"])
L213     if df.empty:
L214         df = pd.DataFrame(columns=["date", "symbol", "breach"])
L215     df = df[df["date"] != date_str]
L216     if hits:
L217         add = pd.DataFrame(
L218             {
L219                 "date": date_str,
L220                 "symbol": sorted({h.upper() for h in hits}),
L221                 "breach": 1,
L222             }
L223         )
L224         df = pd.concat([df, add], ignore_index=True)
L225     df = df.sort_values(["date", "symbol"])
L226     df.to_csv(LOG_PATH, index=False)
L227
L228
L229 def _count_unique_hits_5d(today_utc: pd.Timestamp) -> int:
L230     if not LOG_PATH.exists():
L231         return 0
L232     try:
L233         df = pd.read_csv(LOG_PATH)
L234     except Exception:
L235         return 0
L236     if df.empty or "date" not in df.columns or "symbol" not in df.columns:
L237         return 0
L238     if "breach" in df.columns:
L239         try:
L240             df = df[df["breach"].astype(int) == 1]
L241         except Exception:
L242             df = df[df["breach"] == 1]
L243     try:
L244         df["date"] = pd.to_datetime(df["date"], utc=True)
L245     except Exception:
L246         return 0
L247     today = today_utc.normalize()
L248     start = today - pd.offsets.BDay(4)
L249     mask = (df["date"] >= start) & (df["date"] <= today)
L250     if not mask.any():
L251         return 0
L252     return int(df.loc[mask, "symbol"].str.upper().nunique())
L253
L254
L255 def _combine_modes(mode_a: str, mode_b: str) -> str:
L256     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L257     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L258     for mode, rank in MODE_RANK.items():
L259         if rank == max(a, b):
L260             return mode
L261     return "NORMAL"
L262
L263
L264 def _format_mode(mode: str) -> str:
L265     upper = (mode or "NORMAL").upper()
L266     return f"{MODE_EMOJIS.get(upper, 'ℹ️')} {MODE_LABELS_JA.get(upper, upper)}"
L267
L268
L269 def _ts_mode_growth_eod(g_syms: list[str], ref_mode: str) -> tuple[str, int, list[str]]:
L270     now_utc = pd.Timestamp.today(tz="UTC")
L271     if not g_syms:
L272         k = _count_unique_hits_5d(now_utc)
L273         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L274         return mode1, k, []
L275
L276     try:
L277         df = yf.download(
L278             g_syms,
L279             period="90d",
L280             interval="1d",
L281             auto_adjust=False,
L282             progress=False,
L283             group_by="column",
L284         )
L285     except Exception:
L286         df = None
L287
L288     hi = lo = None
L289     if isinstance(df, pd.DataFrame) and not df.empty:
L290         try:
L291             hi = df["High"] if "High" in df.columns else None
L292             lo = df["Low"] if "Low" in df.columns else None
L293         except Exception:
L294             hi = lo = None
L295         if isinstance(hi, pd.Series):
L296             hi = hi.to_frame(name=g_syms[0])
L297         if isinstance(lo, pd.Series):
L298             lo = lo.to_frame(name=g_syms[0])
L299
L300     if hi is None or lo is None or hi.empty or lo.empty:
L301         roll_hi = pd.Series(dtype=float)
L302         low_today = pd.Series(dtype=float)
L303     else:
L304         try:
L305       
```