```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-19 10:42:36 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 from dataclasses import dataclass
L3
L4 TOTAL_TARGETS = 20
L5
L6 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L7 COUNTS_BASE = {"G": 12, "D": 8}
L8
L9 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L10 COUNTS_BY_MODE = {
L11     "NORMAL": {"G": 12, "D": 8},
L12     "CAUTION": {"G": 10, "D": 8},
L13     "EMERG": {"G": 8,  "D": 8},
L14 }
L15
L16 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L17 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L18
L19 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L20 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L21 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L22 TS_STEP_DELTAS_PT = (3, 6, 8)
L23
L24 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L25 N_G = COUNTS_BASE["G"]
L26 N_D = COUNTS_BASE["D"]
L27
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 # --- breadth utilities (factor parity) ---
L12 BENCH = "^GSPC"
L13 CAND_PRICE_MAX = 450.0
L14 RESULTS_DIR = "results"
L15 os.makedirs(RESULTS_DIR, exist_ok=True)
L16
L17
L18 def _state_file():
L19     return str(Path(RESULTS_DIR) / "breadth_state.json")
L20
L21
L22 def load_mode(default="NORMAL"):
L23     try:
L24         m = json.loads(open(_state_file()).read()).get("mode", default)
L25         return m if m in ("EMERG","CAUTION","NORMAL") else default
L26     except Exception:
L27         return default
L28
L29
L30 def save_mode(mode: str):
L31     try:
L32         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L33     except Exception:
L34         pass
L35
L36
L37 def _read_csv_list(fname):
L38     p = Path(__file__).with_name(fname)
L39     if not p.exists(): return []
L40     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L41
L42
L43 def _load_universe():
L44     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L45     exist = _read_csv_list("current_tickers.csv")
L46     cand  = _read_csv_list("candidate_tickers.csv")
L47     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L48     cand_keep = []
L49     for t in cand:
L50         try:
L51             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L52         except Exception:
L53             px = float("inf")
L54         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L55             cand_keep.append(t)
L56     tickers = sorted(set(exist + cand_keep))
L57     return exist, cand_keep, tickers
L58
L59
L60 def _fetch_prices_600d(tickers):
L61     data = yf.download(
L62         tickers + [BENCH],
L63         period="600d",
L64         auto_adjust=True,
L65         progress=False,
L66         threads=False,
L67     )
L68     close = data["Close"]
L69     px = close.dropna(how="all", axis=1).ffill(limit=2)
L70     spx = close[BENCH].reindex(px.index).ffill()
L71     return px, spx
L72
L73
L74 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L75     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L76     import numpy as np, pandas as pd
L77     if px is None or px.empty:
L78         return pd.Series(dtype=int)
L79     px = px.dropna(how="all", axis=1)
L80     if win_days and win_days > 0:
L81         px = px.tail(win_days)
L82     if px.empty:
L83         return pd.Series(dtype=int)
L84     # æ¬ æå¸å
L85     px = px.ffill(limit=2)
L86     spx = spx.reindex(px.index).ffill()
L87
L88     ma50  = px.rolling(50,  min_periods=50).mean()
L89     ma150 = px.rolling(150, min_periods=150).mean()
L90     ma200 = px.rolling(200, min_periods=200).mean()
L91
L92     tt = (px > ma150)
L93     tt &= (px > ma200)
L94     tt &= (ma150 > ma200)
L95     tt &= (ma200 - ma200.shift(21) > 0)
L96     tt &= (ma50  > ma150)
L97     tt &= (ma50  > ma200)
L98     tt &= (px    > ma50)
L99
L100     lo252 = px.rolling(252, min_periods=252).min()
L101     hi252 = px.rolling(252, min_periods=252).max()
L102     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L103     tt &= (px >= (0.75 * hi252))
L104
L105     r12  = px.divide(px.shift(252)).sub(1.0)
L106     br12 = spx.divide(spx.shift(252)).sub(1.0)
L107     r1   = px.divide(px.shift(22)).sub(1.0)
L108     br1  = spx.divide(spx.shift(22)).sub(1.0)
L109     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L110     tt &= (rs >= 0.10)
L111
L112     return tt.fillna(False).sum(axis=1).astype(int)
L113
L114
L115 def build_breadth_header():
L116     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L117     exist, cand, tickers = _load_universe()
L118     if not tickers:
L119         return "", "NORMAL", 0
L120     px, spx = _fetch_prices_600d(tickers)
L121     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L122     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L123     if C_ts.empty:
L124         return "", "NORMAL", 0
L125     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L126     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L127     C_full = int(C_ts.iloc[-1])
L128
L129     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L130     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L131     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L132
L133     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L134     N_G = config.N_G
L135     th_in_rec   = max(N_G, q05)
L136     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L137     th_norm_rec = max(3*N_G, q60)
L138
L139     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L140     if use_calib:
L141         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L142     else:
L143         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L144         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L145         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L146         th_src = "æ‰‹å‹•"
L147
L148     prev = load_mode("NORMAL")
L149     if   prev == "EMERG":
L150         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L151     elif prev == "CAUTION":
L152         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L153     else:
L154         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L155     save_mode(mode)
L156
L157     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L158     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L159     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L160     eff_days = len(base)
L161
L162     lead_lines = [
L163         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L164         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L165         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L166         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L167         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L168         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L169         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L170         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L171         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L172         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L173     ]
L174     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L175 # Debug flag
L176 debug_mode = False  # set to True for detailed output
L177
L178 # --- Finnhub settings & helper ---
L179 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L180 if not FINNHUB_API_KEY:
L181     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L182
L183 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L184 call_times = []
L185
L186
L187 def finnhub_get(endpoint, params):
L188     """Call Finnhub API with basic rate limiting."""
L189     now = time.time()
L190     cutoff = now - 60
L191     while call_times and call_times[0] < cutoff:
L192         call_times.pop(0)
L193     if len(call_times) >= RATE_LIMIT:
L194         sleep_time = 60 - (now - call_times[0])
L195         time.sleep(sleep_time)
L196     params = {**params, "token": FINNHUB_API_KEY}
L197     try:
L198         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L199         resp.raise_for_status()
L200         data = resp.json()
L201     except requests.exceptions.JSONDecodeError as e:
L202         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L203         return {}
L204     except Exception as e:
L205         print(f"âš ï¸ Finnhub API error: {e}")
L206         return {}
L207     call_times.append(time.time())
L208     return data
L209
L210
L211 def fetch_price(symbol):
L212     try:
L213         data = finnhub_get("quote", {"symbol": symbol})
L214         price = data.get("c")
L215         return float(price) if price not in (None, 0) else float("nan")
L216     except Exception:
L217         return float("nan")
L218
L219
L220 def fetch_vix_ma5():
L221     """Retrieve VIX 5-day moving average via yfinance."""
L222     try:
L223         vix = (
L224             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L225             .dropna()
L226             .tail(5)
L227         )
L228         if len(vix) < 5:
L229             return float("nan")
L230         return vix.mean().item()
L231     except Exception:
L232         return float("nan")
L233
L234
L235
L236 # === Minervini-like sell signals ===
L237 def _yf_df(sym, period="6mo"):
L238     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L239     try:
L240         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L241         if df is None or df.empty:
L242             return None
L243         return df.dropna().assign(
L244             ma20=lambda d: d["Close"].rolling(20).mean(),
L245             ma50=lambda d: d["Close"].rolling(50).mean(),
L246             vol50=lambda d: d["Volume"].rolling(50).mean(),
L247         )
L248     except Exception:
L249         return None
L250
L251
L252 def _scalar(row, col):
L253     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L254     try:
L255         v = row[col]
L256         if hasattr(v, "item"):
L257             try:
L258                 v = v.item()
L259             except Exception:
L260                 pass
L261         return v
L262     except Exception:
L263         return float("nan")
L264
L265
L266 def _is_strict_down(seq):
L267     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L268     try:
L269         xs = [float(x) for x in seq]
L270         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L271             return False
L272         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L273     except Exception:
L274         return False
L275
L276
L277 def _signals_for_day(df, idx):
L278     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L279     try:
L280         sig = []
L281         d = df.loc[idx]
L282         close = _scalar(d, "Close")
L283         ma20 = _scalar(d, "ma20")
L284         ma50 = _scalar(d, "ma50")
L285         vol = _scalar(d, "Volume")
L286         vol50 = _scalar(d, "vol50")
L287
L288         if pd.notna(close) and pd.notna(ma20) and close < ma20:
L289             sig.append("20DMAâ†“")
L290
L291         if all(pd.notna(x) for x in (close, ma50, vol, vol50)) and close < ma50 and vol > 1.5 * vol50:
L292             sig.append("50DMAâ†“(å¤§å•†ã„)")
L293
L294         last4 = df.loc[:idx].tail(4)
L295         last10 = df.loc[:idx].tail(10)
L296
L297         lows_desc = _is_strict_down(last4["Low"].tolist()) if last4["Low"].notna().all() else False
L298         reds = int((last10["Close"] < last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L299         if lows_desc or reds > 5:
L300             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L301
L302         ups = int((last10["Close"] > last10["Open"]).sum()) if last10[["Close", "Open"]].notna().all().all() else 0
L303         if ups >= 7:
L304             
```