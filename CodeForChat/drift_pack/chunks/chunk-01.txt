```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9
L10 # --- breadth utilities (factor parity) ---
L11 BENCH = "^GSPC"
L12 CAND_PRICE_MAX = 450.0
L13 RESULTS_DIR = "results"
L14 os.makedirs(RESULTS_DIR, exist_ok=True)
L15
L16
L17 def _state_file():
L18     return str(Path(RESULTS_DIR) / "breadth_state.json")
L19
L20
L21 def load_mode(default="NORMAL"):
L22     try:
L23         m = json.loads(open(_state_file()).read()).get("mode", default)
L24         return m if m in ("EMERG","CAUTION","NORMAL") else default
L25     except Exception:
L26         return default
L27
L28
L29 def save_mode(mode: str):
L30     try:
L31         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L32     except Exception:
L33         pass
L34
L35
L36 def _read_csv_list(fname):
L37     p = Path(__file__).with_name(fname)
L38     if not p.exists(): return []
L39     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L40
L41
L42 def _load_universe():
L43     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L44     exist = _read_csv_list("current_tickers.csv")
L45     cand  = _read_csv_list("candidate_tickers.csv")
L46     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L47     cand_keep = []
L48     for t in cand:
L49         try:
L50             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L51         except Exception:
L52             px = float("inf")
L53         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L54             cand_keep.append(t)
L55     tickers = sorted(set(exist + cand_keep))
L56     return exist, cand_keep, tickers
L57
L58
L59 def _fetch_prices_600d(tickers):
L60     data = yf.download(tickers + [BENCH], period="600d", auto_adjust=True, progress=False)
L61     px   = data["Close"].dropna(how="all", axis=1)
L62     spx  = data["Close"][BENCH].dropna()
L63     return px, spx
L64
L65
L66 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L67     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L68     import numpy as np, pandas as pd
L69     if px is None or px.empty:
L70         return pd.Series(dtype=int)
L71     px = px.dropna(how="all", axis=1)
L72     if win_days and win_days > 0:
L73         px = px.tail(win_days)
L74     if px.empty:
L75         return pd.Series(dtype=int)
L76     spx = spx.reindex(px.index).ffill()
L77
L78     ma50  = px.rolling(50).mean()
L79     ma150 = px.rolling(150).mean()
L80     ma200 = px.rolling(200).mean()
L81
L82     tt = (px > ma150)
L83     tt &= (px > ma200)
L84     tt &= (ma150 > ma200)
L85     tt &= (ma200 - ma200.shift(21) > 0)
L86     tt &= (ma50  > ma150)
L87     tt &= (ma50  > ma200)
L88     tt &= (px    > ma50)
L89
L90     lo252 = px.rolling(252).min()
L91     hi252 = px.rolling(252).max()
L92     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L93     tt &= (px >= (0.75 * hi252))
L94
L95     r12  = px.divide(px.shift(252)).sub(1.0)
L96     br12 = spx.divide(spx.shift(252)).sub(1.0)
L97     r1   = px.divide(px.shift(22)).sub(1.0)
L98     br1  = spx.divide(spx.shift(22)).sub(1.0)
L99     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L100     tt &= (rs >= 0.10)
L101
L102     return tt.fillna(False).sum(axis=1).astype(int)
L103
L104
L105 def build_breadth_header():
L106     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L107     exist, cand, tickers = _load_universe()
L108     if not tickers:
L109         return "", "NORMAL", 0
L110     px, spx = _fetch_prices_600d(tickers)
L111     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L112     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L113     if C_ts.empty:
L114         return "", "NORMAL", 0
L115     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L116     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L117     C_full = int(C_ts.iloc[-1])
L118
L119     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L120     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L121     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L122
L123     N_G = 12
L124     th_in_rec   = max(N_G, q05)
L125     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L126     th_norm_rec = max(3*N_G, q60)
L127
L128     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L129     if use_calib:
L130         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L131     else:
L132         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L133         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L134         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L135         th_src = "æ‰‹å‹•"
L136
L137     prev = load_mode("NORMAL")
L138     if   prev == "EMERG":
L139         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L140     elif prev == "CAUTION":
L141         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L142     else:
L143         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L144     save_mode(mode)
L145
L146     _MODE_JA   = {"EMERG":"ç·Šæ€¥","CAUTION":"è­¦æˆ’","NORMAL":"é€šå¸¸"}
L147     _MODE_EMOJI= {"EMERG":"ğŸš¨","CAUTION":"âš ï¸","NORMAL":"ğŸŸ¢"}
L148     mode_ja, emoji = _MODE_JA.get(mode,mode), _MODE_EMOJI.get(mode,"â„¹ï¸")
L149     eff_days = len(base)
L150
L151     lead_lines = [
L152         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L153         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L154         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L155         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L156         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L157         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L158         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L159         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L160         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L161         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L162     ]
L163     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L164 # Debug flag
L165 debug_mode = False  # set to True for detailed output
L166
L167 # --- Finnhub settings & helper ---
L168 FINNHUB_API_KEY = os.environ.get("FINNHUB_API_KEY")
L169 if not FINNHUB_API_KEY:
L170     raise ValueError("FINNHUB_API_KEY not set (ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™)")
L171
L172 RATE_LIMIT = 55  # requests per minute (free tier is 60)
L173 call_times = []
L174
L175
L176 def finnhub_get(endpoint, params):
L177     """Call Finnhub API with basic rate limiting."""
L178     now = time.time()
L179     cutoff = now - 60
L180     while call_times and call_times[0] < cutoff:
L181         call_times.pop(0)
L182     if len(call_times) >= RATE_LIMIT:
L183         sleep_time = 60 - (now - call_times[0])
L184         time.sleep(sleep_time)
L185     params = {**params, "token": FINNHUB_API_KEY}
L186     try:
L187         resp = requests.get(f"https://finnhub.io/api/v1/{endpoint}", params=params)
L188         resp.raise_for_status()
L189         data = resp.json()
L190     except requests.exceptions.JSONDecodeError as e:
L191         print(f"âš ï¸ Finnhub API JSON decode error: {e}")
L192         return {}
L193     except Exception as e:
L194         print(f"âš ï¸ Finnhub API error: {e}")
L195         return {}
L196     call_times.append(time.time())
L197     return data
L198
L199
L200 def fetch_price(symbol):
L201     try:
L202         data = finnhub_get("quote", {"symbol": symbol})
L203         price = data.get("c")
L204         return float(price) if price not in (None, 0) else float("nan")
L205     except Exception:
L206         return float("nan")
L207
L208
L209 def fetch_vix_ma5():
L210     """Retrieve VIX 5-day moving average via yfinance."""
L211     try:
L212         vix = (
L213             yf.download("^VIX", period="7d", interval="1d", progress=False, auto_adjust=False)["Close"]
L214             .dropna()
L215             .tail(5)
L216         )
L217         if len(vix) < 5:
L218             return float("nan")
L219         return vix.mean().item()
L220     except Exception:
L221         return float("nan")
L222
L223
L224
L225 # === Minervini-like sell signals ===
L226 def _yf_df(sym, period="6mo"):
L227     """æ—¥è¶³/MA/å‡ºæ¥é«˜å¹³å‡ã‚’å–å¾—ã€‚æ¬ ææ™‚ã¯ Noneã€‚"""
L228     try:
L229         df = yf.download(sym, period=period, interval="1d", auto_adjust=False, progress=False)
L230         if df is None or df.empty:
L231             return None
L232         return df.dropna().assign(
L233             ma20=lambda d: d["Close"].rolling(20).mean(),
L234             ma50=lambda d: d["Close"].rolling(50).mean(),
L235             vol50=lambda d: d["Volume"].rolling(50).mean(),
L236         )
L237     except Exception:
L238         return None
L239
L240
L241 def _scalar(row, col):
L242     """Series/npã‚¹ã‚«ãƒ©â†’Pythonã‚¹ã‚«ãƒ©åŒ–ï¼ˆNaNã¯NaNã®ã¾ã¾ï¼‰"""
L243     try:
L244         v = row[col]
L245         if hasattr(v, "item"):
L246             try:
L247                 v = v.item()
L248             except Exception:
L249                 pass
L250         return v
L251     except Exception:
L252         return float("nan")
L253
L254
L255 def _is_strict_down(seq):
L256     """æ•°åˆ—ãŒå³å¯†ã«é€£ç¶šã§åˆ‡ã‚Šä¸‹ãŒã£ã¦ã„ã‚‹ã‹ï¼ˆlen>=4ã‚’æƒ³å®šï¼‰ã€‚NaNå«ã¿ã¯Falseã€‚"""
L257     try:
L258         xs = [float(x) for x in seq]
L259         if any(pd.isna(x) for x in xs) or len(xs) < 4:
L260             return False
L261         return all(b < a for a, b in zip(xs[:-1], xs[1:]))
L262     except Exception:
L263         return False
L264
L265
L266 def _signals_for_day(df, idx):
L267     """df.loc[idx] 1æ—¥åˆ†ã«å¯¾ã—ã‚·ã‚°ãƒŠãƒ«é…åˆ—ã‚’è¿”ã™ï¼ˆå€¤å‹•ã/å‡ºæ¥é«˜ãƒ™ãƒ¼ã‚¹ã®ã¿ï¼‰ã€‚"""
L268     try:
L269         sig = []
L270         d = df.loc[idx]
L271         close = _scalar(d, "Close")
L272         open_ = _scalar(d, "Open")
L273         ma20 = _scalar(d, "ma20")
L274         ma50 = _scalar(d, "ma50")
L275         vol = _scalar(d, "Volume")
L276         vol50 = _scalar(df.iloc[-1], "vol50")
L277         if any(pd.isna(x) for x in (close, open_, vol, vol50)):
L278             return sig
L279         if pd.notna(ma20) and close < ma20:
L280             sig.append("20DMAâ†“")
L281         if pd.notna(ma50) and close < ma50 and vol > 1.5 * vol50:
L282             sig.append("50DMAâ†“(å¤§å•†ã„)")
L283
L284         last4 = df.loc[:idx].tail(4)
L285         lows_desc = _is_strict_down(last4["Low"].tolist())
L286         last10 = df.loc[:idx].tail(10)
L287         reds = int((last10["Close"] < last10["Open"]).sum())
L288         if lows_desc or reds > 5:
L289             sig.append("é€£ç¶šå®‰å€¤/é™°ç·šå„ªå‹¢")
L290
L291         ups = int((last10["Close"] > last10["Open"]).sum())
L292         if ups >= 7:
L293             sig.append("ä¸Šã’åé‡(>70%)")
L294
L295         last15 = df.loc[:idx].tail(15)
L296         base0 = _scalar(last15.iloc[0], "Close") if len(last15) > 0 else float("nan")
L297         if pd.notna(base0) and base0 != 0 and (close / base0 - 1) >= 0.25:
L298             sig.append("+25%/15æ—¥å†…")
L299
L300         if len(df.loc[:idx]) >= 2:
L301             t1, t0 = df.loc[:idx].iloc[-2], df.loc[:idx].iloc[-1]
L302             t1_high = _scalar(t1, "High")
L303             t0_open = _scalar(t0, "Open")
L304             t0_close = _scalar(t0, "Close")
L305             if all(pd.notna(x) for x in (t1_high, t0_open, t0_close)):
L306                 if (t0_open > t1_high * 1.02) and (t0_close < t0_open):
L307                     sig.append("GUâ†’é™°ç·š")
L308         return sig
L309     except Exception:
L310         return []
L311
L312
L313 def scan_sell_signals(symbols, lookback_days=5):
L314     """
L315     ç›´è¿‘ lookback_days æ—¥ã®ã†ã¡ä¸€åº¦ã§ã‚‚ã‚·ã‚°ãƒŠãƒ«ãŒå‡ºãŸã‚‰ {sym: [(date,[signals]),...]} ã‚’è¿”ã™ã€‚
L316     æ—¥ä»˜ã¯ YYYY-MM-DDã€‚Slackã§åˆ—æŒ™ã™ã‚‹ã€‚
L317     """
L318     out = {}
L319     for s in symbols:
L320         df = _yf_df(s)
L321         if df is None or len(df) < 60:
L322             continue
L323         alerts = []
L324
```