```text
# === Chat Paste Pack ===
# Repo: dakara32/GPT_Code @ main
# Files: config.py, drift.py, .github/workflows/daily-report.yml, documents/README.md, documents/drift_design.md
# ä½œæˆæ—¥æ™‚: 2025-09-26 17:01:10 (JST)
# ä½¿ã„æ–¹: ä¸‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’é †ã«è²¼ã‚Œã°ã“ã®ãƒãƒ£ãƒƒãƒˆã§å…¨ä½“æŠŠæ¡ã§ãã¾ã™ã€‚
# æ³¨è¨˜: å„ãƒ•ã‚¡ã‚¤ãƒ«ã¯å€‹åˆ¥ã« L1.. ã§è¡Œç•ªå·ä»˜ä¸ã€‚
---

## <config.py>
```text
L1 # å…±é€šè¨­å®šï¼ˆfactor / drift ã‹ã‚‰å‚ç…§ï¼‰
L2 TOTAL_TARGETS = 20
L3
L4 # åŸºæº–ã®ãƒã‚±ãƒƒãƒˆæ•°ï¼ˆNORMALï¼‰
L5 COUNTS_BASE = {"G": 12, "D": 8}
L6
L7 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®æ¨å¥¨ãƒã‚±ãƒƒãƒˆæ•°
L8 COUNTS_BY_MODE = {
L9     "NORMAL": {"G": 12, "D": 8},
L10     "CAUTION": {"G": 10, "D": 8},
L11     "EMERG": {"G": 8,  "D": 8},
L12 }
L13
L14 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®ãƒ‰ãƒªãƒ•ãƒˆé–¾å€¤ï¼ˆ%ï¼‰
L15 DRIFT_THRESHOLD_BY_MODE = {"NORMAL": 12, "CAUTION": 14, "EMERG": float("inf")}
L16
L17 # ãƒ¢ãƒ¼ãƒ‰åˆ¥ã®TSï¼ˆåŸºæœ¬å¹…, å°æ•°=å‰²åˆï¼‰
L18 TS_BASE_BY_MODE = {"NORMAL": 0.15, "CAUTION": 0.13, "EMERG": 0.10}
L19 # åˆ©ç›Šåˆ°é”(+30/+60/+100%)æ™‚ã®æ®µéšã‚¿ã‚¤ãƒˆåŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆå·®ï¼‰
L20 TS_STEP_DELTAS_PT = (3, 6, 8)
L21
L22 # Breadthã®æ ¡æ­£ã¯ N_G ã«é€£å‹•ï¼ˆç·Šæ€¥è§£é™¤=ceil(1.5*N_G), é€šå¸¸å¾©å¸°=3*N_Gï¼‰
L23 N_G = COUNTS_BASE["G"]
L24 N_D = COUNTS_BASE["D"]
L25
```

## <drift.py>
```text
L1 import pandas as pd, yfinance as yf
L2 import numpy as np
L3 import requests
L4 import os
L5 import csv
L6 import json
L7 import time
L8 from pathlib import Path
L9 import config
L10
L11 MODE_LABELS_JA = {"NORMAL": "é€šå¸¸", "CAUTION": "è­¦æˆ’", "EMERG": "ç·Šæ€¥"}
L12 MODE_EMOJIS = {"NORMAL": "ğŸŸ¢", "CAUTION": "âš ï¸", "EMERG": "ğŸš¨"}
L13 MODE_RANK = {"NORMAL": 0, "CAUTION": 1, "EMERG": 2}
L14
L15 # --- breadth utilities (factor parity) ---
L16 BENCH = "^GSPC"
L17 CAND_PRICE_MAX = 450.0
L18 RESULTS_DIR = "results"
L19 os.makedirs(RESULTS_DIR, exist_ok=True)
L20
L21
L22 def _state_file():
L23     return str(Path(RESULTS_DIR) / "breadth_state.json")
L24
L25
L26 def load_mode(default="NORMAL"):
L27     try:
L28         m = json.loads(open(_state_file()).read()).get("mode", default)
L29         return m if m in ("EMERG","CAUTION","NORMAL") else default
L30     except Exception:
L31         return default
L32
L33
L34 def save_mode(mode: str):
L35     try:
L36         open(_state_file(),"w").write(json.dumps({"mode": mode}))
L37     except Exception:
L38         pass
L39
L40
L41 def _read_csv_list(fname):
L42     p = Path(__file__).with_name(fname)
L43     if not p.exists(): return []
L44     return pd.read_csv(p, header=None).iloc[:,0].astype(str).str.upper().tolist()
L45
L46
L47 def _load_universe():
L48     # exist + candidate ã‚’ä½¿ç”¨ã€‚candidate ã¯ä¾¡æ ¼ä¸Šé™ã§äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿
L49     exist = _read_csv_list("current_tickers.csv")
L50     cand  = _read_csv_list("candidate_tickers.csv")
L51     cand_info = yf.Tickers(" ".join(cand)) if cand else None
L52     cand_keep = []
L53     for t in cand:
L54         try:
L55             px = cand_info.tickers[t].fast_info.get("lastPrice", float("inf"))
L56         except Exception:
L57             px = float("inf")
L58         if pd.notna(px) and float(px) <= CAND_PRICE_MAX:
L59             cand_keep.append(t)
L60     tickers = sorted(set(exist + cand_keep))
L61     return exist, cand_keep, tickers
L62
L63
L64 def _fetch_prices_600d(tickers):
L65     data = yf.download(
L66         tickers + [BENCH],
L67         period="600d",
L68         auto_adjust=True,
L69         progress=False,
L70         threads=False,
L71     )
L72     close = data["Close"]
L73     px = close.dropna(how="all", axis=1).ffill(limit=2)
L74     spx = close[BENCH].reindex(px.index).ffill()
L75     return px, spx
L76
L77
L78 def trend_template_breadth_series(px: pd.DataFrame, spx: pd.Series, win_days: int | None = None) -> pd.Series:
L79     # scorer.py ã®å®Ÿè£…ã‚’ãã®ã¾ã¾ç§»æ¤ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
L80     import numpy as np, pandas as pd
L81     if px is None or px.empty:
L82         return pd.Series(dtype=int)
L83     px = px.dropna(how="all", axis=1)
L84     if win_days and win_days > 0:
L85         px = px.tail(win_days)
L86     if px.empty:
L87         return pd.Series(dtype=int)
L88     # æ¬ æå¸å
L89     px = px.ffill(limit=2)
L90     spx = spx.reindex(px.index).ffill()
L91
L92     ma50  = px.rolling(50,  min_periods=50).mean()
L93     ma150 = px.rolling(150, min_periods=150).mean()
L94     ma200 = px.rolling(200, min_periods=200).mean()
L95
L96     tt = (px > ma150)
L97     tt &= (px > ma200)
L98     tt &= (ma150 > ma200)
L99     tt &= (ma200 - ma200.shift(21) > 0)
L100     tt &= (ma50  > ma150)
L101     tt &= (ma50  > ma200)
L102     tt &= (px    > ma50)
L103
L104     lo252 = px.rolling(252, min_periods=252).min()
L105     hi252 = px.rolling(252, min_periods=252).max()
L106     tt &= (px.divide(lo252).sub(1.0) >= 0.30)
L107     tt &= (px >= (0.75 * hi252))
L108
L109     r12  = px.divide(px.shift(252)).sub(1.0)
L110     br12 = spx.divide(spx.shift(252)).sub(1.0)
L111     r1   = px.divide(px.shift(22)).sub(1.0)
L112     br1  = spx.divide(spx.shift(22)).sub(1.0)
L113     rs   = 0.7*(r12.sub(br12, axis=0)) + 0.3*(r1.sub(br1, axis=0))
L114     tt &= (rs >= 0.10)
L115
L116     return tt.fillna(False).sum(axis=1).astype(int)
L117
L118
L119 def build_breadth_header():
L120     # factor._build_breadth_lead_lines ã¨åŒä¸€æŒ™å‹•
L121     exist, cand, tickers = _load_universe()
L122     if not tickers:
L123         return "", "NORMAL", 0
L124     px, spx = _fetch_prices_600d(tickers)
L125     win = int(os.getenv("BREADTH_CALIB_WIN_DAYS", "600"))
L126     C_ts = trend_template_breadth_series(px, spx, win_days=win)
L127     if C_ts.empty:
L128         return "", "NORMAL", 0
L129     warmup = int(os.getenv("BREADTH_WARMUP_DAYS","252"))
L130     base = C_ts.iloc[warmup:] if len(C_ts)>warmup else C_ts
L131     C_full = int(C_ts.iloc[-1])
L132
L133     q05 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_IN",  "0.05"))), nan=0.0))
L134     q20 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_EMERG_OUT", "0.20"))), nan=0.0))
L135     q60 = int(np.nan_to_num(base.quantile(float(os.getenv("BREADTH_Q_WARN_OUT",  "0.60"))), nan=0.0))
L136
L137     # Gæ ã‚µã‚¤ã‚ºï¼ˆBreadthåŸºæº–ï¼‰
L138     N_G = config.N_G
L139     th_in_rec   = max(N_G, q05)
L140     th_out_rec  = max(int(np.ceil(1.5*N_G)), q20)
L141     th_norm_rec = max(3*N_G, q60)
L142
L143     use_calib = os.getenv("BREADTH_USE_CALIB", "true").strip().lower() == "true"
L144     if use_calib:
L145         th_in, th_out, th_norm, th_src = th_in_rec, th_out_rec, th_norm_rec, "è‡ªå‹•"
L146     else:
L147         th_in   = int(os.getenv("GTT_EMERG_IN", str(N_G)))
L148         th_out  = int(os.getenv("GTT_EMERG_OUT", str(int(1.5*N_G))))
L149         th_norm = int(os.getenv("GTT_CAUTION_OUT", str(3*N_G)))
L150         th_src = "æ‰‹å‹•"
L151
L152     prev = load_mode("NORMAL")
L153     if   prev == "EMERG":
L154         mode = "EMERG"   if (C_full < th_out)  else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L155     elif prev == "CAUTION":
L156         mode = "CAUTION" if (C_full < th_norm) else "NORMAL"
L157     else:
L158         mode = "EMERG"   if (C_full < th_in)   else ("CAUTION" if (C_full < th_norm) else "NORMAL")
L159     save_mode(mode)
L160
L161     mode_ja, emoji = MODE_LABELS_JA.get(mode, mode), MODE_EMOJIS.get(mode, "â„¹ï¸")
L162     eff_days = len(base)
L163
L164     lead_lines = [
L165         f"{emoji} *ç¾åœ¨ãƒ¢ãƒ¼ãƒ‰: {mode_ja}*",
L166         f"ãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: *{C_full}æœ¬*",
L167         "ã—ãã„å€¤ï¼ˆ{0}ï¼‰".format(th_src),
L168         f"  ãƒ»ç·Šæ€¥å…¥ã‚Š: <{th_in}æœ¬",
L169         f"  ãƒ»ç·Šæ€¥è§£é™¤: â‰¥{th_out}æœ¬",
L170         f"  ãƒ»é€šå¸¸å¾©å¸°: â‰¥{th_norm}æœ¬",
L171         f"å‚è€ƒæŒ‡æ¨™ï¼ˆéå»~{win}å–¶æ¥­æ—¥, æœ‰åŠ¹={eff_days}æ—¥ï¼‰",
L172         f"  ãƒ»ä¸‹ä½5%: {q05}æœ¬",
L173         f"  ãƒ»ä¸‹ä½20%: {q20}æœ¬",
L174         f"  ãƒ»60%åˆ†ä½: {q60}æœ¬",
L175     ]
L176     return "```" + "\n".join(lead_lines) + "```", mode, C_full
L177
L178
L179 TS_LOG_FILE = Path(RESULTS_DIR) / "ts_signal_log.csv"
L180
L181
L182 def _load_growth_symbols(portfolio: list[dict]) -> list[str]:
L183     growth = []
L184     for row in portfolio:
L185         bucket = str(row.get("bucket", "")).strip().upper()
L186         if bucket == "G":
L187             sym = str(row.get("symbol", "")).strip().upper()
L188             if sym:
L189                 growth.append(sym)
L190     return sorted(set(growth))
L191
L192
L193 def _upsert_ts_hits(date_str: str, hits: set[str]):
L194     df = None
L195     if TS_LOG_FILE.exists():
L196         try:
L197             df = pd.read_csv(TS_LOG_FILE)
L198         except Exception:
L199             df = None
L200     if df is None or not isinstance(df, pd.DataFrame):
L201         df = pd.DataFrame(columns=["date", "symbol"])
L202     df = df[df["date"] != date_str]
L203     if hits:
L204         add = pd.DataFrame({"date": date_str, "symbol": sorted({h.upper() for h in hits})})
L205         df = pd.concat([df, add], ignore_index=True)
L206     df = df.sort_values(["date", "symbol"])
L207     df.to_csv(TS_LOG_FILE, index=False)
L208
L209
L210 def _count_unique_hits_5d(today_utc: pd.Timestamp) -> int:
L211     if not TS_LOG_FILE.exists():
L212         return 0
L213     try:
L214         df = pd.read_csv(TS_LOG_FILE)
L215     except Exception:
L216         return 0
L217     if df.empty or "date" not in df.columns or "symbol" not in df.columns:
L218         return 0
L219     try:
L220         df["date"] = pd.to_datetime(df["date"], utc=True)
L221     except Exception:
L222         return 0
L223     today = today_utc.normalize()
L224     start = today - pd.offsets.BDay(4)
L225     mask = (df["date"] >= start) & (df["date"] <= today)
L226     if not mask.any():
L227         return 0
L228     return int(df.loc[mask, "symbol"].str.upper().nunique())
L229
L230
L231 def _combine_modes(mode_a: str, mode_b: str) -> str:
L232     a = MODE_RANK.get((mode_a or "NORMAL").upper(), 0)
L233     b = MODE_RANK.get((mode_b or "NORMAL").upper(), 0)
L234     for mode, rank in MODE_RANK.items():
L235         if rank == max(a, b):
L236             return mode
L237     return "NORMAL"
L238
L239
L240 def _format_mode(mode: str) -> str:
L241     upper = (mode or "NORMAL").upper()
L242     return f"{MODE_EMOJIS.get(upper, 'â„¹ï¸')} {MODE_LABELS_JA.get(upper, upper)}"
L243
L244
L245 def _build_status_block(ts_mode: str, k5: int, ts_hits: list[str], breadth_mode: str, breadth_score: int, combo_mode: str) -> str:
L246     hits_line = "ãªã—" if not ts_hits else ", ".join(sorted(ts_hits))
L247     lines = [
L248         f"*â‘  Growth TS:* {_format_mode(ts_mode)}ï¼ˆ5Dãƒ¦ãƒ‹ãƒ¼ã‚¯: {k5}éŠ˜æŸ„ï¼‰",
L249         f"  ãƒ»å½“æ—¥ãƒ’ãƒƒãƒˆ: {hits_line}",
L250         f"*â‘¡ Breadth:* {_format_mode(breadth_mode)}ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åˆæ ¼æœ¬æ•°: {breadth_score}æœ¬ï¼‰",
L251         f"*ç·åˆï¼ˆORæ‚ªåŒ–/ANDå›å¾©ï¼‰:* {_format_mode(combo_mode)}",
L252     ]
L253     return "\n".join(lines)
L254
L255
L256 def _ts_mode_growth_eod(g_syms: list[str], ref_mode: str) -> tuple[str, int, list[str]]:
L257     now_utc = pd.Timestamp.today(tz="UTC")
L258     if not g_syms:
L259         k = _count_unique_hits_5d(now_utc)
L260         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L261         return mode1, k, []
L262     try:
L263         df = yf.download(
L264             g_syms,
L265             period="90d",
L266             interval="1d",
L267             auto_adjust=False,
L268             progress=False,
L269             group_by="column",
L270         )
L271     except Exception:
L272         df = None
L273     if not isinstance(df, pd.DataFrame) or df.empty:
L274         k = _count_unique_hits_5d(now_utc)
L275         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L276         return mode1, k, []
L277     try:
L278         hi = df["High"] if "High" in df.columns else None
L279         lo = df["Low"] if "Low" in df.columns else None
L280     except Exception:
L281         hi = lo = None
L282     if hi is None or lo is None:
L283         k = _count_unique_hits_5d(now_utc)
L284         mode1 = "EMERG" if k >= 8 else "CAUTION" if k >= 6 else "NORMAL"
L285         return mode1, k, []
L286     if isinstance(hi, pd.Series):
L287         hi = hi.to_frame(name=g_syms[0])
L288     if isinstance(lo, pd.Series):
L289         lo = lo.to_frame(name=g_syms[0])
L290     try:
L291         roll_hi = hi.rolling(60, min_periods=20).max().tail(1).iloc[0]
L292         low_today = lo.tail(1).iloc[0]
L293     except Exception:
L294         k = _count_unique_hits_5d(now_utc)
L295         mode1 = "EMER
```